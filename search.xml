<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>青木華絵</title>
    <url>/Notes/TK/</url>
    <content><![CDATA[<div align=center>夕景の歌を探しました </div>

<br>

<div align=center>青い華が聞こえました</div>


<br>

<div align=center>行方知れず 青木華絵 </div>


<span id="more"></span> 


<br>

<div align=center></div>


<br>

<div align=center></div>


<br>

<div align=center></div>


<br>

<div align=center></div>



]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>Incident Management for Operations</title>
    <url>/2023/Incident-Management/</url>
    <content><![CDATA[<p>This post is a collection of notes from <em><strong>Incident Management for Operations</strong></em> <em>(2017).</em> </p>
<blockquote>
<p>  Being in operations is like being a goalkeeper on a soccer team.<br>  They only remember the ones that get past you, not all the wonderful saves you made along the way.</p>
</blockquote>
<span id="more"></span>

<br>

<h2 id="1-Process"><a href="#1-Process" class="headerlink" title="1 - Process"></a>1 - Process</h2><div class="note default"><ul>
<li>  <strong>IRT</strong> - Incident Response Team</li>
<li>  <strong>Triage</strong> - Sort &amp; assign priority</li>
<li>  <strong>MTTR</strong> - Mean Time To Resolution</li>
</ul>
</div>



<p><strong>IR Evaluation</strong></p>
<ul>
<li>  How many incidents occurred <strong>per month</strong> over the last <strong>two years</strong>?</li>
<li>  What <u>reports/data analysis</u> regarding incident response do you have?</li>
<li>  Are incidents managed and directed in a consistent and efficient manner?</li>
<li>  Are incident voice communications (e.g., conference bridges) recorded / archived / reviewed?</li>
</ul>
<div class="note success"><p><strong>Time</strong> is the most important during incident response: <strong>Mitigate first, ask questions later.</strong></p>
<p>Focus on fixing the issue first and restoring services.</p>
</div>



<br>



<h3 id="Assessment"><a href="#Assessment" class="headerlink" title="Assessment"></a><u>Assessment</u></h3><blockquote>
<p>  Incident response is a team sport, and leaves <u>no room for ego, attitute, or lack of trust within the team</u>.</p>
</blockquote>
<p><strong>1. Predicable</strong></p>
<ul>
<li><p>Clarity of roles &amp; responsibilities</p>
<blockquote>
<p>  If you’re identified as available oncall, it’s <strong>not</strong> optional.</p>
</blockquote>
</li>
<li><p>  Expected behavior of each person before &amp; after they are assembled for an incident</p>
</li>
</ul>
<br>

<p><strong>2. Repeatable</strong></p>
<ul>
<li>  Have <strong>runbooks</strong> &amp; mechanisms for different incident types</li>
<li>  Respond in the <strong>same</strong> way every time</li>
</ul>
<br>

<p><strong>3. Optimized</strong></p>
<ul>
<li>  <strong>Escalation</strong> policies: Conditions for escalation</li>
<li>  Do your <strong>resolvers</strong> know how to respond &amp; participate, and do they share the same sense of <strong>urgency</strong>?</li>
</ul>
<br>

<p><strong>4. Clear</strong></p>
<ul>
<li>  Anyone in the call knows exactly why they’re being <strong>paged</strong>, their <strong>role</strong> in the incident, and when will be <strong>released</strong> by IC</li>
</ul>
<br>

<p><strong>5. Evaluated</strong></p>
<ul>
<li>  Conduct <strong>AAR</strong> regularly and correctly (learning culture to improve operations)</li>
</ul>
<br>

<p><strong>6. Scalable</strong></p>
<ul>
<li>  <strong>Not</strong> dependent on a few people to respond all the time</li>
</ul>
<br>

<p><strong>7. Sustainable</strong></p>
<ul>
<li>  Being oncall should be <strong>respected</strong> in the company, intended to attract skilled talent</li>
</ul>
<br>

<br>



<h2 id="2-IMS"><a href="#2-IMS" class="headerlink" title="2 - IMS"></a>2 - IMS</h2><div class="note default"><ul>
<li>  <strong>IMS</strong> - Incident Management System</li>
<li>  <strong>SitStat</strong> - Situational Status (<strong>Scribe</strong>)</li>
</ul>
</div>

<br>

<p><strong>Attitude</strong></p>
<ul>
<li><p>Responders should be calm &amp; collected, able to <strong>think clearly under pressure</strong></p>
<blockquote>
<p>  “Fire is not an emergency to the fire department, it’s what we do.”</p>
</blockquote>
</li>
<li><p>  Identify yourself by <strong>name &amp; function</strong>, when enter the call bridge</p>
</li>
<li><p>  <strong>Dispatch</strong> is different from notify: It’s not a request, it’s <strong>an order</strong>.</p>
</li>
</ul>
<br>

<p><strong>Peacetime</strong> &amp; <strong>Wartime</strong> org chart</p>
<ul>
<li><p>In wartime: Make the <strong>best</strong> deicision in the <strong>shortest</strong> amount of time</p>
<blockquote>
<p>  Note: Make the best decision, but <u>not the quickest decision</u></p>
</blockquote>
</li>
<li><p>  Solving <strong>wartime</strong> incidents require <u>wartime mentality</u>, and supporting <u>org structure</u></p>
</li>
<li><p>Many executives bring peacetime rank to the wartime incident, potentially intimidating other responders.<br>  Executives also may feel the need to demonstrate leadership, even when they don’t have the IC leadership skills or be the most technically proficient expert.</p>
</li>
</ul>
<br>

<p><strong>IMS</strong></p>
<ul>
<li><p>  Define how resolves should arrive &amp; interact with IC</p>
</li>
<li><p>  Any company adopting IMS should <u>conduct IMS training across its workforce</u></p>
</li>
<li><p><strong>Acronyms</strong>: Without common terminology, abbreviations / jargons could slow down communications</p>
<blockquote>
<p>  Idea: Create acronym / jargon page for Incident Response only.</p>
</blockquote>
</li>
</ul>
<br>

<br>

<h2 id="3-IC"><a href="#3-IC" class="headerlink" title="3 - IC"></a>3 - IC</h2><div class="note default"><ul>
<li>  <strong>IC</strong> - Incident Commander</li>
<li>  <strong>CAN</strong> - Conditions, Actions, Needs</li>
<li>  <strong>SA</strong> - Situational Awareness</li>
</ul>
</div>



<p><strong>Attention</strong></p>
<ul>
<li><p><strong>Must</strong> arrive at a call bridge with a sense of <strong>urgency</strong></p>
<blockquote>
<p>  Define clear expectations for being <strong>oncall</strong> ( <em>“right-now”</em> )</p>
</blockquote>
</li>
<li><p>IC must be an <strong>expert</strong> in the <u>process &amp; function of incident command</u>. This is the most important thing.</p>
<blockquote>
<p>  Do <strong>not</strong> act as Tech Leader, even though you have the domain expertise</p>
<p>  Get info from resolvers to understand the issue, and formulate a plan</p>
</blockquote>
</li>
<li><p>  Identify as IC &amp; provide CAN report, when new resolvers join the bridge</p>
</li>
</ul>
<br>

<p><strong>Duties</strong></p>
<ul>
<li><p>Ensure responders / resolvers have <strong>clear</strong> understanding of the issue, and keep them <strong>focused</strong></p>
<blockquote>
<p>  Periodical <strong>CAN</strong> report</p>
</blockquote>
</li>
<li><p>Direct incident <strong>resolution</strong> effort: Build action plan, set clear resolution objectives</p>
<blockquote>
<p>  Always have <strong>backup plan</strong> 📌, also fully discuss tradeoffs.</p>
</blockquote>
</li>
<li><p>Understand the necessity of <strong>high-risk</strong> actions, and ready to <u>build from a failed action</u></p>
<blockquote>
<p>  <strong>Command presence</strong>: Actions &amp; behaviors should inspire <strong>confidence</strong>.<br>  Hesitation from the IC <u>generates doubt, fear &amp; uncertainty.</u></p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Planning</strong></p>
<ul>
<li>  Regarding the current plan, what are key <strong>indicators</strong> that the plan is working or not working?</li>
<li>  What is the <strong>trigger</strong> point to abandon the initial plan and move to the next one?</li>
<li>  How will I communicate to the resolvers to abandon the current plan and move to an alternative plan?</li>
</ul>
<br>

<p><strong>CAN report</strong> 📌</p>
<ul>
<li>  <strong>Conditions</strong> - current status, <strong>Actions</strong> - what’s been done, <strong>Needs</strong> - additional resources / actions needed</li>
<li>Distill a message down into its most basic parts, when:<ul>
<li>  New resolvers enter the conversation</li>
<li>  The IC needs to make periodic briefings / refocus the group (Re-assess the situation)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Active Listener</strong></p>
<ul>
<li><p>Listen for <u>tone, inflection, and meaning</u>, not just the actual words that are said.</p>
<blockquote>
<p>  Human <strong>emotions</strong> conveyed in the conversation: confidence, hesitation, fear, uncertainty, etc.</p>
<p>  Those subtle emotions are critical to understanding the meaning behind the words of a solution</p>
</blockquote>
</li>
<li><p><strong>How</strong> they are saying it. Are they confident or are they just randomly throwing ideas out?</p>
<blockquote>
<p>  Test the certainty &amp; conviction of resolvers. Pick up on the subtle clues.</p>
</blockquote>
</li>
<li><p>  Listen for those who are <strong>not</strong> contributing, or who are being talked over by stronger voices.</p>
</li>
</ul>
<br>

<p><strong>Examples</strong></p>
<ul>
<li><p>Crisp &amp; direct communication</p>
<blockquote>
<p>  “Network, can you go off the bridge, take a look at your <strong>monitoring</strong> tools, and get back to me in <strong>10 minutes</strong>?”</p>
</blockquote>
</li>
<li><p>Identify resolver by team / <strong>function</strong></p>
<blockquote>
<p>  “Database, please <strong>stand by</strong>.”</p>
</blockquote>
</li>
<li><p>  Make <strong>assignment</strong>: <u>objective</u>, <u>request</u>, <u>action</u>, with specific <u>time frame</u></p>
</li>
<li><p>Planning</p>
<blockquote>
<p>  “We will execute plan X. Is anyone aware of any issues with this plan?”</p>
<p>  “While we are waiting for plan X, I want to discuss what our plan Y will be.”</p>
<p>  “Storage, do you support the plan? / Storage, what’s your concern?”</p>
</blockquote>
</li>
<li><p>Set <strong>expectations</strong> &amp; <strong>urgency</strong>: Assigning a time limit to critical tasks will put the recipient under <strong>time pressure</strong>.</p>
<blockquote>
<p>  “I want to hear from everyone, and I’ll take notes on what you come up with. We have 10 minutes, starting now.”</p>
</blockquote>
</li>
</ul>
<br>



<h3 id="Star"><a href="#Star" class="headerlink" title="Star"></a><u>Star</u></h3><h4 id="1-Size-up-the-incident"><a href="#1-Size-up-the-incident" class="headerlink" title="1. Size up the incident"></a>1. Size up the incident</h4><p>Situational Awareness</p>
<ul>
<li><p>  Continuous process of human <u>focus &amp; observation</u> of data inputs</p>
</li>
<li><p>Make decisions based on <strong>verifiable</strong> inputs</p>
</li>
</ul>
<br>

<h4 id="2-Triage"><a href="#2-Triage" class="headerlink" title="2. Triage"></a>2. Triage</h4><ul>
<li><p>  Important for IC to announce currenct sev level</p>
</li>
<li><p>As the sev level increases, so does the involvement &amp; value of the IC</p>
<blockquote>
<p>  High sev incidents require <strong>strong leadership</strong></p>
</blockquote>
</li>
</ul>
<br>

<h4 id="3-Action-plan"><a href="#3-Action-plan" class="headerlink" title="3. Action plan"></a>3. Action plan</h4><ul>
<li><p>  Maintain timeline for incident resolution effort</p>
</li>
<li><p>  Backup plans (Always)</p>
</li>
<li><p>Set <strong>expectations</strong> for desired outcome</p>
<blockquote>
<p>  Determine if objections are strong enough to rethink the plan</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Confirm support</strong> from appropriate resolvers, which literally means the IC asks each one to say out loud<br>“<u>I support the plan</u>“. (Reinforce <strong>accountability</strong> of all resolvers)</p>
<ul>
<li>The IC should get all relevant SMEs to <strong>affirmatively</strong> support the plan and <u><strong>verbalize</strong> the support on the bridge</u>,<br>  or require the SME to provide a compelling reason for why it is not supported.</li>
<li>  <u>Critical phase</u>: Pay attention to the tone, inflection &amp; emotions of each resolver’s response.</li>
<li>  <u>Ask questions</u>: If the IC only asks if there is <strong>disagreement</strong> with a particular plan, typically the time it takes to complete polling the resolvers is far less. </li>
</ul>
<br>

<p><strong>Attention</strong></p>
<ul>
<li>  Information is <strong>not</strong> the same as opinion</li>
<li>  Ask one question. Get one answer</li>
<li>  <strong>Summarize</strong> often (CAN report): Consistent understanding among all participants</li>
</ul>
<br>

<h4 id="4-Review"><a href="#4-Review" class="headerlink" title="4. Review"></a>4. Review</h4><ul>
<li><p>Operational peroid: frequency for specific actions to be taken</p>
<blockquote>
<p>  e.g. CAN report / Comms email every 30 min</p>
</blockquote>
</li>
<li><p><strong>End state</strong> of incident: Return to pre-event conditions, or some adaptive state</p>
<blockquote>
<p>  Document &amp; understand all <u>temporary fixes and pulled levers</u></p>
</blockquote>
</li>
</ul>
<br>



<h3 id="Time"><a href="#Time" class="headerlink" title="Time"></a><u>Time</u></h3><div class="note primary"><p>What’s a <strong>minute</strong> worth to your company?</p>
<ul>
<li>  Correlate <u>technical issues</u> with <u>business impact</u> (e.g. lost orders)</li>
</ul>
</div>



<h4 id="1-Tone"><a href="#1-Tone" class="headerlink" title="1. Tone"></a>1. Tone</h4><ul>
<li>  IC should be conscious of the need to <u>create and maintain a positive and directed work environment</u></li>
<li>Clarity, alignment, attitude:<br>  Getting the <strong>right</strong> people to the <strong>right</strong> place at the <strong>right</strong> time to make the <strong>right</strong> decision.</li>
</ul>
<br>

<h4 id="2-Interaction"><a href="#2-Interaction" class="headerlink" title="2. Interaction"></a>2. Interaction</h4><ul>
<li><p>  <u>Respectfully, truthfully, ego-free</u>, and with the goal of resolving the incident as a <strong>team</strong> in the shortest time</p>
</li>
<li><p>Unproductive behaviors: </p>
<ul>
<li>  Make these observations as part of AAR, in a <u>positive &amp; constructive</u> way</li>
<li>  Offline conversation with resolvers or their managers</li>
</ul>
</li>
<li><p>  Resolvers personality type analysis:  <em><a href="#Appendix">Appendix</a></em></p>
</li>
</ul>
<br>

<h4 id="3-Management"><a href="#3-Management" class="headerlink" title="3. Management"></a>3. Management</h4><p>Balance: Resolvers’ <strong>personalities</strong> &amp; <strong>Situational</strong> issues (good personalities can also lead to bad situations)</p>
<p>Example situations:</p>
<ul>
<li>  Long unproductive conversations</li>
<li>  Background noise</li>
<li>  Language &amp; culture challenges</li>
<li>  Pressure from executives</li>
</ul>
<br>

<h4 id="4-Engagement"><a href="#4-Engagement" class="headerlink" title="4. Engagement"></a>4. Engagement</h4><div class="note success"><p><strong>False Alarms</strong></p>
<p>To be clear, it’s annoying at times, but it’s the job that comes with accepting the <strong>duties</strong> of incident response.</p>
<p>An alarm is a false alarm, <u>only after the issue was detected &amp; investigated by the IR team</u>.</p>
</div>

<ul>
<li><p>  <strong>Dispatch</strong>: <strong>agreement</strong> between the resolvers and the dispatch function that <strong>guarantees</strong> an incident response</p>
</li>
<li><p>  If the IC no longer needs the resolver: <strong>release</strong> it</p>
</li>
<li><p>Common errors:</p>
<ul>
<li>  Ineffective dispatch procedures</li>
<li>  Ambiguity about available resources</li>
<li>  Poor notification technology</li>
</ul>
</li>
</ul>
<br>

<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><u>Summary</u></h3><ul>
<li><p>  IC’s job: bring <strong>order</strong> &amp; <strong>direction</strong> to the chaotic nature of an incident</p>
</li>
<li><p><strong>Star &amp; Time</strong>: Important elements of incident response</p>
<blockquote>
<p>  Be mindful about <u>human interactions</u></p>
</blockquote>
</li>
</ul>
<br>

<br>

<h2 id="4-UC-amp-Scaling-Up"><a href="#4-UC-amp-Scaling-Up" class="headerlink" title="4 - UC &amp; Scaling Up"></a>4 - UC &amp; Scaling Up</h2><div class="note default"><ul>
<li>  <strong>GL</strong> - Group Leader</li>
<li>  <strong>UC</strong> - Unified Command</li>
<li>  <strong>OCE</strong> - On Call Executives</li>
<li>  <strong>IAP</strong> - Incident Action Plan</li>
</ul>
</div>



<p><strong>Span</strong> of control </p>
<ul>
<li><p>  5 - 7 resolvers per person</p>
</li>
<li><p>  Recognize your <strong>limits</strong>, and the limits of others</p>
</li>
<li><p><strong>Group Leader</strong>: group resolvers by functions, set rules &amp; timing for resolvers engagement</p>
</li>
</ul>
<br>

<p><strong>Transfer</strong> of Command</p>
<ul>
<li>  IC might be <strong>struggling</strong>, and a more qualified person is available</li>
<li>  <strong>Handover</strong>: provide CAN report to the incoming IC (<strong>off</strong> the call bridge)</li>
</ul>
<br>



<p><strong>Training</strong></p>
<ul>
<li>  Build skills &amp; proficiency: regularly use IMS for less severe incidents (green &amp; yellow box issues)</li>
<li>  All side communications should be documented in the timeline</li>
<li>  <strong>All</strong> resolvers tasked with response should be <strong>fully trained</strong> prior to taking on the responsibilities</li>
</ul>
<br>

<p><strong>UC &amp; OCE</strong></p>
<ul>
<li><p>  <strong>UC</strong> makes <u>business impact decisions</u> (<strong>strategy</strong>), <strong>IC</strong> drivers incident <strong>resolution</strong></p>
</li>
<li><p>UC: Business impact transcends solving the technical problem</p>
<blockquote>
<p>  When each resolution has different business impact: (<u>competing interests at stake</u>)<br>  Executive engagement is required to make the <strong>best</strong> business decision</p>
</blockquote>
</li>
<li><p>Liason Officer</p>
<ul>
<li>  Move between communication channels (UC should be on a separate call bridge from resolvers)</li>
<li>  Provide updates &amp; briefings on behalf of IC </li>
<li>  Gather info from those channels to bring back to IC</li>
</ul>
</li>
</ul>
<br>

<p><strong>UC Leader</strong></p>
<ul>
<li>  Establish UC call bridge</li>
<li>  Determine the need for OCE involvement</li>
<li>  Maintain communications between IC &amp; OCE</li>
<li>  Set briefing cadence (e.g. CAN report every 30 min)</li>
</ul>
<br>

<br>

<h2 id="5-AAR"><a href="#5-AAR" class="headerlink" title="5 - AAR"></a>5 - AAR</h2><div class="note default"><ul>
<li><p>  <strong>AAR</strong> - After Action Review</p>
</li>
<li><p>  <strong>RCA</strong> - Root Cause Analysis</p>
</li>
</ul>
</div>



<p><strong>Culture</strong></p>
<ul>
<li><p>  <u>Positive &amp; blameless</u> post-incident evaluation, with <u>honest &amp; in-depth</u> review of IR actions</p>
</li>
<li><p>Technology failure is the <u>perfect chance</u> to learn about operating environment and <u>make improvements</u></p>
<blockquote>
<p>  Foster <strong>trust</strong> and respect among team members, <strong>allow</strong> mistakes to be made and <strong>learning</strong> to take place </p>
</blockquote>
</li>
<li><p>  Look at the <u>contributing factors</u> that may have prevented the resolvers from arriving at a quicker resolution.</p>
</li>
<li><p>Debriefing: <strong>Description</strong> 📌</p>
<blockquote>
<p>  Complex events require exploration with an open mind. </p>
<p>  As facilitators of debriefings, if we start questions with <strong>why</strong>, we typically get an <strong>explanation</strong>.<br>  When we start questions with <strong>how</strong>, <strong>what</strong>, <strong>when</strong>, then we get much more data during a debrief. </p>
</blockquote>
</li>
</ul>
<br>

<div class="note info"><p><strong>AAR</strong> </p>
<ul>
<li>  <strong>Technology</strong> - What broke (RCA)</li>
<li>  <strong>People</strong> - <strong>How did people respond</strong> to what broke?  📌</li>
</ul>
</div>

<ul>
<li><p>Successful AAR requires prepartion</p>
<ul>
<li>  An <strong>accurate</strong> incident <strong>timeline</strong> is the basis of AAR</li>
<li>  Collect resolver rosters &amp; orgs, notes on discussion of possible resolutions</li>
</ul>
</li>
<li><p>AAR is a collection of <strong>lessons</strong> learned from each incident</p>
<ul>
<li>  Help to see a blind spot in the service architecture</li>
<li>  Perhaps some mistakes were made in detection, which leads to improvement in monitoring</li>
<li>  Perhaps a junior IC was covering the shift for a senior, and gained valuable experience from the incident</li>
<li><strong>Change Management</strong><br>  For each release / change, there should be an <strong>IAP</strong>, ready to <strong>transition CM to incidents</strong> if things go wrong</li>
</ul>
</li>
</ul>
<br>

<p><strong>Evaluation</strong></p>
<ul>
<li>  Problem</li>
<li>  Detection / Monitoring</li>
<li>  Dispatch</li>
<li>  Incident response</li>
<li>  Resolution</li>
</ul>
<br>

<table>
<thead>
<tr>
<th>Description</th>
<th>Question</th>
</tr>
</thead>
<tbody><tr>
<td>1. Problem description</td>
<td><em>What happened?</em></td>
</tr>
<tr>
<td>2. Cause of the incident</td>
<td><em>What caused/contributed to the problem? <br />(capture <u>what caused a change from uptime to downtime</u>)</em></td>
</tr>
<tr>
<td>3. Timestamp, initial responders &amp; resolvers</td>
<td><em>Were the <u>right</u> people assembled in the <u>right</u> spot,<br />to make the <u>right</u> decisions at the <u>right</u> time?</em></td>
</tr>
<tr>
<td>4. Solution</td>
<td><em>Did the incident responders choose the right solution?</em><br /><em><u>Why</u> a decision was made, at the <u>time</u> it’s made, with the <u>available info</u></em></td>
</tr>
<tr>
<td>5. Localizations &amp; MTTR</td>
<td><em>How long did it take to assemble and solve the problem?</em></td>
</tr>
</tbody></table>
<br>

<p><strong>Human Factors</strong></p>
<ul>
<li><p>  Use of IMS framework</p>
</li>
<li><p>Focused leadership of IC</p>
<ul>
<li>  How did the IR team perform?</li>
</ul>
</li>
<li><p>Process &amp; results of collective problem-solving effort</p>
<ul>
<li>What’s the business impact?</li>
<li>What’s the behaviour of those people participating on the call bridge?  e.g. Duplication of effort, and no accountability</li>
</ul>
</li>
</ul>
<br>

<h3 id="Talent"><a href="#Talent" class="headerlink" title="Talent"></a><u>Talent</u></h3><blockquote>
<p>  Evaluating soft skills<br>  e.g. Not just the Scribe, but also track involvement of IC, TL &amp; resolvers</p>
</blockquote>
<p><strong>1. Training</strong></p>
<ul>
<li>  Provide company wide training for all resolvers &amp; all teams</li>
</ul>
<p><strong>2. Accountability</strong></p>
<ul>
<li>  Respond with urgency, be accountable for resolution plans</li>
</ul>
<p><strong>3. Leadership</strong></p>
<ul>
<li><p>High sev incidents / UC is activated:</p>
<p>  Evaluate if the executives of the company performed well according to their function during the incident</p>
</li>
</ul>
<p><strong>4 . Empowerment</strong></p>
<ul>
<li>  Joined resolvers should be the right people with the right skills, knowledge, and <strong>authority</strong></li>
</ul>
<p><strong>5. Notification</strong></p>
<ul>
<li>  Incidents should be <u>treated as <strong>something</strong> until proven that they are nothing</u></li>
</ul>
<p><strong>6. Trust</strong></p>
<br>

<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a><u>Summary</u></h3><ul>
<li><p>  To conduct an effective AAR, first need a team <strong>knowledgeable</strong> enough to have opinions on the evaluted aspects</p>
</li>
<li><p>  Always include the person skilled in IMS framework (i.e. the <strong>IC</strong>)</p>
</li>
<li><p>Key elements of AAR:</p>
<ul>
<li><p>  Incident timeline, revelant communications &amp; participation</p>
</li>
<li><p>  Foster an open, honest, and blameless culture</p>
</li>
<li><p>Identify &amp; implement improvements to the <strong>people</strong> part of the response as well as the technical problems</p>
<blockquote>
<p>  Ensure changes are <u>followed up on</u> and actually get implemented</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<br>

<br>

<hr>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><blockquote>
<p>  Common resolver personality types and IC tactics</p>
</blockquote>
<br>

<h3 id="The-Awesome-Contributor"><a href="#The-Awesome-Contributor" class="headerlink" title="The Awesome Contributor"></a><u>The Awesome Contributor</u></h3><p>The <strong>perfect</strong> resolver.</p>
<ul>
<li><p>  Arrive with sense of urgency, announce by name &amp; function</p>
</li>
<li><p>  Operationally ready to contribute (e.g. access to monitoring tools)</p>
</li>
<li><p>  Clear &amp; direct, support decisions with facts</p>
</li>
<li><p>Respect IC’s timeline and instructions</p>
</li>
</ul>
<br>

<h3 id="The-Quiet-One"><a href="#The-Quiet-One" class="headerlink" title="The Quiet One"></a><u><strong>The Quiet One</strong></u></h3><ul>
<li>  Uncomfortable speaking up in a group</li>
<li>  May be reserved in speech and actions, but can provide invaluable insights and info</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Don’t deem them as uninterested / unqualified based on the amount of interaction</li>
<li>  Ask <u>direct questions</u> by name / function to create entry point for engagement</li>
</ul>
<br>

<h3 id="The-Naysayer"><a href="#The-Naysayer" class="headerlink" title="The Naysayer"></a><u><strong>The Naysayer</strong></u></h3><ul>
<li>  Often cites past history as justification why a current idea or plan won’t work</li>
<li>  Finds <u>many reasons why something won’t work</u> but few reasons why it will</li>
<li>  Often “what ifs” all plans or ideas to the extreme</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  The Naysayer isn’t always wrong. Beware of discounting the issues they raise, just because they may be difficult to deal with</li>
<li>  Require specific details / <u>data points</u> when Naysayers throw up obstacles or dissension</li>
</ul>
<br>

<h3 id="The-Overbearing-One"><a href="#The-Overbearing-One" class="headerlink" title="The Overbearing One"></a><u><strong>The Overbearing One</strong></u></h3><ul>
<li>  Frequently identified in the peacetime organization as a “<u>know-it-all</u>”</li>
<li>  May not easily accept being wrong or that others are making contributions that appear to be more useful</li>
<li>  Puts people on the <u>defensive</u></li>
<li>  May be <u>impulsive</u>. Quick to pass judgment and make snap decisions</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Stay <u>calm</u>. Don’t engage verbally</li>
<li>  Beware of very opinionated suggestions that may be more colorful and grandiose than helpful</li>
<li>  Avoid pointing out <u>directly</u> that the person is wrong</li>
<li>May be useful to assign tasks to an Overbearing One that take them <u>off the main communications channel</u>.<br>  Make the assignment technically challenging but not busy work, and indicate its importance</li>
</ul>
<br>

<h3 id="The-Over-Explainer"><a href="#The-Over-Explainer" class="headerlink" title="The Over Explainer"></a><u><strong>The Over Explainer</strong></u></h3><ul>
<li>  Intelligent, competent, confident, and talented</li>
<li>  Generally doesn’t provide yes or no answers</li>
<li>  Provides lengthy <u>explanations</u> when asked for solutions</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li><p>  <u>Interrupt if necessary</u> once obtain required info</p>
</li>
<li><p>  Beware when two Over Explainers are engaged: A journey of unnecessary details</p>
</li>
<li><p>Give a <u>timeline</u> prior to asking a question.</p>
<blockquote>
<p>  “Can you explain xx to me in a minute or less?” </p>
</blockquote>
</li>
</ul>
<br>

<h3 id="The-Joker"><a href="#The-Joker" class="headerlink" title="The Joker"></a><u><strong>The Joker</strong></u></h3><ul>
<li>  Most have high self-esteem and are usually good resolvers</li>
<li>  Constantly injecting <u>humor or irrelevant comments</u> into the conversation</li>
<li>  Doesn’t take the urgency seriously</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Be direct in reminding the Joker to <u>stay focused</u></li>
<li>  Even though the behavior is not toxic, yet do not encourage it</li>
</ul>
<br>

<h3 id="The-Uncertain-Contributor"><a href="#The-Uncertain-Contributor" class="headerlink" title="The Uncertain Contributor"></a><u><strong>The Uncertain Contributor</strong></u></h3><ul>
<li><p>  Frequently needs more time to “check one more thing” before taking action</p>
</li>
<li><p>The higher the stakes, the higher the level of uncertainty</p>
<blockquote>
<p>  Words: “well,” “maybe,” “perhaps,” “it could be,” or “it might.”</p>
</blockquote>
</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li><p>  Demand <u>specificity and accuracy</u></p>
</li>
<li><p>  Phrase questions that only require <u>yes or no</u> answers</p>
</li>
<li><p>Rephrase certain questions into a range or certainty</p>
<blockquote>
<p>On a <u>scale of 1 to 5</u>, with 5 being the most certain, what’s the number you’d assign to your suggestion?</p>
</blockquote>
</li>
<li><p>  Get another SME from the same domain to <u>replace or assist</u></p>
</li>
</ul>
<br>

<h3 id="The-Gunslinger"><a href="#The-Gunslinger" class="headerlink" title="The Gunslinger"></a><u><strong>The Gunslinger</strong></u></h3><ul>
<li>  Talented, knowledgeable, and extremely valuable to the organization. <u>And the Gunslinger <em>knows it</em></u></li>
<li>  Often gets called specifically, because they have built a reputation as key problem-solver and go-to person</li>
<li>  Drop names, jargon, and <u>obscure</u> facts to solidify their position</li>
<li>  Gunslingers may be <u>more intimidating than helpful</u></li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li><p>  Prevent the Gunslinger from <u>informally assuming the role of IC</u></p>
</li>
<li><p>  Don’t engage technically one on one with the Gunslinger</p>
</li>
<li><p>Don’t confuse the <u>confidence</u> of the Gunslinger with the <u>ability to get to the right answer</u></p>
</li>
</ul>
<br>

<h3 id="The-Interrupter"><a href="#The-Interrupter" class="headerlink" title="The Interrupter"></a><u><strong>The Interrupter</strong></u></h3><ul>
<li>  Routinely <u>cuts off</u> others during conversation</li>
<li>  Continuously seeks attention. Only want to talk instead of carrying on a two-way conversation</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Ask Interrupters to <u>wait for their turn</u></li>
<li>  Need to be <u>firm and assertive</u> with the Interrupter, otherwise IC will get rolled over</li>
</ul>
<br>

<h3 id="The-Grenade-Thrower"><a href="#The-Grenade-Thrower" class="headerlink" title="The Grenade Thrower"></a><u><strong>The Grenade Thrower</strong></u></h3><ul>
<li>  May derail a plan or line of thinking <u>after decisions have been made</u></li>
<li>  Creates fear, uncertainty, and doubt</li>
<li>  Plan with <u>“what ifs”</u> to the point that nothing looks like a good idea</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li><p>  Refocus the discussion with a CAN report and stick to the <u>verifiable facts</u></p>
</li>
<li><p>Distinguish between <u>possible</u> and <u>likely</u>. An event may be <u>possible but unlikely.</u></p>
<blockquote>
<p>  On a scale of 0 to 100%, what’s the probability that an asteroid will crash the earth today and cause massive damage?</p>
</blockquote>
</li>
</ul>
<br>



<h3 id="The-Chicken-Little"><a href="#The-Chicken-Little" class="headerlink" title="The Chicken Little"></a><u>The Chicken Little</u></h3><ul>
<li>  Views every incident as a catastrophe</li>
<li>  Thinks <u>conservatively</u> when it comes to taking action</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Focus on <u>facts and known conditions</u></li>
</ul>
<br>

<h3 id="The-Jumper-to-Conclusions"><a href="#The-Jumper-to-Conclusions" class="headerlink" title="The Jumper (to Conclusions)"></a><u><strong>The Jumper (to Conclusions)</strong></u></h3><ul>
<li>  <u>Quick to arrive at a conclusion without fully investigating</u> a situation, idea, thought, etc</li>
<li>  Likes others to think of them as <u>smart</u></li>
<li>  Use intuition, pattern recognition, past experience</li>
<li>  Believe sev of incident warrants <u>quick decisions</u></li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Keep the Jumper focused on <u>fact-based decision-making</u></li>
<li>  Remember: Make the <strong>best</strong> decision in the <strong>shortest</strong> amount of time, <u>not to just make quick decisions</u></li>
</ul>
<br>

<h3 id="The-Tunnel-Rat"><a href="#The-Tunnel-Rat" class="headerlink" title="The Tunnel Rat"></a><u>The Tunnel Rat</u></h3><ul>
<li>  Focus on a single priority</li>
<li>  Use strong language of conviction. e.g. “absolutely,” “we must,” “can’t you see it?”</li>
<li>  Ignore or downplay information that does not support their position</li>
</ul>
<p><strong>IC Tactics</strong></p>
<ul>
<li>  Be <strong>factual</strong> in briefing</li>
<li>  Prevent the Tunnel Rat from forming opinions that <u>cannot be verified</u></li>
</ul>
<br>

<br>

<br>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Operations</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 110 Linux Security</title>
    <url>/2022/LPIC-110/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-110/#">Local Security</a></li>
<li>  <a href="/2022/LPIC-110/#">Network Security</a></li>
<li>  <a href="/2022/LPIC-110/#">SSH &amp; GPG</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="Local-Security"><a href="#Local-Security" class="headerlink" title="Local Security"></a><p align="center">Local Security</p></h2><p><strong>Methods</strong></p>
<ul>
<li>  Password security</li>
<li>  Limit <code>root</code> access</li>
<li>  Set user limits - <code>ulimit</code></li>
<li>  Track SUID / SGID files</li>
<li>Use <strong>secure</strong> remote login protocols (<strong>Disable Telnet / FTP</strong>)  📌 <ul>
<li>  Also disable protocols using <strong>cleartext</strong> passwords</li>
</ul>
</li>
</ul>
<br>

<p><strong>Password Management</strong></p>
<ul>
<li>  <strong>John the Ripper</strong> - spot poor passwords</li>
<li>  <code>/etc/shadow</code> </li>
<li>  <code>/etc/passwd</code> - world readable</li>
</ul>
<br>

<h3 id="1-Limit-root-Access"><a href="#1-Limit-root-Access" class="headerlink" title="1 - Limit root Access"></a><p align="center">1 - Limit <code>root</code> Access</p></h3><p><strong>Switch User</strong></p>
<ul>
<li>  <code>su</code> - change user identity</li>
<li></li>
</ul>
<br>



<h2 id="Network-Security"><a href="#Network-Security" class="headerlink" title="Network Security"></a><p align="center">Network Security</p></h2><p>Restrict access to servers</p>
<ul>
<li>  Check <u>existing network connections &amp; Open ports</u></li>
<li>  <strong>Super server</strong> restriction - Limit access</li>
<li>  <strong>Disable</strong> unused servers</li>
</ul>
<br>

<h3 id="1-Super-Server"><a href="#1-Super-Server" class="headerlink" title="1 - Super Server"></a><p align="center">1 - Super Server</p></h3><blockquote>
<ul>
<li>  <code>inetd</code> - <strong>TCP Wrappers</strong></li>
<li>  <code>xinetd</code> - Built-in</li>
</ul>
</blockquote>
<br>

<p><strong>How it works</strong></p>
<ul>
<li>  Listen for network connections on behalf of another program</li>
<li>  After connection initiated, hands off control to the intended server</li>
</ul>
<br>

<p><strong>Benefits</strong></p>
<ul>
<li>  Reduce memory load</li>
<li>  <strong>Security</strong> - Use security check in super server </li>
</ul>
<div class="note danger"><p>Apply <strong>redundant access control</strong> whenever possible, to protect against bugs / misconfiguration.</p>
</div>

<br>

<h4 id="inetd"><a href="#inetd" class="headerlink" title="inetd"></a><u>inetd</u></h4><p><strong>Config file</strong></p>
<ul>
<li>  <code>/etc/inetd.conf</code></li>
<li>  <code>/etc/inetd.d/</code></li>
</ul>
<br>

<p><strong>Options</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ftp stream tcp nowait root /usr/sbin/tcpd /usr/sbin/in.ftpd -l</span><br></pre></td></tr></table></figure>

<ul>
<li>  Service name</li>
<li><strong>Socket type</strong><ul>
<li>  <code>stream</code> - Reliable 2-way connection</li>
<li>  <code>dgram</code> - Less reliable connection, with less overhead</li>
<li>  <code>raw</code> - Low-level connection to the network</li>
</ul>
</li>
<li>  Protocol - TCP / UDP</li>
<li><code>wait</code> / <code>nowait</code><ul>
<li>  <code>nowait</code> - server connects to client &amp; fress the socket (For <strong>all</strong> socket types)</li>
<li>  <code>wait</code> - server process all packets &amp; timeout (For <code>dgram</code> socket types)</li>
</ul>
</li>
<li>  User - always run with a <strong>low-privileged</strong> user</li>
</ul>
<br>

<div class="note success"><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reload config file</span></span><br><span class="line"><span class="built_in">kill</span> -HUP [server pid]</span><br><span class="line">killall -HUP [server name]</span><br></pre></td></tr></table></figure>

<p>The SysV script use above technique to implement <code>reload</code> option.</p>
</div>

<br>

<p><strong>TCP Wrappers</strong></p>
<ul>
<li><p><code>inetd</code> calls <code>tcpd</code></p>
<ul>
<li>  Checks whether client is authorized to access the server</li>
<li>  If the client is authorized,<code>tcpd</code> calls the server program</li>
</ul>
</li>
<li><p>Two config files</p>
<ul>
<li>  <code>/etc/hosts.allow</code>  (takes precedence, if listed in <strong>both</strong>)</li>
<li>  <code>/etc/hosts.deny</code></li>
</ul>
</li>
<li><p>Format</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># in hosts.deny</span></span><br><span class="line"><span class="comment"># blocks all in 192.168.7.0/24 subnet, except for 192.168.7.10</span></span><br><span class="line">192.168.7. EXCEPT 192.168.7.10</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<h4 id="xinetd"><a href="#xinetd" class="headerlink" title="xinetd"></a><u>xinetd</u></h4><p><strong>Notes</strong></p>
<ul>
<li>  Extended super server - <code>inetd</code> + <strong>security</strong> options</li>
<li>  Config file - <code>/etc/xinetd.conf</code></li>
</ul>
<br>

<p>Access control via <code>xinetd</code></p>
<ul>
<li>  Network interfaces - <code>bind</code> (Listen only <strong>one</strong> interface)</li>
<li>  Allowed &amp; Disallowed IPs</li>
<li>  Access times - set times during which users may access the server</li>
</ul>
<br>

<p><strong>Firewall</strong></p>
<ul>
<li><strong>Packet</strong> filters - access control based on low-level info about <strong>data packets</strong><ul>
<li>  e.g. source / destination IP and ports</li>
<li>  Linux kernel includes packet-filter firewall - <code>iptables</code>  📌 </li>
</ul>
</li>
<li><strong>Proxy</strong> filters - partially process transaction, access control based on <strong>high-level features</strong><ul>
<li>  e.g. web page retrieval, file / image name in a web page</li>
</ul>
</li>
</ul>
<br>

<h3 id="2-Scanning-Servers"><a href="#2-Scanning-Servers" class="headerlink" title="2 - Scanning Servers"></a><p align="center">2 - Scanning Servers</p></h3><blockquote>
<ul>
<li>  <code>netstat</code></li>
<li>  <code>lsof</code> - list open files</li>
<li>  <code>nmap</code></li>
</ul>
</blockquote>
<br>

<p><code>netstat</code></p>
<ul>
<li>  <strong>Listening</strong> - Omit client connections / server instances that are already connected to clients</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check active ports</span></span><br><span class="line">netstat -pa</span><br><span class="line"></span><br><span class="line"><span class="comment"># check servers listening for connections</span></span><br><span class="line">netstat -pl</span><br></pre></td></tr></table></figure>



<br>

<p><code>lsof</code></p>
<ul>
<li>  File includes <strong>network connections</strong></li>
<li>  Also used for identifying who’s accessing files (before <strong>unmount a NFS</strong>, make sure it’s not busy)  📌   </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># system-wide, basic use</span></span><br><span class="line">sudo lsof -i</span><br><span class="line"> </span><br><span class="line"><span class="comment"># search for connection with SSH port</span></span><br><span class="line">lsof -i :ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># find active servers</span></span><br><span class="line">lsof -i | grep LISTEN</span><br></pre></td></tr></table></figure>

<br>

<p><code>nmap</code></p>
<ul>
<li>  Scan for open ports</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check open TCP ports</span></span><br><span class="line">nmap -sT xx.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># check open UDP ports, need root</span></span><br><span class="line">sudo nmap -sU xx.com</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Check Server Config Files</strong></p>
<ul>
<li>Startup script config<ul>
<li>  SysV - <code>/etc/inittab</code></li>
<li>  <code>systemd</code></li>
</ul>
</li>
<li>Super server config<ul>
<li>  <code>inetd</code></li>
<li>  <code>xinetd</code></li>
</ul>
</li>
</ul>
<br>

<br>

<h2 id="xx"><a href="#xx" class="headerlink" title="xx"></a><p align="center">xx</p></h2><h3 id="1-xx"><a href="#1-xx" class="headerlink" title="1 - xx"></a><p align="center">1 - xx</p></h3><br>

<h3 id="2-xx"><a href="#2-xx" class="headerlink" title="2 - xx"></a><p align="center">2 - xx</p></h3><br>

<br>



<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 109 Scripting</title>
    <url>/2022/LPIC-109/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-109/#Shell-Environment">Manage Shell Environment</a></li>
<li>  <a href="/2022/LPIC-109/#Shell-Scripting">Shell Scripting</a></li>
<li>  <a href="/2022/LPIC-109/#3-SQL-Queries">SQL Queries</a></li>
</ul>
</div>

<blockquote>
<p>  More reference - <a href="/tags/Scripting/">Scripting (Tag)</a></p>
</blockquote>
<span id="more"></span> 

<br>



<h2 id="Shell-Environment"><a href="#Shell-Environment" class="headerlink" title="Shell Environment"></a><p align="center">Shell Environment</p></h2><h3 id="1-Shell-Config"><a href="#1-Shell-Config" class="headerlink" title="1 - Shell Config"></a><p align="center">1 - Shell Config</p></h3><p><strong>Global</strong> &amp; <strong>Local</strong> vars</p>
<ul>
<li><strong>Global</strong> - Available from current shell &amp; any child processes spawned from the shell<ul>
<li>  <code>printenv</code> - Show <strong>all global</strong> env vars  📌 </li>
<li>  <code>export</code> - make var available to all programs launched from the shell</li>
</ul>
</li>
<li><strong>Local</strong> - Only available in the <u>shell that creates it</u><ul>
<li>  <code>set</code> - Show <strong>all</strong> env vars for a <strong>specific</strong> process</li>
<li>  <code>env</code> - set var for just one program</li>
<li>  Recommend using <strong>lowercase</strong> letters (distinguish from system env vars) </li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># var is available to all</span></span><br><span class="line"><span class="built_in">export</span> FCEDIT=/usr/bin/vim</span><br><span class="line"></span><br><span class="line"><span class="comment"># var is available for one program</span></span><br><span class="line">env FCEDIT=/usr/bin/vim mail</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Common env vars</strong></p>
<blockquote>
<p>  Note: For <strong>multiple X sessions</strong>, <code>DISPLAY</code> always starts with <code>0:0</code> for the <strong>first session</strong>, then <code>1:0</code></p>
</blockquote>
<table>
<thead>
<tr>
<th>Variable</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>SHELL</code></td>
<td>Path to current shell</td>
</tr>
<tr>
<td><code>HOSTNAME</code></td>
<td>Current hostname</td>
</tr>
<tr>
<td><code>PS1</code></td>
<td>Default bash prompt</td>
</tr>
<tr>
<td><code>TERM</code></td>
<td>Current terminal type (e.g. <code>xterm</code>)</td>
</tr>
<tr>
<td><code>DISPLAY</code></td>
<td>Identify X display. Usually <code>0:0</code></td>
</tr>
</tbody></table>
<br>

<p>3 Ways to start Bash shell</p>
<ul>
<li>  At login time - As default <strong>login shell</strong></li>
<li>  <strong>Interactive</strong> shell (launched via Terminal GUI)</li>
<li>  <strong>Non-interactive</strong> shell - To run a script</li>
</ul>
<br>

<p><strong>Shell config files</strong></p>
<ul>
<li><strong>Global</strong><ul>
<li>  Login - <code>/etc/profile</code>  (main default startup file)</li>
<li>  Interactive - <code>/etc/bashrc</code></li>
</ul>
</li>
<li><strong>User</strong><ul>
<li>  Login - <code>~/.bash_profile</code></li>
<li>  Interactive - <code>~/.bashrc</code></li>
</ul>
</li>
<li><code>~/.inputrc</code> - Customize keyboard config<ul>
<li>  <u>X uses its own keyboard config</u>. So this doesn’t affect programs running in X</li>
</ul>
</li>
</ul>
<br>

<br>

<h2 id="Shell-Scripting"><a href="#Shell-Scripting" class="headerlink" title="Shell Scripting"></a><p align="center">Shell Scripting</p></h2><h3 id="1-General"><a href="#1-General" class="headerlink" title="1 - General"></a><p align="center">1 - General</p></h3><p><strong>Notes</strong></p>
<ul>
<li><p>  <strong>Piping</strong> - Redirect output to another command</p>
</li>
<li><p>  Run script directly from command prompt - New <strong>subshell</strong></p>
</li>
<li><p>Make <strong>local</strong> shell env vars availbale in the script  📌 </p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">exec</span> ./xx.sh</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>Shebang / hashbang</strong></p>
<ul>
<li>  <code>#!</code> - Tells Linux it’s a script</li>
<li>  <code>/bin/bash</code> - Path to interpreter to run the shellscript (e.g. Bash)</li>
</ul>
<br>

<p><strong>Source</strong> a script</p>
<ul>
<li>  Run in the <strong>current</strong> shell. Script has access to env vars defined in the calling shell. 📌 </li>
<li>  <code>source ~/.bashrc</code></li>
<li>  <code>. ~/.bashrc</code></li>
</ul>
<br>

<p><strong>Shell Variables</strong></p>
<ul>
<li><p>  <code>$0</code> - Script name</p>
</li>
<li><p>  <code>$$</code> - PID of current shell</p>
</li>
<li><p><code>$?</code> - Exit status of last command (e.g. <code>0</code>)</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change exit status (from 0 to 120)</span></span><br><span class="line"><span class="built_in">exit</span> 120</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<p><strong>Command-line Arguments</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example - test.sh</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$1</span> checked <span class="keyword">in</span> <span class="variable">$2</span> days ago</span><br><span class="line"></span><br><span class="line"><span class="comment"># run the script</span></span><br><span class="line">./test.sh Merikanto 10</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Command Substitution</strong></p>
<ul>
<li>  Assign the command’s <strong>output</strong> to a user var in the script</li>
<li>  Can also capture <strong>function output</strong> using <code>$()</code>  📌 </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use ``</span></span><br><span class="line">v1=`date`</span><br><span class="line"></span><br><span class="line"><span class="comment"># or $()</span></span><br><span class="line">v2=$(who)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$v1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$v2</span></span><br></pre></td></tr></table></figure>



<br>

<p><strong>File Descriptor</strong></p>
<ul>
<li>  Non-negative number</li>
<li>  <code>0</code> - <code>STDIN</code> (keyboard)</li>
<li>  <code>1</code> - <code>STDOUT</code> </li>
<li>  <code>2</code> - <code>STDERR</code></li>
</ul>
<br>

<p><strong>Read input</strong></p>
<blockquote>
<p>  <strong>Silent</strong> reading - <u>Text is displayed</u>, but sets text color <u>same as terminal background color</u>  📌 </p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># read &amp; use input</span></span><br><span class="line"><span class="built_in">read</span> name</span><br><span class="line">useradd -aG <span class="variable">$name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># specify a prompt</span></span><br><span class="line"><span class="built_in">read</span> -p <span class="string">&quot;Your name:&quot;</span> first last</span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">&quot;Hello <span class="variable">$last</span>, <span class="variable">$first</span>&quot;</span>	<span class="comment"># -n: suppress newline char</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># read password / silent reading</span></span><br><span class="line"><span class="built_in">read</span> -s -p <span class="string">&quot;Password: &quot;</span> pass</span><br><span class="line"></span><br><span class="line"><span class="comment"># use timer</span></span><br><span class="line"><span class="built_in">read</span> -t 5 -p <span class="string">&quot;Your name:&quot;</span> name	<span class="comment"># timeout is 5s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># count input char</span></span><br><span class="line"><span class="built_in">read</span> -n1 -p <span class="string">&quot;Enter [Y/N]&quot;</span> answer	<span class="comment"># 1 char, Y or N</span></span><br></pre></td></tr></table></figure>

<br>

<p>Running <strong>multiple</strong> commands</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use ;</span></span><br><span class="line">date; who</span><br></pre></td></tr></table></figure>

<br>

<p>List <strong>all active aliases</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> -p</span><br></pre></td></tr></table></figure>



<br>





<h3 id="2-Synatx"><a href="#2-Synatx" class="headerlink" title="2 - Synatx"></a><p align="center">2 - Synatx</p></h3><p><strong>Math</strong></p>
<ul>
<li>  Floating point arthmetic is controlled by a built-in var - <code>scale</code> (set to desired number of decimals)  📌 </li>
<li>  <code>zsh</code> - Supports advanced math functions &amp; features</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># $[] - int only</span></span><br><span class="line">result=$[ 25 * 5 ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># floating point calc</span></span><br><span class="line">scale=3</span><br><span class="line">bc</span><br><span class="line"></span><br><span class="line"><span class="comment"># substitute as var</span></span><br><span class="line">v1=$(<span class="built_in">echo</span> <span class="string">&quot;scale=3; 2.0/3&quot;</span> | bc)</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Condition Tests - Numeric</strong></p>
<table>
<thead>
<tr>
<th>Test - If [ … ]</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><code>n1 -eq n2</code></td>
<td><code>n1 == n2</code></td>
</tr>
<tr>
<td><code>n1 -ne n2</code></td>
<td><code>n1 != n2</code></td>
</tr>
<tr>
<td><code>n1 -ge n2</code></td>
<td><code>n1 &gt;= n2</code></td>
</tr>
<tr>
<td><code>n1 -gt n2</code></td>
<td><code>n1 &gt; n2</code></td>
</tr>
<tr>
<td><code>n1 -le n2</code></td>
<td><code>n1 &lt;= n2</code></td>
</tr>
<tr>
<td><code>n1 -lt n2</code></td>
<td><code>n1 &lt; n2</code></td>
</tr>
</tbody></table>
<br>

<p><strong>Condition Tests - File</strong></p>
<table>
<thead>
<tr>
<th>Test - If [ … ]</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><code>-e [file]</code></td>
<td>If file <strong>exists</strong></td>
</tr>
<tr>
<td><code>-f [file]</code></td>
<td>If file exists &amp; is a <strong>file</strong></td>
</tr>
<tr>
<td><code>-d [file]</code></td>
<td>If file exists &amp; is a <strong>directory</strong></td>
</tr>
<tr>
<td><code>-s [file]</code></td>
<td>If file exists &amp; <strong>not empty</strong></td>
</tr>
<tr>
<td><code>-r [file]</code></td>
<td>If file exists &amp; <strong>readable</strong></td>
</tr>
<tr>
<td><code>-w [file]</code></td>
<td>If file exists &amp; <strong>writeable</strong></td>
</tr>
<tr>
<td><code>-x [file]</code></td>
<td>If file exists &amp; <strong>executable</strong></td>
</tr>
</tbody></table>
<br>

<p><strong>Logics</strong> - Combine <strong>tests</strong> with boolean symbols</p>
<ul>
<li>  <code>&amp;&amp;</code> - And</li>
<li>  <code>||</code> - Or</li>
</ul>
<br>

<p><strong>If</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [ ... ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        ...</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Case</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># input is 1 char, Y or N</span></span><br><span class="line"><span class="built_in">read</span> -n1 -p <span class="string">&quot;Enter [Y/N]&quot;</span> answer	</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$answer</span> <span class="keyword">in</span> </span><br><span class="line">Y | y)	<span class="built_in">echo</span> <span class="string">&quot;\nOK, continue...&quot;</span>;;</span><br><span class="line"></span><br><span class="line">N | n)	<span class="built_in">echo</span> <span class="string">&quot;\nBye&quot;</span></span><br><span class="line">        <span class="built_in">exit</span>;;</span><br><span class="line">        </span><br><span class="line">*)		<span class="built_in">echo</span> <span class="string">&quot;\nWrong Input&quot;</span></span><br><span class="line">        <span class="built_in">exit</span>;;</span><br></pre></td></tr></table></figure>



<br>

<p><strong>For</strong></p>
<blockquote>
<p>  <code>seq</code> - Similar to <code>range()</code>, but is <code>[a, b]</code> （闭区间）</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># execute 4 times, default interval = 1</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> `seq 2 5`</span><br><span class="line"></span><br><span class="line"><span class="comment"># example</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> $(ls | sort) ; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ -d <span class="variable">$file</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$file</span> is a directory&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$file</span> is a file&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>While</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> [ ... ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Function</strong></p>
<blockquote>
<p>  Use <code>return</code> to specify single int value to define exit status</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Format 1</span></span><br><span class="line"><span class="keyword">function</span> hello &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Format 2</span></span><br><span class="line"><span class="function"><span class="title">hello</span></span>() &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Example</strong> - Putting it altogether</p>
<blockquote>
<p>  Accepts source &amp; target filename. Aborts when target file exits</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">doit</span></span>() &#123;</span><br><span class="line">    cp <span class="variable">$1</span> <span class="variable">$1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> check &#123;</span><br><span class="line">    <span class="keyword">if</span> [ -s <span class="variable">$2</span> ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;Target exits. Exiting...&quot;</span></span><br><span class="line">            <span class="built_in">exit</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">check <span class="variable">$1</span> <span class="variable">$2</span></span><br><span class="line">doit  <span class="variable">$1</span> <span class="variable">$2</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="3-SQL-Queries"><a href="#3-SQL-Queries" class="headerlink" title="3 - SQL Queries"></a><p align="center">3 - SQL Queries</p></h3><blockquote>
<p>  All Syntax is used in <strong>MySQL</strong></p>
</blockquote>
<p><strong>Update</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">UPDATE objects <span class="keyword">SET</span> size<span class="operator">=</span><span class="number">5</span> </span><br><span class="line">    <span class="keyword">WHERE</span> name<span class="operator">=</span>&quot;lizard&quot;;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Exact Matches</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> objects </span><br><span class="line">    <span class="keyword">WHERE</span> color<span class="operator">=</span>&quot;green&quot;;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Multiple Tests</strong></p>
<blockquote>
<p>  Return an <strong>ordered</strong> list</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> objects </span><br><span class="line">    <span class="keyword">WHERE</span> type<span class="operator">=</span>&quot;soft&quot; </span><br><span class="line">    <span class="keyword">AND</span> <span class="keyword">value</span><span class="operator">&gt;</span><span class="number">7.50</span></span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">value</span>;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Deletion</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="keyword">delete</span> <span class="keyword">all</span> data <span class="keyword">from</span> a <span class="keyword">table</span> (keeps the <span class="keyword">table</span>)</span><br><span class="line"><span class="keyword">DELETE</span> <span class="operator">*</span> <span class="keyword">from</span> objects;</span><br><span class="line"></span><br><span class="line"># <span class="keyword">delete</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> objects;</span><br></pre></td></tr></table></figure>



<br>

<p>Other Syntax</p>
<ul>
<li>  <code>JOIN</code> - combine data from multiple tables</li>
<li>  <code>GROUP BY</code> - Used with math operators, e.g. <code>SUM()</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> objects.name, objects.value, <span class="built_in">SUM</span>(<span class="keyword">value</span>)</span><br><span class="line">    <span class="keyword">FROM</span> objects, locations</span><br><span class="line">    <span class="keyword">WHERE</span> locations.name<span class="operator">=</span>objects.name</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">value</span>;</span><br></pre></td></tr></table></figure>



<br>

<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
        <tag>Scripting</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 108 Linux Network</title>
    <url>/2022/LPIC-108/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-108/#Network-Protocols">Network Protocols</a></li>
<li>  <a href="/2022/LPIC-108/#Network-Addressing">Network Addressing</a></li>
<li>  <a href="/2022/LPIC-108/#Linux-Network-Config">Linux Network Config</a></li>
<li>  <a href="/2022/LPIC-108/#Network-Troubleshooting">Network Troubleshooting</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="Network-Protocols"><a href="#Network-Protocols" class="headerlink" title="Network Protocols"></a><p align="center">Network Protocols</p></h2><p>Linux uses the <strong>TCP/IP</strong> stack.</p>
<br>

<h3 id="1-General"><a href="#1-General" class="headerlink" title="1 - General"></a><p align="center">1 - General</p></h3><p><strong>Network hardware</strong></p>
<ul>
<li>  Facilitate <strong>data</strong> transfer between computers</li>
<li>  <strong>Ethernet</strong> hardware - <strong>twister-pair</strong> cabling (<code>-T</code>, pairs of twister wires, reduce inteference)</li>
<li>Other types<ul>
<li>  Token Ring (common on IBM networks)</li>
<li>  LocalTalk (Apple, early Macs)</li>
</ul>
</li>
<li><strong>High-speed</strong> interfaces (for high performance applications)<ul>
<li>  Fibre Channel</li>
<li>  <strong>FDDI</strong> - Fiber Distributed Data Inteference</li>
<li>  <strong>HIPPI</strong> - High Performance Parallel Interface</li>
</ul>
</li>
</ul>
<div class="note success"><p>Network devices don’t have entries in <code>/dev</code>.<br>Low-level network utilities take device name and work with them <strong>directly</strong>.</p>
</div>

<br>

<p><strong>Cabling</strong></p>
<ul>
<li><p><strong>Fiber</strong>-optic cables - use light to transmit data down a thin glass strand (faster speed &amp; longer distance)</p>
<ul>
<li><p>  For 100 Base-T Ethernet:  <strong>Cat-5</strong> (Category 5)</p>
</li>
<li><p>  Gigabit Ethernet works best with <strong>Cat-5e</strong> / optical cables</p>
</li>
</ul>
</li>
<li><p>Many network types (including twister-pair Ethernet), require a <strong>hub</strong> / <strong>switch</strong></p>
<ul>
<li><p>  <strong>Switches</strong> are superior to hubs 📌 </p>
</li>
<li><p>  Hub <strong>mirror</strong> all traffic to all computers (<strong>half-duplex</strong>)</p>
</li>
<li><p>Switch send packets only to intended destination (<strong>full-duplex</strong>)</p>
<blockquote>
<p>  Both parties can send data at the <strong>same time</strong> in <strong>full speed</strong>, instead of taking turns</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<br>

<p><strong>PPP &amp; DSL</strong></p>
<ul>
<li>  <strong>DSL</strong> connections (Digital Subscriber Line) - For broadband users</li>
<li>  <strong>PPP</strong> - login-based way to access the Internet (e.g. <strong>Dial-up</strong> Internet access)</li>
<li>  PPP &amp; DSL - <strong>PPPoE</strong> (PPP over Ethernet)</li>
</ul>
<br>

<p>Network <strong>Packets</strong></p>
<ul>
<li><p>  Packets - discrete chunks of data</p>
</li>
<li><p>  <strong>Error-recovery</strong> procedures - critical for protocols that <u>handle large transfers</u></p>
</li>
<li><p>Packets can be stored within each other (e.g. TCP packets within Ethernet <strong>frames</strong>)</p>
<blockquote>
<p>  A data transfer can involves several layers of wrapping &amp; unwrapping data</p>
</blockquote>
</li>
</ul>
<br>

<h4 id="Wireless-networking"><a href="#Wireless-networking" class="headerlink" title="Wireless networking"></a><u>Wireless networking</u></h4><p>Common protocols</p>
<ul>
<li>  <code>802.11a</code> - 54 Mbps</li>
<li>  <code>802.11b</code> - 11 Mbps</li>
<li>  <code>802.11g</code> - 54 Mbps</li>
<li>  <code>802.11n</code> - 300 Mbps</li>
</ul>
<br>

<p><strong>Transmission</strong></p>
<ul>
<li>Transmitted via <strong>radio waves</strong> (network device - network <strong>Access Point</strong>)<ul>
<li>  <strong>AP</strong> - controls how data is sent to each network device (similar to switch)</li>
<li>  Each AP has a unique <strong>SSID</strong> (Service Set Identifier)</li>
</ul>
</li>
<li>  Easily intercepted - need to enable <strong>encryption</strong></li>
</ul>
<br>

<p><strong>Encryption</strong></p>
<ul>
<li>  WEP - Wired Equivalent Privacy (<strong>weak</strong>)</li>
<li>  <strong>WPA</strong> - WiFi Protected Access</li>
<li>  WPA2</li>
</ul>
<br>

<p><strong>WiFi Adapters</strong></p>
<ul>
<li>  Computers with wifi adapters can communicate directly with each other</li>
<li>  But it’s more common to use a <strong>wireless router</strong> </li>
</ul>
<br>

<p><strong>Wireless Routers</strong></p>
<ul>
<li>  Link together both <u>wireless &amp; Ethernet devices</u></li>
<li>  Connection to outside netowrk (sometimes via <strong>broadband</strong> connection)</li>
</ul>
<br>



<h3 id="2-TCP-IP"><a href="#2-TCP-IP" class="headerlink" title="2 - TCP / IP"></a><p align="center">2 - TCP / IP</p></h3><p><strong>Common Protocols</strong></p>
<ul>
<li><strong>IP</strong><ul>
<li>  Connectionless, <strong>best effort</strong> delivery - not guranteed to reach destination</li>
<li>  Packets may arrive <strong>our of order</strong> / corrupted</li>
</ul>
</li>
<li><strong>ICMP</strong> - Internet Control Message Protocol<ul>
<li>  Layer 3 protocol</li>
<li>  For sending error msgs between computers</li>
</ul>
</li>
<li><strong>UDP</strong> - User Datagram Protocol<ul>
<li>  Faster than TCP, but no checking / verification</li>
<li>  L7 protocols built on top of UDP - streaming protocols, <strong>DNS</strong>, <strong>NFS</strong> (Network File System)</li>
</ul>
</li>
<li><strong>TCP</strong> - Transmission Control Protocol<ul>
<li>  Establish full connection, with error checking &amp; correction</li>
<li>  L7 protocols built on top of TCP - <strong>HTTP</strong>, <strong>FTP</strong>, <strong>SMTP</strong></li>
</ul>
</li>
</ul>
<br>

<br>

<h2 id="Network-Addressing"><a href="#Network-Addressing" class="headerlink" title="Network Addressing"></a><p align="center">Network Addressing</p></h2><div class="note success"><p>Configure a host with <strong>static IP</strong></p>
<ul>
<li>  IP address (subnet + host address )</li>
<li>  Netmask</li>
<li>  Gateway address (default router)</li>
<li>  Hostname</li>
<li>  DNS server</li>
</ul>
</div>





<br>



<h3 id="1-Addresses-amp-Netmasks"><a href="#1-Addresses-amp-Netmasks" class="headerlink" title="1 - Addresses &amp; Netmasks"></a><p align="center">1 - Addresses &amp; Netmasks</p></h3><p><strong>Hardware Address</strong></p>
<ul>
<li>  Also called - <strong>MAC</strong> address (Media Access Control)</li>
<li>  6 bytes in <strong>hex</strong></li>
<li>  Network switches use it to direct data packets</li>
<li>  DHCP can use the <strong>MAC</strong> address to <u>consistently assign the same IP</u> to a given host</li>
</ul>
<br>

<p><strong>IP Address</strong></p>
<ul>
<li>Convert between MAC &amp; IP address <ul>
<li>  Send <strong>broadcast</strong> query - Ask computer with given IP to <strong>identify</strong> itself. Receive reply with <strong>MAC</strong> address</li>
<li>  IPv4 - <strong>ARP</strong> (Address Resolution Protocol)</li>
<li>  IPv6 - <strong>NDP</strong> (Neighbor Discovery Protocol)</li>
</ul>
</li>
<li>Two Section<ul>
<li>  <strong>Network / Subnet</strong> address - All devices on the <strong>same</strong> physical network, share the <strong>same</strong> network address portion</li>
<li><strong>Host</strong> address - Each device must have a <strong>unique</strong> host address</li>
</ul>
</li>
</ul>
<br>

<p><strong>Network Mask</strong>  📌 </p>
<blockquote>
<p>  Also called - subnet mask, <strong>netmask</strong></p>
</blockquote>
<ul>
<li><p>  Identifies <strong>network</strong> address (binary <code>1</code>) &amp; <strong>host</strong> address (binary <code>0</code>)</p>
</li>
<li><p>  Another way to express netmask - <strong>CIDR</strong> (Classless Inter-Domain Routing)</p>
</li>
<li><p><strong>Broadcast</strong> address - address binary all set to <code>1</code></p>
</li>
</ul>
<p><strong>Example</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># IP</span></span><br><span class="line">172.30.9.102</span><br><span class="line"></span><br><span class="line"><span class="comment"># netmask</span></span><br><span class="line">255.255.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># in CIDR</span></span><br><span class="line">172.30.9.102/16</span><br><span class="line"></span><br><span class="line"><span class="comment"># network addr</span></span><br><span class="line">172.30.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># broadcast addr</span></span><br><span class="line">172.30.255.255</span><br></pre></td></tr></table></figure>



<br>

<p><strong>IPv4 network classes</strong></p>
<ul>
<li><strong>Private</strong> Address range - <strong>RFC1918</strong><ul>
<li>  Routers will <strong>drop</strong> packets sent to these addresses, isolating them from the Internet</li>
<li>  Class <strong>A</strong> - <code>10.0.0.0</code> to <code>10.255.255.255</code></li>
<li>  Class <strong>B</strong> - <code>172.16.0.0</code> to <code>172.31.255.255</code></li>
<li>  Class <strong>C</strong> - <code>192.168.0.0</code> to <code>192.168.255.255</code></li>
</ul>
</li>
<li>  Class D - <strong>multicasting</strong> ( <code>224.0.0.0</code> to <code>239.255.255.255</code> )</li>
<li>  Class E - future use</li>
<li>  Special case</li>
<li><code>127.x.x.x</code> - For <strong>loopback</strong> (i.e. <strong>localhost</strong>)  📌 <ul>
<li>Ultimate broadcast address - <code>255.255.255.255</code><br>  Routers normally block packets sent to this address, to prevent flooding the network</li>
</ul>
</li>
</ul>
<div class="note primary"><p>Small <strong>private</strong> networks (Class A, B, C) hide behind one <strong>NAT</strong> router (Natwork Address Translation),<br>with <strong>one public IP</strong> on the Internet.</p>
</div>

<br>

<p><strong>Default Router (Gateway)</strong> </p>
<ul>
<li>  Connect different physical networks together</li>
<li>  Network devices must know the <strong>local default gateway</strong> to forward packets to remote hosts 📌 </li>
</ul>
<div class="note success"><p>For a computer on a local network to communicate to the outside - Need a <strong>router</strong> / <strong>gateway</strong></p>
</div>

<br>



<h3 id="2-DNS"><a href="#2-DNS" class="headerlink" title="2 - DNS"></a><p align="center">2 - DNS</p></h3><p><strong>Hostnames</strong></p>
<ul>
<li>To make up a hostname - choose an invalid domain name (Below are <strong>reserved</strong> for this purpose)<ul>
<li>  <code>xx.example.com</code></li>
<li>  <code>xx.example.org</code></li>
<li>  <code>xx.localhost</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>DNS</strong></p>
<ul>
<li><p>  Distributed database</p>
</li>
<li><p>  Each domain has at least 2 DNS servers (<strong>nameservers</strong>)</p>
</li>
<li><p>  Resolve hostname in corporate network - point your laptop to your org’s DNS servers</p>
</li>
<li><p>DNS Error - <code>NXDOMAIN</code> : Hasn’t configured <strong>reverse</strong> lookup (get IP address based on hostnames)</p>
</li>
</ul>
<br>

<p><strong>DNS Lookup Tools</strong></p>
<ul>
<li>  <code>nslookup</code> - <strong>Deprecated</strong>, dropped from parent pacakge (<code>bind-utils</code> / <code>bind-tools</code>)</li>
<li>  <code>host</code> - Replacement of <code>nslookup</code>. For simple queries only</li>
<li>  <code>dig</code> - For complex DNS lookup</li>
<li>  <code>whois</code> - lookup domain info</li>
<li><code>getent</code> - look for entries in any type of text database on Linux  📌 <ul>
<li>  parse through host databases defined in <code>/etc/nsswitch.conf</code></li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># whois - omit legal disclaimer</span></span><br><span class="line">whois -H github.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># dig</span></span><br><span class="line">dig +short github.com CNAME</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Local config</strong> - <code>/etc/hosts</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">192.168.7.23   merikanto.org   merikanto</span><br></pre></td></tr></table></figure>

<ul>
<li>  <code>merikanto.org</code> - FQDN</li>
<li>  <code>merikanto</code> - <strong>alias</strong> (<strong>hostname</strong> without full domain specification)</li>
<li>  For <strong>small</strong> network - maintain <code>/etc/hosts</code> on all computers in the network</li>
<li>Linux DNS lookup: First <code>/etc/hosts</code>, then DNS<ul>
<li>  Modify lookup order - <code>/etc/nsswitch.conf</code> (Configure <strong>NSS</strong> - Name Service Switch)</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reverse files &amp; dns order</span></span><br><span class="line">hosts:    files dns</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Local config</strong> - <code>/etc/networks</code></p>
<ul>
<li>  Applies to network address</li>
<li>  Rarely necessary to edit this file</li>
</ul>
<br>



<h3 id="3-Network-Ports"><a href="#3-Network-Ports" class="headerlink" title="3 - Network Ports"></a><p align="center">3 - Network Ports</p></h3><p>Port numbers are <strong>Layer 4</strong> features (TCP / UDP)</p>
<table>
<thead>
<tr>
<th>Port Number</th>
<th>Protocol</th>
<th>Purpose</th>
</tr>
</thead>
<tbody><tr>
<td><code>20</code></td>
<td>TCP</td>
<td>FTP (<strong>Unsecured</strong>)</td>
</tr>
<tr>
<td><code>53</code></td>
<td>TCP &amp; UDP</td>
<td><strong>DNS</strong></td>
</tr>
<tr>
<td><code>67</code></td>
<td><strong>UDP</strong></td>
<td><strong>DHCP</strong></td>
</tr>
<tr>
<td><code>123</code></td>
<td><strong>UDP</strong></td>
<td><strong>NTP</strong> - Network Time Protocol</td>
</tr>
<tr>
<td><code>161</code></td>
<td>UDP</td>
<td><strong>SNMP</strong> - Simple Network Management Protocol</td>
</tr>
<tr>
<td><code>162</code></td>
<td>UDP</td>
<td>SNMP <strong>Trap</strong></td>
</tr>
<tr>
<td><code>389</code></td>
<td>TCP</td>
<td><strong>LDAP</strong></td>
</tr>
<tr>
<td><code>636</code></td>
<td>TCP</td>
<td>LDAP over <strong>SSL</strong></td>
</tr>
<tr>
<td><code>5900+</code></td>
<td>TCP</td>
<td><strong>RFB</strong> (Remote Frame Buffer), for <strong>VNC</strong></td>
</tr>
<tr>
<td><code>6000</code> - <code>6007</code></td>
<td>TCP</td>
<td>X Window System</td>
</tr>
</tbody></table>
<br>

<p><strong>Privileged Ports</strong></p>
<ul>
<li>  Privileged - port number less than <strong>1024</strong> (restrict access to <code>root</code>)</li>
<li>  Purpose - Ensure client connection to privileged ports are configured by sys admin</li>
<li>  This distinction isn’t useful today - Trust is <strong>unjustified</strong> based soly on the port number</li>
</ul>
<br>

<p><strong>Local config</strong> - <code>/etc/services</code></p>
<ul>
<li>  Map <strong>port numbers</strong> to <strong>names</strong> - Link servers to correct <strong>ports</strong></li>
<li>  Then use names in server configs</li>
</ul>
<br>

<br>

<h2 id="Linux-Network-Config"><a href="#Linux-Network-Config" class="headerlink" title="Linux Network Config"></a><p align="center">Linux Network Config</p></h2><div class="note default"><p><strong>Legacy</strong> Tools (from <code>net-tools</code> pkg)</p>
<ul>
<li>  <code>ethtool</code> - Display ethernet setting</li>
<li>  <code>iwconfig</code> - Set SSID &amp; encryption key for wireless interface</li>
<li>  <code>ifconfig</code> - Set IP &amp; Netmask</li>
<li>  <code>route</code> - Set default router </li>
</ul>
</div>





<h3 id="1-Basic"><a href="#1-Basic" class="headerlink" title="1 - Basic"></a><p align="center">1 - Basic</p></h3><p><strong>Configure Network Hardware</strong></p>
<blockquote>
<p>  Find the name of the network hardware’s kernel module</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load network driver</span></span><br><span class="line">sudo modprobe tulip</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Systemd</strong> - <code>systemd-networkd</code></p>
<ul>
<li>  Detect network interfaces</li>
<li>  Create entries for interfaces in the network config file</li>
</ul>
<br>

<p><strong>Netplan</strong></p>
<ul>
<li>  Used by Ubuntu to manage network settings</li>
<li>  Config file - <code>/etc/netplan</code></li>
</ul>
<br>

<p><strong>Network Manager CLIs</strong></p>
<ul>
<li><p>  <code>nmtui</code> - text based UI</p>
</li>
<li><p><code>nmcli</code> - text only CLI</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">nmcli device xx</span><br><span class="line">nmcli connection xx</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>Configure DHCP</strong></p>
<ul>
<li>  DHCP <strong>client</strong> sends a <strong>broadcast</strong> to search for DHCP server</li>
<li>Server replies with following info  📌 <ul>
<li>  IP address</li>
<li>  Netmask</li>
<li>  Network’s <strong>gateway</strong></li>
<li>  DNS server</li>
</ul>
</li>
<li>  DHCP <strong>lease</strong> - If not renewed, the DHCP server will give the lease to another host</li>
<li>Clients<ul>
<li>  <code>pump</code></li>
<li>  <code>dhclient</code> - e.g. <code>dhclient eth0</code></li>
<li>  <code>dhcpcd</code> - Most popular</li>
</ul>
</li>
</ul>
<div class="note danger"><p>It’s not a good idea to use DHCP for servers - <strong>Servers</strong> need to have <strong>fixed IP</strong> address.</p>
<p>Safest to manually configure network info for servers (<strong>static</strong> host address)</p>
</div>



<br>

<p><strong>Configure Static IP</strong></p>
<ul>
<li>Config files<ul>
<li>  Redhat - <code>/etc/sysconfig/network-scripts/</code></li>
<li>  Debian - <code>/etc/network/interfaces</code></li>
</ul>
</li>
<li>Configure following items<ul>
<li>  IP address</li>
<li>  Netmask</li>
<li>  <strong>Gateway</strong> address - <code>route</code> (necessary for hosts communicating with wider network)</li>
<li>  DNS setting - specify at least 1 DNS server in <code>/etc/resolve.conf</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>Wireless Interface</strong></p>
<blockquote>
<p>  <code>iwlist</code> - Display all wirelss signals</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">iwlist wlan0 scan</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Use</strong> <code>ifconfig</code></p>
<ul>
<li>  <code>RX</code> - packets <strong>received</strong></li>
<li>  <code>TX</code> - packets <strong>transmitted</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># bring up network interface eth0</span></span><br><span class="line">ifconfig eth0 up 192.168.1.1 netmask 255.255.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># add gateway</span></span><br><span class="line">route add default gw 192.168.10.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># view config</span></span><br><span class="line">ifconfig eth0</span><br></pre></td></tr></table></figure>

<br>

<div class="note warning"><p>If <code>ifconfig</code> viewing shows <code>TX</code> collision rate is high - Consider replacing hub with a <strong>switch</strong>.</p>
</div>

<br>

<h3 id="2-Interface-Bonding"><a href="#2-Interface-Bonding" class="headerlink" title="2 - Interface Bonding"></a><p align="center">2 - Interface Bonding</p></h3><p>Network <strong>interface bonding</strong> types  📌 </p>
<blockquote>
<p>  <strong>Aggregate</strong> multiple interfaces into <strong>one virtual network device</strong> (Similar concept - <strong>LACP</strong>)</p>
</blockquote>
<ul>
<li>  <strong>Load Balancing</strong> - Share traffic between multiple interfaces</li>
<li>  <strong>Aggregation</strong> - Combined to create one larger network pipe</li>
<li>  <strong>Active / Passive</strong> - One primary, one used as <strong>backup</strong> for fault tolerance</li>
</ul>
<br>

<p><strong>Boning modes</strong></p>
<table>
<thead>
<tr>
<th>Mode</th>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td><code>balance-rr</code></td>
<td>LB + Fault tolerance in <strong>round-robin</strong> approach</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td><code>active-backup</code></td>
<td>Fault tolerance with one as <strong>primary</strong>, one as <strong>backup</strong></td>
</tr>
<tr>
<td><strong>2</strong></td>
<td><code>balance-xor</code></td>
<td>LB + Fault tolerance by <strong>transmitting</strong> on one interface, and <strong>receiving</strong> on the other</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td><code>broadcast</code></td>
<td>Transmit all packets on <strong>all</strong> interfaces</td>
</tr>
<tr>
<td><strong>4</strong></td>
<td><code>802.3ad</code></td>
<td><strong>Aggregate</strong> interfaces to create one connection combining interface <strong>bandwidths</strong></td>
</tr>
<tr>
<td><strong>5</strong></td>
<td><code>balance-tlb</code></td>
<td>LB + Fault tolerance based on current <strong>transmit load</strong></td>
</tr>
<tr>
<td><strong>6</strong></td>
<td><code>balance-alb</code></td>
<td>LB + Fault tolerance based on current <strong>receive load</strong></td>
</tr>
</tbody></table>
<br>

<p><strong>Example</strong> - Steps to enable network interface bonding  📌 </p>
<blockquote>
<p>  <code>bond0</code> will be treated as a <strong>single network interface</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load bonding module - create bond0 interface</span></span><br><span class="line">sudo modprobe bonding</span><br><span class="line"></span><br><span class="line"><span class="comment"># define bond0 mode</span></span><br><span class="line">sudo ip link add bond0 <span class="built_in">type</span> bond mode 4</span><br><span class="line"></span><br><span class="line"><span class="comment"># add interfaces to the bond</span></span><br><span class="line">sudo ip link <span class="built_in">set</span> eth0 master bond0</span><br><span class="line">sudo ip link <span class="built_in">set</span> eth1 master bond0</span><br></pre></td></tr></table></figure>



<br>

<div class="note primary"><p>When to use a <strong>network bridge</strong>:</p>
<p>Connect <strong>multiple</strong> network interfaces to <strong>separate</strong> networks. Configure LInux as a <strong>bridge</strong> between networks.</p>
</div>

<blockquote>
<p>  Don’t forget to set <code>ip_forward 1</code> in <code>/etc/sysctl</code>. Use <code>brctl</code> to control the bridge.</p>
</blockquote>
<br>

<h3 id="3-Routing"><a href="#3-Routing" class="headerlink" title="3 - Routing"></a><p align="center">3 - Routing</p></h3><p><strong>Notes</strong></p>
<ul>
<li>  Each router has at least 2 network interfaces, and keeps a <strong>routing table</strong> (rules)</li>
</ul>
<br>

<p><strong>View routing info</strong></p>
<ul>
<li>  Use <code>-n</code> : Use <strong>IP address</strong> instead of hostnames (If DNS config is broken, lookup can be slow or fail)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># diagnostic</span></span><br><span class="line">route -n </span><br></pre></td></tr></table></figure>



<div class="note danger"><p><code>127.x.x.x</code> - Loopback / Localhost: Special <strong>virtual</strong> interface that loops back to the originating host</p>
<ul>
<li>  <code>lo</code> - Local <strong>loopback</strong> interface</li>
<li>Any local program can use it to communicate with other programs, as if they were <u>across a network</u>.<br>  This simplifies <strong>data transfer</strong> between programs.</li>
</ul>
</div>

<br>

<p><strong>Configure Routing</strong> </p>
<ul>
<li>  <strong>Route Tables</strong> - Direct packets based on destination IP </li>
<li>  <code>reject</code> - block the route</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># set default gateway</span></span><br><span class="line">route add default gw 192.168.1.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># destination  - 172.20.0.0/16 subnet</span></span><br><span class="line"><span class="comment"># pass through - 172.21.1.1 router</span></span><br><span class="line">route add -net 172.20.0.0 \</span><br><span class="line">      netmask 255.255.0.0 \ </span><br><span class="line">      gw 172.21.1.1</span><br><span class="line">      </span><br><span class="line"><span class="comment"># enable routing - /etc/sysctl.conf</span></span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Config Tools</strong></p>
<ul>
<li>  GUI tool - <code>system-config-network</code></li>
<li>CLI tool<ul>
<li>  <code>ifup</code> - bring up interface</li>
<li>  <code>ifdown</code> - bring down interface</li>
</ul>
</li>
</ul>
<div class="note warning"><p>If config breaks the network connection, then</p>
<ul>
<li>  Bring down &amp; up the interface ( <code>ifdown</code> + <code>ifup</code> )</li>
<li>  <strong>Reboot</strong></li>
</ul>
</div>



<br>



<h3 id="4-Hostnames"><a href="#4-Hostnames" class="headerlink" title="4 - Hostnames"></a><p align="center">4 - Hostnames</p></h3><p>Setting local hostname (Does not affect remote servers)</p>
<ul>
<li>  <code>hostname</code></li>
<li>  <code>dnsdomainname</code></li>
<li>  <code>/etc/hostname</code></li>
</ul>
<br>

<p><strong>With Systemd</strong></p>
<ul>
<li>  <code>hostnamectl</code></li>
<li>  DNS server - <code>systemd-resolved</code></li>
</ul>
<br>

<h3 id="5-The-New-Standard-iproute2"><a href="#5-The-New-Standard-iproute2" class="headerlink" title="5 - The New Standard : iproute2"></a><p align="center">5 - The New Standard : <code>iproute2</code></p></h3><div class="note success"><p>Most of the legacy tools have been replaced by the <code>iproute2</code> package. The main utility is <code>ip</code></p>
</div>

<br>

<p><strong>Options</strong> for <code>ip</code> </p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>address</code> / <code>a</code></td>
<td>Set IPv4 / IPv6 address</td>
</tr>
<tr>
<td><code>route</code></td>
<td>Manage routing table</td>
</tr>
<tr>
<td><code>link</code></td>
<td>Define <strong>network device</strong></td>
</tr>
<tr>
<td><code>monitor</code></td>
<td>Watch for <strong>netlink</strong> msg</td>
</tr>
<tr>
<td><code>netns</code></td>
<td>Manage</td>
</tr>
<tr>
<td><code>rule</code></td>
<td>Manage entries in routing policy database</td>
</tr>
<tr>
<td><code>tcpmetrics</code></td>
<td>Manage TCP metrics on the interface</td>
</tr>
<tr>
<td><code>token</code></td>
<td>Manage tokenized interface identifiers</td>
</tr>
<tr>
<td><code>tunnel</code></td>
<td><strong>Tunnel</strong> over IP</td>
</tr>
<tr>
<td><code>l2tp</code></td>
<td>Tunnel <strong>Ethernet</strong> over IP</td>
</tr>
<tr>
<td><code>xfrm</code></td>
<td>Manage IPSec policies for secure connections</td>
</tr>
</tbody></table>
<br>

<p><strong>Multicast options</strong></p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>maddress</code></td>
<td>Define <strong>multicast</strong> address for system to listen to</td>
</tr>
<tr>
<td><code>mroute</code></td>
<td>Define entry in <strong>multicast routing cache</strong></td>
</tr>
<tr>
<td><code>mrule</code></td>
<td>Define rule in multicast routing policy database</td>
</tr>
</tbody></table>
<br>

<p><strong>Example</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show address</span></span><br><span class="line">ip a show</span><br><span class="line"></span><br><span class="line"><span class="comment"># specify host address &amp; netmask for interface eth0</span></span><br><span class="line">ip a add 192.168.1.2/24 dev eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># set default router</span></span><br><span class="line">ip route add default via 192.168.1.10 dev eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># make interface active</span></span><br><span class="line">ip link <span class="built_in">set</span> eth0 up</span><br></pre></td></tr></table></figure>

<br>

<p>Fine-tune network interface parameters in <code>/etc/sysctl.conf</code></p>
<ul>
<li>  <strong>Disable packet forwarding</strong> - <code>ip_forward  0</code></li>
<li><strong>Disable ICMP</strong> message response - <code>icmp_echo_ignore_broadcasts    1</code><ul>
<li>  ICMP packets can be used to create DOS attack 📌 </li>
</ul>
</li>
</ul>
<br>

<br>



<h2 id="Network-Troubleshooting"><a href="#Network-Troubleshooting" class="headerlink" title="Network Troubleshooting"></a><p align="center">Network Troubleshooting</p></h2><blockquote>
<ul>
<li>  <code>ping</code></li>
<li>  <code>traceroute</code> / <code>tracepath</code></li>
<li>  <code>tcpdump</code></li>
<li>  <code>netstat</code></li>
<li>  <code>ss</code></li>
<li>  <code>netcat</code> ( <code>nc</code> )</li>
</ul>
</blockquote>
<br>

<h3 id="1-Connectivity-amp-Trace-Route"><a href="#1-Connectivity-amp-Trace-Route" class="headerlink" title="1 - Connectivity &amp; Trace Route"></a><p align="center">1 - Connectivity &amp; Trace Route</p></h3><p><strong>Test Connectivity</strong> - <code>ping</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># specify number of tests</span></span><br><span class="line">ping -c 4 [host]</span><br></pre></td></tr></table></figure>





<br>

<p><strong>Route Tracing</strong> - <code>traceroute</code> / <code>tracepath</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -n: display target host&#x27;s IP address</span></span><br><span class="line">traceroute -n 10.1.0.43</span><br></pre></td></tr></table></figure>

<ul>
<li><code>traceroute</code> can localize problems in network connectivity<br>  Highly variable / missing times indicate a overloaded router, or has an unreliable link to the preious system.</li>
<li><code>tracepath</code> - yields longer output<ul>
<li>  Common use - Find <strong>mismatch in MTU</strong> (Max Transmission Unit) between network hops in a path. 📌 </li>
<li>  MTU - Size of <strong>largest data packet</strong> allowed by a network device</li>
</ul>
</li>
</ul>
<div class="note danger"><p>Some routers <strong>block</strong> all  <code>traceroute</code> data.</p>
</div>



<br>

<h3 id="2-Network-Status-amp-Traffic"><a href="#2-Network-Status-amp-Traffic" class="headerlink" title="2 - Network Status &amp; Traffic"></a><p align="center">2 - Network Status &amp; Traffic</p></h3><p><strong>Check network status</strong> - <code>netstat</code></p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>-i</code></td>
<td><strong>Interface</strong> information. Similar to <code>ifconfig</code> results</td>
</tr>
<tr>
<td><code>-r</code></td>
<td><strong>Routing table</strong> list. Similar to <code>route</code> results</td>
</tr>
<tr>
<td><code>-l</code></td>
<td>Listening</td>
</tr>
<tr>
<td><code>-M</code></td>
<td>Get info about connection mediated by Linux NAT features (<strong>IP Masquerading</strong>)<br />NAT enables a Linux router to hide a network behind a single IP</td>
</tr>
<tr>
<td><code>-p</code></td>
<td>Get info about <strong>programs</strong> that are using network connections</td>
</tr>
<tr>
<td><code>-a</code></td>
<td>Get info about <strong>all</strong> listening &amp; open ports</td>
</tr>
<tr>
<td><code>-t</code></td>
<td><strong>TCP</strong> connections only</td>
</tr>
<tr>
<td><code>-u</code></td>
<td><strong>UDP</strong> connections only</td>
</tr>
<tr>
<td><code>-s</code></td>
<td>Stats for different packet types</td>
</tr>
</tbody></table>
<br>



<p><strong>Examine Sockets</strong> - <code>ss</code> </p>
<ul>
<li>  <strong>Socket</strong> - Program connection to a port  📌 </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show listening &amp; established TCP connections</span></span><br><span class="line">ss -anpt</span><br></pre></td></tr></table></figure>



<br>

<p><code>netcat</code></p>
<ul>
<li>  <strong>Read</strong> from &amp; <strong>write</strong> any network <strong>port</strong></li>
<li>  Accept input from <strong>redirection</strong> &amp; <strong>piping</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># listen for incoming traffic on 80/tcp</span></span><br><span class="line">nc -l 80</span><br><span class="line"></span><br><span class="line"><span class="comment"># listen to server on 443/tcp</span></span><br><span class="line">nc 192.168.1.4 443</span><br></pre></td></tr></table></figure>





<br>

<h3 id="3-Other"><a href="#3-Other" class="headerlink" title="3 - Other"></a><p align="center">3 - Other</p></h3><p>Examine <strong>Raw Network Traffic</strong> - <code>tcpdump</code> (<strong>Packet Sniffer</strong>)  📌 </p>
<ul>
<li>  Packet sniffer - intercept network packets</li>
<li>  Must run as <code>root</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-c [n]	<span class="comment"># show number of packets</span></span><br><span class="line">-v	<span class="comment"># verbose</span></span><br><span class="line"></span><br><span class="line">-A	<span class="comment"># show packet content in ASCII</span></span><br><span class="line">-D	<span class="comment"># show list of listenable interfaces</span></span><br><span class="line">-n	<span class="comment"># show all addresses numerically</span></span><br><span class="line">-w	<span class="comment"># write captured packets to file</span></span><br></pre></td></tr></table></figure>

<br>

<p><code>telnet</code></p>
<ul>
<li>  Unencrypted connection</li>
<li>  Debug network protocols (<strong>TCP only</strong>)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">telnet [host] 25	<span class="comment"># SMTP</span></span><br></pre></td></tr></table></figure>

<br>







<h2 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a><p align="center">IPv6</p></h2><h3 id="1-Address"><a href="#1-Address" class="headerlink" title="1 - Address"></a><p align="center">1 - Address</p></h3><p><strong>Notes</strong></p>
<ul>
<li><p>  <strong>Multicasting</strong> - transmit data simultaneously from one computer to <strong>multiple</strong> recipients</p>
</li>
<li><p>New feature - <strong>SLAAC</strong> (Stateless Adress Auto-Config), simplifies initial network setup</p>
<blockquote>
<p>  Similar to IPv4  <strong>DHCP</strong> (Dynamic Host Config Protocol)</p>
</blockquote>
</li>
<li><p>  Originates the <strong>IPSec</strong> tools. IPSec then is <strong>back-ported to IPv4</strong>  📌 </p>
</li>
<li><p>  Streamlined data structures - Quicker processing by routers</p>
</li>
</ul>
<br>

<p>IPv6 address <strong>format</strong></p>
<ul>
<li>  128-bit, split to <strong>8</strong> groups with <code>:</code></li>
<li>  If one or more groups of 4-digit is <code>0000</code>, then omitted with <code>::</code> (only <strong>one groups</strong> of zeros 📌 )</li>
<li>Host address types<ul>
<li>  <strong>Link local</strong> addresses (<strong>uniquely</strong> identify the device)</li>
<li>  <strong>Global</strong> addresses</li>
</ul>
</li>
</ul>
<br>

<p><strong>IPv6 Private Addresses</strong></p>
<ul>
<li>IPv6 <strong>site-local</strong> addresses maybe routed within a site, but not offsite<ul>
<li>  Begin with - <code>fec</code>, <code>fed</code>, <code>fee</code>, <code>fef</code></li>
</ul>
</li>
<li><strong>Link-local</strong> addresses are restricted to <strong>single network segment</strong>. They <u>shouldn’t be routed at all</u> 📌 <ul>
<li>  Begin with - <code>fe8</code>, <code>fe9</code>, <code>fea</code>, <code>feb</code></li>
<li>  Assign address (<code>auto</code> to assign <strong>link local</strong> address) - <code>iface eth0 inet6 auto</code></li>
</ul>
</li>
</ul>
<br>

<h3 id="2-Config-amp-Troubleshoot"><a href="#2-Config-amp-Troubleshoot" class="headerlink" title=" 2 - Config &amp; Troubleshoot"></a><p align="center"> 2 - Config &amp; Troubleshoot</p></h3><p>Test connectivity - <code>ping6</code></p>
<ul>
<li>  With link local address - need to specify the <strong>interface</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -c : specify number of tests</span></span><br><span class="line"><span class="comment"># after % : specify interface</span></span><br><span class="line">ping6 -c 4 fe80::2ed0:cbce%enp0s3</span><br></pre></td></tr></table></figure>







<br>

<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 107 Linux System Admin</title>
    <url>/2022/LPIC-107/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-107/#Manage-User-amp-Groups">Manage User &amp; Group</a></li>
<li>  <a href="/2022/LPIC-107/#System-Logging">System Logging</a></li>
<li>  <a href="/2022/LPIC-107/#Maintain-System-Time">Maintain System Time</a></li>
<li>  <a href="/2022/LPIC-107/#Job-Scheduling">Job Scheduling</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="Manage-User-amp-Groups"><a href="#Manage-User-amp-Groups" class="headerlink" title="Manage User &amp; Groups"></a><p align="center">Manage User &amp; Groups</p></h2><p>Linux is a multi-user system that relies on <strong>accounts</strong></p>
<blockquote>
<p>  Traditional Linux security control - <strong>DAC</strong> (Discretionary Access Control)</p>
</blockquote>
<br>



<h3 id="1-Users"><a href="#1-Users" class="headerlink" title="1 - Users"></a><p align="center">1 - Users</p></h3><p><strong>Summary</strong></p>
<ul>
<li>Commands<ul>
<li>  <code>getent</code> - view account info</li>
<li>  <code>chage</code> - change account password setting</li>
<li>  <code>passwd</code></li>
<li>  <code>useradd</code></li>
<li>  <code>usermod</code></li>
<li>  <code>userdel</code></li>
</ul>
</li>
<li>User account creation process 📌 <ul>
<li>Input<ul>
<li>  <code>/etc/default/useradd</code></li>
<li>  <code>/etc/login.defs</code> - set account numbering limits </li>
<li>  <code>/etc/skel</code></li>
</ul>
</li>
<li>Output (changes)<ul>
<li>  <code>/etc/passwd</code> - account info</li>
<li>  <code>/etc/shadow</code></li>
<li>  <code>/etc/group</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<br>

<p><strong>Notes</strong></p>
<ul>
<li>  <code>UID=0</code> - <code>root</code> user</li>
<li>  First regular user account - UID is <code>500</code> or <code>1000</code></li>
<li>  Reusing UID can cause problems, if old user’s files are not cleaned 📌 </li>
</ul>
<br>

<p>Attention when creating usernames</p>
<ul>
<li>  Via <code>useradd</code> - Forbid uppercase letters &amp; most punctuation</li>
<li>  Other utilities truncate usernames (longer than 8 char)</li>
<li>  Usernames in Linux are <strong>case-sensitive</strong></li>
<li>  Safe practice: Usernames in all <strong>lower-case</strong> letters</li>
</ul>
<br>

<p><strong>Create user</strong> - <code>useradd</code></p>
<ul>
<li>Create user: <strong>Two</strong> steps<ul>
<li>  Create user - <code>useradd</code></li>
<li>  Set password - <code>passwd</code></li>
</ul>
</li>
<li>Copy files from <strong>skeleton directory</strong> - <code>/etc/skel</code><ul>
<li>  Provide <strong>core</strong> set of config files, which should be present in user’s home directory</li>
</ul>
</li>
<li>Special accounts (shells)<ul>
<li>Some systesm include a <code>shutdown</code> account with default shell <code>/sbin/shutdown</code><br>  Logging into this account immediately shuts down the system</li>
<li>  System service account - <code>/sbin/nologin</code></li>
<li>  Logout - Account with shell <code>/sbin/false</code>,  <code>/sbin/logout</code></li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create user merikanto</span></span><br><span class="line">sudo useradd -m -g kk -G sigure, kk -s /bin/bash merikanto</span><br><span class="line">sudo passwd merikanto</span><br><span class="line"></span><br><span class="line">-D	<span class="comment"># show file content  📌 </span></span><br><span class="line"></span><br><span class="line">-m	<span class="comment"># auto creates home dir</span></span><br><span class="line">-d	<span class="comment"># specify home dir</span></span><br><span class="line">-g	<span class="comment"># set group name / GID</span></span><br><span class="line">-G	<span class="comment"># set additional group</span></span><br><span class="line">-s	<span class="comment"># set default shell</span></span><br></pre></td></tr></table></figure>

<p>Modify settings in <code>/etc/default/useradd</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># modify SHELL directive</span></span><br><span class="line">sudo useradd -D -s /bin/bash</span><br></pre></td></tr></table></figure>



<br>

<div class="note warning"><p>When use <code>useradd -G</code> for additional groups:<br>Need to include <strong>all current groups</strong>. Any unlisted groups will be <strong>removed</strong>.</p>
<p><strong>Solution</strong>: Use <code>useradd -aG</code>. Keep current membership: <code>-a</code></p>
</div>

<br>

<p><strong>Manage password &amp; users</strong> - <code>passwd</code></p>
<blockquote>
<p>  <code>pwconv</code> - Migrate password from <code>/etc/passwd</code> to <code>/etc/shadow</code></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example</span></span><br><span class="line">passwd merikanto</span><br><span class="line"></span><br><span class="line">-S	<span class="comment"># display account password status  📌 </span></span><br><span class="line"></span><br><span class="line">-l	<span class="comment"># lock account / temp suspension of user access</span></span><br><span class="line">-u	<span class="comment"># unlock account</span></span><br></pre></td></tr></table></figure>

<p>View account records: <code>getent</code></p>
<ul>
<li>  <code>/etc/shadow</code> - <code>getent shadow [user]</code></li>
<li>  <code>/etc/passwd</code> -  <code>getent passwd [user]</code></li>
<li>  <code>/etc/group</code> - <code>getent group</code> [user]</li>
</ul>
<br>

<p>View account password status</p>
<ul>
<li><code>passwd -S</code> (3 status)<ul>
<li>  <code>P</code> - usable password</li>
<li>  <code>NP</code> - not usable</li>
<li>  <code>L</code> - locked</li>
</ul>
</li>
<li>  <code>chage -l</code> (more human readable)</li>
</ul>
<br>

<p><strong>Modify user</strong> - <code>usermod</code></p>
<ul>
<li>  Change contents of <code>/etc/passwd</code> &amp; <code>/etc/shadow</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># move user&#x27;s file to new dir xx</span></span><br><span class="line">usermod -md	</span><br><span class="line"></span><br><span class="line"><span class="comment"># change login name</span></span><br><span class="line">useradd -l	</span><br></pre></td></tr></table></figure>

<div class="note info"><p>If change account’s UID, need to <strong>manually</strong> <strong>update</strong> UID on all files</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">chown -R merikanto /home/merikanto</span><br></pre></td></tr></table></figure>
</div>

<br>

<p><strong>Modify account expiration</strong> - <code>chage</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-l	<span class="comment"># display info</span></span><br><span class="line"></span><br><span class="line">-d	<span class="comment"># set last password change date</span></span><br><span class="line">-E	<span class="comment"># set expiration date</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Modify account config files</strong> - <code>/etc/passwd</code> &amp; <code>/etc/shadow</code></p>
<ul>
<li>Fields in <code>/etc/passwd</code> <ul>
<li>  Username</li>
<li>  Password - <code>x</code> (shadow password, encrypted in <code>/etc/shadow</code>)</li>
<li>  UID</li>
<li>  <strong>Primary GID</strong>  📌 </li>
<li>  Comment</li>
<li>  Home directory</li>
<li>  Default Shell</li>
</ul>
</li>
<li>Permissions<ul>
<li>  <code>/etc/shadow</code> has restrictive permissions - <code>600</code></li>
<li>  <code>/etc/passwd</code> is readable by normal users - <code>644</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>Network Account Databases (NAD)</strong></p>
<ul>
<li>Types<ul>
<li>  <strong>NIS</strong> - Network Information System</li>
<li>  <strong>LDAP</strong> - Lightweight Directory Access Protocol</li>
<li>  <strong>AD</strong> - Active Directory</li>
</ul>
</li>
<li>  Enable at OS installation - Need to know server IP &amp; protocol</li>
<li>Activate NAD<ul>
<li>  Install relevant packages</li>
<li>  Edit <code>/etc/nsswitch.conf</code></li>
<li>  Edit <code>/etc/pam.d</code> - <strong>PAM</strong> (Pluggable Authentication Module)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Delete users</strong> - <code>userdel</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># force remove all files from mail &amp; user home dir</span></span><br><span class="line">userdel -rf merikanto</span><br><span class="line"></span><br><span class="line"><span class="comment"># confirm file deletion</span></span><br><span class="line">find / -uid xx</span><br></pre></td></tr></table></figure>

<p>Attention: <strong>Samba</strong></p>
<ul>
<li>  Samba keeps its own list of users</li>
<li>Delete user: <ul>
<li>  Edit <code>/etc/samba/sbmpasswd</code></li>
<li>  Command - <code>smbpasswd -x merikanto</code></li>
</ul>
</li>
</ul>
<br>



<h3 id="2-Groups"><a href="#2-Groups" class="headerlink" title="2 - Groups"></a><p align="center">2 - Groups</p></h3><p><strong>Summary</strong></p>
<ul>
<li>Commands<ul>
<li>  <code>groupadd</code></li>
<li>  <code>groupmod</code></li>
<li>  <code>groupdel</code></li>
<li>  <code>groups</code> - audit account group membership</li>
</ul>
</li>
<li>File Locations<ul>
<li>  <code>/etc/group</code></li>
<li>  <code>/etc/gshadow</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>Notes</strong></p>
<ul>
<li><p>  Set user’s primary group: <code>/etc/passwd</code></p>
</li>
<li><p>User access other groups files:</p>
<ul>
<li>  User is a group member</li>
<li>  The group has access permission</li>
</ul>
</li>
<li><p>Run programs with a different group: switch group with <code>newgrp</code></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">newgrp kk</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>Create group</strong> - <code>groupadd</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># most common</span></span><br><span class="line">groupadd kk</span><br><span class="line"></span><br><span class="line">-r	<span class="comment"># create system group</span></span><br><span class="line">-g	<span class="comment"># set GID, override default gid set by system</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Modify group</strong> - <code>groupmod</code></p>
<ul>
<li>  Usually use <code>usermod</code> to add user to a group</li>
<li>Add users to group without specifying existing membership<ul>
<li>  Edit <code>/etc/group</code></li>
<li>  <code>gpasswd</code></li>
<li>  <code>usermod -aG</code>  ✅ </li>
</ul>
</li>
</ul>
<br>

<p><strong>Manage password &amp; groups</strong> - <code>gpasswd</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change group password</span></span><br><span class="line">gpasswd kk</span><br><span class="line"></span><br><span class="line">-a	<span class="comment"># add user</span></span><br><span class="line">-A	<span class="comment"># add as group admin</span></span><br><span class="line">-M	<span class="comment"># bulk add users</span></span><br><span class="line">-d	<span class="comment"># delete user</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Modify group config files</strong> - <code>/etc/group</code> &amp; <code>/etc/gshadow</code></p>
<ul>
<li>Fields in <code>/et/group</code><ul>
<li>  Group name</li>
<li>  Password - x (shadow password, encrypted in <code>/etc/gshadow</code>)</li>
<li>  GID</li>
<li>  User list</li>
</ul>
</li>
</ul>
<br>

<p><strong>Delete groups</strong> - <code>groupdel</code></p>
<ul>
<li>  First check <u>whether group is any user’s primary group</u></li>
<li>  Can also leave orphaned files </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># delete group</span></span><br><span class="line">groupdel kk</span><br><span class="line"></span><br><span class="line"><span class="comment"># delete all related files</span></span><br><span class="line">sudo find / -gid xx 2&gt;/dev/null</span><br></pre></td></tr></table></figure>





<br>

<br>

<h2 id="System-Logging"><a href="#System-Logging" class="headerlink" title="System Logging"></a><p align="center">System Logging</p></h2><p>Provide <strong>unified</strong> means of handling log files.</p>
<br>

<h3 id="1-Syslog"><a href="#1-Syslog" class="headerlink" title="1 - Syslog"></a><p align="center">1 - Syslog</p></h3><p><strong>Syslog Daemon</strong> - <code>syslogd</code></p>
<ul>
<li>  <code>syslogd</code> runs in the background, waiting for events to trigger</li>
<li>Install - <code>sysklogd</code> package<ul>
<li>  <code>syslogd</code></li>
<li>  <code>klogd</code> - logging <strong>kernel</strong> messages</li>
</ul>
</li>
<li>Alternatives<ul>
<li>  <code>syslog-ng</code> - Supports <strong>advanced filtering</strong></li>
<li>  <code>metalog</code></li>
<li>  <code>rsyslogd</code> - <strong>Speed</strong> (rocket fast)</li>
<li>  <code>systemd-journald</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>Config</strong> - <code>/etc/syslog.conf</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">service.log_level    location</span><br></pre></td></tr></table></figure>

<ul>
<li>  <strong>Selector</strong> - service (facility) + log level (priority)</li>
<li>Valid codes for <strong>facility</strong><ul>
<li>  <code>*</code> - all facilities</li>
<li>  <code>auth</code>, <code>security</code></li>
<li>  <code>authpriv</code></li>
<li>  <code>cron</code></li>
<li>  <code>daemon</code> - general system services</li>
<li>  <code>kern</code></li>
<li>  <code>lpr</code> - printer</li>
<li>  <code>mail</code></li>
<li>  <code>mark</code> - reserved for <strong>internal</strong> use</li>
<li>  <code>news</code> - news application</li>
<li>  <code>syslog</code></li>
<li>  <code>user</code></li>
<li>  <code>uucp</code> - Unix-to-Unix copy</li>
<li>  <code>local0</code> - <code>local7</code> - locally defined</li>
</ul>
</li>
<li>Valid codes for <strong>priority</strong><ul>
<li>  <code>*</code> - all priorities</li>
<li>  <code>!</code> - <strong>reverse</strong> (make the log level as highest)</li>
<li>  <code>debug</code></li>
<li>  <code>info</code></li>
<li>  <code>notice</code></li>
<li>  <code>warning</code></li>
<li>  <code>err</code></li>
<li>  <code>crit</code></li>
<li>  <code>alert</code></li>
<li>  <code>emerg</code></li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># send all emerg-level logs to all users</span></span><br><span class="line">*.emerg    *</span><br><span class="line"></span><br><span class="line"><span class="comment"># save logs between info &amp; err level to /var/log/kernel-info</span></span><br><span class="line">kern.info;kern.!err    /var/<span class="built_in">log</span>/kernel-info</span><br></pre></td></tr></table></figure>

<br>

<p><code>rsyslogd</code></p>
<ul>
<li>  Config file - <code>/etc/rsyslogd.conf</code></li>
<li>Actions<ul>
<li>  Foward to regular <strong>file</strong></li>
<li>  <strong>Pipe</strong> to application</li>
<li>  Display in <strong>terminal</strong></li>
<li>  Send to <strong>remote host</strong></li>
<li>  Send to list of <strong>users</strong></li>
<li>  Send to all <strong>logged-in</strong> users</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># log with specific level</span></span><br><span class="line">kern.=crit</span><br><span class="line"></span><br><span class="line"><span class="comment"># - : not sync after each write</span></span><br><span class="line"><span class="comment"># .none = except (handle all events except security events)</span></span><br><span class="line">*.*;auth,authpriv.none	-/var/<span class="built_in">log</span>/syslog</span><br><span class="line"></span><br><span class="line"><span class="comment"># omusrmsg: send msg to user account</span></span><br><span class="line">*.emerg	:omusrmsg:kk</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Send log to remote server</strong></p>
<blockquote>
<ul>
<li>  Edit config file - <code>/etc/rsyslogd.conf</code></li>
<li>  Reload config file / restart <code>rsyslogd</code> after editing</li>
</ul>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># syntax</span></span><br><span class="line"><span class="string">log</span>  <span class="string">TCP|UDP[(z#)]HOST:[PORT#]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># example</span></span><br><span class="line"><span class="string">*.*</span>  <span class="string">@@(z9)merikanto.org:6514</span></span><br></pre></td></tr></table></figure>

<ul>
<li>  <code>@</code> - UDP, <code>@@</code> - TCP</li>
<li>  <code>z</code> - Use <code>zlib</code> to compress</li>
<li>  <code>#</code> - Compression level (9 is the highest)</li>
<li>  <code>HOST</code> - FQDN / IP</li>
</ul>
<br>

<h3 id="2-Journal"><a href="#2-Journal" class="headerlink" title="2 - Journal"></a><p align="center">2 - Journal</p></h3><blockquote>
<p>   Config file - <code>/etc/systemd/journald.conf</code></p>
</blockquote>
<br>

<p><strong>Storage</strong></p>
<ul>
<li>  Options - <code>auto</code>, <code>persistent</code>, <code>volatile</code>, <code>none</code></li>
<li><code>auto</code> - store logs in <code>/var/log/journal/</code> if directory exists (log will persist through restart)<br>  else store in <code>/run/log/journal/</code> (temporary)</li>
<li>  <code>persistent</code> - always create <code>/var/log/journal/</code> and store logs</li>
<li>  <code>volatile</code> - always temporary (<code>/run/log/journal/</code>)</li>
<li>  <code>none</code> - all event messages are discarded</li>
</ul>
<br>

<p><strong>Layered logging</strong></p>
<ul>
<li><p><strong>Journal client method</strong> - allow syslog protocol program to act as <strong>journal client,</strong> read entries stored in journal</p>
<blockquote>
<p>  For <code>/etc/rsyslog.conf</code> - Load with <code>Modload</code></p>
<ul>
<li>  <code>imusock</code> - local system logging</li>
<li>  <code>imjournal</code> - systemd journal</li>
</ul>
</blockquote>
</li>
<li><p><strong>Forward to Syslog</strong></p>
<blockquote>
<ul>
<li>  Edit <code>/etc/systemd/journald.conf</code> - Set <code>ForwardToSyslog</code> to <code>yes</code></li>
<li>  Restart to reload config - <code>systemctl restart systemd-journald</code></li>
</ul>
</blockquote>
</li>
</ul>
<br>

<h4 id="Journalctl"><a href="#Journalctl" class="headerlink" title="Journalctl"></a>Journalctl</h4><ul>
<li><p>  View journal entries</p>
</li>
<li><p><code>journald</code> doesn’t store journal entries in text files, but in <strong>binary</strong> file format</p>
<blockquote>
<p>  Similar to database. Binary format for fast index and quick search</p>
</blockquote>
</li>
<li><p>  Format: <code>journalctl [options] [matches]</code></p>
</li>
</ul>
<br>

<p><strong>Options</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># last 10 lines, turn off pager</span></span><br><span class="line">sudo journalctl -n 10 --no-pager</span><br><span class="line"></span><br><span class="line">-a	<span class="comment"># display all data fields</span></span><br><span class="line">-e	<span class="comment"># jump to end</span></span><br><span class="line">-k	<span class="comment"># only kernel entries</span></span><br><span class="line">-r	<span class="comment"># reverse the order</span></span><br><span class="line">-f	<span class="comment"># real-time log stream</span></span><br><span class="line"></span><br><span class="line">-n [num]	<span class="comment"># most recent number</span></span><br><span class="line">-S [date]	<span class="comment"># start from (2022-04-07:08:00:00)</span></span><br><span class="line">-U [date]	<span class="comment"># end with</span></span><br><span class="line">-u [pattern]	<span class="comment"># pattern match</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Matches</strong> - Filter types of journal entries</p>
<ul>
<li>  <code>PRIORITY</code></li>
<li>  <code>_HOSTNAME</code></li>
<li>  <code>_SYSTEMD_UNIT</code></li>
<li>  <code>_UDEV_SYSNAME</code> - received from the specified device</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example</span></span><br><span class="line">sudo journalctl --since=today _SYSTEMD_UNIT=ssh.service</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Maintain Journal</strong></p>
<ul>
<li>  Vaccum only works on <strong>archived</strong> journal files</li>
<li>  Send journals to remote host - <code>systemd-journal-remote</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check disk usage</span></span><br><span class="line">journalctl --disk-usage</span><br><span class="line"></span><br><span class="line"><span class="comment"># clean up &amp; only leave 300M from archive</span></span><br><span class="line">sudo journalctl --vacuum-size=300M</span><br><span class="line"></span><br><span class="line"><span class="comment"># before backup: sync</span></span><br><span class="line">journalctl --sync</span><br><span class="line"></span><br><span class="line"><span class="comment"># view different journal files</span></span><br><span class="line">journalctl --directory=xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge journals</span></span><br><span class="line">journalctl -m xx</span><br></pre></td></tr></table></figure>

<br>

<p>Make journal entries <strong>manually</strong></p>
<blockquote>
<p>  <code>systemd-cat</code>  📌 </p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create entry</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;hello&quot;</span> | systemd-cat</span><br><span class="line"></span><br><span class="line"><span class="comment"># view</span></span><br><span class="line">journalctl --no-pager | grep hello</span><br></pre></td></tr></table></figure>



<br>

<h3 id="3-Logger"><a href="#3-Logger" class="headerlink" title="3 - Logger"></a><p align="center">3 - Logger</p></h3><p><strong>Manually</strong> create log entry</p>
<p>Example</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create log entry</span></span><br><span class="line">logger shutting down</span><br><span class="line"></span><br><span class="line"><span class="comment"># result: in /var/log/messages</span></span><br><span class="line">Jan 01 08:00:00 merikanto logger: shutting down</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Options</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-i	<span class="comment"># record logger PID</span></span><br><span class="line">-s	<span class="comment"># output to stderr</span></span><br><span class="line">-f	<span class="comment"># log file content</span></span><br><span class="line">-p	<span class="comment"># specify log level</span></span><br><span class="line">-u xx	<span class="comment"># log directly to network socket xx	</span></span><br></pre></td></tr></table></figure>





<br>

<h3 id="4-Logrotate"><a href="#4-Logrotate" class="headerlink" title="4 - Logrotate"></a><p align="center">4 - Logrotate</p></h3><p><strong>Notes</strong></p>
<ul>
<li>  Called on a regular basis via <strong><code>cron</code> job</strong></li>
<li>  Also compress, delete, mail log file to user account</li>
<li>  Logrotate status file - <code>/var/lib/logrotate/status</code></li>
</ul>
<br>

<p><strong>Config</strong> - <code>/etc/logrotate.conf</code></p>
<ul>
<li>Compression<ul>
<li>  Default -  <code>gzip</code></li>
<li>  Use <code>xz</code> - <code>compresscmd xz</code></li>
</ul>
</li>
<li><code>create</code><ul>
<li>  Create new log file</li>
<li>  Options - <strong>file mode</strong> (<code>0664</code>), <strong>owner</strong> (<code>root</code>), <strong>group</strong> (<code>kk</code>)</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># section in the config file </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Rotate wtmp, which isn&#x27;t handled by a specific program</span></span><br><span class="line">/var/<span class="built_in">log</span>/wtmp &#123;</span><br><span class="line">    monthly</span><br><span class="line">    create 0664 root kk</span><br><span class="line">    rotate 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<table>
<thead>
<tr>
<th>Directives</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>rotate n</code></td>
<td>Number of old files to be maintained (e.g. <code>log.1</code>, <code>log.2</code>) <br />If <code>n = 0</code>, rotated files are <strong>deleted</strong></td>
</tr>
<tr>
<td><code>weekly n</code></td>
<td>0 - 6 (<strong>Sunday</strong> - Saturday). <br /><strong>7</strong> means log is rotated every 7 days, regardless of the current day</td>
</tr>
<tr>
<td><code>size n</code></td>
<td>Rotate based on size (K, M, G)</td>
</tr>
<tr>
<td><code>notifempty</code></td>
<td>Don’t rotate, if log file is empty</td>
</tr>
</tbody></table>
<br>

<h3 id="5-Mail"><a href="#5-Mail" class="headerlink" title="5 - Mail"></a>5 - Mail</h3><p>Linux follows the <strong>Unix</strong> method of handling email.</p>
<ul>
<li><strong>MTA</strong> - Mail <strong>Transfer</strong> Agent<ul>
<li>  Send incoming mails to MDA / local user’s inbox</li>
<li>  Outbound messages to remote system: establish communication link with another MTA program</li>
</ul>
</li>
<li><strong>MDA</strong> - Mail <strong>Delivery</strong> Agent<ul>
<li>  Deliver message to local user’s inbox</li>
</ul>
</li>
<li><strong>MUA</strong> - Mail <strong>User</strong> Agent<ul>
<li>  Interface to display user meesages</li>
</ul>
</li>
</ul>
<br>

<p><strong>Protocols</strong></p>
<ul>
<li><strong>SMTP</strong> - Simple Mail transfer Protocol <ul>
<li>  SMTP servers are known as <strong>MTA</strong></li>
</ul>
</li>
<li><strong>Pull</strong> mail protocol<ul>
<li>  <strong>POP</strong> - Post Office Protocol</li>
<li>  <strong>IMAP</strong> - Internet Message Access Protocol</li>
</ul>
</li>
</ul>
<br>

<p>Popular MTA packages</p>
<ul>
<li><strong>Sendmail</strong><ul>
<li>  Message forwarding</li>
<li>  User aliases</li>
<li>  Mail lists</li>
</ul>
</li>
<li>  <strong>Postfix</strong> - Simplicity</li>
<li>  <strong>Exim</strong> - Sendmail <strong>replacement</strong></li>
<li>  <strong>qmail</strong> - <strong>Security</strong> as major design goal</li>
</ul>
<br>

<p><strong>Relays</strong></p>
<ul>
<li>  At each step in a relay chain, email is altered</li>
<li>  Each server adds a <strong>header</strong> to the email (can trace email back to its source)</li>
<li>  <strong>Open relay</strong> - Relay mail from any computer to another  📌 </li>
</ul>
<br>

<p><strong>Notes</strong></p>
<ul>
<li>  Binary: <code>/usr/bin/mail</code></li>
<li>  Messages stored in <code>/var/spool/mail</code></li>
<li>Operations<ul>
<li>  Get log - <code>/var/log/mail</code></li>
<li>  Read email -  <code>mail</code></li>
<li>  Check email queue - <code>mailq</code> / <code>sendmail -bp</code> </li>
<li>  Clear mail queue - <code>sendmail -q</code></li>
<li>  Setup email alias (For <strong>redirction</strong>) - <code>/etc/aliases</code> ( Command: <code>newaliases</code> )  📌 </li>
</ul>
</li>
</ul>
<br>

<br>





<h2 id="Maintain-System-Time"><a href="#Maintain-System-Time" class="headerlink" title="Maintain System Time"></a><p align="center">Maintain System Time</p></h2><div class="note info"><p>If messed up software clock, typically can make things right by <strong>rebooting</strong>.</p>
</div>

<h3 id="1-Linux-Time"><a href="#1-Linux-Time" class="headerlink" title="1 - Linux Time"></a><p align="center">1 - Linux Time</p></h3><p><strong>Two built-in clocks</strong></p>
<ul>
<li><p>  <strong>Software</strong> clock - Linux use it when it’s <strong>running</strong></p>
</li>
<li><p><strong>Hardware</strong> clock - <strong>RTC</strong> (Real Time Clock), maintains time when computer is turned <strong>off</strong></p>
<blockquote>
<p>  Gets power from system battery (<strong>CMOS</strong> battery)</p>
</blockquote>
</li>
<li><p>  <code>x86-64</code> hardware maintains <u>both hardware &amp; software clocks</u>, Linux provides tools to <strong>sync</strong> the two</p>
</li>
<li><p>  Linux read the timestamp in UTC, then do the calculation, so time appears in <strong>local</strong> time</p>
</li>
</ul>
<br>

<p>Set hardware clock from software clock - <code>hwclock</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># view hardware clock</span></span><br><span class="line">hwclock --show</span><br><span class="line"></span><br><span class="line"><span class="comment"># view current rtc</span></span><br><span class="line">hwclock -r</span><br><span class="line"></span><br><span class="line"><span class="comment"># sets rtc to use UTC</span></span><br><span class="line">hwclock -u</span><br></pre></td></tr></table></figure>

<br>

<p>System time services - If any is in <strong>active</strong> status, unable to set time with <code>date</code></p>
<ul>
<li>  <code>systemctl status ntpd</code> - NTP</li>
<li>  <code>chronyd</code> - improved <code>ntpd</code></li>
<li>  <code>systemd-timesyncd</code></li>
</ul>
<br>

<p><code>chronyd</code></p>
<ul>
<li>  Config file - <code>/etc/chrony/chrony.conf</code></li>
<li>  <code>rtcsync</code> - periodic update of RTC</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># view system time sources</span></span><br><span class="line">chronyc sources -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># view time server stats</span></span><br><span class="line">chronyc sourcestats</span><br><span class="line"></span><br><span class="line"><span class="comment"># view software clock performance</span></span><br><span class="line">chronyc tracking</span><br></pre></td></tr></table></figure>

<br>

<p>Set time with <code>timedatectl</code> instead</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># turn off ntp</span></span><br><span class="line">timedatectl set-ntp 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># set time</span></span><br><span class="line">timedatectl set-time <span class="string">&quot;2022-04-07 08:00:00&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># turn on ntp</span></span><br><span class="line">timedatectl set-ntp 1</span><br></pre></td></tr></table></figure>



<br>

<h3 id="2-NTP"><a href="#2-NTP" class="headerlink" title="2 - NTP"></a><p align="center">2 - NTP</p></h3><p><strong>NTP</strong> - Network Time Protocol</p>
<ul>
<li>Tiered <strong>hierarchy</strong> of time sources<ul>
<li><strong>Top</strong> level (<strong>stratum-0</strong> time servers):<br>  One or more hightly accurate <strong>time sources</strong> (atomic clocks / radio receivers)</li>
</ul>
</li>
<li>Select NTP source - Select one with <u>shortest network time delay</u><ul>
<li>  Use <code>ping</code> 📌 </li>
</ul>
</li>
</ul>
<br>

<p>Works by measuring packet’s <strong>round-trip</strong> time between server &amp; client</p>
<ul>
<li>  Two systems exchange packets with embedded time stamps (mechanism to <strong>offset</strong> packet travel time)</li>
<li>  Client adjust the time, so it’s in sync with timestamp from source (server)</li>
<li>  Server improves system clock accuracy - <code>/var/lib/ntp/ntp.drift</code> </li>
</ul>
<br>

<p><strong>Config NTP</strong></p>
<ul>
<li>  Package -  <code>ntp</code> / <code>ntpd</code></li>
<li>  Config file - <code>/etc/ntp.conf</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># obtain server list &amp; polling info</span></span><br><span class="line">ntpq -p</span><br><span class="line"></span><br><span class="line"><span class="comment"># one-time clock setting on client</span></span><br><span class="line">ntpd -g</span><br><span class="line"></span><br><span class="line"><span class="comment"># view software time sync  📌</span></span><br><span class="line">ntpstat  </span><br><span class="line"></span><br><span class="line"><span class="comment"># set time manually</span></span><br><span class="line">ntpdate</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Leap-smearing</strong></p>
<ul>
<li>  Google introduced the free public time server that uses NTP, and <strong>smear the leap second</strong> over course of time</li>
<li>  Servers: <code>time1.google.com</code>   ( from 1 to 4 )</li>
<li>  <a href="https://support.ntp.org/Servers/WebHome">NTP server list</a></li>
</ul>
<br>

<br>

<h2 id="Job-Scheduling"><a href="#Job-Scheduling" class="headerlink" title="Job Scheduling"></a><p align="center">Job Scheduling</p></h2><div class="note success"><p>Can also use  <code>systemd-run</code> to <strong>schedule</strong> a job to run at a specific time.</p>
</div>

<h3 id="1-Cron"><a href="#1-Cron" class="headerlink" title="1 - Cron"></a><p align="center">1 - Cron</p></h3><p><strong>Crontab</strong> - The Cron Table</p>
<ul>
<li>  Running <strong>unsupervised</strong> - <u>No user input</u></li>
<li>Two types of cron job<ul>
<li>  System cron - different intervals in <code>/etc/cron.xx</code> (e.g. weekly, daily)</li>
<li>  User cron</li>
</ul>
</li>
<li>Config file<ul>
<li><pre><code>**User** crontab - `/var/spool/cron/crontabs/` (Directory)
</code></pre>
</li>
<li>   <strong>System</strong> crontab (<code>root</code>) - <code>/etc/crontab</code> (<strong>File</strong>)</li>
<li>  <code>/etc/cron.d</code> </li>
</ul>
</li>
</ul>
<br>

<p><strong>Edit cron job</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">02 4 * * * root run-parts /etc/cron.daily</span><br></pre></td></tr></table></figure>

<ul>
<li>Fields<ul>
<li>  Minute - <code>0 - 59</code></li>
<li>  Hour - <code>0 - 23</code></li>
<li>  Day of the month - <code>1 - 31</code></li>
<li>  Month - <code>1 - 12</code></li>
<li>  Day of the week - <code>0 - 7</code> (<u>Both <code>0</code> &amp; <code>7</code> means Sunday</u> ) 📌 </li>
</ul>
</li>
<li>Matching<ul>
<li>  Comma-separated <strong>list</strong> (<code>0, 6, 12</code>) matches any specified values</li>
<li>  Specify <strong>range</strong> - <code>9-17</code> (9am to 5pm)</li>
<li>  Specify <strong>steps</strong> - <code>*/10</code> in minutes (every 10 min)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Use <code>crontab</code></strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create crontab from file</span></span><br><span class="line">crontab -u merikanto [file]</span><br><span class="line"></span><br><span class="line">-l	<span class="comment"># show current crontab</span></span><br><span class="line">-r	<span class="comment"># remove current crontab</span></span><br><span class="line">-e	<span class="comment"># edit</span></span><br><span class="line">-u xx	<span class="comment"># specify user</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="2-Anacron"><a href="#2-Anacron" class="headerlink" title="2 - Anacron"></a><p align="center">2 - <a href="https://anacron.sourceforge.net/">Anacron</a></p></h3><p>Advantage over <code>cron</code></p>
<ul>
<li>More useful on systems that <u>frequently shut down</u> :<br>  Ensures regular maintenance jobs are executed at reasonable <strong>intervals</strong></li>
<li>  Run from <strong>system startup script</strong></li>
</ul>
<br>

<p><strong>Config</strong> <code>anacron</code></p>
<ul>
<li>  Config file - <code>/etc/anacrontab</code></li>
<li>Fields<ul>
<li>  Frequency - in <strong>days</strong></li>
<li>  Delay - in <strong>mins</strong> (keep system from overloaded at boot time)</li>
<li>  Identifier</li>
<li>  Command</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># weekly job, delay for 10 min</span></span><br><span class="line">7  10  cron.weekly  run-parts  /etc/cron.weekly</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Create</strong> <code>anacron</code> jobs ( 2 ways )</p>
<ul>
<li>  Create <strong><code>cron</code> job</strong> to run <code>anacron</code>  📌 </li>
<li>  Use <strong>startup</strong> script - Can slow down performance during boot time, if running time-consuming task</li>
</ul>
<div class="note primary"><p><strong>Disable</strong> any <code>cron</code> jobs that handled by <code>anacron</code>. Otherwise tasks will be performed <strong>twice</strong>.</p>
</div>

<br>





<h3 id="3-At"><a href="#3-At" class="headerlink" title="3 - At"></a><p align="center">3 - At</p></h3><blockquote>
<p>  For running <strong>once-off</strong> jobs in the future</p>
</blockquote>
<br>

<p><strong>Time</strong></p>
<ul>
<li>  Standard time - <code>HH:MM</code></li>
<li>  Standard date - <code>DD.MM.YY</code></li>
<li>  Keywords - <code>noon</code>, <code>midnight</code>, <code>teatime</code> (4pm)</li>
<li>  Specific <strong>period</strong> - <code>now + 2 hours</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use -f for filename</span></span><br><span class="line">at -f script.sh 08:00 </span><br></pre></td></tr></table></figure>



<br>

<p><strong>Utilities</strong></p>
<ul>
<li>  <code>atd</code> - the daemon, checks <code>/var/soool/at</code>  📌 </li>
<li>  <code>atq</code> - list pending jobs</li>
<li>  <code>atrm</code> - remove job from queue (take <u>job number</u>, e.g.  <code>atrm 12</code>)</li>
<li>  <code>batch</code> - execute jobs when <u>system load &lt; 0.8</u></li>
</ul>
<br>

<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 106 Configure GUI &amp; Localization</title>
    <url>/2022/LPIC-106/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-106/#Configure-X">Configuring X Window System</a></li>
<li>  <a href="/2022/LPIC-106/#5-Remote-Access">X for Remote Access</a></li>
<li>  <a href="/2022/LPIC-106/#Localization">Localization</a></li>
<li>  <a href="/2022/LPIC-106/#Printing">Printing</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="Configure-X"><a href="#Configure-X" class="headerlink" title="Configure X"></a><p align="center">Configure X</p></h2><p>The main GUI in Linux is the X Window System (The <strong>X Server</strong>). Few extra topics beyond basic X configuration:</p>
<ul>
<li>  Fonts</li>
<li>  GUI login tools - <strong>Display Manager</strong> (e.g. GDM) - <u>Control the graphical <strong>login</strong></u></li>
<li>  <strong>Desktop Environments</strong> (e.g. Gnome)</li>
<li>  X for <strong>Remote Access</strong></li>
<li>  Accessibility - <strong>AccessX</strong> (acessibility control panels)</li>
</ul>
<br>

<p><strong>Serving the GUI component</strong></p>
<blockquote>
<p>  The <strong>windows manager</strong> communicates with the <strong>display server</strong> on behalf of the UI</p>
</blockquote>
<ul>
<li>  Desktop Environment (e.g. Gnome)</li>
<li>  Windows Manager (e.g. Mutter, Kwin, Muffin, Metacity)</li>
<li>Display Server (e.g. X)<ul>
<li>  <strong>Compositor</strong>: Arrange display elements within a window to create a screen image</li>
</ul>
</li>
</ul>
<br>



<h3 id="1-X-Basic"><a href="#1-X-Basic" class="headerlink" title="1 -X Basic"></a><p align="center">1 -X Basic</p></h3><blockquote>
<p>  <u>X is Linux’s GUI system. X isn’t a single program.</u></p>
</blockquote>
<br>



<p>Features for configuration: (As an example)</p>
<ul>
<li><p>  Mouse</p>
</li>
<li><p>  Keyboard layout</p>
</li>
<li><p>  Screen resolution</p>
</li>
<li><p>  Video refresh rate</p>
</li>
<li><p>  Display color depth</p>
</li>
<li><p><strong>Video card</strong> - X provides <strong>drivers</strong> that control the video card</p>
<blockquote>
<p>  Most modern computers include video hardware on the <strong>motherboard</strong></p>
</blockquote>
</li>
</ul>
<div class="note success"><p>Both AMD &amp; Nvidia drivers include Linux kernel drivers as a necessary component.<br>So if <strong>upgrade</strong> Linux kernel, need to <strong>reinstall drivers</strong>.</p>
</div>

<br>

<p><strong>X Server</strong> options</p>
<ul>
<li>  <a href="https://xfree86.org/">XFree86</a> - Open source. Basis for X11</li>
<li>  <a href="https://x.org/wiki/"><strong>X11</strong></a> - Open source</li>
<li>  Accelerated-X - Commercial license, from <a href="https://xig.com/">Xi Graphics</a> (Improvement on compatibility with video cards)</li>
</ul>
<br>

<p><strong>Config Notes</strong></p>
<ul>
<li>  Cmdline Tools: <code>sudo Xorg -configure</code>  (File location: <code>/root/xorg.conf.new</code>)</li>
<li>  <strong>Main</strong> config file: <code>/etc/X11/xorg.conf</code></li>
<li><strong>X Accessibility</strong><ul>
<li>  Magnifier (<code>kmag</code>) - Enlarges the area around the mouse cursor</li>
</ul>
</li>
</ul>
<br>

<p><strong>Test X Config Changes</strong></p>
<ul>
<li><p>Boot Linux to <strong>text mode</strong></p>
<ul>
<li>  Redhat - <code>telinit 3</code></li>
<li>  Debian - <code>/etc/init.d/gdm stop</code> (Shut down <strong>Display Manager</strong>)</li>
</ul>
</li>
<li><p>  Change config via command line</p>
</li>
<li><p>  Start X server: <code>startx</code> 📌</p>
</li>
<li><p>Logout &amp; Restore to <strong>GUI login</strong> mode</p>
<ul>
<li>  Redhat - <code>telinit 5</code></li>
<li>  Debian - <code>/etc/init.d/gdm start</code></li>
</ul>
</li>
<li><p>Can also boot into Graphics mode, then <strong>kill</strong> the X server.</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get X</span></span><br><span class="line">ps aux | grep X</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill by PID</span></span><br><span class="line"><span class="built_in">kill</span> [PID]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>X Config Options</strong></p>
<blockquote>
<p>  Edit config file: Identify the feature that’s not working, and focus on the section that controls this feature.</p>
</blockquote>
<div class="note danger"><p>An <strong>incorrect</strong> config of the <strong>video card</strong> is likely to cause <strong>failures in starting X</strong>.</p>
</div>

<br>

<p>1 - <code>Module</code></p>
<ul>
<li>  Controls loading X server modules - <strong>drivers</strong> for specific features / hardware</li>
<li>  If X configuration works, <u>don’t adjust <code>Module</code> manually</u></li>
</ul>
<p>2 - <code>InputDevice</code> (<strong>Keyboard</strong> + <strong>Mouse</strong>)</p>
<ul>
<li>  <code>Identifier</code> - ser defined label, to use in <code>ServerLayout</code> section</li>
<li>  <code>Driver</code> - keyboard drivers: <code>kbd</code>, <code>Keyboard</code>, <code>evdev</code></li>
</ul>
<p>3 - <code>Monitor</code></p>
<ul>
<li>  <code>ModelName</code> - user-defined name</li>
<li><code>HorizSync</code> &amp; <code>VertRefresh</code> 📌<ul>
<li>  Horizontal  (<strong>kHz</strong>)  &amp; Vertical (<strong>Hz</strong>) refresh rates</li>
<li>  Together define <u>monitor’s max resolution &amp; refresh rate</u></li>
</ul>
</li>
<li><code>Modeline</code><ul>
<li>  Look through modeline to select a resolution</li>
<li>  X11 supports Data Display Channel (<strong>DDC</strong>) - Monitor can communicate max refresh rates &amp; mode lines to the computer</li>
</ul>
</li>
</ul>
<p>4 - <code>Device</code> (e.g. <strong>Video Card</strong>)</p>
<ul>
<li><p>  X sends data to monitor via <strong>video card</strong> - Video card also controls monitor resolution</p>
</li>
<li><p>Set device driver - <code>Driver &quot;nv&quot;</code></p>
<ul>
<li>  Drivers location: <code>/usr/lib64/xorg/modules/drivers/xx_drv.o</code></li>
<li>  Nvidia - <code>nv</code> / <code>nouveau</code></li>
<li>  AMD - <code>radeon</code></li>
<li>  Intel - <code>intel</code></li>
</ul>
</li>
<li><p>Graphical video modes require some <strong>RAM</strong> on the <strong>video card</strong> (BIOS will reserve some system RAM)</p>
<blockquote>
<p>  Modern video cards ship with large RAM to support <strong>3D acceleration</strong></p>
</blockquote>
</li>
</ul>
<p>5 - <code>Screen</code></p>
<ul>
<li>  Combination of monitos + video cards</li>
<li>  Choose between <code>Display</code> subsections: add option <code>DefaultDepth</code></li>
</ul>
<p>6 - <code>ServerLayout</code></p>
<ul>
<li>  Links all above components - Usually Screen &amp; Keyboard &amp; Mouse</li>
<li>  <strong>Multi-head display</strong> - multiple monitors combined to form one large desktop</li>
</ul>
<br>

<p><strong>X Display Info</strong></p>
<ul>
<li><p><code>xdpyinfo</code> - display info for all available extensions</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">xdpyinfo -ext [name]</span><br></pre></td></tr></table></figure>

</li>
<li><p><code>xwininfo</code> - window info</p>
<ul>
<li>  Colormap</li>
<li>  Bit Gravity State</li>
</ul>
</li>
</ul>
<br>

<h4 id="Wayland-Server"><a href="#Wayland-Server" class="headerlink" title="Wayland Server"></a><u>Wayland Server</u></h4><blockquote>
<p>  <a href="https://wayland.freedesktop.org/">Wayland Website</a></p>
</blockquote>
<p>Wayland is a <strong>replacement of X</strong> Windows System</p>
<ul>
<li>  Initial release was in 2009, now used by many desktop environments, e.g. Gnome Shell &amp; KDE Plasma</li>
<li>  Wayland native applications <u>won’t use X at all</u></li>
<li>  Fewer video card problems</li>
</ul>
<br>

<p>Check if display server is Wayland</p>
<ul>
<li><p>Method 1 - Check env var</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$WAYLAND_DISPLAY</span></span><br></pre></td></tr></table></figure></li>
<li><p>Method 2 - Use <code>loginctl</code></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get GUI session number</span></span><br><span class="line">loginctl </span><br><span class="line"></span><br><span class="line"><span class="comment"># show type (Type=Wayland)</span></span><br><span class="line">loginctl show-session [session number] -p Type</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<p><strong>Turn off</strong> Wayland</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># edit file: WaylandEnable=false</span></span><br><span class="line">sudo /etc/gdm3/custom.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reboot</span></span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>



<br>

<p>More about Wayland</p>
<ul>
<li>Compositor: <strong>Weston</strong><ul>
<li>  Weston is a <strong>reference implementation</strong> - As a compistor requirements example</li>
</ul>
</li>
<li>For backward compatibility: <strong>XWayland</strong><ul>
<li>  Allows X-dependent applications to run on X server &amp; display via Wayland session</li>
</ul>
</li>
</ul>
<div class="note info"><p>If system running fine under X, but problems under Wayland </p>
<ul>
<li>  Check <strong>graphics card</strong></li>
<li>  Go to graphics card vendor’s website, check if the <strong>driver</strong> support Wayland</li>
</ul>
</div>





<br>

<h3 id="2-X-Fonts"><a href="#2-X-Fonts" class="headerlink" title="2 - X Fonts"></a><p align="center">2 - X Fonts</p></h3><p><strong>Notes</strong></p>
<ul>
<li>  X’s <strong>core font</strong> system can be setup form the X config file (managed <strong>directly</strong> by X)</li>
<li><strong>Font server</strong><ul>
<li>  Deliver fonts via network protocols</li>
<li>Integrate with X core fonts, but run as separate programs</li>
</ul>
</li>
</ul>
<ul>
<li>Most modern program are using a <strong>new</strong> font system - <strong>Xft</strong> (to replace X core fonts)<ul>
<li>  Xft bypass the core font system to provide <strong>client-side</strong> fonts</li>
</ul>
</li>
</ul>
<br>

<p><strong>Font Formats</strong></p>
<ul>
<li><strong>Bitmap</strong> fonts<ul>
<li>  Each font must be optimized for display at a particular resolution</li>
</ul>
</li>
<li><strong>Outline</strong> fonts (<strong>Scalable</strong>)<ul>
<li>  Represent each character as a series of lines &amp; curves in a <u>high-resolution matrix</u></li>
<li>  Scaling is <strong>imperfect</strong> - Scalable fonts often look slightly worse than bitmap fonts</li>
<li>  Scaling takes <strong>more CPU</strong> time - But on modern CPU it’s not really an issue</li>
<li>Font rendering<ul>
<li>  Apple <strong>TrueType</strong> - <code>freetype</code> (<code>.ttf</code>)</li>
<li>  Adobe PostScript <strong>Type 1</strong> - <code>type1</code> (<code>.pfa</code>, <code>.pfb</code>)</li>
</ul>
</li>
</ul>
</li>
</ul>
<br>

<p><strong>X Core Fonts</strong></p>
<ul>
<li><p>  Font directory: <code>/usr/share/X11/fonts</code></p>
</li>
<li><p>  Store fonts elsewhere to prevent wiping from upgrade: <code>/opt/fonts</code>, <code>/usr/local/fonts</code></p>
</li>
<li><p>Create font file</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create font.dir file for trutype</span></span><br><span class="line">ttmkdir</span><br><span class="line"></span><br><span class="line"><span class="comment"># For type 1</span></span><br><span class="line">typelinst</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply to both type1 &amp; truetype</span></span><br><span class="line">mkfontscale</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<h3 id="3-Display-Manager"><a href="#3-Display-Manager" class="headerlink" title="3 - Display Manager"></a><p align="center">3 - Display Manager</p></h3><div class="note info"><p>X’s GUI login system uses <strong>XDMCP server</strong>. It starts X &amp; manages X display</p>
</div>



<p>X is a <strong>network-enabled</strong> GUI</p>
<ul>
<li>  The <strong>login system</strong> uses a network login protocol - <strong>XDMCP</strong> (X Display Manager Control Protocol)</li>
<li>  For <strong>remote</strong> login - XDMCP server listens for connections from remote X server</li>
<li>  For <strong>local</strong> login - XDMCP starts the local X server</li>
</ul>
<br>

<p>Common <strong>XDMCP</strong> servers (i.e. <strong>Display Managers</strong>)</p>
<ul>
<li>  XDM - oldest</li>
<li>  MDM - recursive acronym. Derivative of GDM</li>
<li>  <strong>GDM</strong> - for Gnome</li>
<li>  <strong>KDM</strong> - for KDE</li>
<li>  <strong>LightDM</strong> - bare-bone display manager for <strong>lightweight</strong> desktop environments like <strong>Xfce</strong></li>
</ul>
<br>

<p><strong>Select</strong> Display Manager</p>
<ul>
<li>  Select via config file - <code>/etc/sysconfig</code>, set <code>DISPLAYMANAGER=/bin/gdm</code></li>
<li>  Select via <code>systemd</code> startup script</li>
</ul>
<br>

<p><strong>Configure</strong> Display Manager</p>
<ul>
<li><strong>XDM</strong><ul>
<li>  Main config file - <code>/etc/X11/xdm/xdm-config</code></li>
<li>  Control remote access - <code>/etc/X11/xdm/Xaccess</code></li>
</ul>
</li>
<li><strong>KDM</strong><ul>
<li>  File location - <code>/etc/X11/kdm</code>, <code>/etc/kde/kdm</code></li>
<li>  Try searching KDM config files in <code>kdm</code> or <code>kdebase</code> package</li>
<li>  Expands on XDM - User can select <strong>session type</strong> when login</li>
<li>  Extra options - <code>kdmrc</code> file, <code>[Xdmcp]</code> section is for network operations</li>
</ul>
</li>
<li><strong>GDM</strong><ul>
<li>  File location - <code>/etc/X11/gdm</code></li>
<li>  Set local options in <code>custom.conf</code> file</li>
<li>  GDM settings tool - <code>gdmconfig</code> or <code>gdmsetup</code></li>
</ul>
</li>
</ul>
<br>

<h3 id="4-Desktop-Environment"><a href="#4-Desktop-Environment" class="headerlink" title="4 - Desktop Environment"></a><p align="center">4 - Desktop Environment</p></h3><h4 id="KDE-Plasma"><a href="#KDE-Plasma" class="headerlink" title="KDE Plasma"></a><u>KDE Plasma</u></h4><ul>
<li>  Display Manager - <strong>SDDM</strong> (Simple Desktop DM)</li>
<li>  File Manager - <strong>Dolphin</strong></li>
<li>  Windows Manager - <strong>Kwin</strong></li>
</ul>
<br>



<h4 id="Gnome"><a href="#Gnome" class="headerlink" title="Gnome"></a><u>Gnome</u></h4><ul>
<li>  Display Manager - <strong>GDM</strong></li>
<li>  File Manager - Gnome Files (Formerly: <strong>Nautilus</strong>)</li>
<li>  Windows Manager - <strong>Mutter</strong></li>
</ul>
<br>



<h4 id="Cinnamon"><a href="#Cinnamon" class="headerlink" title="Cinnamon"></a><u>Cinnamon</u></h4><blockquote>
<p>  Fork of Gnome 3</p>
</blockquote>
<ul>
<li>  Display Manager - <strong>LightDM</strong></li>
<li>  File Manager - Nemo (Fork of <strong>Nautilus</strong>)</li>
<li>  Windows Manager - Muffin (Fork of <strong>Mutter</strong>)</li>
</ul>
<br>



<h4 id="Xfce"><a href="#Xfce" class="headerlink" title="Xfce"></a><u>Xfce</u></h4><ul>
<li>  Display Manager - <strong>LightDM</strong></li>
<li>  File Manager - <strong>Thunar</strong></li>
<li>  Windows Manager - <strong>Xfwm</strong> (utilize its own compositor manager)</li>
</ul>
<br>

<p><strong>More about Xfce</strong></p>
<ul>
<li>  Lightweight environment: Not much CPU &amp; memory consumption compared to the above ones</li>
<li>Developed in 1996, as extension of <strong>CDE</strong> (Unix Common Desktop Environment)<br>  Use XForms graphical toolkit (<strong>Xf</strong>ce)</li>
<li>  Rewritten and no longer use codes from CDE / XForms, but remain to be lightweight</li>
</ul>
<br>

<h4 id="Other"><a href="#Other" class="headerlink" title="Other"></a><u>Other</u></h4><p>Install <strong>MATE</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo tasksel install ubuntu-mate-desktop</span><br></pre></td></tr></table></figure>





<br>

<h3 id="5-Remote-Access"><a href="#5-Remote-Access" class="headerlink" title="5 - Remote Access"></a><p align="center">5 - Remote Access</p></h3><blockquote>
<p>  📌 只有 X Server 的 client-server model 是<strong>反过来</strong>的：Remote X clients access your X server.</p>
</blockquote>
<h4 id="X-Server"><a href="#X-Server" class="headerlink" title="X Server"></a><u>X Server</u></h4><br>

<p><strong>X Client-Server</strong></p>
<ul>
<li>  In most cases, X server &amp; client are on the <strong>same</strong> computer</li>
<li>  By <strong>default</strong>, X server only responds to <strong>local</strong> access requsts (as <strong>security</strong> measure)</li>
<li>  <code>xhost</code> <strong>port</strong>: <code>6000</code> to <code>6063</code> (set firewall policy for connection to pass through)</li>
<li>  <code>xauth</code> - add, remove &amp; list remote hosts in X11 config file</li>
</ul>
<br>

<p>Using <strong>Remote X Client</strong></p>
<blockquote>
<p>  Access remote machine (<code>remote</code>) via machine (<code>local</code>)<br>  Use compute resource on <code>remote</code>, while using GUI on <code>local</code></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># local: connect to remote</span></span><br><span class="line">xhost +remote</span><br><span class="line"></span><br><span class="line"><span class="comment"># remote: export display to local</span></span><br><span class="line"><span class="built_in">export</span> DISPLAY=<span class="built_in">local</span>:0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># local: close connection</span></span><br><span class="line">xhost -remote</span><br></pre></td></tr></table></figure>

<br>

<h4 id="Tunneling-X-via-SSH"><a href="#Tunneling-X-via-SSH" class="headerlink" title="Tunneling X via SSH"></a><u>Tunneling X via SSH</u></h4><blockquote>
<p>  <strong>X11 forwarding</strong> - Remote GUI interactions within a <strong>secure</strong> channel</p>
</blockquote>
<br>

<p><strong>Encrypting X connection with SSH</strong></p>
<ul>
<li>  Encryption might <strong>slow</strong> down X access - Enable <strong>SSH compression</strong></li>
<li>  Preferred &amp; Secured: <strong>Tunneling X via SSH</strong></li>
<li>Change SSH config (enable <strong>forwarding</strong>)<ul>
<li>  <strong>Client</strong> - <code>/etc/ssh/ssh_config</code>. Use <code>SSH -X</code>,  set <code>ForwardX11 yes</code></li>
<li>  <strong>Server</strong> - <code>/etc/sh/sshd_config</code>, set  <code>X11Forwarding yes</code></li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ssh -X user@remote</span><br></pre></td></tr></table></figure>



<div class="note danger"><p>SSH can <strong>tunnel</strong> network connections: Carry <strong>another potocol</strong> via its own encrypted connection.</p>
<p><strong>Never</strong> use <code>SSH -Y</code>, because it treats remote connection as <strong>trusted</strong>, which imposes security risks.</p>
</div>

<br>

<h4 id="VNC"><a href="#VNC" class="headerlink" title="VNC"></a><u>VNC</u></h4><p><strong>Notes</strong></p>
<ul>
<li>  VNC - Virtual Network Computing</li>
<li>VNC is a <strong>cross-platform</strong> protocol, uses the <strong>RFB</strong> protocol (Remote Frame Buffer)<ul>
<li>  Allows client to send <strong>GUI commands</strong> (mouse clicks) to the server</li>
<li>  Server sends <strong>desktop frames</strong> back to client</li>
</ul>
</li>
</ul>
<ul>
<li>Ports<ul>
<li>  Server port -<code>TCP 5900 + n</code> (display number, usually port <code>5901</code>)</li>
<li>  Java-enabled browser - <code>TCP 5800 + n</code></li>
</ul>
</li>
</ul>
<br>

<p>2 types of desktop UIs</p>
<ul>
<li>  <strong>Persistent</strong> - Persist GUI session state. Only available via <strong>browser</strong> access</li>
<li>  <strong>Static</strong> - Does not save state. Always show the default desktop environment</li>
</ul>
<br>

<p><strong>Pros &amp; Cons</strong></p>
<ul>
<li>  Desktop is available for multiple users</li>
<li>  VNC only handles mouse &amp; keyboard input. Does not provide file / audio transfer</li>
<li>  No traffic encryption by itself</li>
<li>  Password stored in plaintext in server file</li>
</ul>
<br>

<p><a href="https://tigervnc.org/"><strong>TigerVNC</strong></a></p>
<ul>
<li>  Improvement of <a href="https://www.realvnc.com/en/"><strong>RealVNC</strong></a></li>
<li><strong>Server</strong><ul>
<li>  Install - <code>tigervnc-server</code></li>
<li>  Control -  <code>vncserver</code>, <code>vncconfig</code></li>
</ul>
</li>
<li><strong>Client</strong><ul>
<li>  Install - <code>tigervnc</code></li>
<li>  Control - <code>vncviewer</code></li>
</ul>
</li>
<li>  Use <strong>SSH port forwarding</strong> for VNC server ports - Allow traffic via <strong>port <code>22</code></strong></li>
</ul>
<br>

<h4 id="Remote-Desktop"><a href="#Remote-Desktop" class="headerlink" title="Remote Desktop"></a><u>Remote Desktop</u></h4><p><strong>Xrdp</strong></p>
<ul>
<li><p>  Alternative to VNC. Use <strong>RDP</strong> (Remote Desktop Protocol)</p>
</li>
<li><p>Standard RDP port -  <strong><code>TCP 3389</code></strong></p>
</li>
</ul>
<br>

<p><strong>NX</strong></p>
<ul>
<li>  NX protocol, created by <a href="https://www.nomachine.com/">NoMachine</a> in 2001</li>
<li>  <strong>Compress X11 data</strong> - Excellent response time even over low-bandwidth connections</li>
<li>  Faster than VNC-based connections</li>
<li>  <strong>SSH tunneling by default</strong></li>
<li>  Support multiple simultaneous users via a single network port</li>
</ul>
<br>

<p><a href="https://spice-space.org/"><strong>SPICE</strong></a> (Simple Protocol for Independent Computing Environments)</p>
<ul>
<li>  X.org version - <strong>Xspice</strong></li>
<li>  Provide connections with KVM <strong>virual machines</strong></li>
<li>  Client uses <strong>multiple</strong> data <strong>socket</strong> connections</li>
<li>  Consumes low amount of CPU</li>
<li><strong>Strong security</strong><ul>
<li>  Traffic encrypted using <strong>TLS</strong></li>
<li>  Authentication - <strong>SASL</strong> (Simple Authentication and Security Layer), supports <strong>Keberos</strong></li>
</ul>
</li>
</ul>
<div class="note success"><p>Both <strong>VNC &amp; SPICE</strong> provide remote desktop connections to <strong>KVM</strong> vrirtual machines.</p>
</div>



<br>

<br>

<h2 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a><p align="center">Localization</p></h2><blockquote>
<ul>
<li><p>  <code>timedatectl</code> - Manage time &amp; date</p>
</li>
<li><p>  <code>localectl</code> - Manage locale</p>
</li>
</ul>
</blockquote>
<br>



<h3 id="1-Time-Zone"><a href="#1-Time-Zone" class="headerlink" title="1 - Time Zone"></a><p align="center">1 - Time Zone</p></h3><p>Linux uses <strong>UTC</strong> (Coordinated Universal Time) by default</p>
<ul>
<li>Translate to local time  (<strong>Not</strong> a plain text file, cannot directly edit)<ul>
<li>  Debian - <code>/etc/timezone</code></li>
<li>  Redhat - <code>/etc/localtime</code></li>
</ul>
</li>
</ul>
<br>

<p><code>hwclock</code> - Set <strong>Hardware clock (RTC)</strong></p>
<ul>
<li>  Display internal BIOS / UEFI clock</li>
<li>  Provide access to hardware clock built into the physical server</li>
</ul>
<br>

<p><strong>Verify</strong> local time</p>
<blockquote>
<p>  <a href="https://www.timeanddate.com/time/zones/">Time zone code reference</a></p>
</blockquote>
<ul>
<li><p>  <code>tzselect</code> - determines timezone  ✅ </p>
</li>
<li><p><code>date</code> - 3-letter TZ code (<strong>legacy</strong> command)</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Set time &amp; date format</span></span><br><span class="line">date MMDDhhmm[[CC]YY][.ss]</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<p><strong>Change</strong> Time Zone</p>
<ul>
<li><p>  Tools - <code>tzsetup</code>, <code>tzselect</code>, <code>tzconfig</code></p>
</li>
<li><p>Create <strong>softlink</strong> from <strong>zonefile</strong> to <code>localtime</code></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># remove or rename original timezone</span></span><br><span class="line">sudo mv /etc/timezone /timezone.bkup</span><br><span class="line"></span><br><span class="line"><span class="comment"># create softlink</span></span><br><span class="line">sudo ln -s /usr/share/zoneinfo/US/Pacific /etc/timezone</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<p><strong>Use <code>timedatectl</code></strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show time &amp; date</span></span><br><span class="line">timedatectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># change time</span></span><br><span class="line">sudo timedatectl set-time <span class="string">&quot;2022-03-25 08:00:00&quot;</span></span><br></pre></td></tr></table></figure>



<div class="note info"><p>Most Linux system use <strong>NTP</strong> (network Time Protocol) to sync time &amp; date with centralized time server.<br>If use NTP, <strong>unable</strong> to alter time / date using <code>date</code> or <code>timedatectl</code> locally.</p>
</div>



<br>

<h3 id="2-Locale"><a href="#2-Locale" class="headerlink" title="2 - Locale"></a><p align="center">2 - Locale</p></h3><p><strong>Codeset</strong> / <strong>Charater set</strong></p>
<ul>
<li><p>  <strong>ASCII</strong> (American Standard Code for Information Interchange), <strong>7-bit</strong></p>
</li>
<li><p>  <strong>ISO-8859</strong></p>
</li>
<li><p>  <strong>Unicode</strong> - 3-byte code (24-bit) to represent every know character</p>
</li>
<li><p><strong>UTF</strong> (Unicode Transformation Format)<br>  Transform long unicode value to <strong>1-byte (UTF-8)</strong> or 2-bye (UTF-16) codes</p>
<ul>
<li><strong>UTF-8</strong> (8-bit)  ✅ <strong>New standard</strong><br>  Adopt UTF-8 over ISO-8859: No need to specify a <strong>substandard</strong></li>
</ul>
</li>
</ul>
<br>

<p><strong>Locale</strong>: Specify language, country &amp; related info for customizing display</p>
<ul>
<li>  Format - <code>lang_country.codeset</code> (e.g. <code>en_US.UTF-8</code>)</li>
</ul>
<br>

<p><strong>Locale options</strong></p>
<ul>
<li><p>File location - <code>/usr/bin/locale</code></p>
<ul>
<li>  <code>LC_PAPER</code> - paper size. e.g. US letter, or standard A4</li>
<li>  <code>LC_MEASUREMENT</code> - measuring units</li>
<li>  <code>LC_ALL</code> - Master override (all previous settings)</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check available locale</span></span><br><span class="line">locale -a</span><br><span class="line"></span><br><span class="line"><span class="comment"># show env var setting</span></span><br><span class="line">locale -ck</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Change locale</strong></p>
<ul>
<li><p>  <strong>Temporary</strong> - Export both in current shell</p>
</li>
<li><p>  <strong>Permanent</strong> - Add both lines in <code>~/.bashrc</code></p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># need both LC_ALL &amp; LANG</span></span><br><span class="line"><span class="built_in">export</span> LANG=en_GB.UTF-8</span><br><span class="line"><span class="built_in">export</span> LC_ALL=en_GB.UTF-8</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Use <code>localectl</code></strong>  (<code>systemd</code> is enabled)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show current setting</span></span><br><span class="line">localectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># list all available locales</span></span><br><span class="line">localectl list-locales</span><br><span class="line"></span><br><span class="line"><span class="comment"># change locale</span></span><br><span class="line">localectl set-locale LANG=xx</span><br></pre></td></tr></table></figure>



<br>

<p>Modify Text file <strong>codesets</strong>  📌 </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get encoding list</span></span><br><span class="line">iconv --list</span><br><span class="line"></span><br><span class="line"><span class="comment"># change from ISO-8859 to UTF-8</span></span><br><span class="line"><span class="comment"># -f (source), -t (destination)</span></span><br><span class="line">iconv -f iso-8859-1 -t UTF-8 1.txt &gt; 2.txt</span><br></pre></td></tr></table></figure>





<br>

<br>



<h2 id="Printing"><a href="#Printing" class="headerlink" title="Printing"></a><p align="center">Printing</p></h2><blockquote>
<p>  Two major <strong>visual output</strong> tool on the computer: <strong>Monitor &amp; Printer</strong></p>
</blockquote>
<br>



<h3 id="1-Linux-Printing-Architecture"><a href="#1-Linux-Printing-Architecture" class="headerlink" title="1 - Linux Printing Architecture"></a><p align="center">1 - Linux Printing Architecture</p></h3><div class="note success"><p>The Linux <strong>print queue</strong> is managed by <strong>CUPS</strong> (Common Unix Printing System)</p>
</div>



<p>Linux printing is built around the concept of <strong>print queue</strong></p>
<ul>
<li>  Print queue directory - <code>/var/spool/cups</code></li>
<li>  <strong>Network</strong>-oriented: Can accept print jobs from both remote &amp; local systems</li>
</ul>
<br>

<p><strong>PostScript</strong> &amp; <a href="https://pages.cs.wisc.edu/~ghost/"><strong>GhostScript</strong></a></p>
<ul>
<li>  <strong>PostScript</strong> - common printer language</li>
<li>  Printer <u><strong>driver</strong> - Between application &amp; print queue</u></li>
<li>Linux printer driver is part of <strong>GhostScript</strong> (<strong>translator</strong> for PostScript)<ul>
<li>  Some mid / low-end printers <u>does not directly support PostScript</u></li>
<li>  GhostScript takes PostScript input, and produces output in many different <strong>bitmap formats</strong></li>
<li>  Large GhostScript output file: Store briefly on <strong>hard disk</strong></li>
<li>  Fit Ghostcript into the print queue: <strong>Smart filter</strong></li>
</ul>
</li>
</ul>
<br>





<h3 id="2-Network-Printing"><a href="#2-Network-Printing" class="headerlink" title="2 - Network Printing"></a><p align="center">2 - Network Printing</p></h3><p><strong>CUPS</strong> (act as both server &amp; client)</p>
<ul>
<li>  Main config file - <code>/etc/cups/cupsd.conf</code></li>
<li>  <strong>Daemon</strong> runs in the <strong>background</strong>, watching for print jobs to be submitted</li>
<li>  <strong>Client</strong> pass print jobs to other computers</li>
<li>  Application can query CUPS about printer’s capabilities</li>
</ul>
<br>

<p><strong>CUPS Utilities</strong></p>
<ul>
<li>  Access CUPS daemon in browser: At <a href="http://localhost:631/">port <strong>631</strong></a>  📌 </li>
<li>  Authentication: <strong>root</strong> (username) &amp; root password</li>
</ul>
<br>

<p><strong>Network Printers</strong></p>
<ul>
<li><p>  <strong>IPP</strong> - Internet Printing Protocol</p>
</li>
<li><p>  Windows: <strong>SMB / CIFS</strong> (Server Message Block / Common internet File System)</p>
</li>
<li><p>  Linux <strong>Samba</strong> server - Enable <strong>file sharing</strong> between machines in a single network</p>
</li>
<li><p>Two ways of printing to Windows from Linux</p>
<ul>
<li><p>  <u>GhostScript</u> - Windows SMB is  <strong>non-PostScript</strong>, need a <strong>local Linux smart filter</strong> &amp; <strong>GhostScript driver</strong></p>
</li>
<li><p><u>PostScript</u>  - Print to Windows SMB queue from Linux via <strong>Samba</strong> (use <strong>PostScript driver</strong>)</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># URI for SMB share</span></span><br><span class="line">smb://username:password@SERVER/SHARE</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<br>



<h3 id="3-Commands"><a href="#3-Commands" class="headerlink" title="3 - Commands"></a><p align="center">3 - Commands</p></h3><blockquote>
<p>  <strong>Legacy BSD</strong> commands</p>
<ul>
<li>  <code>lpr</code></li>
<li>  <code>lpq</code></li>
<li>  <code>lprm</code></li>
<li>  <code>lpc</code></li>
</ul>
</blockquote>
<br>

<p><strong><code>lpr</code> - Submit</strong> print jobs</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">-P [<span class="built_in">queue</span>]	<span class="comment">// specify queue name</span></span><br><span class="line">-J [job]	<span class="comment">// job name</span></span><br><span class="line">-m [user]	<span class="comment">// notify user by email</span></span><br><span class="line">-# [number]	<span class="comment">// number of copies</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// Example: print pdf in myqueue, 3 copies. Then notify user kk</span></span><br><span class="line">lpr -P myqueue -# <span class="number">3</span> -m kk file.pdf</span><br></pre></td></tr></table></figure>

<br>

<p><strong><code>lpq</code> - Display info</strong> about print queue</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">lpq -P myqueue</span><br></pre></td></tr></table></figure>

<br>

<p><strong><code>lprm</code> - Remove</strong> print jobs</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Get job ID</span></span><br><span class="line">lpq -P xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove by job ID</span></span><br><span class="line">lprm 1630</span><br></pre></td></tr></table></figure>

<br>

<p><strong><code>lpc</code> - Control</strong> print queue</p>
<ul>
<li>  Start, stop &amp; reorder jobs within print queue</li>
<li>Other commands to control the queue<ul>
<li>  <code>cupsenable</code> - enable queue</li>
<li>  <code>cupsdisable</code> - disable queue</li>
<li>  <code>lpmove</code> - move job from one queue to anothe</li>
</ul>
</li>
</ul>
<br>

<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 105 Booting Linux</title>
    <url>/2022/LPIC-105/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-105/#Boot-Linux">Boot Linux system</a></li>
<li>  <a href="/2022/LPIC-105/#Init-SysV-amp-Systemd">SysV <code>service</code> &amp; systemd <code>systemctl</code></a></li>
<li>  <a href="/2022/LPIC-105/#2-Boot-Loader">Install Boot Manager</a></li>
<li>  <a href="/2022/LPIC-105/#Virtualization">Linux as Virtualization Guest</a></li>
</ul>
</div>

<span id="more"></span> 

<br>





<h2 id="Boot-Linux"><a href="#Boot-Linux" class="headerlink" title="# Boot Linux"></a># Boot Linux</h2><h3 id="1-Boot-Process"><a href="#1-Boot-Process" class="headerlink" title="1 - Boot Process"></a>1 - Boot Process</h3><p><strong>Steps</strong></p>
<ul>
<li><p>Turn on computer</p>
<blockquote>
<p>  Special hardware circuit causes the <strong>CPU</strong> to look at pre-determined address, and execute <strong>firmware</strong> stored in that location </p>
</blockquote>
</li>
<li><p><u><strong>Firmware</strong></u></p>
<ul>
<li>  Motherboard firmware performs Power-On-Self-Test (<strong>POST</strong>)</li>
<li>  Initialize &amp; configure hardware to a known operational state</li>
<li>  Loads <strong>boot loader</strong> from <u>boot device</u> (<strong>first</strong> hard disk)</li>
<li>  Pass control to <strong>boot loader</strong></li>
</ul>
</li>
<li><p><u><strong>Boot loader</strong></u> loads the OS kernel, or chainload another loader</p>
<ul>
<li>  <strong>BIOS</strong> - MBR</li>
<li>  <strong>EFI</strong> - ESP</li>
</ul>
</li>
<li><p><u><strong>Linux kernel</strong></u> program loads into <strong>memory</strong></p>
<ul>
<li>  Initializing devices</li>
<li>  <strong>Mount</strong> the root partition</li>
<li>Load &amp; execute the initial program (<code>/sbin/init</code>)<br>  <code>/sbin/init</code> has PID = 1, and reads from <code>/etc/inittab</code></li>
</ul>
</li>
<li><p>  <strong><u>Initialization</u></strong> - <code>init</code> starts the rest of the system services via <u><strong>startup scripts</strong></u> (SysV / systemd)</p>
</li>
<li><p>  Once Linux is running, it <u>doesn’t use BIOS services for I/O</u>.  It uses its own drivers to access hardware</p>
</li>
</ul>
<div class="note success"><p><strong>Boot without a keyboard</strong></p>
<ul>
<li>  Many won’t boot, if keyboard is unplugged</li>
<li>Firmware option: <strong>Halt On</strong><br>  Tells firmware in what situation it should <strong>refuse</strong> to boot</li>
</ul>
</div>





<br>



<h4 id="BIOS"><a href="#BIOS" class="headerlink" title="BIOS"></a><u>BIOS</u></h4><blockquote>
<p>  BIOS &amp; UEFI are embedded <strong>firmware</strong> to start the boot process (launch boot loader program)</p>
</blockquote>
<br>

<p><strong>Notes</strong></p>
<ul>
<li><p>  Boot process begin by reading <strong>boot sector</strong> (first sector) from disk, then execute the code</p>
</li>
<li><p>Boot options for BIOS-based computers are <strong>limited</strong> </p>
<ul>
<li>  Can only select the <strong>order</strong> in which boot devices are examined, to find the boot sector</li>
<li>  SCSI disks &amp; SATA disks <strong>won’t appear</strong> in the main BIOS disk-detection screen</li>
</ul>
</li>
</ul>
<br>

<p><strong>Most important limitation</strong></p>
<p>Can only read <strong>one sector’s data</strong> from hard drive into memory to run</p>
<ul>
<li>  Not enough space to load entire OS</li>
</ul>
<p><strong>Work-around</strong>: Split boot process into <strong>2 parts</strong></p>
<ul>
<li><p>BIOS runs <strong>boot loader</strong> program : init. hardware &amp; find and run full OS program</p>
<blockquote>
<p>  BIOS finds boot loader program :  internal / external hard drive, CD / DVD, USB, ISO, etc.</p>
<p>  Boot loader program usually has a <strong>config</strong> file</p>
</blockquote>
</li>
<li><p>Boot loader program points to OS kernel file / another boot loader program</p>
<blockquote>
<p>  <u>No size limitation</u> on the kernel boot file</p>
</blockquote>
</li>
</ul>
<br>

<div class="note info"><p>BIOS <strong>2</strong> important functions</p>
<ul>
<li>  Configures <strong>hardware</strong> (built into motherboard &amp; on different plug-in cards)</li>
<li>  Begins <strong>boot process</strong>, pass control to the <strong>boot loader</strong> in MBR</li>
</ul>
</div>



<br>



<h4 id="UEFI"><a href="#UEFI" class="headerlink" title="UEFI"></a><u>UEFI</u></h4><blockquote>
<p>  UEFI: <strong>U</strong>nified <strong>E</strong>xtensible <strong>F</strong>irmware <strong>I</strong>nterface</p>
</blockquote>
<br>

<p>Check whether system is using EFI:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ls /sys/firmware/efi	<span class="comment"># no such file: BIOS</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Notes</strong></p>
<ul>
<li><p>Boot process involves read <strong>boot loader file</strong> from filesystem, on <strong>ESP</strong> (EFI System Partition)</p>
<ul>
<li><p>  EFI begins boot redirection from the <strong>firmware</strong> level</p>
</li>
<li><p>  ESP use <strong>FAT</strong> filesystem to store boot loader program</p>
</li>
<li><p>  ESP is mounted in <code>/boot/efi</code> , boot loader file: <code>.efi</code> (stores separate boot loader for each OS)</p>
</li>
</ul>
</li>
<li><p>Present extended range of boot options</p>
<blockquote>
<p>  e.g. Default boot loader files from multiple boot loaders on the computer’s hard disk,<br>  or various devices (e.g grant precedence to bootable USB)</p>
</blockquote>
</li>
<li><p>  With UEFI: need to register each boot loader file to appear at boot time</p>
</li>
<li><p>  <strong>No size limit</strong> for <u>loading boot loader program</u>: Possible to load OS kernel <strong>directly</strong> without boot loader</p>
</li>
</ul>
<div class="note default"><p>For <strong>security</strong> reason, better to make <strong>first</strong> hard disk as the <strong>only</strong> boot device</p>
</div>

<br>



<h3 id="2-Boot-Loader"><a href="#2-Boot-Loader" class="headerlink" title="2 - Boot Loader"></a>2 - Boot Loader</h3><p><strong>Primary boot loader</strong></p>
<ul>
<li>  Examine partition table, locates the <u>bootable partition</u></li>
<li>  Or locates <u>OS kernel</u> &amp; execute directly</li>
</ul>
<p>Boot loader &amp; Boot manager</p>
<ul>
<li>  <strong>Boot loader</strong>: loads kernel into memory, and transfers control to it</li>
<li>  <strong>Boot manager</strong>:  presents a menu of boot options</li>
</ul>
<div class="note warning"><p><strong>Superblock</strong> is part of the filesystem. It describes basic filesystem features such as size, status.</p>
<p>On BIOS based computers, superblock can hold a <strong>portion of the boot loader</strong>, so damaging it can cause boot problems.</p>
<ul>
<li>  Fix: <code>fsck</code> to repair filesystem</li>
</ul>
</div>





<br>

<h4 id="Grub-Legacy"><a href="#Grub-Legacy" class="headerlink" title="Grub Legacy"></a><u>Grub Legacy</u></h4><ul>
<li>  Supports BIOS, but not EFI</li>
<li>  Disk &amp; partition: both <u>indexes start from <strong>0</strong></u>. e.g. <code>(hd0, 0)</code></li>
<li>  Doesn’t distinguish between PATA, SATA, SCSI: First SCSI drive is <code>hd0</code></li>
<li>  Treat USB as hard disk</li>
<li>Config file<ul>
<li>  <strong>Two</strong> sections:  <strong>Global</strong> definitions &amp; <strong>OS</strong> boot definitions</li>
<li>  <code>/boot/grub/menu.lst</code></li>
<li><code>/boot/grub/grub.conf</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>Options</strong></p>
<ul>
<li><p>  <code>splashimage</code>: Background image for boot menu</p>
</li>
<li><p>  <code>default=</code> : which OS to boot</p>
</li>
<li><p>  <code>timeout=</code>: wait for user input before booting the default OS</p>
</li>
<li><p>  <code>chainloader</code>: pass control to another boot loader</p>
</li>
<li><p><code>initrd</code>: Initial RAM disk (contains <strong>drivers</strong> for <u>kernel to interact with system hardware</u>)</p>
<blockquote>
<p>  Replaced by <strong><code>initramfs</code></strong> (initial RAM filesystem)</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Install</strong></p>
<ul>
<li><p>Install to the first sector (<strong>MBR</strong>): <code>grub-install /dev/sda</code></p>
<blockquote>
<p>  Install on a hard disk, not on a partition</p>
</blockquote>
</li>
</ul>
<div class="note primary"><p>Remember to install grub when changes are made to the <u>disk configuration</u>.<br>e.g. <u>Resizing / moving the GRUB root partition</u></p>
</div>

<br>

<h4 id="Grub-2"><a href="#Grub-2" class="headerlink" title="Grub 2"></a><u>Grub 2</u></h4><blockquote>
<p>  Boot loader + Boot manager</p>
<p>  Grub Manual at <a href="https://www.gnu.org/software/grub/manual/grub/grub.html">GNU website</a></p>
</blockquote>
<br>

<p><strong>Notes</strong></p>
<ul>
<li><p>  BIOS + EFI</p>
</li>
<li><p>Config file (<u>never edit explicitly</u>): </p>
<ul>
<li><p>  BIOS: <code>/boot/grub/grub.cfg</code></p>
</li>
<li><p>  UEFI: <code>/boot/efi/EFI/[distro]</code></p>
</li>
</ul>
</li>
</ul>
<ul>
<li>  <strong>Modify</strong>: <code>/etc/default/grub</code>  (global commands)</li>
<li>  Support loadable modules for specific filesystems &amp; operation modes</li>
<li>  Partition indexes start from <strong>1</strong>, support GPT: <code>(hd0, gpt2)</code></li>
<li>  Files in <code>/etc/grub.d</code>: control particular GRUB OS <strong>probers</strong></li>
</ul>
<br>

<p><strong>Options</strong></p>
<ul>
<li><p>  <code>Menuentry</code>: 1st line for each boot definition section</p>
</li>
<li><p>  <code>initrdefi</code>: initial RAM filesystem (for UEFI system only)</p>
</li>
<li><p>  Install: <code>grub-install</code></p>
</li>
<li><p>Update: <code>update grub</code>  📌</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># equivalent to</span></span><br><span class="line">grub-mkconfig -o &gt; /boot/grub/grub.cfg</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<p><strong>Kernel Boot Parameters</strong></p>
<blockquote>
<p>  Reference: <a href="https://kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt">Linux Kernel Archive</a></p>
</blockquote>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>debug</code></td>
<td>Enable kernel debugging</td>
</tr>
<tr>
<td><code>init=</code></td>
<td>Execute specific program. e.g. <code>/bin/bash</code> instead of <code>/sbin/init</code></td>
</tr>
<tr>
<td><code>initrd=</code></td>
<td>Change location of inital RAM filesystem</td>
</tr>
<tr>
<td><code>root=</code></td>
<td>Change root filesystem</td>
</tr>
<tr>
<td><code>ro</code></td>
<td>Mount root filesystem as <strong>read-only</strong></td>
</tr>
<tr>
<td><code>rootflags=</code></td>
<td>Set root filesystem’s mount options</td>
</tr>
<tr>
<td><code>single</code> / <code>Single</code> /<code>S</code> / <code>1</code></td>
<td>Boot into <strong>single-user</strong> mode (<strong>SysV</strong> init system only!)</td>
</tr>
<tr>
<td><code>systemd.unit=</code></td>
<td>Boot to specified <strong>target</strong> (<strong>Systemd</strong> system only!)</td>
</tr>
</tbody></table>
<br>

<h4 id="Other"><a href="#Other" class="headerlink" title="Other"></a><u>Other</u></h4><ul>
<li>  Syslinux</li>
<li>  <strong>LILO</strong> (Linux Loader)</li>
<li>  ELILO</li>
<li>  rEFIt</li>
<li>  rEFInd</li>
<li>  gummiboot</li>
</ul>
<br>

<p><strong>Secure boot</strong></p>
<ul>
<li>  Microsoft’s request of firmware feature</li>
<li>EFI-based computer will launch a boot loader,<br>  only if it’s been <u>cryptographically signed</u> with a key whose counterpart is stored in the <u>firmware</u></li>
</ul>
<br>

<p><strong>Fix damaged boot loader</strong></p>
<ul>
<li><p>  Try to boot a kernel from the hard disk</p>
</li>
<li><p>Use live image (e.g. <a href="https://www.supergrubdisk.org/">Super GRUB Disk</a>) </p>
<blockquote>
<p>  Bootable disc image with options to locate &amp; use the GRUB config file</p>
</blockquote>
</li>
</ul>
<br>

<h3 id="3-Boot-Info"><a href="#3-Boot-Info" class="headerlink" title="3 - Boot Info"></a>3 - Boot Info</h3><blockquote>
<ul>
<li>  <code>dmesg</code></li>
<li>  <code>/var/log</code></li>
</ul>
</blockquote>
<div class="note success"><p>Linux kernel &amp; module log information: <strong>Kernel ring buffer</strong></p>
</div>



<p><strong>Boot message</strong></p>
<ul>
<li><p><strong>Kernel ring buffer</strong> is stored under <code>/var/log/dmesg</code></p>
<ul>
<li>  Circular buffer, set to a predetermined size</li>
<li>  Held <u>in memory</u>, cleared &amp; regenerated after each boot</li>
<li>  If using <code>systemd-journald</code>, then boot messages are stored in a journal. Check with <code>journalctl</code></li>
</ul>
</li>
</ul>
<ul>
<li>  <strong>System logger</strong> (<code>syslogd</code>) : <code>/var/log/messages</code> or <code>/var/log/syslog</code></li>
</ul>
<br>

<p>Interpret boot message</p>
<ul>
<li><p>Look for <strong>hardware type</strong> names</p>
<blockquote>
<p>  Search for <code>SCSI</code> - Linux treats many disk devices as SCSI disks</p>
</blockquote>
</li>
<li><p>Hardware <strong>chipset</strong> name</p>
<blockquote>
<p>  <code>8169</code> for RealTek 8169 Ethernet interface</p>
</blockquote>
</li>
<li><p>Study the output from a <strong>working</strong> system</p>
<blockquote>
<p>  During boot, reveal message by pressing <code>Esc</code></p>
</blockquote>
</li>
</ul>
<br>

<br>

<h2 id="Init-SysV-amp-Systemd"><a href="#Init-SysV-amp-Systemd" class="headerlink" title="# Init: SysV &amp; Systemd"></a># Init: SysV &amp; Systemd</h2><p>The <strong>initialization daemon</strong> (<code>init</code>) determines which services are started, in what order</p>
<ul>
<li><p>  <strong>SysV</strong>: Based on Unix System V initialization daemon</p>
</li>
<li><p>  <strong>Systemd</strong>: located in <code>/etc</code>, <code>/bin</code>, <code>/sbin</code>, <strong><code>PID = 1</code></strong></p>
</li>
<li><p>Find <code>init</code> program</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># find init location</span></span><br><span class="line"><span class="built_in">which</span> init</span><br><span class="line"></span><br><span class="line"><span class="comment"># check linked file</span></span><br><span class="line">readlink -f /sbin/init</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<h3 id="1-SysV-amp-Runlevels"><a href="#1-SysV-amp-Runlevels" class="headerlink" title="1 - SysV &amp; Runlevels"></a>1 - SysV &amp; Runlevels</h3><br>

<h4 id="Runlevels"><a href="#Runlevels" class="headerlink" title="Runlevels"></a><u>Runlevels</u></h4><p>Runlevel <strong>0</strong>, <strong>1</strong>, and <strong>6</strong> are reserved for special purposes.</p>
<table>
<thead>
<tr>
<th>Runlevel</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0</strong></td>
<td>Power off (<code>sudo init 0</code>)</td>
</tr>
<tr>
<td><strong>1</strong> (or <code>s</code>, <code>S</code>)</td>
<td><strong>Single user mode</strong>. For low-level maintenance, e.g. resizing partitions</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td>Debian: Multi-user graphic mode</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td>Redhat: Multi-user text mode</td>
</tr>
<tr>
<td><strong>4</strong></td>
<td>For user <strong>customization</strong></td>
</tr>
<tr>
<td><strong>5</strong></td>
<td>Redhat: Multi-user graphic mode</td>
</tr>
<tr>
<td><strong>6</strong></td>
<td>Reboot (<code>sudo init 6</code>)</td>
</tr>
</tbody></table>
<br>

<p><strong><code>/etc/inittab</code></strong> file</p>
<ul>
<li><p>Format</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">id:runlevel:action:process</span><br></pre></td></tr></table></figure></li>
<li><p>Example</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">l0:0:<span class="built_in">wait</span>:/etc/init.d/rc 0</span><br><span class="line">...</span><br><span class="line">l6:6:<span class="built_in">wait</span>:/etc/init.d/rc 6</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<h4 id="SysV-Startup-Script"><a href="#SysV-Startup-Script" class="headerlink" title="SysV Startup Script"></a><u>SysV Startup Script</u></h4><ul>
<li><p>Location: </p>
<ul>
<li>  <code>/etc/init.d/rc</code>  📌</li>
<li>  <code>/etc/rc.d/rc</code></li>
</ul>
</li>
<li><p>  Crucial task: Run all the scripts associated with the runlevel</p>
</li>
<li><p>  Determine current runlevel: <code>runlevel</code></p>
</li>
<li><p>Change runlevel: </p>
<blockquote>
<p>  <code>reboot</code> &amp; <code>poweroff</code> are usually symlink to <code>halt</code></p>
</blockquote>
<ul>
<li>  <code>halt</code></li>
<li>  <code>reboot</code></li>
<li>  <code>poweroff</code></li>
</ul>
</li>
</ul>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># status</span></span><br><span class="line">service xx status</span><br><span class="line"></span><br><span class="line"><span class="comment"># show all status</span></span><br><span class="line">service --status-all</span><br><span class="line"></span><br><span class="line"><span class="comment"># start</span></span><br><span class="line">service xx start</span><br><span class="line"></span><br><span class="line"><span class="comment"># stop</span></span><br><span class="line">service xx stop</span><br></pre></td></tr></table></figure>



<br>

<h3 id="2-Systemd"><a href="#2-Systemd" class="headerlink" title="2 - Systemd"></a>2 - Systemd</h3><p><strong>Notes</strong></p>
<ul>
<li>  Parallel startup</li>
<li>  <strong>Master</strong> config: <code>/etc/systemd/system.conf</code></li>
</ul>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reload config file</span></span><br><span class="line">systemctl reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># reload config file for running services</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure unit to start at next boot</span></span><br><span class="line">systemctl <span class="built_in">enable</span> xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># check status: is-enabled, is-active, is-failed</span></span><br><span class="line">systemctl is-active xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># prevent unit from starting</span></span><br><span class="line"><span class="comment"># to undo: unmask</span></span><br><span class="line">systemctl mask xx</span><br></pre></td></tr></table></figure>

<p><strong>States</strong></p>
<ul>
<li>  <code>enabled</code> - start at <strong>system</strong> <strong>boot</strong></li>
<li>  <code>disabled</code> - doesn’t start at system boot</li>
<li>  <code>static</code> - only starts if another unit depends on it</li>
</ul>
<div class="note warning"><p><strong>Turn off</strong> the <code>less</code> pager for <code>systemctl</code> display:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">systemctl xx --nopager</span><br></pre></td></tr></table></figure>
</div>



<br>

<h4 id="Unit-Files"><a href="#Unit-Files" class="headerlink" title="Unit Files"></a><u>Unit Files</u></h4><p>A <strong>unit</strong> defines an <u>action / service / target</u> (group of services). Each unit consists of <strong>name</strong>, <strong>type</strong> &amp; <strong>config</strong> file.<br>Currently there’re <strong>12</strong> types of systemd unit file:</p>
<ol>
<li>  Automount</li>
<li>  Device</li>
<li>  Mount</li>
<li>  Path</li>
<li>  Scope</li>
<li>  Service</li>
<li>  Slice</li>
<li>  Snapshot</li>
<li>  Socket</li>
<li>  Swap</li>
<li>  Target (<strong>groups</strong> of services that start at system boot)</li>
<li>  Timer</li>
</ol>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show current status of all configured units</span></span><br><span class="line">systemctl list-units</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter by type</span></span><br><span class="line">systemctl list-units --<span class="built_in">type</span>=target</span><br><span class="line"></span><br><span class="line"><span class="comment"># show all unit files</span></span><br><span class="line">systemctl list-unit-files</span><br><span class="line"></span><br><span class="line"><span class="comment"># display a unit file</span></span><br><span class="line">systemctl cat xx.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># get default services</span></span><br><span class="line">systemctl get-default</span><br><span class="line"></span><br><span class="line"><span class="comment"># get help</span></span><br><span class="line">man -k systemd</span><br><span class="line">man systemd.directives</span><br></pre></td></tr></table></figure>



<br>

<p>The <code>default.target</code> ensures all required services are launched at system init. </p>
<ul>
<li>  <code>graphical.target</code> - GUI</li>
<li>  <code>multi-user.target</code> - Text</li>
<li>  <code>runlevel[n].target</code> - backward compatibility to <strong>legacy</strong> SysV (n = 1 to 5)</li>
</ul>
<br>

<p><strong>Directory location</strong> for a unit file is <strong>critical</strong>, due to precedence override.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">/etc/systemd/system		<span class="comment"># priority 1</span></span><br><span class="line">/run/systemd/system		<span class="comment"># priority 2</span></span><br><span class="line">/usr/lib/systemd/system		<span class="comment"># priority 3</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Config Sections</strong></p>
<ul>
<li><code>[Unit]</code><ul>
<li>  <code>Requires</code> - If any required unit does not start, this unit <strong>won’t start</strong></li>
<li>  <code>Wants</code> - <strong>Still starts</strong>, even any required unit fails to start</li>
</ul>
</li>
<li><code>[Install]</code><ul>
<li>  <code>Alias</code> - Set additional names</li>
<li>  <code>RequiredBy</code> - Other units that require this service </li>
<li>  <code>WantBy</code> - Other units that want thos service</li>
</ul>
</li>
<li><code>[Service]</code><ul>
<li>  <code>ExecReload</code> - Run commands when <strong>reload</strong> unit</li>
<li>  <code>ExecStart</code> - Run commands when <strong>start</strong> unit</li>
<li>  <code>ExecStop</code> - Run commands when <strong>stop</strong> unit</li>
<li>  <code>Environment</code> - Set env var, <strong>separated</strong> by a <strong>space</strong>  📌</li>
<li>  <code>Environment File</code> - Set file that contains env var</li>
<li><code>RemainAfterExit</code> - Set to <code>no</code> / <code>yes</code>.<br>  If yes, service is left <strong>active</strong> even process starts with <code>ExecStart</code> is <strong>terminated</strong></li>
</ul>
</li>
</ul>
<br>



<h4 id="Special-Commands"><a href="#Special-Commands" class="headerlink" title="Special Commands"></a><u>Special Commands</u></h4><div class="note success"><p>Determine system’s <strong>operational status</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">systemctl is-system-running</span><br></pre></td></tr></table></figure>
</div>

<p><strong>Operational status</strong></p>
<ul>
<li>  <strong><code>running</code></strong> - everything is in <strong>full working order</strong></li>
<li>  <code>degraded</code> - has one or more failed units</li>
<li>  <code>maintenance</code> - emergency / recovery mode</li>
<li>  <code>initializing</code> - start to boot</li>
<li>  <code>starting</code> - still booting</li>
<li>  <code>stopping</code> - shut down in progress</li>
</ul>
<br>

<p><strong>Other commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># find failed units</span></span><br><span class="line">systemctl --failed</span><br><span class="line"></span><br><span class="line"><span class="comment"># jump between system targets</span></span><br><span class="line"><span class="comment"># jump from default (graphical) to multi-user (text)</span></span><br><span class="line">systemctl isolate multi-user.target</span><br></pre></td></tr></table></figure>

<p>Special targets</p>
<ul>
<li>  <strong>Rescue</strong> target</li>
<li>  <strong>Emergency</strong> target:   <code>systemctl isolate emergency</code></li>
</ul>
<br>

<h3 id="3-Notification"><a href="#3-Notification" class="headerlink" title="3 - Notification"></a>3 - Notification</h3><blockquote>
<p>  View message status: <code>mesg</code></p>
</blockquote>
<br>

<p>Tools for notifying users of system <strong>change</strong></p>
<table>
<thead>
<tr>
<th>Location</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><code>/etc/issue</code></td>
<td>Display texts on tty terminal login screen (<strong>Before</strong> login to the system)</td>
</tr>
<tr>
<td><code>/etc/issue.net</code></td>
<td><strong>Logon</strong> screen messages for <strong>remote</strong> login</td>
</tr>
<tr>
<td><code>/etc/motd</code></td>
<td>Display <strong>text</strong> after logged into tty terminal</td>
</tr>
<tr>
<td><code>/bin/notify</code></td>
<td>GUI message (via <code>notify-send</code> utility)</td>
</tr>
<tr>
<td><code>/bin/wall</code></td>
<td><strong>Wall message</strong>. Logged into tty terminal with GUI terminal <strong>emulator</strong> (e.g. iTerm)</td>
</tr>
</tbody></table>
<p><code>systemctl</code> will send a wall message after the following commands</p>
<ul>
<li>  <code>halt</code> / <code>power-off</code></li>
<li>  <code>reboot</code></li>
<li>  <code>emergency</code></li>
<li>  <code>rescue</code></li>
</ul>
<br>

<br>





<h2 id="Virtualization"><a href="#Virtualization" class="headerlink" title="# Virtualization"></a># Virtualization</h2><h3 id="1-VM"><a href="#1-VM" class="headerlink" title="1 - VM"></a>1 - VM</h3><div class="note primary"><p>Virtualizing an application typically <u>doesn’t make the performance faster</u>.</p>
</div>





<p>Two types of <strong>hypervisor</strong></p>
<ul>
<li><p>Type 1 - <strong>Baremetal</strong></p>
<blockquote>
<p>  <strong>No need</strong> for host OS. e.g. Xen, Hyper-V, <strong>KVM</strong> (Linux built-in)</p>
</blockquote>
</li>
<li><p>Type 2 - On <strong>top of Host OS</strong></p>
<blockquote>
<p>  Need to install host OS first. e.g. VirtualBox, <strong>VMware</strong></p>
</blockquote>
</li>
</ul>
<br>

<h4 id="Create-VM"><a href="#Create-VM" class="headerlink" title="Create VM"></a><u>Create VM</u></h4><blockquote>
<ul>
<li>  Clone</li>
<li>  <strong>OVF</strong></li>
<li>  Template</li>
</ul>
</blockquote>
<br>

<p><strong>Clone</strong></p>
<p>Some hypervisors do not issue a <u>new NIC MAC address</u> when cloning VM.<br>List of items that may need modification:</p>
<ul>
<li>  Host name</li>
<li>  NIC <strong>MAC</strong> address</li>
<li>  NIC <strong>IP</strong> (if using static IP)</li>
<li>  Machine <strong>ID</strong>, UUID</li>
</ul>
<br>

<p><strong>OVF</strong> (Open Virtualization Format)</p>
<ul>
<li>  Export VM to OVF format, to use in other hypervisors</li>
<li>  Single compressed archive file: <strong>OVA</strong> (Open Virtualization Archive) </li>
<li>  Developed by <strong>DMTF</strong> (Distributed Management Task Force)</li>
</ul>
<br>

<p><strong>Template</strong></p>
<ul>
<li>  A VM template is a <strong>master copy</strong>: Template itself is not bootable</li>
<li>  Scan current system &amp; create VM out of it: <strong>P2V</strong> (physical-to-virtual)</li>
<li>  Manage VMs with shellscripts: <code>virsh</code>  📌</li>
</ul>
<br>



<h4 id="Linux-Extension-Support"><a href="#Linux-Extension-Support" class="headerlink" title="Linux Extension Support"></a><u>Linux Extension Support</u></h4><p>Hardware extension</p>
<ul>
<li>  Based on the system’s <strong>CPU</strong> (require <strong>64-bit</strong>)</li>
<li>  Grants <strong>hypervisor</strong> <strong>direct access to CPU</strong></li>
<li>  Check <strong>BIOS</strong> if virtualization is enabled</li>
</ul>
<br>



<p><strong>Commands</strong></p>
<ul>
<li><p>Check hardware extension</p>
<blockquote>
<p>  If the <strong>flag</strong> is <strong><code>hypervisor</code></strong>, means that the OS is not running on a physical machine. It’s a <strong>VM</strong><br>  Use <strong><code>virt-what</code></strong> to check which hypervisor is being used.</p>
</blockquote>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Intel: vmx</span></span><br><span class="line"><span class="comment"># AMD: svm</span></span><br><span class="line">grep ^flags /proc/cpuinfo</span><br></pre></td></tr></table></figure></li>
</ul>
<ul>
<li><p>Check if module is loaded</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check if kvm is loaded</span></span><br><span class="line">lsmod | grep -i kvm</span><br><span class="line"></span><br><span class="line"><span class="comment"># load module</span></span><br><span class="line">sudo modprobe kvm-amd</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<h3 id="2-Others"><a href="#2-Others" class="headerlink" title="2 - Others"></a>2 - Others</h3><p><strong>Containers</strong></p>
<ul>
<li>  A container is managed by <strong>container engine</strong> (e.g. <strong>LXC</strong>).</li>
</ul>
<br>

<p><strong>Block Storage</strong></p>
<ul>
<li>  Underlying <strong>hardware</strong>: Disk drivers in <strong>RAID</strong> configuration</li>
</ul>
<br>

<p><strong>Cloud-init</strong>  (Canonical)</p>
<ul>
<li>  Tool that applies user data to your instances</li>
</ul>
<br>

<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 104 Manage Files</title>
    <url>/2022/LPIC-104/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-104/#File-Management-Commands">File Management Commands</a></li>
<li>  <a href="/2022/LPIC-104/#File-Ownership-amp-Permissions">File Ownership &amp; Permissions</a></li>
<li>  <a href="/2022/LPIC-104/#Hard-amp-Soft-Links">Hard &amp; Soft Links</a></li>
<li>  <a href="/2022/LPIC-104/#3-Disk-Quotas">Manage Disk Quota</a></li>
<li>  <a href="/2022/LPIC-104/#Locating-Files">Locate Files</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="File-Management-Commands"><a href="#File-Management-Commands" class="headerlink" title="# File Management Commands"></a># File Management Commands</h2><h3 id="1-File-Commands"><a href="#1-File-Commands" class="headerlink" title="1 - File Commands"></a>1 - File Commands</h3><h4 id="File-naming"><a href="#File-naming" class="headerlink" title="File naming"></a><u>File naming</u></h4><p>Linux filename length depends on filesystem</p>
<ul>
<li>  For <code>ext4</code>, limit is <strong>255</strong> char</li>
<li>  <code>.xx</code> files are hidden : store <strong>configuration</strong> files </li>
</ul>
<br>

<p><strong>Special Chars</strong> : Do not use for file names</p>
<ul>
<li>  <code>*</code> - matches 0 ~ N chars (<code>b*k</code>)</li>
<li>  <code>?</code> - matches single char (<code>b?k</code>)</li>
<li>  <code>[]</code> - matches any char in the set (<code>b[ao][a-z]k</code>)</li>
<li>  <code>/</code> - folder</li>
<li>  <code>\</code> - folder in windows</li>
<li>  <code>&quot;</code></li>
<li>  <code>^</code> - <strong>negate</strong> selection (i.e. except the selected one)</li>
</ul>
<br>







<h4 id="File-Operation"><a href="#File-Operation" class="headerlink" title="File Operation"></a><u>File Operation</u></h4><div class="note warning"><p>Quickly determine file type: <code>file</code>  (e.g. <code>file blog.txt</code>)</p>
</div>



<p><code>ls</code></p>
<blockquote>
<p>  The number after <code>rwxr-xr-x</code> in <code>ls -l</code>:  <strong>Hard Link count</strong>  📌</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ls</span></span><br><span class="line">--color  differentiate <span class="built_in">dirs</span>, links, etc.</span><br><span class="line">-R       recursive listing</span><br><span class="line"></span><br><span class="line">-d       only dir name</span><br><span class="line">-F       show file <span class="built_in">type</span></span><br><span class="line">-i       display inode</span><br></pre></td></tr></table></figure>

<p><strong>Examples</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># long list all dirs matches a*</span></span><br><span class="line">ls -dl a*</span><br><span class="line"></span><br><span class="line"><span class="comment"># file globbing</span></span><br><span class="line">ls b??k</span><br><span class="line"></span><br><span class="line"><span class="comment"># bracketed wildcard</span></span><br><span class="line">ls b[a-z][^eio]t	<span class="comment"># negate e</span></span><br></pre></td></tr></table></figure>



<br>

<p><code>cp</code></p>
<blockquote>
<p>  📌 Use <code>cp -a</code> instead of <code>cp -r</code></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cp</span></span><br><span class="line">-a	recursive copy + keep all original attributes</span><br><span class="line"></span><br><span class="line">-p	preserve ownership &amp; permission</span><br><span class="line">-r	recursive</span><br><span class="line">-u	update, only <span class="keyword">if</span> <span class="built_in">source</span> is newer than dest   </span><br></pre></td></tr></table></figure>

<br>

<p><code>touch</code></p>
<blockquote>
<p>  Mainly for updating file’s <strong>timestamps</strong></p>
</blockquote>
<p>Linux maintain 3 timestamps for each file</p>
<ul>
<li>  Last <strong>file</strong> modified time</li>
<li>  Last <strong>inode</strong> change time</li>
<li>  Last <strong>access</strong> time</li>
</ul>
<p>By default, <code>touch</code> set modified &amp; access time to <strong>current</strong> time</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-a	change access time (atime)</span><br><span class="line">-m	change modified time (mtime)</span><br><span class="line">-c	<span class="keyword">do</span> not create new file</span><br><span class="line"></span><br><span class="line">-r	<span class="built_in">set</span> ref file, to replicate timestamp</span><br><span class="line">-t	<span class="built_in">set</span> specified time</span><br><span class="line">    MMDDhhmm[[CC]YY][.ss]</span><br></pre></td></tr></table></figure>



<br>



<h4 id="Hard-amp-Soft-Links"><a href="#Hard-amp-Soft-Links" class="headerlink" title="Hard &amp; Soft Links"></a><u>Hard &amp; Soft Links</u></h4><p><strong>Link</strong>: Give a file multiple identities</p>
<ul>
<li>  Hard link</li>
<li>  Soft link (symbolic)</li>
</ul>
<br>

<p><code>ln</code></p>
<blockquote>
<p>  <code>ln</code> creates <strong>hard</strong> link by default</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># format</span></span><br><span class="line">ln [option] <span class="built_in">source</span> link</span><br><span class="line"></span><br><span class="line"><span class="comment"># options</span></span><br><span class="line">-s	soft link</span><br><span class="line"></span><br><span class="line">-f	remove all existing links</span><br><span class="line">-i	interactive</span><br><span class="line">-d	directory hard link (not supported by most filesystem)</span><br></pre></td></tr></table></figure>

<p><strong>Hard</strong> links</p>
<blockquote>
<p>  Points to <strong>same data</strong> on disk</p>
</blockquote>
<ul>
<li>  Two entries that point to the <strong>same</strong> <strong>inode</strong>: a <u>pseudo copy</u> of a file, without truly copying the data</li>
<li>  All hard links need to exist on a <strong>single</strong> low-level filesystem (cannot create hard links across filesystems)</li>
<li>  To <strong>delete</strong> file: need to delete all hard links to the file</li>
<li>  Can use hard link for <strong>file backup</strong> (the backup points to the data on disk)</li>
</ul>
<br>

<p><strong>Soft</strong> links</p>
<blockquote>
<p>  Points to <strong>original file</strong> (alias): If linked file is removed, soft link will be <strong>broken</strong></p>
</blockquote>
<ul>
<li>  Special file <strong>types</strong>: A separate file that <strong>points</strong> to the linked file / directory by <strong>name</strong> </li>
<li>  Do <strong>not</strong> share same inode numbers, because do <strong>not</strong> point to the same disk data</li>
<li>  Can point <strong>across</strong> filesystems 📌</li>
<li>  <strong>Slower</strong> than hard links (but very tiny difference)</li>
</ul>
<br>

<p>Other options</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># remove link</span></span><br><span class="line">unlink xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># find the final linked file</span></span><br><span class="line">readlink -f [soft linked file]</span><br></pre></td></tr></table></figure>

<div class="note danger"><p><strong>Stale links</strong> can be serious security problem.<br>Use soft link with caution, and remember to <code>unlink</code>.</p>
</div>



<br>

<h4 id="Directory-Commands"><a href="#Directory-Commands" class="headerlink" title="Directory Commands"></a><u>Directory Commands</u></h4><p><code>mkdir</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir</span></span><br><span class="line">-m [mode]	New directory has specific permission mode</span><br><span class="line">-p	create parent directory</span><br><span class="line">-v	verification (success message)</span><br></pre></td></tr></table></figure>

<div class="note success"><p><code>mkdir -v</code> for <strong>verification</strong> (also <code>rm</code>, <code>mv</code>, etc.)</p>
</div>

<br>

<p><code>rmdir</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># rmdir</span></span><br><span class="line">-p	delete entire directory tree</span><br><span class="line">-r	recursive</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Examples</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># remove empty directory only, with verification</span></span><br><span class="line">rm -dv xx	</span><br><span class="line"></span><br><span class="line"><span class="comment"># delete directory by inode</span></span><br><span class="line">ls -li</span><br><span class="line">find . -inum 31162147 -<span class="built_in">exec</span> rm -rv &#123;&#125; \;</span><br></pre></td></tr></table></figure>



<br>

<h3 id="2-File-Archiving"><a href="#2-File-Archiving" class="headerlink" title="2 - File Archiving"></a>2 - File Archiving</h3><blockquote>
<ul>
<li>   <code>gzip</code>, <code>bzip2</code>, <code>xz</code></li>
<li>  <code>tar</code></li>
<li>  <code>cpio</code></li>
<li>  <code>dd</code></li>
</ul>
</blockquote>
<br>

<h4 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a><u>Compression</u></h4><p><strong>Compression</strong> tool ( <code>gzip</code>, <code>bzip2</code>, <code>xz</code> )</p>
<ul>
<li>  Apply compression to tarball as a whole (<code>tar.gz</code>)</li>
<li>  <u>Reduce tarball size</u>, compared to compress file individually</li>
<li>  <strong>View content</strong> of compressed file: Temporarily decompress, and show content to terminal <code>stdout</code></li>
</ul>
<br>

<p>Comparison:</p>
<ul>
<li>  <code>gzip</code> - oldest, least compression</li>
<li>  <code>bzip2</code> - improved compression</li>
<li>  <code>xz</code> - newest, best compression (<strong>LZMA2</strong> compression algorithm)</li>
<li>  <code>zip</code> - normally we don’t use this one</li>
</ul>
<table>
<thead>
<tr>
<th>Compress</th>
<th>Extension</th>
<th>Uncompress</th>
<th>View Content</th>
</tr>
</thead>
<tbody><tr>
<td><code>gzip</code></td>
<td><code>.gz</code> / <code>.tgz</code></td>
<td><code>gunzip -c</code></td>
<td><code>gzcat</code></td>
</tr>
<tr>
<td><code>bzip2</code></td>
<td><code>.bz2</code> / <code>.tbz</code></td>
<td><code>bunzip2 -c</code></td>
<td><code>bzcat</code></td>
</tr>
<tr>
<td><code>xz</code></td>
<td><code>.xz</code> / <code>.txz</code></td>
<td><code>unxz -b</code></td>
<td><code>xzcat</code></td>
</tr>
<tr>
<td><code>zip</code></td>
<td><code>.zip</code></td>
<td><code>unzip</code></td>
<td><code>zcat</code></td>
</tr>
</tbody></table>
<p><strong>Example</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># compress</span></span><br><span class="line">bzip2 [xx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># uncompress</span></span><br><span class="line">unxz -b [xx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># specify compression level</span></span><br><span class="line">gzip -6 [xx]</span><br></pre></td></tr></table></figure>



<p>Compression level: <strong>1 to 9</strong></p>
<ul>
<li>  1 - Fatest, but lowest compression</li>
<li>  9 - Slowest, highest compression</li>
<li>  <strong>6</strong> - <strong>default</strong> compression level</li>
</ul>
<br>

<h4 id="tar"><a href="#tar" class="headerlink" title="tar"></a><u>tar</u></h4><blockquote>
<p>  Tape Archiver:  directs the output straight to <u>tape device / regular file</u>  (No intermediate storage)</p>
</blockquote>
<p><strong>Tarballs</strong>: archives created by <code>tar</code>, compressed by <code>gzip</code> / <code>bzip2</code> </p>
<ul>
<li><p>  Distribute source code</p>
</li>
<li><p><code>.snar</code>: tarball <strong>snapshot</strong> file</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create incremental backup with -g</span></span><br><span class="line">tar -g hello.snar -Jcvf hello_new.txz hello.txt </span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>Options</strong></p>
<ul>
<li><p>General</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-x	extract</span><br><span class="line">-c	create archive</span><br><span class="line">-v	verbose</span><br><span class="line">-f	use [file] as archive file</span><br><span class="line">-X	exclude files from archive (--exclude-from-file)</span><br></pre></td></tr></table></figure></li>
<li><p>Archive options</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-z	archive with gzip</span><br><span class="line">-j	archive with bzip2</span><br><span class="line">-J	archive with xz</span><br></pre></td></tr></table></figure></li>
<li><p>Append</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-A	append tar file to archive</span><br><span class="line">-r	append non-tar file to archive</span><br><span class="line">-u	append newer ones only (update)</span><br><span class="line">-g	incremental / full archive based on metadata</span><br></pre></td></tr></table></figure></li>
<li><p>Verification</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-d	compare archive to file on disk (diff)</span><br><span class="line">-t	list content</span><br><span class="line">-W	veirify each file</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>Example</strong></p>
<ul>
<li><p><strong>Compress</strong></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">tar  -cvf xx.tar.gz  [xx folder, file]</span><br><span class="line">tar -zcvf xx.tar.tgz [xx folder, file]</span><br><span class="line">tar -jcvf xx.tar.tbz [xx folder, file]</span><br><span class="line">tar -Jcvf xx.tar.txz [xx folder, file]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Extract</strong></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">tar  -xvf xx.tar.gz</span><br><span class="line">tar -zxvf xx.tar.tgz</span><br><span class="line">tar -jxvf xx.tar.tbz</span><br><span class="line">tar -Jxvf xx.tar.txz</span><br></pre></td></tr></table></figure></li>
<li><p>Other</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list tar content</span></span><br><span class="line">tar -tf xx.tar.gz </span><br><span class="line"></span><br><span class="line"><span class="comment"># compare tarball memebrs to external files</span></span><br><span class="line">tar -df hello.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># auto verify backup file</span></span><br><span class="line">tar -Wcvf hello.tar hello_*.txt</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Cannot use <code>-W</code> if tarball is compressed: <strong>Verify first, compress later</strong>.</p>
</blockquote>
</li>
</ul>
<br>

<h4 id="cpio"><a href="#cpio" class="headerlink" title="cpio"></a><u>cpio</u></h4><blockquote>
<p>  <code>cpio</code> = copy in and out</p>
<p>  Restore data: read directly from tape device file</p>
</blockquote>
<p>3 operating mode:</p>
<ul>
<li>  <strong>Copy-out</strong> (<code>-o / --create</code>) : Create archive &amp; copy files</li>
<li>  <strong>Coyp-in</strong> (<code>-i / --extract</code>) : Extract data from existing archive</li>
<li>  <strong>Copy-pass</strong> (<code>-p / --pass-through</code>) : copy-out + copy-in. Copy directory from one location to another.</li>
</ul>
<p>Options</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-A	append to exsiting archive</span><br><span class="line">-F xx	<span class="built_in">set</span> cpio archive file <span class="keyword">in</span> xx name</span><br><span class="line">-t	list contents</span><br><span class="line">-v	verbose</span><br></pre></td></tr></table></figure>

<br>

<p>Examples</p>
<blockquote>
<p>  Archive directory: pass a list of files using <strong>standard input</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># archive &amp; compress</span></span><br><span class="line">find ~/repo | cpio -o | xz &gt; /mnt/data/repo.cpio.xz</span><br><span class="line"></span><br><span class="line"><span class="comment"># uncompress &amp; unarchive</span></span><br><span class="line">gunzip -c /mnt/data/repo.cpio.xz | cpio -i</span><br></pre></td></tr></table></figure>







<br>

<h4 id="dd"><a href="#dd" class="headerlink" title="dd"></a><u>dd</u></h4><blockquote>
<p>  Archive filesystem / partition at <strong>low level</strong></p>
</blockquote>
<p>Create exact backup of <strong>entire</strong> partition</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># back up partition</span></span><br><span class="line">dd <span class="keyword">if</span>=/dev/sda1 of=/mnt/data</span><br><span class="line"></span><br><span class="line"><span class="comment"># create empty file of particular size</span></span><br><span class="line"><span class="comment"># 1024 * 720B = 720 KB</span></span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=file.img bs=1024 count=720</span><br></pre></td></tr></table></figure>

<ul>
<li>  <code>if</code> - input size</li>
<li>  <code>of</code> - output size</li>
<li>  <code>bs</code> - <strong>block</strong> size (in <strong>bytes</strong>, default is <strong>512</strong>)</li>
<li>  <code>count</code> - length</li>
<li><code>status</code> - level of info to be displayed<ul>
<li>  <code>none</code> - error message only</li>
<li>  <code>noxfer</code> - no final transfer stats</li>
<li>  <code>progress</code> - periodic transfer stats</li>
</ul>
</li>
</ul>
<p>After block file is created, can use <code>mkfs</code> to create filesystem.</p>
<br>

<p><strong>Zero an entire disk</strong> </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># zero the disk</span></span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=/dev/sda1 status=progress</span><br></pre></td></tr></table></figure>

<div class="note danger"><p>Need to perform at least <strong>10 times</strong> to thoroughly wipe the disk.</p>
<p>Can also use <code>/dev/random</code>, <code>/dev/urandom</code> to write random data.</p>
</div>

<br>



<h3 id="3-Disk-Quotas"><a href="#3-Disk-Quotas" class="headerlink" title="3 - Disk Quotas"></a>3 - Disk Quotas</h3><blockquote>
<p>  Limit how many files / disk space a single user may consume</p>
</blockquote>
<p>Modify quota in <code>/etc/fstab</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># modify</span></span><br><span class="line">/dev/sda1	/home	ext4	usrquota,grpquota	1	1</span><br><span class="line"></span><br><span class="line"><span class="comment"># remount</span></span><br><span class="line">mount -o remount /mnt/data</span><br></pre></td></tr></table></figure>

<ul>
<li>   <code>quotacheck</code> - check quota</li>
<li>   <code>edquota</code> - modify user quota, or temporarily in <code>/etc/quotatab</code></li>
<li>  <code>quotaon</code> - run from <strong>SysV</strong> startup script (installed by the distro’s <strong>quota package</strong>)</li>
</ul>
<br>

<br>

<h2 id="File-Ownership-amp-Permissions"><a href="#File-Ownership-amp-Permissions" class="headerlink" title="# File Ownership &amp; Permissions"></a># File Ownership &amp; Permissions</h2><h3 id="1-Ownership"><a href="#1-Ownership" class="headerlink" title="1 - Ownership"></a>1 - Ownership</h3><p><strong>Three</strong> tiers of permissions</p>
<ul>
<li>  <code>u</code> - Owner</li>
<li>  <code>g</code> - Group</li>
<li>  <code>o</code> - World</li>
</ul>
<br>

<p><code>chown</code> &amp; <code>chgrp</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># chown</span></span><br><span class="line">chown user:group file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># recursive</span></span><br><span class="line">-R</span><br><span class="line"></span><br><span class="line"><span class="comment"># chgrp</span></span><br><span class="line">chgrp -R group file.txt</span><br></pre></td></tr></table></figure>

<br>

<h3 id="2-Manage-Access"><a href="#2-Manage-Access" class="headerlink" title="2 - Manage Access"></a>2 - Manage Access</h3><h4 id="Permissions"><a href="#Permissions" class="headerlink" title="Permissions"></a><u>Permissions</u></h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-rwxr-xr-x 	file</span><br></pre></td></tr></table></figure>

<ul>
<li>  First char: file <strong>type code</strong></li>
<li>  read - <code>4</code></li>
<li>  write - <code>2</code></li>
<li>  execute - <code>1</code></li>
</ul>
<table>
<thead>
<tr>
<th>File type code</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><code>-</code></td>
<td>Normal file</td>
</tr>
<tr>
<td><code>d</code></td>
<td>Directory</td>
</tr>
<tr>
<td><code>l</code></td>
<td>Soft link</td>
</tr>
<tr>
<td><code>p</code></td>
<td>Pipe</td>
</tr>
<tr>
<td><code>s</code></td>
<td>Socket (similar to pipe, but permits <u>network &amp; bi-directional links</u>)</td>
</tr>
<tr>
<td><code>b</code></td>
<td>Block device (e.g. hard disks)</td>
</tr>
<tr>
<td><code>c</code></td>
<td>Character device (data is traferred in <u>one-byte</u> unit. e.g. parallel port, audio device)</td>
</tr>
</tbody></table>
<blockquote>
<ul>
<li>  When a directory’s execute bit is <code>1</code>, meansthat its contents are <strong>searchable</strong></li>
<li>  Root can read / write any file, including those has <code>000</code> permission</li>
</ul>
</blockquote>
<br>

<p><strong>Special permission bit</strong></p>
<div class="note danger"><p>SUID &amp; SGID (especially SUID root) programs are potential <strong>security risks</strong>.</p>
</div>



<ul>
<li><p><code>SUID</code> - <code>4</code></p>
<blockquote>
<p>  Set user ID: run program with file <strong>owner’s</strong> permission</p>
</blockquote>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># owner&#x27;s execute bit: set to s</span></span><br><span class="line">rwsr-xr-x	4755</span><br></pre></td></tr></table></figure></li>
<li><p><code>SGID</code> - <code>2</code></p>
<blockquote>
<p>  Set grop ID: run with file <strong>group</strong> permission</p>
</blockquote>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># group&#x27;s execute bit: set to s</span></span><br><span class="line">rwxr-sr-x	2755</span><br><span class="line">rws-r-s---	6750</span><br></pre></td></tr></table></figure></li>
<li><p>Sticky - <code>1</code></p>
<blockquote>
<p>  <strong>Protect</strong> files from being deleted by non file owners</p>
</blockquote>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># world&#x27;s execute bit: set to t</span></span><br><span class="line">rwxr-xr-t	1755</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<h4 id="Modify-File-Mode"><a href="#Modify-File-Mode" class="headerlink" title="Modify File Mode"></a><u>Modify File Mode</u></h4><div class="note success"><p>Files permissions are stored as part of the file’s <strong>inode</strong>, which isn’t part of the directory entry.</p>
<p>Read / write access to the directory or file doesn’t grant the right to <u>change inode sturctures</u>.</p>
</div>



<p><code>chmod</code></p>
<ul>
<li>  <strong>Octal</strong> mode: set specific absolute permission</li>
<li>  <strong>Symbolic</strong> mode: make simple change (<code>+</code>, <code>-</code>, <code>=</code>)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># add execute to all</span></span><br><span class="line">chmod a+x</span><br><span class="line"></span><br><span class="line"><span class="comment"># assign only read + write to owner &amp; group</span></span><br><span class="line">chmod ug=rw</span><br><span class="line"></span><br><span class="line"><span class="comment"># make owner and group permission equal</span></span><br><span class="line">chmod g=u</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove write from group, read + write from world</span></span><br><span class="line">chmod g-w, o-rw</span><br><span class="line"></span><br><span class="line"><span class="comment"># add SUID + SGID + sticky</span></span><br><span class="line">chomd u+s, g+s, o+t</span><br></pre></td></tr></table></figure>

<br>

<h4 id="Set-Default-Mode"><a href="#Set-Default-Mode" class="headerlink" title="Set Default Mode"></a><u>Set Default Mode</u></h4><p><code>umask</code>: <strong>Bitwise removal</strong> from <strong>directory’s</strong> <code>777</code> permissions, or <strong>file’s</strong> <code>666</code> permissions</p>
<table>
<thead>
<tr>
<th><code>umask</code></th>
<th>Files</th>
<th>Directories</th>
</tr>
</thead>
<tbody><tr>
<td><code>000</code></td>
<td>666</td>
<td>777</td>
</tr>
<tr>
<td><code>002</code></td>
<td>664</td>
<td>775</td>
</tr>
<tr>
<td><code>027</code></td>
<td>640</td>
<td>750</td>
</tr>
<tr>
<td><code>077</code></td>
<td>600</td>
<td>700</td>
</tr>
<tr>
<td><code>277</code></td>
<td>400</td>
<td>500</td>
</tr>
</tbody></table>
<blockquote>
<p>  By <strong>default</strong>, <u>file doesn’t have execution permission</u>. So need to <code>chmod +x</code></p>
</blockquote>
<br>

<p><strong>Modify</strong></p>
<ul>
<li><p>  <code>umask</code> value is normally set in <code>/etc/profile</code> at login time</p>
</li>
<li><p>Default umask: <code>0022</code></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">umask</span> -S	<span class="comment"># symbolic:  u=rwx,g=rx,o=rx</span></span><br></pre></td></tr></table></figure></li>
<li><p>change default group</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -l: re-init environment</span></span><br><span class="line">newgrp -l merikanto</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<h4 id="Modify-File-Attributes"><a href="#Modify-File-Attributes" class="headerlink" title="Modify File Attributes"></a><u>Modify File Attributes</u></h4><p><code>chattr</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example</span></span><br><span class="line">chattr +i / -i file</span><br><span class="line"></span><br><span class="line">A	no access time update</span><br><span class="line">a	append, <span class="built_in">disable</span> write access except appending data</span><br><span class="line">c	kernel compresses data written to file</span><br><span class="line">i	immutable. File cannot be deleted / linked / renamed</span><br><span class="line">j	journal all data written to file</span><br><span class="line">s	secure deletion</span><br><span class="line">t	no tail-merging</span><br></pre></td></tr></table></figure>

<p><strong>Secure deletion</strong></p>
<ul>
<li>  Kernel <strong>zeros</strong> the data blocks</li>
</ul>
<div class="note danger"><p>When deleting a file with <code>rm</code>, its directory entry is removed, and <strong>inode</strong> marked as <strong>available for recycling</strong>.</p>
<p>But the file’s <strong>data blocks aren’t erased</strong>.</p>
</div>





<br>

<br>



<h2 id="Locating-Files"><a href="#Locating-Files" class="headerlink" title="# Locating Files"></a># Locating Files</h2><h3 id="1-General"><a href="#1-General" class="headerlink" title="1 - General"></a>1 - General</h3><p><code>whereis</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># executable + man page</span></span><br><span class="line">whereis ls		</span><br></pre></td></tr></table></figure>

<ul>
<li>  Find program <strong>executables</strong> / config files + <strong>man</strong> page</li>
<li>  Does <strong>not</strong> search user directories</li>
</ul>
<br>



<p><code>which</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -a: list all complete paths</span></span><br><span class="line"><span class="built_in">which</span> -a python3	</span><br></pre></td></tr></table></figure>

<ul>
<li>  List <strong>complete</strong> path for command (weak search tool)</li>
<li>  Remove alias: <code>unalias py3</code></li>
<li>  <code>diff</code>: determine text file’s differences</li>
</ul>
<br>

<p><code>type</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -t: shorten output</span></span><br><span class="line"><span class="built_in">type</span> -t locate</span><br></pre></td></tr></table></figure>

<p>How a command will be interpreted:</p>
<ul>
<li>  <strong>built-in</strong></li>
<li>  <strong>alias</strong></li>
<li>  <strong>external</strong> command (absolute directory reference)</li>
</ul>
<br>

<h3 id="2-Find"><a href="#2-Find" class="headerlink" title="2 - Find"></a>2 - Find</h3><blockquote>
<p>  <strong>Brute-force</strong> approach to find files: slow but flexible</p>
</blockquote>
<table>
<thead>
<tr>
<th>Option</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><code>-name xx</code></td>
<td>By file <strong>name</strong></td>
</tr>
<tr>
<td><code>-iname xx</code></td>
<td>By file name, <strong>ignore</strong> case</td>
</tr>
<tr>
<td><code>-perm xx</code></td>
<td>By permission mode</td>
</tr>
<tr>
<td><code>-size n</code></td>
<td>By file size</td>
</tr>
<tr>
<td><code>-maxdepth n</code></td>
<td>By directory depth</td>
</tr>
<tr>
<td><code>-inum n</code></td>
<td>By <strong>inode</strong></td>
</tr>
<tr>
<td><code>-mmin n</code></td>
<td>File <strong>data</strong> changed <code>n</code> mins ago</td>
</tr>
<tr>
<td><code>-cmin n</code></td>
<td>Files <strong>status</strong> changed <code>n</code> mins ago</td>
</tr>
</tbody></table>
<br>

<p><strong>Examples</strong></p>
<ul>
<li>  Can specify <strong>one or more paths</strong></li>
<li>  Use <code>&quot; &quot;</code> to make matches more <strong>accurate</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># find all c files in home</span></span><br><span class="line">find /home -name <span class="string">&quot;*.c&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># permission audit</span></span><br><span class="line">find /usr/bin -perm /4600</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Permission as <code>/4600</code>: <code>/</code> ignores other permissions (e.g. <code>600</code>), make it strictly <code>4600</code></p>
</blockquote>
<br>

<h3 id="3-Locate"><a href="#3-Locate" class="headerlink" title="3 - Locate"></a>3 - Locate</h3><p><strong>Limitation</strong></p>
<ul>
<li><p>  Simple tool, search only on filenames (But much <strong>faster</strong> than <code>find</code>)</p>
</li>
<li><p>Maintains a database that updates once daily: <code>/var/lib/mlocate/mlocate.db</code></p>
<blockquote>
<p>  Manual update: <code>sudo updatedb</code>  📌</p>
</blockquote>
</li>
<li><p>  <code>slocate</code>: <strong>secure</strong> locate. Prevent users from seeing file names in directories they shouldn’t access</p>
</li>
</ul>
<br>

<p>Options</p>
<blockquote>
<p>  By default, <code>locate</code> adds wildcard to the pattern: <code>*xx*</code>.<br>  To find exact match, use <code>&quot;xx&quot;</code> </p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-A	all</span><br><span class="line">-b	only file names</span><br><span class="line">-c	number of matches</span><br><span class="line">-q	quiet. No error messages</span><br></pre></td></tr></table></figure>





<br>

<br>

<br>]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 103 Configure Hardware</title>
    <url>/2022/LPIC-103/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-103/#Configure-Firmware">Configure firmware</a></li>
<li>  <a href="/2022/LPIC-103/#Configure-Hardware">Configure hardware</a></li>
<li>  <a href="/2022/LPIC-103/#3-Hard-Disk-Layout">Partition &amp; Hard disk layout</a></li>
<li>  <a href="/2022/LPIC-103/#4-Create-Partition">Create partitions &amp; filesystem</a></li>
<li>  <a href="/2022/LPIC-103/#2-Maintain-Filesystem-Health">Maintain filesystem health</a></li>
<li>  <a href="/2022/LPIC-103/#3-Mount-amp-Unmount-Filesystem">Mount &amp; unmount filesystem</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="Configure-Firmware"><a href="#Configure-Firmware" class="headerlink" title="# Configure Firmware"></a># Configure Firmware</h2><br>



<div class="note primary"><p>Provides config tools &amp; initiates OS booting process</p>
<p>Firmware settings can control onboard devices (hard disk controllers, USB ports, etc.)</p>
</div>



<p>The most <strong>important</strong> firmware is installed on the <strong>motherboard</strong></p>
<blockquote>
<p>  <em>Motherboard’s firmware resides in <strong>flash memory</strong></em><br>  <em>i.e.  <strong>EEP-ROM</strong> (Electronically Erasable Programmable Read-Only Memory)</em></p>
</blockquote>
<ul>
<li><p>  Initialize motherboard’s hardware &amp; control boot process</p>
</li>
<li><p>  Provide fundamental <strong>I/O</strong> services (at boot time)</p>
</li>
<li><p>Types:</p>
<ul>
<li><p>  <strong>BIOS</strong> (Basic Input / Output System)</p>
</li>
<li><p>  <strong>EFI</strong>  (Extensible Firmware Interface)</p>
</li>
<li><p>  <strong>UEFI</strong> (Unified EFI,  EFI 2.0)</p>
</li>
</ul>
</li>
<li><p>  <u>Enable / disable on-board hardware</u></p>
</li>
</ul>
<br>





<h3 id="1-Virtual-Filesystem"><a href="#1-Virtual-Filesystem" class="headerlink" title="1 - Virtual Filesystem"></a>1 - Virtual Filesystem</h3><div class="note warning"><p><code>/dev, /sys, /proc</code>  are all <strong>virtual filesystems</strong></p>
<ul>
<li>  <code>/dev </code>  :  virtual fs to represent <strong>hotplug</strong> devices </li>
<li>  <code>/proc</code>:  virtual fs to represent <strong>kernel &amp; hardware</strong> data (access <u>hardware info that aren’t accessible via <code>/dev</code></u>)</li>
<li>  <code>/sys </code>:    virtual fs to represent <strong>device</strong> info</li>
</ul>
</div>

<br>

<h4 id="dev"><a href="#dev" class="headerlink" title="/dev"></a><u>/dev</u></h4><p><strong>Device file</strong>:</p>
<p>After Linux kernel <strong>communicates</strong> with device on a <strong>interface</strong>,<br>it must be able to <strong>transfer data to &amp; from</strong> the device</p>
<blockquote>
<p>  Use <code>/dev</code> to interface with hardware devices</p>
</blockquote>
<br>

<p>When add hardware device (USB, NIC, hard drives) </p>
<ul>
<li>  Linux creates file in <code>/dev</code> representing the device</li>
<li>  Application then interact directly with the file to receive &amp; send data</li>
</ul>
<div class="note primary"><p><strong>Design</strong>:<br>Much easier than requiring each application to know how to directly interact with a device.</p>
</div>

<br>

<p>Device <strong>data transfer</strong></p>
<ul>
<li>  <strong>Receive</strong> data from device: <strong>read</strong> Linux <strong>device file</strong> associated with the device</li>
<li>  Send data to device: <strong>write</strong> to Linux <strong>device file</strong></li>
</ul>
<br>

<p><strong>Device file types</strong></p>
<ul>
<li><p><strong>Character</strong> device (<code>c</code>) : Transfer data one char per time</p>
<blockquote>
<p>  For <strong>serial</strong> device, e.g. termianls, USB</p>
</blockquote>
</li>
<li><p><strong>Block</strong> device (<code>b</code>) : Transfer large blocks of data</p>
<blockquote>
<p>  For high speed data transfer, e.g. hard drives, network cards</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Device mapper</strong></p>
<ul>
<li>  Create files in <code>/dev/mapper</code>, which <strong>links</strong> to physical block device files in <code>/dev</code></li>
<li>  Maps <strong>physical</strong> <strong>block</strong> device to <strong>virtual</strong> block device</li>
<li>  Virtual block device :  allows system to <strong>intercept</strong> device IO, and perform certain operations</li>
<li>Mapped device are used by:<ul>
<li>  LVM (to create logical volumes)</li>
<li>  LUKS (encrypt data on hard drives)</li>
</ul>
</li>
</ul>
<br>



<h4 id="sys"><a href="#sys" class="headerlink" title="/sys"></a><u>/sys</u></h4><p><strong>Notes</strong></p>
<ul>
<li>  Created by kernel in the <code>sysfs</code> filesystem format</li>
<li>Obtain information about<ul>
<li>  system bus</li>
<li>  devices</li>
<li>  kernel</li>
<li>  installed kernel modules</li>
</ul>
</li>
</ul>
<br>

<h4 id="proc"><a href="#proc" class="headerlink" title="/proc"></a><u>/proc</u></h4><blockquote>
<p>  Use it to troubleshoot hardware issues</p>
<p>  Linux kernel changes files &amp; data in <code>/proc</code>, as it monitors system hardware status</p>
</blockquote>
<br>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo apt install -y procinfo</span><br><span class="line"></span><br><span class="line"><span class="comment"># show info about all connected hardware devices</span></span><br><span class="line">lsdev</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Retrieve info from <code>/proc/interrupts, /proc/ioports, /proc/dma</code><br>  And combine them in <strong>one output</strong></p>
</blockquote>
<br>

<p>More details of <code>/proc</code> is in the below section.</p>
<br>



<h3 id="2-proc"><a href="#2-proc" class="headerlink" title="2 -  proc"></a>2 -  proc</h3><blockquote>
<ul>
<li>  <strong>IRQ</strong> - <code>/proc/interrupts</code></li>
<li>  <strong>I/O</strong> - <code>/proc/ioports</code></li>
<li>  <strong>DMA</strong> - <code>/proc/dma</code></li>
</ul>
</blockquote>
<br>

<h4 id="IRQ-Interrupt-Request"><a href="#IRQ-Interrupt-Request" class="headerlink" title="IRQ (Interrupt Request)"></a><u>IRQ (Interrupt Request)</u></h4><blockquote>
<ul>
<li>  Signal sent to CPU, instructing it to suspend current activity, and handle external event (e.g. keyboard input)</li>
<li>  Allow hardware devices to indicate when they have data to send to CPU</li>
</ul>
</blockquote>
<br>

<p>On the <strong>x86</strong> platform, IRQs are numbered from <strong>0 to 15</strong><br>On newer platforms (<strong>x86-64</strong>), IRQs are more than 16</p>
<ul>
<li>  IRQ  <strong>1</strong> - reserved for keyboard use only</li>
<li>  IRQ  <strong>8</strong>  - real-time clock (reserved for system clock)</li>
</ul>
<blockquote>
<p>  IRQ <strong>conflicts</strong>: reconfigure devices to use different IRQs </p>
</blockquote>
<br>

<p><strong>Buses</strong>:</p>
<ul>
<li><p><strong>ISA</strong> bus (Industry Standard Architecture) </p>
<blockquote>
<p>  Sharing IRQ between 2 devices is tricky, become rare since 2001</p>
</blockquote>
</li>
<li><p><strong>PCI</strong> bus (Peripheral Component Interconnect) </p>
<blockquote>
<p>  PCI devices can share IRQs more easily</p>
</blockquote>
</li>
</ul>
<br>

<p>Explore IRQs</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo cat /proc/interrupts</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Linux doesn’t begin to use an IRQ, until relevant driver is <strong>loaded</strong></p>
</blockquote>
<div class="note primary"><p>The <code>/proc</code> filesystem is a <strong>virtual</strong> filesystem </p>
<ul>
<li>  Refer to <strong>kernel</strong> data that’s convenient to represent using a filesystem</li>
<li>  Files in <code>/proc</code> provides info about hardware, running processes, etc.</li>
<li>  Many Linux utilities use <code>/proc</code> behind the scenes</li>
</ul>
</div>

<br>



<h4 id="I-O-Addresses-I-O-Ports"><a href="#I-O-Addresses-I-O-Ports" class="headerlink" title="I/O Addresses   (I/O Ports)"></a><u>I/O Addresses   (I/O Ports)</u></h4><blockquote>
<p>  Unique locations in <strong>memory</strong>, reserved for communications between CPU &amp; specific physical hardware devices</p>
</blockquote>
<p>I/O addresses are associated with specific <strong>devices</strong>, and normally should not be shared</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo cat /proc/ioports</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  With PnP, IO ports conflicts aren’t very common. When in conflict, use <code>setpci</code></p>
</blockquote>
<br>



<h4 id="DMA-Addresses"><a href="#DMA-Addresses" class="headerlink" title="DMA Addresses"></a><u>DMA Addresses</u></h4><blockquote>
<p>  <strong>DMA</strong>:  Direct Memory Addressing</p>
</blockquote>
<p><strong>Alternative</strong> method to communication to I/O ports</p>
<ul>
<li>Rather than have CPU mediate data transfer between device &amp; memory,<br>  DMA permits device to transfer data <strong>directly</strong></li>
<li>Send data from hardware device directly to <strong>memory</strong>, without waiting for CPU.<br>  Then CPU can read those <strong>memory locations</strong> to <strong>access data</strong></li>
<li>  Lower CPU requirements for I/O activity, <strong>improve</strong> overall system performance</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show dma channels</span></span><br><span class="line">sudo cat /proc/dma</span><br></pre></td></tr></table></figure>



<br>

<br>

<h2 id="Configure-Hardware"><a href="#Configure-Hardware" class="headerlink" title="# Configure Hardware"></a># Configure Hardware</h2><br>

<h3 id="1-Geometry-Settings"><a href="#1-Geometry-Settings" class="headerlink" title="1 - Geometry Settings"></a>1 - Geometry Settings</h3><p><strong>Traditional</strong> hard dark layout</p>
<blockquote>
<p>  Hard disk’s Cylinder / Head / Sector (<strong>CHS</strong>) geometry</p>
</blockquote>
<ul>
<li>  Fixed number of read / write <strong>heads</strong></li>
<li>Any sector on a hard disk can be un iquely identified by <strong>3 numbers</strong> :<br>  <strong>C</strong>ylinder number + <strong>H</strong>ead number + <strong>S</strong>ector number</li>
<li>  Hard disks are built from <strong>platters</strong>, each of which is broken into <strong>tracks</strong>, which are broken into <strong>sectors</strong></li>
</ul>
<br>

<p><strong>Problems with CHS</strong></p>
<ul>
<li><p>  Earliest hard disks use <strong>variable</strong> numbers of sectors per cylinder</p>
</li>
<li><p>CHS <strong>translation</strong>: Moving disks between computers can result in problems </p>
<blockquote>
<p>  Mismatched CHS geometries claimed in disk structures &amp; by BIOS</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Solution</strong>:  </p>
<p>Logical Block Addressing (<strong>LBA</strong>) mode  (or Linear Block Addressing)</p>
<ul>
<li>Single <strong>unique</strong> number assigned to each <strong>sector</strong> on the disk<br>  Given sector number, disk <strong>firmware</strong> can read from correct head &amp; cylinder</li>
<li>Modern BIOS provides option to use <strong>LBA / CHS</strong> <strong>translation</strong> mode<br>  <strong>EFI</strong> use <strong>LBA</strong> mode exclusively (no CHS translation)</li>
</ul>
<br>



<h3 id="2-Coldplug-amp-Hotplug-Devices"><a href="#2-Coldplug-amp-Hotplug-Devices" class="headerlink" title="2 - Coldplug &amp; Hotplug Devices"></a>2 - Coldplug &amp; Hotplug Devices</h3><p><strong>Difference</strong></p>
<ul>
<li><p>  <strong>Coldplug</strong>: attach / detach when power <strong>off</strong> only</p>
</li>
<li><p>  <strong>Hotplug</strong>: attach / detach, even when power <strong>on</strong></p>
</li>
</ul>
<div class="note success"><p>Coldplug devices are designed to be physically connected,<br>only disconnected when power <strong>off</strong></p>
<ul>
<li>  Old external devices (parallel&amp; RS-232 ports) are coldplug devices</li>
</ul>
</div>

<br>

<p><strong>Kernel &amp; user space</strong></p>
<ul>
<li><p>  User space program: run as <strong>ordinary</strong> program, communicate with external devices</p>
</li>
<li><p>  Only <strong>kernel</strong> can communicate <strong>directly</strong> with <strong>hardware</strong></p>
</li>
<li><p><code>/dev</code> : interface between user-space programs &amp; hardware</p>
<blockquote>
<p>  e.g.  Link to optical drive: <code>/dev/cdrom</code></p>
</blockquote>
</li>
</ul>
<br>

<p>Utilities to manage <strong>hotplug</strong> devices</p>
<ul>
<li><p><strong>Sysfs</strong>  :  <strong>virtual</strong> filesystem, mounted as <code>/sys</code></p>
<blockquote>
<p>  Export device info, for user space program to access</p>
</blockquote>
</li>
<li><p><strong>HAL Daemon (<code>hald</code>)</strong>  :  Hardware Abstraction Layer (<strong>HAL</strong>)    </p>
<blockquote>
<p>  User space daemon. Provide other user space programs with available hardware info</p>
</blockquote>
</li>
<li><p><strong>D-Bus</strong>  : Desktop Bus</p>
<blockquote>
<p>  <strong>Daemon</strong>. Enables processes to communicate with each other &amp; registers, to be notified for process / hardware event</p>
<p>  e.g. New USB device is available</p>
</blockquote>
</li>
<li><p><code>udev</code>:  <strong>virtual filesystem</strong> mounted at <code>/dev</code>  (for hardware devices)</p>
<ul>
<li><p>  Runs in the <strong>background</strong>, <strong>auto-detect</strong> new hardware connected to Linux (auto install required kernel modules)</p>
</li>
<li><p>Create <strong>dynamic</strong> device files &amp; assign each a <strong>unique device filename</strong> in <code>/dev</code>,<br>  as drivers are loaded &amp; unloaded</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># configure udev</span></span><br><span class="line">sudo cat /etc/udev/udev.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># debug</span></span><br><span class="line">/lib/systemd/systemd-udevd --debug &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Also creates <strong>persistent device files</strong> for storage device</p>
<blockquote>
<p>  Use <code>/dev/disk</code> to create <strong>links</strong> to <code>/dev</code> device files</p>
<p>  e.g. <code>/dev/disk/by-path</code> : Link storage device by <strong>physical hardware port</strong> they’re connected to</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<div class="note default"><p>With <code>udev</code> device links, can specify reference to storage device by <strong>permanent identifier</strong></p>
</div>



<br>

<br>

<h2 id="Interface-Kernel-Hard-Disks"><a href="#Interface-Kernel-Hard-Disks" class="headerlink" title="# Interface, Kernel, Hard Disks"></a># Interface, Kernel, Hard Disks</h2><div class="note success"><p>Device Interface (3 popular standards)</p>
<ul>
<li>  PCI </li>
<li>  USB Interface</li>
<li>  GPIO Interface</li>
</ul>
</div>



<br>

<h3 id="1-Device-Interface"><a href="#1-Device-Interface" class="headerlink" title="1 - Device Interface"></a>1 - Device Interface</h3><div class="note default"><p><strong>PCI</strong>         <code>lspci,  setpci,  lsdev</code></p>
<p><strong>Module</strong>   <code>lsmod,  insmod,  modprobe,  rmmod</code></p>
<p><strong>USB</strong>        <code>lsusb,  usbmgr,  hotplug</code></p>
<p><strong>Disks</strong>       <code>lsblk,  blkid</code></p>
</div>

<br>

<h4 id="PCI"><a href="#PCI" class="headerlink" title="PCI"></a><u>PCI</u></h4><blockquote>
<p>  PCI Standard (1993) : connecting hardware boards to PC motherboards </p>
</blockquote>
<br>

<p><strong>Tweak</strong> how PCI devices are detected</p>
<ul>
<li><p>  Kernel configuration screens under <strong>Bus</strong> Options</p>
</li>
<li><p>  Most <strong>firmware</strong> implementations have PCI options</p>
</li>
<li><p>  Linux <strong>drivers support</strong> options</p>
</li>
</ul>
<br>

<p><strong>Commands</strong>:</p>
<ul>
<li><p>  <code>setpci</code> :  directly query &amp; adjust <strong>low-level</strong> PCI device configuration</p>
</li>
<li><p><code>lspci</code> :  show current PCI configuration</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># lspci</span></span><br><span class="line">-vv	more verbose</span><br><span class="line">-t	tree view</span><br><span class="line">-M	perform scan <span class="keyword">in</span> bus-mapping mode</span><br><span class="line">  	reveal device hidden behind misconfigured PCI bridge</span><br><span class="line"></span><br><span class="line">-x	<span class="keyword">in</span> hex dump</span><br><span class="line">-k	show kernel driver module <span class="keyword">for</span> each installed PCI card</span><br></pre></td></tr></table></figure></li>
</ul>
<div class="note default"><p>In case of conflicts on the PCI board, use <code>setpci</code></p>
</div>



<br>

<h5 id="PCI-Boards"><a href="#PCI-Boards" class="headerlink" title="PCI Boards"></a>PCI Boards</h5><blockquote>
<p>  <strong>PCI bus</strong>: Plug-and-Play (<strong>PnP</strong> style configuration — <strong>auto</strong>-config)</p>
</blockquote>
<br>

<p><strong>PCIe</strong></p>
<ul>
<li>  PCI Express</li>
<li>  common interface for external hardware device, PCI 2.0 (much faster)</li>
</ul>
<br>

<p>Client devices use PCI boards:</p>
<ul>
<li><p><strong>Internal</strong> hard drives - SATA / SCSI</p>
<blockquote>
<p>  Linux auto recognize SATA &amp;  SCSI hard drives connected to PCI boards</p>
</blockquote>
</li>
<li><p><strong>External</strong> hard drives - Network hard drive</p>
<blockquote>
<p>  Communicate on a fiber channel network: <strong>HBA</strong> (Host Bus Adapter)</p>
</blockquote>
</li>
<li><p>  Network Interface Controllers (<strong>NIC</strong>) </p>
</li>
<li><p>  <strong>Wireless</strong> cards ( IEEE 802.11 )</p>
</li>
<li><p>  <strong>Bluetooth</strong> </p>
</li>
<li><p>  <strong>Audio</strong> cards</p>
</li>
<li><p><strong>Video</strong> accelerators</p>
<blockquote>
<p>  Advanced graphics often use video accelerator cards</p>
</blockquote>
</li>
</ul>
<br>



<h4 id="USB"><a href="#USB" class="headerlink" title="USB"></a><u>USB</u></h4><blockquote>
<ul>
<li><p>  Linux uses <strong>drivers</strong> for <strong>USB controllers</strong> (<code>/proc/bus/usb</code>)</p>
</li>
<li><p>  USB interface use <strong>serial</strong> communication, hence fewer connectors with motherboard</p>
</li>
</ul>
</blockquote>
<br>

<h5 id="USB-Basics"><a href="#USB-Basics" class="headerlink" title="USB Basics"></a>USB Basics</h5><p>Protocol &amp; hardware port for transferring data</p>
<ul>
<li>  USB 1.0  :  up to 127 devices, 12 Mbps data transfer</li>
<li>  USB 2.0  :  480 Mbps data transfer</li>
<li>  USB 3.0  :  4.8 Gbps data transfer</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># lsusb</span></span><br><span class="line">-v	verbose</span><br><span class="line">-t	tree view</span><br><span class="line">-d vendor:product  </span><br><span class="line"><span class="comment"># restrict vendor &amp; product  (codes afrer ID)</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Most system includes standard <strong>USB hub</strong> to connect <strong>multiple USB devices</strong> to <strong>USB controller</strong></p>
</blockquote>
<br>

<p>Early Linux USB implementation:</p>
<p>USB disk storage device use <strong>USB storage drivers</strong> that interface with Linux’s <strong>SCSI</strong> support</p>
<blockquote>
<p>  Make USB look like SCSI devices</p>
</blockquote>
<br>

<p>Linux provides <strong>USB filesystem</strong>, that in turn <u>provides <strong>access</strong> to USB devices</u></p>
<ul>
<li>  Filesystem appears as part of <code>/proc</code> virtual fs</li>
<li>  USB device info:  <code>/proc/bus/usb</code>  </li>
</ul>
<br>

<p><strong>Two steps</strong> to get Linux interact with USB</p>
<ul>
<li><p>Linux kernel have the proper <strong>module</strong> installed to recognize <strong>USB controller</strong></p>
<blockquote>
<p>  <strong>Controller</strong> provides communication between <em><strong>Linux kernel &amp; USB bus on the system</strong></em></p>
</blockquote>
</li>
<li><p>Linux has <strong>kernel module</strong> installed for the <strong>individual device type</strong> plugged into the USB bus</p>
<blockquote>
<p>  This is for Linux to recognize the specific device,<br>  after communication established via installing modules to recognize controller</p>
</blockquote>
</li>
</ul>
<div class="note info"><p>Software can access files in <code>/proc</code> to control USB devices,<br>rather than using device files in <code>/dev</code></p>
</div>

<br>

<h5 id="USB-Manager-Applications"><a href="#USB-Manager-Applications" class="headerlink" title="USB Manager Applications"></a>USB Manager Applications</h5><blockquote>
<p>  USB is designed as <strong>hot-pluggable</strong> </p>
</blockquote>
<br>

<p><code>usbmgr</code> :  </p>
<ul>
<li>  Runs in the background, detect <strong>changes</strong> on the <strong>USB bus</strong></li>
<li>  When it detects changes, load / unload the kernel modules that are required to handle the devices</li>
<li>  Global configuration:  <code>/etc/usbmgr/usbgr.conf</code></li>
</ul>
<br>

<p><code>hotplug</code> :  </p>
<ul>
<li><p>  Config of specific USB device: <code>/etc/hotplug</code> </p>
</li>
<li><p><code>/etc/hotplug/usb.usermap</code> contain database of USB device IDs &amp; <strong>pointers</strong> to scripts in <code>/etc/hotplug/usb</code></p>
<blockquote>
<p>  Scripts run, when devices are plugged / unplugged</p>
</blockquote>
</li>
</ul>
<br>

<h4 id="GPIO"><a href="#GPIO" class="headerlink" title="GPIO"></a><u>GPIO</u></h4><blockquote>
<p>  GPIO: <strong>G</strong>eneral <strong>P</strong>urpose <strong>IO</strong></p>
</blockquote>
<br>

<p><strong>Notes</strong></p>
<ul>
<li>  Example : Raspberry Pi</li>
<li>  <strong>Purpose</strong> : control external devices for automation</li>
<li>  Provides multiple <strong>digital IO lines</strong> to control individually (Down to single-bit level)</li>
<li>  Handled by special <strong>IC</strong> chip (Integrated Circuit), mapped into <strong>memory</strong></li>
</ul>
<br>

<p><strong>Feature</strong></p>
<ul>
<li><p>Ideal for supporting communications to external devices</p>
<blockquote>
<p>  e.g. lights, sensors, motors, robot operations</p>
</blockquote>
</li>
<li><p>  Possibility to use Linux to control objects &amp; environments</p>
</li>
</ul>
<br>

<h3 id="2-Kernel"><a href="#2-Kernel" class="headerlink" title="2 - Kernel"></a>2 - Kernel</h3><br>

<h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a><u>Overview</u></h4><p>Linux kernel needs <strong>device drivers</strong> to communicate with installed hardware devices.</p>
<ul>
<li><p>  Compile device drivers for all known devices into kernel, makes <strong>large kernel binary file</strong></p>
</li>
<li><p>Use <strong>kernel modules</strong> to avoid above situation</p>
<blockquote>
<p>  System only links modules need for the hardware</p>
</blockquote>
</li>
<li><p>When compiling new Linux kernel:<br>  Also compile any hardware modules along with the new kernel</p>
</li>
</ul>
<br>

<p>Module file <strong>type</strong></p>
<ul>
<li>  As <strong>source code</strong> (need to <strong>compile</strong>)</li>
<li>  As <strong>binary object files</strong> ( <code>.ko</code> )</li>
</ul>
<blockquote>
<p>  Create separate modules for each kernel version: <code>/lib/modules/5.16-xx</code></p>
</blockquote>
<br>

<p><strong>Notes</strong></p>
<ul>
<li><p>  Modules to load at boot time : <code>/etc/modules</code></p>
</li>
<li><p>kernel module config file</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat /etc/modules-load.d/modules.conf</span><br></pre></td></tr></table></figure></li>
<li><p>modules dependencies</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat /lib/modules/[version]/modules.dep</span><br></pre></td></tr></table></figure>

</li>
</ul>
<div class="note info"><p>When use <code>moduel_install</code> to install modules, it calls <code>depmod</code> utility</p>
<p>If modify / add modules, must manual run <code>depmod</code> to update <code>modules.dep</code></p>
</div>

<br>

<h4 id="Kernel-Modules"><a href="#Kernel-Modules" class="headerlink" title="Kernel Modules"></a><u>Kernel Modules</u></h4><p>Hardware in Linux is handled by <strong>kernel drivers</strong>,<br>many in the form of <strong>kernel modules</strong> -  <code>/lib/modules</code></p>
<blockquote>
<p>  Stand-alone driver files can be loaded to provide <strong>access</strong> to hardware<br>  i.e. can be <strong>linked</strong> into kernel at <strong>runtime</strong></p>
</blockquote>
<br>

<p><code>lsmod</code>:  <strong>currently</strong> loaded drivers</p>
<ul>
<li>  Info only about kernel <strong>modules</strong>, NOT about drivers that compiled directly to Linux kernel</li>
<li>  <code>Used by</code> column:  number of other modules / processes that are using the module</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># more info about module</span></span><br><span class="line">modinfo nouveau</span><br></pre></td></tr></table></figure>

<br>

<h4 id="Load-Kernel-Modules"><a href="#Load-Kernel-Modules" class="headerlink" title="Load Kernel Modules"></a><u>Load Kernel Modules</u></h4><p>Load kernel modules with 2 programs: <code>insmod</code> &amp; <code>modprobe</code></p>
<ul>
<li>  <code>insmod</code>: inserts <strong>single</strong> module into the kernel</li>
<li>  <code>modprobe</code>:  <strong>auto</strong> loads any depended-on modules </li>
</ul>
<blockquote>
<p>  When problems with <code>insmod</code>:  manually load the depended-on modules, or use <code>modeprobe</code></p>
</blockquote>
<p>View config files:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo cat /etc/modprobe.d/xx</span><br></pre></td></tr></table></figure>



<div class="note info"><p>Linux kernel module has <strong>auto-loader</strong> feature (load modules automatically),<br>which must be <strong>compiled</strong> into kernel, and on various config files.</p>
</div>



<br>

<p><strong>Commands</strong></p>
<blockquote>
<p>  <code>modprobe</code> handle modules based on <strong>module name</strong>, no need to list full filename</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load using insmod</span></span><br><span class="line">insmod /lib/modules/5.16/kernel/drivers/pci/pci-stub.ko</span><br><span class="line"></span><br><span class="line"><span class="comment"># load modules</span></span><br><span class="line">modprobe -vv xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># change config file by creating a new file</span></span><br><span class="line">modprobe -C /etc/modprobe.d/xx.conf  xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># dry run</span></span><br><span class="line">modprobe -n / --dry-run</span><br><span class="line"></span><br><span class="line"><span class="comment"># show deps</span></span><br><span class="line">modprobe --show-depends</span><br></pre></td></tr></table></figure>

<br>

<h4 id="Remove-Kernel-Modules"><a href="#Remove-Kernel-Modules" class="headerlink" title="Remove Kernel Modules"></a><u>Remove Kernel Modules</u></h4><blockquote>
<p>  <code>rmmod</code> :  unload <strong>single</strong> kernel module</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># unload</span></span><br><span class="line">rmmod -v xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># wait until unused</span></span><br><span class="line">rmmod -w xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># force</span></span><br><span class="line">rmmod -f xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># unload entire module stack (with deps)</span></span><br><span class="line">modprobe -r xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># dry run remove</span></span><br><span class="line">modprobe -nvr btusb</span><br></pre></td></tr></table></figure>



<br>



<h3 id="3-Hard-Disks-amp-Storage"><a href="#3-Hard-Disks-amp-Storage" class="headerlink" title="3 - Hard Disks &amp; Storage"></a>3 - Hard Disks &amp; Storage</h3><blockquote>
<ul>
<li>  <strong>PATA / ATA</strong>  (Parallel Advanced Technology Attachment)</li>
<li>  <strong>SATA</strong>  (Serial ATA)</li>
<li>  <strong>SCSI</strong>  (Small Computer System Interface)</li>
<li>  <strong>External</strong> Disks  (USB, SCSI, IEEE-1394)</li>
</ul>
</blockquote>
<br>

<p>Storage <strong>type</strong></p>
<ul>
<li><p><strong>HDD</strong> (hard disk drive)</p>
<blockquote>
<p>  Store data <strong>magnetically</strong> on <strong>disk platters</strong>,<br>  with <strong>movable read / write head</strong> to write / retrieve <strong>magnetic images</strong> on the platters</p>
</blockquote>
</li>
<li><p><strong>SSD</strong> (solid state drive)</p>
<blockquote>
<p>  Store data <strong>electronically</strong> using <strong>integrated circuits</strong></p>
<p>  No moving parts in SSD : Faster &amp; more resilient</p>
</blockquote>
</li>
</ul>
<br>

<p><u><strong>Summary of 3 Standard Interface</strong></u></p>
<ul>
<li><strong>PATA</strong><ul>
<li>  <strong>Parallel</strong> interface</li>
<li>  Wide cable</li>
<li>  <strong>2</strong> devices per adapter</li>
</ul>
</li>
<li><strong>SATA</strong><ul>
<li>  <strong>Serial</strong> interface</li>
<li>  Thin cable</li>
<li>  <strong>4</strong> devices per adapter</li>
</ul>
</li>
<li><strong>SCSI</strong><ul>
<li>  <strong>Parallel</strong> interface</li>
<li>  Faster than SATA</li>
<li>  <strong>8</strong> devices per adapter (More disks together in a <strong>single</strong> interface)</li>
</ul>
</li>
</ul>
<br>

<h4 id="PATA"><a href="#PATA" class="headerlink" title="PATA"></a><u>PATA</u></h4><p><strong>Configure PATA Disks</strong></p>
<ul>
<li>  PATA disks use <strong>parallel</strong> interface (several <strong>bits</strong> of data are transferred over cable at once)</li>
<li>  <strong>Wide</strong> cable: support 40 / 80 lines</li>
<li>  Connect up to <strong>2 devices</strong> to each PATA <strong>connector</strong> on a motherboard</li>
<li>PATA cables have <strong>3 connectors</strong>:<ul>
<li>  1 for motherboard</li>
<li>  2 for disks</li>
</ul>
</li>
</ul>
<br>

<p>PATA disks must be configured as <strong>masters / slaves</strong>. Can be done via <strong>jumpers</strong> on the disks.  </p>
<ul>
<li>  <strong>Master</strong> device at the <strong>end</strong> of the cable</li>
<li>  <strong>Slave</strong> device on the <strong>middle connector</strong> </li>
</ul>
<br>

<p>All modern PATA disks support <strong>cable select</strong></p>
<blockquote>
<p>  Driver attempt to configure itself automatically (based on position on the PATA cable)</p>
</blockquote>
<div class="note success"><p><strong>Easiest</strong> way to configure:</p>
<ul>
<li>  Set <strong>all</strong> PATA devices to use <strong>cable select</strong> option</li>
</ul>
<p>For <strong>best</strong> performance: Disks should be placed on <strong>separate</strong> controllers</p>
</div>



<br>

<p>PATA disks &amp; partitions <strong>naming scheme</strong>: </p>
<ul>
<li><code>/dev/hda</code> -  <strong>Master</strong> drive on controller 1<ul>
<li>  <code>/dev/hda1</code> -    Partition 1  on disk 1</li>
<li>  <code>/dev/hda2</code> -    Partition 2  on disk 1</li>
</ul>
</li>
<li>  <code>/dev/hdb</code>  -  <strong>Slave</strong> drive on controller 1</li>
<li>  <code>......</code></li>
</ul>
<blockquote>
<p>  For instance, if there’s master disk on controller 1 &amp; 2, but no slave disk on controller 1:</p>
<ul>
<li>  <code>/dev/hda</code></li>
<li>  <code>/dev/hdc</code></li>
</ul>
</blockquote>
<br>

<h4 id="SATA"><a href="#SATA" class="headerlink" title="SATA"></a><u>SATA</u></h4><p>SATA is a <strong>replacement</strong> for PATA:</p>
<p>Newer motherboards often has <strong>4+ SATA</strong> interfaces, and <strong>no PATA</strong> interface</p>
<br>

<p><strong>Connect</strong> SATA disks</p>
<ul>
<li><p>Connect to motherboard / controllers on a <strong>1-to-1</strong> basis </p>
<blockquote>
<p>  Cannot connect more than one disk to a single cable  (Simplify config)</p>
</blockquote>
</li>
<li><p>SATA is a <strong>serial bus</strong></p>
<ul>
<li>  Only <strong>1 bit</strong> of data can be transferred at a time</li>
<li>  SATA transfers <strong>more bits per unit of time</strong> on the data line</li>
<li>  SATA is <strong>faster</strong> than PATA, cable is <strong>thinner</strong> (serial)</li>
</ul>
</li>
</ul>
<div class="note primary"><p>Modern PATA drivers treat <strong>PATA</strong> disks as <strong>SCSI</strong> disks</p>
<p><strong>Most</strong> SATA drivers treat <strong>SATA</strong> disks as <strong>SCSI</strong> disks</p>
<blockquote>
<p>  Some old drivers treat SATA disks as PATA disks</p>
</blockquote>
</div>



<br>



<h4 id="SCSI"><a href="#SCSI" class="headerlink" title="SCSI"></a><u>SCSI</u></h4><p><strong>History</strong></p>
<ul>
<li><p>  Traditionally a <strong>parallel</strong> bus (like PATA)</p>
</li>
<li><p>Newer variants is a <strong>serial</strong> bus (like SATA)</p>
<blockquote>
<p>  <strong>SAS</strong> (Serial Attached SCSI)</p>
</blockquote>
</li>
<li><p>  Cost is very high (used on <strong>high end</strong> systems)</p>
</li>
</ul>
<br>

<p><strong>Configuration</strong></p>
<ul>
<li><p>Supports up to 8 / 16 devices per bus</p>
<ul>
<li>One of these is the <strong>SCSI host adapter</strong>, either built into motherboard, or come as plug-in card</li>
<li>In reality, number of attached devices is limited, due to <strong>cable length</strong> limit</li>
</ul>
</li>
<li><p>  Each device has <strong>unique</strong> ID, assigned from a <strong>jumper</strong> on the device</p>
</li>
<li><p>If motherboard lacks built-in SCSI <strong>ports</strong>, possibly it won’t detect SCSI devices<br>  Can still boot from SCSI hard disk, if SCSI host adapter has it own <strong>firmware</strong> to support booting</p>
</li>
</ul>
<br>

<p><strong>Naming</strong></p>
<ul>
<li>  <code>/dev/sda</code></li>
<li>  <code>/dev/sdb</code></li>
<li>  <code>......</code></li>
</ul>
<div class="note primary"><p>Best practice: </p>
<p>Give hard disks <strong>lowest</strong> possible SCSI ID</p>
<blockquote>
<p>  <em>Avoid future disks use higher ID and potential Linux device identifier collision</em></p>
</blockquote>
</div>

<br>

<p><strong>Problems</strong></p>
<ul>
<li><p><strong>Multiple</strong> SCSI host adapters</p>
<blockquote>
<p>  Linux assign device filenames to all disks on the <strong>first</strong> adapter</p>
</blockquote>
</li>
<li><p>Some non-SCSI devices (e.g. USB, SATA) are mapped to Linux <strong>SCSI subsystem</strong></p>
<blockquote>
<p>  Cause a true SCSI hard disk assigned a higher device ID</p>
</blockquote>
</li>
<li><p>SCSI bus is logically <strong>one-dimensional</strong> (all device on a single line)</p>
<ul>
<li>  Special <strong>resistor pack</strong>:  prevent signal from bouncing around along SCSI chain</li>
<li>  Each <strong>end</strong> of SCSI bus must be <strong>terminated</strong>, but device <strong>mid-chain</strong> must NOT be terminated</li>
<li>Incorrect termination will result in bizarre SCSI problems</li>
</ul>
</li>
</ul>
<div class="note success"><p>List only SCSI block devices</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">lsblk -S</span><br></pre></td></tr></table></figure>
</div>

<br>

<h4 id="External-Disks"><a href="#External-Disks" class="headerlink" title="External Disks"></a><u>External Disks</u></h4><blockquote>
<p>  Common types: USB, SCSI, IEEE-1394</p>
</blockquote>
<p><strong>SCSI</strong></p>
<ul>
<li><p>  Direct support for external disks</p>
</li>
<li><p>Many SCSI host adapters have both <strong>internal &amp; external connectors</strong></p>
<blockquote>
<p>  Can configure external SCSI disks just like internal disks</p>
</blockquote>
</li>
<li><p>  Linux treats USB &amp; IEEE-1394 as SCSI devices</p>
</li>
</ul>
<div class="note warning"><p>Remove external drives:</p>
<ul>
<li>  <code>umount</code></li>
<li>  unplug device</li>
</ul>
<p>Direct unplug may result in <strong>damage</strong> to filesystem</p>
<blockquote>
<p>  Most <strong>SCSI buses</strong> are <strong>NOT hot-pluggable</strong></p>
</blockquote>
</div>



<br>

<br>



<h2 id="Partition"><a href="#Partition" class="headerlink" title="# Partition"></a># Partition</h2><p><strong>Advantages</strong> for Disk Partition</p>
<ul>
<li><p>  Multi-OS support, use different filesystems</p>
</li>
<li><p>Disk error protection</p>
<blockquote>
<p>  Errors only affect the files on that partition</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Partition System</strong></p>
<p>Partitions are defined by <strong>data structures</strong> that are written to <strong>specified</strong> parts of the hard disk.</p>
<ul>
<li><p>  <strong>MBR</strong> (Master Boot Record, old)</p>
</li>
<li><p>Stores data in the <strong>first</strong> sector of the disk</p>
<ul>
<li>  Limited to partitions of 2TB max</li>
</ul>
</li>
<li><p><strong>GPT</strong> (GUID Partition Table, new)</p>
<ul>
<li>  Higher limits</li>
</ul>
</li>
</ul>
<br>



<h3 id="1-Partition-Schema"><a href="#1-Partition-Schema" class="headerlink" title="1 - Partition Schema"></a>1 - Partition Schema</h3><blockquote>
<p>  MBR &amp; GPT: a way of <strong>indexing</strong> partitions</p>
</blockquote>
<div class="note success"><p>Linux creates <code>/dev</code> files for each separate disk partition</p>
</div>



<h4 id="MBR"><a href="#MBR" class="headerlink" title="MBR"></a><u>MBR</u></h4><blockquote>
<p>  <strong>First</strong> sector on the <strong>first</strong> hard drive partition on the system</p>
</blockquote>
<br>

<p>Original x86 partitioning scheme allows only <strong>4</strong> partitions.</p>
<blockquote>
<p>  <strong>Each primary</strong> partition can split into <strong>multiple extended</strong> partitions</p>
</blockquote>
<br>

<p>New scheme is <strong>extended</strong>: (with backward compatibility)</p>
<ul>
<li><p>  <strong>Primary</strong> partition :  same as original partition type</p>
</li>
<li><p>  <strong>Extended</strong> partition :  special type of primary partition. <strong>Placeholder</strong> for logical partition</p>
</li>
<li><p><strong>Logical</strong> partition :  resides in a <strong>single</strong> <strong>extended</strong> partition</p>
<blockquote>
<p>  All logical partitions must be <strong>contiguous</strong></p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Numbering</strong></p>
<ul>
<li><p>  Many OS must <strong>boot</strong> from <strong>primary</strong> partition</p>
</li>
<li><p>  4 primary partitions / 3 primary + 1 extended</p>
</li>
<li><p>Primary :  number 1 - 4</p>
<ul>
<li>  Logical :  number 5 +</li>
</ul>
</li>
<li><p>Gaps can appear in MBR numbering (primary only, no logical partitions)</p>
<ul>
<li>  Example: 1, 3, 5, 6, 7</li>
</ul>
</li>
</ul>
<br>

<p><strong>MBR &amp; Boot</strong></p>
<ul>
<li><p>  MBR data structures hold both <strong>partition table</strong> &amp; <strong>primary BIOS boot loader</strong></p>
</li>
<li><p>MBR exists only in the <strong>first sector</strong> of the disk: </p>
<ul>
<li>  easy to damage</li>
<li>erasure of MBR will make entire disk unusable</li>
</ul>
</li>
</ul>
<br>

<p><strong>MBR Backup</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># backup MBR partition</span></span><br><span class="line">sfdisk -d /dev/nvme0n1 &gt; backup.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># restore</span></span><br><span class="line">sfdisk -f /dev/nvme0n1 &lt; backup.txt</span><br></pre></td></tr></table></figure>

<br>

<p><strong>MBR Type codes</strong></p>
<blockquote>
<p>  Type code: 1 byte number (2-digit hex)</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x0c	FAT</span><br><span class="line">0x07	NTFS</span><br><span class="line">0x82	SWAP</span><br><span class="line">0x83	Linux filesystem</span><br></pre></td></tr></table></figure>

<br>

<h4 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a><u>GPT</u></h4><p><strong>Overview</strong></p>
<ul>
<li><p>  Part of Intel’s <strong>EFI</strong> specification</p>
</li>
<li><p>GPT uses <strong>Protective MBR</strong>, additional data structures defines <strong>true</strong> GPT partitions</p>
<blockquote>
<p>  <em>Legal MBR definition makes utilities think the disk holds a <u>single MBR partition across entire disk</u></em></p>
<p>  <em>(Just like <u>protected mode flat memory model</u>)</em></p>
</blockquote>
</li>
<li><p>Define <strong>128</strong> partitions max (by default)</p>
<blockquote>
<p>  Gaps can occur in partition numbering (e.g.  3, 5, 104)</p>
</blockquote>
</li>
<li><p>  <strong>Type codes</strong> :  <strong>16</strong>-byte <strong>GUID</strong> values</p>
</li>
</ul>
<br>





<h3 id="2-Partition-Alternatives"><a href="#2-Partition-Alternatives" class="headerlink" title="2 - Partition Alternatives"></a>2 - Partition Alternatives</h3><blockquote>
<p>  More dynamic &amp; fault-tolerant</p>
<ul>
<li>  <strong>Multipath</strong></li>
<li>  <strong>LVM</strong> (<strong>L</strong>ogical <strong>V</strong>olume <strong>M</strong>anager)</li>
<li>  <strong>RAID</strong> (<strong>R</strong>edundant <strong>A</strong>rray of <strong>I</strong>nexpensive <strong>D</strong>isks)</li>
</ul>
</blockquote>
<br>



<h4 id="Multipath"><a href="#Multipath" class="headerlink" title="Multipath"></a><u>Multipath</u></h4><p><strong>DM Multipathing</strong> (<strong>D</strong>evice <strong>M</strong>apper)</p>
<ul>
<li><p>  Utilize dynamic <code>/dev/mapper</code> device file directory</p>
</li>
<li><p>For each new multipath device: <code>/dev/mapper/mpathN</code></p>
<blockquote>
<p>  <code>N</code> is the number of multipath drive</p>
</blockquote>
</li>
<li><p>  This device file is a <strong>normal</strong> device file, allow to <strong>create partitions &amp; filesystems</strong></p>
</li>
</ul>
<br>

<p>Configure <strong>multiple paths</strong> between Linux &amp; network storage devices</p>
<ul>
<li>  <u>All path active</u>: <strong>increased throughput</strong></li>
<li>  <u>One path inactive</u>: <strong>fault tolerance</strong></li>
</ul>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo apt install multipath-tools -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel module</span></span><br><span class="line">dm-multipath</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show multipath devices</span></span><br><span class="line">multipath</span><br><span class="line"></span><br><span class="line"><span class="comment"># background process to monitor path</span></span><br><span class="line"><span class="comment"># and activate / deactivate paths</span></span><br><span class="line">multipathd</span><br><span class="line"></span><br><span class="line"><span class="comment"># create device entries for multipath device</span></span><br><span class="line">kpartx</span><br></pre></td></tr></table></figure>



<br>

<h4 id="LVM"><a href="#LVM" class="headerlink" title="LVM"></a><u>LVM</u></h4><p><strong>Usage</strong></p>
<ul>
<li><p>  Set aside one or more partitions</p>
</li>
<li><p>  Assign them MBR partition type code  <code>0x8e</code>  (or GPT equivalent)</p>
</li>
<li><p>Access logical volumes: <code>/dev/mapper/</code></p>
<blockquote>
<p>  Logical volumes create entries in <code>/dev/mapper</code>, which represents <strong>LVM device</strong></p>
</blockquote>
</li>
</ul>
<div class="note default"><p>For each physical partition, need to <strong>mark partition type</strong> in <code>fdisk / gdisk</code></p>
</div>

<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo apt install lvm2 -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># create physical volume</span></span><br><span class="line">pvcreate</span><br><span class="line"></span><br><span class="line"><span class="comment"># groups physical volume to volume group</span></span><br><span class="line">vgcreate</span><br><span class="line"></span><br><span class="line"><span class="comment"># create logical volume from partitions in each physical volume</span></span><br><span class="line">lvcreate</span><br><span class="line"></span><br><span class="line"><span class="comment"># list all logical volumes in all volume group</span></span><br><span class="line">lvscan</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Advantage</strong></p>
<ul>
<li><p>Easily <strong>resize</strong> logical volume</p>
<blockquote>
<p>  Logical volumes in <strong>volume groups</strong>, are like files in <strong>filesystem</strong></p>
<p>  Volume groups manages allocation of space, when resize logical volumes</p>
</blockquote>
</li>
<li><p>Easily <strong>add</strong> disk space (add new physical disk, then expand existing volume group)</p>
<blockquote>
<p>  Aggregate multiple <strong>physical drive partitions</strong> into <strong>virtual volumes</strong><br>  Then treated as <strong>single partition</strong> in the system</p>
</blockquote>
</li>
<li><p>  Create installation with many specialized filesystem, retain option to resize in the future</p>
</li>
</ul>
<br>

<p><strong>Disadvantage</strong></p>
<ul>
<li>  Complicates disaster recovery</li>
<li>  If LVM config spans multiple disks, failure in one disk puts <strong>all</strong> files in volume group at risk</li>
</ul>
<div class="note success"><p>Solution:</p>
<p>Configure at least 1 filesystem in conventional partition (dedicate to <code>/boot</code>)</p>
<p>Reserve LVM for <code>/home</code> ,  <code>/usr</code> , etc.</p>
</div>



<br>



<h4 id="RAID"><a href="#RAID" class="headerlink" title="RAID"></a><u>RAID</u></h4><p><strong>Advantage</strong></p>
<ul>
<li>  <strong>Striping</strong>: Improve data access <strong>performance</strong> &amp; <strong>reliability</strong></li>
<li>  <strong>Mirroring</strong>: <strong>Fault tolerance</strong>, combine multiple drivers into one virtual drive</li>
</ul>
<br>

<p><strong>Disadvantage</strong></p>
<ul>
<li>  Can be expensive</li>
</ul>
<br>

<p><strong>RAID versions</strong></p>
<ul>
<li><p><strong>RAID 0</strong> : Disk <strong>striping</strong></p>
<blockquote>
<p>  Stripe: spread data across multiple disks for faster access</p>
</blockquote>
</li>
<li><p><strong>RAID 1</strong> : Disk <strong>mirroring</strong></p>
<blockquote>
<p>  Mirror: duplicate data across 2 drives</p>
</blockquote>
</li>
<li><p><strong>RAID 10</strong> : Disk <strong>mirroring + striping</strong></p>
<blockquote>
<p>  Stripe for performance, mirror for fault tokerance</p>
</blockquote>
</li>
<li><p><strong>RAID 4</strong> : Disk striping with <strong>parity</strong></p>
<blockquote>
<p>  Add a <strong>parity bit</strong> stored on a <strong>separate</strong> disk, so data on a failed disk can be recovered</p>
</blockquote>
</li>
<li><p><strong>RAID 5</strong> : Disk striping with <strong>distributed parity</strong></p>
<blockquote>
<p>  Add parity bit to <strong>data stripe</strong>, so appears on all disks that any failed disk can be recovered</p>
</blockquote>
</li>
<li><p><strong>RAID 6</strong> : Disk striping with <strong>double parity</strong></p>
<blockquote>
<p>  <u>Stripes both data &amp; parity bit</u>, so <strong>two</strong> failed disks can be recovered</p>
</blockquote>
</li>
</ul>
<br>

<p>Linux’s <strong>software</strong> implementation</p>
<blockquote>
<p>  Software RAID system that can implement RAID features on any disk system</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo apt install mdadm</span><br></pre></td></tr></table></figure>

<p><code>mdadm</code> allows to specify multiple partitions to be used in any type of RAID environment.</p>
<p>RAID device appears as a <strong>single device</strong> in <code>/dev/mapper</code></p>
<br>

<h3 id="3-Hard-Disk-Layout"><a href="#3-Hard-Disk-Layout" class="headerlink" title="3 - Hard Disk Layout"></a>3 - Hard Disk Layout</h3><h4 id="Mount-Point"><a href="#Mount-Point" class="headerlink" title="Mount Point"></a><u>Mount Point</u></h4><blockquote>
<p>  Provide OS access to data on partitioned disks</p>
</blockquote>
<p>Linux OS uses a <strong>unified directory tree</strong></p>
<ul>
<li><p>Each <strong>partition</strong> is mounted at a <strong>mount point</strong> in the tree</p>
<blockquote>
<p>  Mount point: A <strong>directory</strong> (a way to access filesystem on the partition)</p>
</blockquote>
</li>
<li><p>Mount the filesystem: <u>Link filesystem to the mount point</u> (<strong>create empty dir</strong>)</p>
<blockquote>
<p>  e.g.  root partition <code>/</code> , and <code>/home</code>, <code>/usr</code></p>
<p>  If <code>/home</code> is unmounted &amp; remounted at <code>/hello</code>,  then all subdirectories under <code>/hello</code> will have new parent path as <code>hello</code></p>
</blockquote>
</li>
</ul>
<br>



<h4 id="Partition-amp-Filesystem-Layout"><a href="#Partition-amp-Filesystem-Layout" class="headerlink" title="Partition &amp; Filesystem Layout"></a><u>Partition &amp; Filesystem Layout</u></h4><div class="note default"><p>Steps to add new filesystem</p>
<ul>
<li>  Create <strong>Partition</strong> (<code>fdisk, gdisk, parted</code>)</li>
<li>  <strong>Format</strong> partition with a Linux fs (<code>mkfs</code>)</li>
<li>  <strong>Mount</strong> (<code>mount xx /mnt</code>)</li>
</ul>
</div>

<br>

<p>Linux <strong>FHS</strong> (Filesystem Hierarchy Standard)</p>
<ul>
<li>  Defines core directory names, locations, and contain what type of data</li>
<li>  <a href="https://refspecs.linuxfoundation.org/"><strong>Reference Specification</strong></a></li>
</ul>
<br>

<table>
<thead>
<tr>
<th>Mount point</th>
<th>Typical size</th>
<th>Comments</th>
</tr>
</thead>
<tbody><tr>
<td>Swap</td>
<td>1x ~ 2x RAM size</td>
<td>Memory extension. <strong>Slower</strong> than RAM</td>
</tr>
<tr>
<td><code>/home</code></td>
<td>200 M ~ 3 T</td>
<td>Isolate on a <u><strong>separate</strong></u> partition, to <u>preserve user data during system upgrade</u></td>
</tr>
<tr>
<td><code>/boot</code></td>
<td>100 M ~ 500 M</td>
<td>Critical boot files. Can be on a <u><strong>separate</strong></u> partition</td>
</tr>
<tr>
<td><code>/usr</code></td>
<td>0.5 G ~ 25 G</td>
<td>Linux standard program &amp; data files</td>
</tr>
<tr>
<td><code>/usr/local</code></td>
<td>0.1 G ~ 3 G</td>
<td>Data files that are <strong>unique</strong> to this installation (installed locally, <strong>safe from OS upgrade</strong>) 📌</td>
</tr>
<tr>
<td><code>/opt</code></td>
<td>0.1 G ~ 5 G</td>
<td>Data files associated with <strong>3rd party packages</strong></td>
</tr>
<tr>
<td><code>/var</code></td>
<td>0.1 G ~ 3 T</td>
<td>System &amp; app logs, <strong>transient</strong>. Can be on a <u><strong>separate</strong></u> partition</td>
</tr>
<tr>
<td><code>/tmp</code></td>
<td>0.1 G ~ 20 G</td>
<td>User-created temp files</td>
</tr>
<tr>
<td><code>/mnt  /media</code></td>
<td>/</td>
<td>Mount points for <u>removable media</u></td>
</tr>
</tbody></table>
<div class="note warning"><p><code>/etc, /bin, /sbin, /lib, /dev</code>  should <strong>never</strong> be placed on separate partitions (<strong>Must</strong> reside on <strong>root</strong> partition)</p>
</div>



<br>

<p>Second Table (for other <strong>FHS directories</strong>)</p>
<table>
<thead>
<tr>
<th>Directory</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><code>/etc</code></td>
<td>System &amp; app config files. Executable files <strong>shouldn’t</strong> reside in <code>/etc</code></td>
</tr>
<tr>
<td><code>/bin</code></td>
<td>Critical executable files. e.g. <code>ls</code>, <code>cp</code>, <code>mount</code></td>
</tr>
<tr>
<td><code>/sbin</code></td>
<td>Run only by system admin. e.g. <code>fdisk</code></td>
</tr>
<tr>
<td><code>/opt</code></td>
<td>Optional 3rd party programs. (ready-made pkgs that <u>don’t ship with the OS</u>)</td>
</tr>
<tr>
<td><code>/usr/bin</code></td>
<td>Local user programs &amp; data</td>
</tr>
<tr>
<td><code>/usr/sbin</code></td>
<td><strong>System</strong> programs &amp; data</td>
</tr>
<tr>
<td><code>/usr/lib</code></td>
<td>Libraries for software packages</td>
</tr>
</tbody></table>
<br>

<p>Distinctions made by FHS:</p>
<ul>
<li>  Sharable &amp; unshrable files: Files can be shared via <strong>NFS</strong> server</li>
<li>  <strong>Static</strong> (executables) &amp; <strong>variable</strong> (logs) files</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Sharable</th>
<th>Unsharable</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Static</strong></td>
<td><code>/usr</code> <br><code>/opt</code></td>
<td><code>/etc</code><br><code>/boot</code></td>
</tr>
<tr>
<td><strong>Variable</strong></td>
<td><code>/home</code><br><code>/var/logs</code></td>
<td><code>/var/run</code><br><code>/var/lock</code></td>
</tr>
</tbody></table>
<br>

<h3 id="4-Create-Partition"><a href="#4-Create-Partition" class="headerlink" title="4 - Create Partition"></a>4 - Create Partition</h3><h4 id="Disk-Partition"><a href="#Disk-Partition" class="headerlink" title="Disk Partition"></a><u>Disk Partition</u></h4><p><strong>Partition Tools</strong></p>
<ul>
<li>  <code>fdisk / cfdisk</code> :  fixed disk, handles <strong>MBR only</strong></li>
<li>  <code>gdisk / cgdisk</code> :  handles <strong>GPT</strong></li>
<li>  <code>parted</code> : GNU parted command line tool </li>
<li>  <code>gparted</code> :  MBR, GPT, etc  ( Gnome Partition Editor )</li>
</ul>
<blockquote>
<p>  <code>sfdisk / sgdisk</code> :  Useful for writing scripts to handle disk partitioning</p>
</blockquote>
<div class="note default"><p>Both <code>fdisk</code> &amp; <code>gdisk</code> <u>don’t allow altering existing partition size</u><br>If wants to modify, needs to <u>delete existing partition &amp; rebuild from scratch</u>.</p>
</div>

<br>

<p><code>fdisk</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show partition scheme on disk</span></span><br><span class="line">fdisk -l /dev/nvme0n1</span><br><span class="line"></span><br><span class="line"><span class="comment"># show partition detail</span></span><br><span class="line">fdisk -l /dev/nvme0n1p1</span><br><span class="line"></span><br><span class="line"><span class="comment"># partition</span></span><br><span class="line">fdisk /dev/nvme0n1</span><br><span class="line"></span><br><span class="line"><span class="comment"># inside fdisk prompt</span></span><br><span class="line">p	show current partition</span><br><span class="line">n	create </span><br><span class="line">d	delete </span><br><span class="line">a	mark as bootable</span><br><span class="line"></span><br><span class="line">t	change partition <span class="built_in">type</span> code</span><br><span class="line">l	list <span class="built_in">type</span> code</span><br><span class="line">v	verify partition table</span><br><span class="line"></span><br><span class="line">q	quit</span><br><span class="line">w	write &amp; quit</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  In the past, partitions were aligned on <strong>CHS cylinders</strong>. </p>
<p>  Modern disks require partition alignment on <strong>8+ sector</strong> boundaries for optimal performance.<br>  e.g. Boundary of 1 M (2048-sector)</p>
<p>  Failure to align partitions properly, will result in severe performance degradation</p>
</blockquote>
<br>

<p><code>gdisk</code></p>
<blockquote>
<p>  If hard drive currently isn’t using GPT, then offers options to <strong>convert to GPT</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># inside gdisk prompt</span></span><br><span class="line">i	show detailed info on a partition</span><br><span class="line">v	verify disk</span><br></pre></td></tr></table></figure>



<br>

<p><code>parted</code></p>
<blockquote>
<p>  Allow <strong>modify existing partition size</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># enter</span></span><br><span class="line">parted</span><br><span class="line"></span><br><span class="line"><span class="comment"># inside parted prompt</span></span><br><span class="line">p	<span class="built_in">print</span></span><br></pre></td></tr></table></figure>





<br>

<p><code>gparted</code></p>
<div class="note danger"><p><u>Resizing / moving filesystem</u> can be dangerous.</p>
<ul>
<li><p>  If resizing code has bug, or power failure during operation, there will be <strong>data lost</strong>.</p>
</li>
<li><p>  Resize / move boot partition on BIOS-based machine can make system <strong>unbootable</strong>, until boot loader is <strong>reinstalled</strong>.</p>
</li>
</ul>
</div>

<br>

<h4 id="Disk-Formatting"><a href="#Disk-Formatting" class="headerlink" title="Disk Formatting"></a><u>Disk Formatting</u></h4><ul>
<li>  <strong>Low-level</strong> formatting:  create a structure of sectors &amp; tracks on the disk </li>
<li>  <strong>High-level</strong> formatting:  create <strong>filesystem</strong></li>
</ul>
<blockquote>
<p>  <strong>Prepare partition for use</strong>:  </p>
<p>  Format partition / Make filesystem (write low-level data structures to disk)</p>
</blockquote>
<div class="note primary"><p>Hard disks are low-level formatted at the factory, should <strong>never</strong> need to be low-level formatted again.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># low level format hard disk</span></span><br><span class="line">fdformat /dev/xx</span><br></pre></td></tr></table></figure>
</div>



<br>

<br>

<h2 id="Filesystem"><a href="#Filesystem" class="headerlink" title="# Filesystem"></a># Filesystem</h2><blockquote>
<p>  Handles: <strong>read &amp; write data to raw device</strong></p>
</blockquote>
<div class="note success"><p>Filesystem in essence: <strong>big data structures</strong>  (Store data on disk in an <strong>indexed</strong> method)</p>
<p><a href="http://ext4magic.sourceforge.net/howto_en.html">Link: <code>ext4</code> black magic</a></p>
</div>



<p>Filesystem: Win &amp; Linux</p>
<ul>
<li><p>  Windows assign <strong>drive letters</strong>, file path tells exactly what physical device the file is stored on</p>
</li>
<li><p>Linux use <strong>virtual directory</strong>, contains file path from all storage devices installed on system</p>
<ul>
<li>  Single <strong>root <code>/</code></strong> directory</li>
<li>  Doesn’t show physical device that contains the file</li>
<li>Place physical device in virtual filesystem with <strong>mount points</strong> :<br>  Empty directory points to a specific physical device</li>
</ul>
</li>
</ul>
<br>

<h3 id="1-Make-Filesystem"><a href="#1-Make-Filesystem" class="headerlink" title="1 - Make Filesystem"></a>1 - Make Filesystem</h3><h4 id="Filesystem-Type"><a href="#Filesystem-Type" class="headerlink" title="Filesystem Type"></a><u>Filesystem Type</u></h4><p><strong>Linux</strong> Filesystem</p>
<table>
<thead>
<tr>
<th>Filesystem</th>
<th>Type Code</th>
<th>Comments</th>
</tr>
</thead>
<tbody><tr>
<td>Ext2fs</td>
<td><code>ext2</code></td>
<td>traditional Linux native fs (2 TB max)</td>
</tr>
<tr>
<td>Ext3fs</td>
<td><code>ext3</code></td>
<td>ext2fs with a journal</td>
</tr>
<tr>
<td>Ext4fs</td>
<td><code>ext4</code></td>
<td><strong>Default</strong>. work on large disks (16+ TB)</td>
</tr>
<tr>
<td>ReiserFS</td>
<td><code>reiserfs</code></td>
<td>best at handling large number of <strong>small files</strong>. This feature is also found in <code>ext4</code></td>
</tr>
<tr>
<td>JFS</td>
<td><code>jfs</code></td>
<td>Journaled. created by IBM (for AIX OS)</td>
</tr>
<tr>
<td>Btrfs</td>
<td><code>btrfs</code></td>
<td>advanced filesystem inspired by ZFS</td>
</tr>
<tr>
<td>eCryptfs</td>
<td><code>ecryptfs</code></td>
<td><u>POSIX-compliant encryption protocol</u> applies to data before storing on device. Only OS that creates the FS can read data from it.</td>
</tr>
<tr>
<td>Swap</td>
<td><code>swap</code></td>
<td>Create Virtual memory using physical drive space</td>
</tr>
</tbody></table>
<blockquote>
<p>  eCryptfs on a partition: Appear in <code>/etc/crypttab</code></p>
</blockquote>
<div class="note success"><p><strong>Btrfs</strong></p>
<ul>
<li>  Improved fault tolerance &amp; High performance (up to 16 EB)</li>
<li>  Perform RAID &amp; LVM subvolumes</li>
<li>  Built-in snapshots for backups</li>
<li>  Automatic data compression</li>
<li>  Create filesystem across multiple devices</li>
</ul>
</div>





<br>



<p><strong>Non-Linux</strong> Filesystem</p>
<table>
<thead>
<tr>
<th>Filesystem</th>
<th>Type Code</th>
<th>Comments</th>
</tr>
</thead>
<tbody><tr>
<td>CIFS</td>
<td><code>cifs</code></td>
<td>Common Internet Filesystem (<strong>Microsoft</strong>). Read / Write data across network using network storage device.</td>
</tr>
<tr>
<td>NFS</td>
<td><code>nfs</code></td>
<td>Network FS. <strong>Open source</strong> standard for read / write data across network</td>
</tr>
<tr>
<td>SMB</td>
<td>/</td>
<td>Server Message Block (Microsoft). For network storage &amp; devices (e.g. printers). SMB support allows Linux clients &amp; servers interact with Microsoft clients &amp; servers.</td>
</tr>
<tr>
<td>FAT</td>
<td><code>msdos</code> / <code>vfat</code></td>
<td>File Allocation Table. <u>DOS &amp; Win only support FAT</u></td>
</tr>
<tr>
<td>VFAT</td>
<td><code>vfat</code></td>
<td>Virtual FAT. Format USB &amp; SD cards</td>
</tr>
<tr>
<td>exFAT</td>
<td><code>exfat</code></td>
<td>Format USB &amp; SD cards</td>
</tr>
<tr>
<td>NTFS</td>
<td>/</td>
<td>New Technology FS. preferred for win7</td>
</tr>
<tr>
<td>HFS / HFS+</td>
<td>/</td>
<td>Hierarchical FS (by Apple)</td>
</tr>
<tr>
<td>XFS</td>
<td><code>xfs</code></td>
<td>created by SGI (Silicon Graphics, for IRIX OS)</td>
</tr>
<tr>
<td>ZFS</td>
<td><code>zfs</code></td>
<td>Zettabyte FS (Sun, now Oracle). For <strong>Unix</strong> servers, inspires Btrfs.</td>
</tr>
<tr>
<td>ISO-9660</td>
<td><code>iso9660</code></td>
<td>standard for CD-ROM. also works with Rock Ridge extensions</td>
</tr>
<tr>
<td>UDF</td>
<td>/</td>
<td>Universal Disc Format. common for DVD-ROM</td>
</tr>
</tbody></table>
<div class="note default"><p><strong>FAT</strong></p>
<ul>
<li>  Every major OS understands FAT, making FAT excellent for <strong>exchanging data</strong> on removable media</li>
<li>  Also for <strong>cross-platform disk</strong> (e.g. Linux &amp; Windows)</li>
</ul>
</div>



<div class="note warning"><p>If using non x86 platform, make sure to check <strong>filesystem development</strong> on that platform.</p>
<p><u>A fast &amp; reliable filesystem on one CPU might be slow &amp; unreliable on another.</u></p>
</div>



<br>

<h4 id="Create-Filesystem"><a href="#Create-Filesystem" class="headerlink" title="Create Filesystem"></a><u>Create Filesystem</u></h4><blockquote>
<ul>
<li>  <code>mkfs</code></li>
<li>  <code>mkdosfs</code>  (for FAT)</li>
</ul>
</blockquote>
<br>

<p><code>mkfs</code> creates all <u>index files &amp; tables</u> necessary for the specific filesystem</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># make fs on a PARTITION, pass typecode </span></span><br><span class="line">mkfs -t ext4 /dev/sda2</span><br><span class="line"></span><br><span class="line"><span class="comment"># set reserved block percentage</span></span><br><span class="line">mkfs -t ext4 -m 1 /dev/sda2</span><br><span class="line"></span><br><span class="line"><span class="comment"># help</span></span><br><span class="line">man mkfs.ext4</span><br><span class="line"></span><br><span class="line"><span class="comment"># bad block check</span></span><br><span class="line"><span class="comment"># every sector in the partition will be checked</span></span><br><span class="line">mkfs -c </span><br></pre></td></tr></table></figure>



<div class="note default"><p><strong>Reserved block percentage</strong></p>
<p>If disk is getting close to full, Linux will <u>report disk is full before it actually gets full.</u></p>
</div>



<div class="note info"><p>If bad block check returns result that <u>several sectors are bad</u>, chances are the <strong>entire</strong> hard disk doesn’t have long to live.</p>
</div>

<br>

<h4 id="Create-Swap-Space"><a href="#Create-Swap-Space" class="headerlink" title="Create Swap Space"></a><u>Create Swap Space</u></h4><p><strong>Swap Space</strong> </p>
<ul>
<li>  Linux can use <strong>swap partition</strong> or <strong>swap file</strong> for memory extension</li>
<li>  Identify: MBR partition type code <code>0x82</code></li>
<li>  Linux use <code>/etc/fstab</code> to hold swap space definition</li>
</ul>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># make swap space</span></span><br><span class="line">mkswap /dev/sda6</span><br><span class="line"></span><br><span class="line"><span class="comment"># activate swap</span></span><br><span class="line">swapon /dev/sda6</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Activate swap space <strong>permanently</strong>:  Create entry in <code>/etc/fstab</code></p>
</blockquote>
<br>

<h3 id="2-Maintain-Filesystem-Health"><a href="#2-Maintain-Filesystem-Health" class="headerlink" title="2 - Maintain Filesystem Health"></a>2 - Maintain Filesystem Health</h3><blockquote>
<ul>
<li>  <strong>Tuning</strong> : <code>dumpe2fs,  tune2fs,  debugfs</code></li>
<li>  <strong>Monitor</strong> : <code>df,  du,  iostat </code></li>
</ul>
</blockquote>
<p>Additionally, <code>/proc</code> &amp; <code>/sys</code> are used for recording system stats</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># partitions</span></span><br><span class="line">cat /proc/partitions</span><br><span class="line"></span><br><span class="line"><span class="comment"># mount points</span></span><br><span class="line">cat /proc/mounts</span><br><span class="line"></span><br><span class="line"><span class="comment"># partitions &amp; kernel-level stats</span></span><br><span class="line">ls /sys/block</span><br></pre></td></tr></table></figure>



<div class="note primary"><p>Many Linux filesystem maintenance tools should run, when filesystem is <strong>unmounted</strong>.</p>
<p>Changes made by maintenance tools while filesystem is mounted, may <u>confuse kernel drivers</u>.</p>
</div>



<br>



<h4 id="Filesystem-Tools"><a href="#Filesystem-Tools" class="headerlink" title="Filesystem Tools"></a><u>Filesystem Tools</u></h4><p><strong>Linux</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">sudo apt install -y e2fsprogs</span><br><span class="line"></span><br><span class="line"><span class="comment"># change file attributes</span></span><br><span class="line">chattr</span><br><span class="line"></span><br><span class="line"><span class="comment"># change label</span></span><br><span class="line">e2label</span><br><span class="line"></span><br><span class="line"><span class="comment"># resize fs</span></span><br><span class="line">resize2fs</span><br><span class="line"></span><br><span class="line"><span class="comment"># show block &amp; superblock info</span></span><br><span class="line">dumpe2fs</span><br><span class="line"></span><br><span class="line"><span class="comment"># tuning</span></span><br><span class="line">tune22fs,  debugfs</span><br></pre></td></tr></table></figure>

<br>

<p><strong>XFS</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show / edit fs params (e.g. UUID)</span></span><br><span class="line">xfs_admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># info</span></span><br><span class="line">xfs_info</span><br><span class="line"></span><br><span class="line"><span class="comment"># debug</span></span><br><span class="line">xfs_db</span><br><span class="line"></span><br><span class="line"><span class="comment"># repair</span></span><br><span class="line">xfs_repair</span><br><span class="line"></span><br><span class="line"><span class="comment"># improve organization of mounted fs</span></span><br><span class="line">xfs_fsr</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Filesystem Check</strong>: <code>fsck</code></p>
<ul>
<li>  A frontend to filesystem-specific tools (<code>e2fsck</code> , <code>fsck.jfs</code> , etc.)</li>
<li>  Examine filesystem’s major <strong>data structures</strong> for <strong>internal consistency</strong> (filesystem <strong>match</strong> the index against actual files)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check all files in /etc/fstab</span></span><br><span class="line">fsck -A</span><br><span class="line"></span><br><span class="line"><span class="comment"># check only specified filesystem</span></span><br><span class="line">fsck -t ext4</span><br><span class="line"></span><br><span class="line"><span class="comment"># indicate progress, verbose</span></span><br><span class="line">fsck -CV</span><br></pre></td></tr></table></figure>

<div class="note info"><p>Linux runs <code>fsck</code> automatically at startup on partitions marked in <code>/etc/fstab</code> :  </p>
<ul>
<li>  Perform quick <strong>cursory examination</strong> of a partition, to confirm it’s unmounted cleanly</li>
<li>  Linux boot process is not delayed due to filesystem check, <strong>unless system isn’t shutdown properly</strong></li>
</ul>
</div>



<div class="note success"><p>If problem with filesystem:</p>
<ul>
<li>  Run <code>fsck</code> in <strong>recovery</strong> mode, on a specific <strong>partition</strong> (e.g. <code>fsck /dev/part1</code>)</li>
<li>  If fail on first run, try running <strong>again</strong> for a few times</li>
</ul>
</div>

<br>

<h4 id="Filesystem-Tuning"><a href="#Filesystem-Tuning" class="headerlink" title="Filesystem Tuning"></a><u>Filesystem Tuning</u></h4><blockquote>
<ul>
<li>  Provide info (<strong>mounted</strong>) :  <code>dumpe2fs</code> </li>
<li>  Change tuning options  (<strong>un-mounted</strong>) :  <code>tune2fs,  debugfs</code></li>
</ul>
</blockquote>
<br>

<p><strong><code>dumpe2fs</code> : Obtain FS Info</strong></p>
<div class="note warning"><p><code>ext2 / ext3</code>  ONLY</p>
</div>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -h: omit info about group descriptors</span></span><br><span class="line">dumpe2fs -h /dev/nvme0n1p1</span><br><span class="line"></span><br><span class="line"><span class="comment"># XFS equivalent</span></span><br><span class="line">xfs_info [mount point]</span><br><span class="line">xfs_metadump</span><br></pre></td></tr></table></figure>

<div class="note danger"><p>An <strong>inode</strong> is an entry in the <u>index table</u> that <strong>tracks</strong> files stored on the filesystem.</p>
<p>Each <strong>inode</strong> contains info for <strong>one file</strong>.<br><strong>Number of inodes limit number of files</strong></p>
</div>



<br>

<p><strong><code>tune2fs</code> : Adjust Tunable FS Parameters</strong></p>
<blockquote>
<p>  Change filesystem parameters reported by <code>dumpe2fs</code></p>
</blockquote>
<div class="note warning"><p><code>ext2 / ext3</code>  ONLY</p>
</div>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># unmount first</span></span><br><span class="line">umount /dev/sda6</span><br><span class="line"></span><br><span class="line"><span class="comment"># adjust max mount count</span></span><br><span class="line"><span class="comment"># trick system to think filesystem has mouted x number of times</span></span><br><span class="line">-c [num x]</span><br><span class="line"></span><br><span class="line"><span class="comment"># adjust periodic disk checks interval</span></span><br><span class="line">-i [1d / 1w / 1m]</span><br><span class="line"></span><br><span class="line"><span class="comment"># add journal (verison 2 log format, convert ext2 to ext3)</span></span><br><span class="line"><span class="comment"># will create a file called .journal</span></span><br><span class="line">-j</span><br><span class="line"></span><br><span class="line"><span class="comment"># set journal parameters</span></span><br><span class="line">-J size=xx device=xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># set reserved blocks</span></span><br><span class="line">-m [percent]</span><br><span class="line"></span><br><span class="line"><span class="comment"># change filesystem UUID</span></span><br><span class="line">-U xx</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <strong>Note</strong>:</p>
<ul>
<li>  <code>ext2, ext3, ext4</code>  require <strong>periodic disk check</strong> with <code>fsck</code></li>
</ul>
</blockquote>
<br>

<p><strong><code>debugfs</code> : Debug FS Interactively</strong></p>
<blockquote>
<p>  <a href="https://www.cyberciti.biz/tips/linux-ext3-ext4-deleted-files-recovery-howto.html">Reference Link</a></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># unmount first</span></span><br><span class="line">umount /dev/sda6</span><br><span class="line"></span><br><span class="line"><span class="comment"># enter interactive mode</span></span><br><span class="line">debugfs /dev/sda6</span><br><span class="line"></span><br><span class="line"><span class="comment"># superblock info</span></span><br><span class="line">stats -h</span><br><span class="line"></span><br><span class="line"><span class="comment"># inode info</span></span><br><span class="line"><span class="built_in">stat</span> [filename]</span><br><span class="line"></span><br><span class="line"><span class="comment"># undelete file	</span></span><br><span class="line">undelete inode [num]</span><br><span class="line"></span><br><span class="line"><span class="comment"># get inode number</span></span><br><span class="line">lsdel</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract file</span></span><br><span class="line">write [<span class="built_in">source</span>] [dest]</span><br></pre></td></tr></table></figure>



<div class="note danger"><p>Use <code>debugfs</code> to <strong>undelete</strong> a file:  (file deleted using <code>rm</code>)</p>
<p><code>inode</code> is the <strong>inode number</strong> of the deleted file. (e.g.  Use <code>ls -li</code> to see file inode number)</p>
</div>



<br>



<h4 id="Maintain-a-Journal"><a href="#Maintain-a-Journal" class="headerlink" title="Maintain a Journal"></a><u>Maintain a Journal</u></h4><p><strong>Journaling</strong></p>
<p><strong>Problem</strong>: After power failure / system crash, <code>ext2</code> filesystem could be in an <strong>inconsistent</strong> state. Only way to safely mount is to do a <strong>full disk check</strong> before mount.</p>
<p><strong>Solution</strong>: Convert to a <strong>journaling</strong> filesystem (<code>ext3</code>), <strong>track</strong> data not yet written to the drive in a <strong>log file</strong>  (journal)</p>
<ul>
<li><p>  <strong>Journal</strong> :  data structure that describes <strong><u>pending</u></strong> operations</p>
</li>
<li><p>Prior to <strong>writing</strong> data to disk’s main data structures, Linux <strong>describes</strong> what’s going to do in the journal</p>
<ul>
<li>  When operation <strong>complete</strong>, entries are <strong>removed</strong> from journal</li>
</ul>
</li>
<li><p>In case system crashes, only need to examine the journal, and <strong><u>only check data structures mentioned in the journal</u></strong></p>
<ul>
<li><p>  Inconsistency: <strong>roll back</strong> or <strong>complete</strong> changes</p>
</li>
<li><p>  Return disk to consistent state, without checking every data structure in the filesystem</p>
</li>
</ul>
</li>
<li><p>  Greatly <strong>speeds up</strong> disk check process</p>
</li>
</ul>
<br>

<p>Linux filesystem with a <strong>journal</strong></p>
<ul>
<li>  <code>ext3</code></li>
<li>  <code>ext4</code></li>
<li>  <code>reiserfs</code></li>
<li>  <code>xfs</code></li>
<li>  <code>jfs</code></li>
</ul>
<div class="note primary"><p>To use a journal, must <strong>mount filesystem with correct type code</strong></p>
</div>



<br>

<h4 id="Monitor-Disk-Usage"><a href="#Monitor-Disk-Usage" class="headerlink" title="Monitor Disk Usage"></a><u>Monitor Disk Usage</u></h4><blockquote>
<ul>
<li>  <code>df</code>     (by <strong>partition / mounted filesystem</strong>)</li>
<li>  <code>du</code>     (by <strong>directory</strong>)</li>
</ul>
</blockquote>
<br>

<p><code>df</code></p>
<blockquote>
<p>  Helpful to find out which <strong>partition</strong> are in danger of being overloaded</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># e.g  /proc, /sys, /proc/bus/usb</span></span><br><span class="line">-a	include all fs (virtual fs size = 0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># partition with small files can deplete inodes soon</span></span><br><span class="line">-i	available &amp; used inodes</span><br><span class="line"></span><br><span class="line">-h	human readable</span><br><span class="line">-l	omit network fs (only show <span class="built_in">local</span> fs)</span><br><span class="line">-T	show fs <span class="built_in">type</span></span><br><span class="line">-t <span class="built_in">type</span>	<span class="built_in">limit</span> by fs <span class="built_in">type</span></span><br></pre></td></tr></table></figure>

<div class="note default"><p><code>df -i</code> works well for filesystems that creates <strong>fixed</strong> number of inodes.</p>
<p>Other filesystems (e.g. <code>reiserfs</code>, <code>btrfs</code>) create inodes <strong>dynamically</strong>.</p>
</div>



<br>

<p><code>du</code></p>
<blockquote>
<p>  Adds up disk space used by <u>all files in a specified directory</u></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">du -shc ~/Downloads/*</span><br><span class="line"></span><br><span class="line">-h	human readable</span><br><span class="line">-a	report of individual files</span><br><span class="line">-c	grand total</span><br><span class="line">-s	summary of subdirectory</span><br><span class="line"></span><br><span class="line">-l	count hard links</span><br><span class="line">-x	<span class="built_in">limit</span> report to one fs</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Normally <code>du</code> counts files that appear <strong>multiple</strong> times as <strong>hard links</strong> only <strong>once</strong>.</p>
</blockquote>
<br>

<h3 id="3-Mount-amp-Unmount-Filesystem"><a href="#3-Mount-amp-Unmount-Filesystem" class="headerlink" title="3 - Mount &amp; Unmount Filesystem"></a>3 - Mount &amp; Unmount Filesystem</h3><blockquote>
<p>  Filesystems are most often used by being <strong>mounted</strong> - <u>associated with a directory</u></p>
<ul>
<li>  <strong>Temporary</strong> : <code>mount / umount</code></li>
<li>  <strong>Permanent</strong> : edit <code>/etc/fstab</code></li>
</ul>
</blockquote>
<br>

<h4 id="Temp-Mount"><a href="#Temp-Mount" class="headerlink" title="Temp - Mount"></a><u>Temp - Mount</u></h4><blockquote>
<p>  Ties a filesystem to a Linux directory</p>
</blockquote>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-a	mount all fs <span class="keyword">in</span> /etc/fstab</span><br><span class="line">-r	mount as <span class="built_in">read</span> only</span><br><span class="line">-w	mount as <span class="built_in">read</span> / write</span><br><span class="line"></span><br><span class="line">-v	verbose output</span><br><span class="line">-L	label</span><br><span class="line">-U	UUID</span><br><span class="line"></span><br><span class="line"><span class="comment"># if no -t, Linux will auto detect fs type</span></span><br><span class="line">-t <span class="built_in">type</span> specify fs <span class="built_in">type</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example</span></span><br><span class="line">sudo mount -t ext4 /dev/sdb1 /mnt</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Options</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use loopback device</span></span><br><span class="line"><span class="comment"># mount a file as if it were a partition</span></span><br><span class="line">mount -t vfat -o loop 1.img /mnt/img</span><br><span class="line"></span><br><span class="line"><span class="comment"># enable / disable normal user to mount fs</span></span><br><span class="line"><span class="comment"># only user who mount the fs may unmount it</span></span><br><span class="line">-o user / nouser</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Notes</strong></p>
<ul>
<li><p>If <code>/etc/fstab</code> specify <code>user, users, owner</code> ,<br>  ordinary user may mount fs that specifiy <strong>either</strong> device <strong>or</strong> mount point, but <strong>not both</strong>.</p>
</li>
<li><p>Most Linux distros ship with <strong>auto-mounter</strong> support,<br>  which let OS auto mount removable media when inserted</p>
</li>
<li><p>  Using <code>mount</code> : record in <code>/etc/mtab</code>. <u>Not a config file to edit</u></p>
</li>
</ul>
<br>



<h4 id="Temp-Umount"><a href="#Temp-Umount" class="headerlink" title="Temp - Umount"></a><u>Temp - Umount</u></h4><p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-a	unmount all <span class="keyword">in</span> /etc/mtab</span><br><span class="line">-r	fallback to read-only</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Notes</strong></p>
<ul>
<li><code>umount -r</code><br>  If Linux can’t unmount a filesystem, it should attempt to <strong>remount</strong> as <strong>read-only</strong> mode</li>
<li>  Specify only <code>device</code> or <code>mount point</code>, no need to specify both</li>
</ul>
<div class="note success"><p>Linux <strong>caches access</strong> to most fs, hence data may not be written to disk until some time after <strong>write</strong> command.<br>Possible to <strong>corrupt</strong> disk by <strong>unplugging</strong>, even when disk is <strong>inactive</strong>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># write cache to disk manually</span></span><br><span class="line">sync</span><br></pre></td></tr></table></figure>
</div>

<br>

<h4 id="Permanent"><a href="#Permanent" class="headerlink" title="Permanent"></a><u>Permanent</u></h4><p><code>/etc/fstab</code> </p>
<ul>
<li>  <code>fstab</code> : filesystem table, mount at <strong>boot time</strong></li>
<li>  Describes <u><strong>permanent</strong> mappings of filesystem to mount points</u>, controls how Linux provides access to disk partitions &amp; removable media drivers</li>
<li>  Can <strong>manually</strong> add device to <code>/etc/fstab</code></li>
</ul>
<br>

<p><strong>Content</strong> of <code>/etc/fstab</code></p>
<blockquote>
<p>  Most distros now specify partitions by labels / <strong>UUID</strong><br>  Ensuring <u>correct drive partition</u> is accessed, despite the order it appears in the raw device table</p>
</blockquote>
<ul>
<li>  <code>dump</code> : equals <strong>1</strong>, if <code>dump</code> utility should back up a partition</li>
<li><code>fsck</code> : filesystem check order <ul>
<li>  <strong>Higher</strong> number represents <strong>check order</strong></li>
<li>  <strong>0</strong> : <code>fsck</code> should <strong>not</strong> check fs</li>
<li>  <strong>1</strong> : root partition</li>
<li>  <strong>2</strong> : other partition</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Example</span></span><br><span class="line">UUID=xx  /mnt/data  ext4  users,credentials=/etc/creds  0 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># /etc/creds</span></span><br><span class="line">username=kk</span><br><span class="line">password=hello</span><br></pre></td></tr></table></figure>



<div class="note warning"><ul>
<li>  If add new hard disk, or repartition, then need to modify <code>/etc/fstab</code></li>
<li>  If devices in <code>/etc/fstab</code> don’t exist at boot time, then will generate <strong>boot error</strong></li>
</ul>
</div>



<br>

<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
        <tag>Low Level System</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 102 Manage Software</title>
    <url>/2022/LPIC-102/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-102/#Rpm-Yum">Use Rpm &amp; Yum</a></li>
<li>  <a href="/2022/LPIC-102/#Deb-pkg">Use Debian pkg management</a></li>
<li>  <a href="/2022/LPIC-102/#Manage-shared-libs">Manage shared libs</a></li>
<li>  <a href="/2022/LPIC-102/#Manage-Process">Create, monitor, prioritize &amp; kill Processes</a></li>
</ul>
</div>

<span id="more"></span> 

<br>





<h2 id="Rpm-amp-Yum"><a href="#Rpm-amp-Yum" class="headerlink" title="# Rpm &amp; Yum"></a># Rpm &amp; Yum</h2><p><strong>Pkg general</strong></p>
<ul>
<li>  Foundation that all programs rely on: <strong>Linux kernel</strong></li>
<li>Package system maintain a <strong>database</strong> of installed files (with exact files &amp; file locations)<br>  Different ways of tracking pkgs &amp; files:<ul>
<li>  Application files (track each individual file)</li>
<li>  Library dependencies</li>
<li>  Application version</li>
</ul>
</li>
</ul>
<br>

<h3 id="1-RPM"><a href="#1-RPM" class="headerlink" title="1 - RPM"></a>1 - RPM</h3><blockquote>
<p>  RedHat pkg manager</p>
</blockquote>
<p>Naming of the package: </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Package name + Version number + Build number ()+ CPU architecture</span><br></pre></td></tr></table></figure>

<br>

<p>A pkg designed for one distro, may have <strong>unmet</strong> dependencies in another distro</p>
<blockquote>
<ul>
<li>  ✗: upgrade dependencies may break other pkgs</li>
<li>  ✗ : (Servers) distro-specific scripts / config files</li>
<li>  ✗ / ✓: <u><strong>rebuild target pkg from source</strong></u> (not guaranteed, if pkg naming is different for dependencies)</li>
</ul>
</blockquote>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install </span></span><br><span class="line">rpm -Uvh samba.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify pkg (-qi / -V)</span></span><br><span class="line">rpm -qi samba.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># display all installed pkgs</span></span><br><span class="line">rpm -qa</span><br><span class="line"></span><br><span class="line"><span class="comment"># More options</span></span><br><span class="line">-i    install (only <span class="keyword">if</span> not present)    &lt;==</span><br><span class="line">-U    install new &amp; upgrade existing (without manually uninstall old one)</span><br><span class="line">-e    uninstall (erase)</span><br><span class="line"></span><br><span class="line">-F    upgrade <span class="keyword">for</span> existing pkgs only</span><br><span class="line">-b    build binary pkg</span><br><span class="line">-vh   show progress</span><br><span class="line"></span><br><span class="line">-qc   configuration files of installed pkg</span><br><span class="line">-qR   deps of installed pkg</span><br><span class="line">-qRp  deps of uninstlled** pkg</span><br><span class="line"></span><br><span class="line">-ivh  install new </span><br><span class="line">-Uvh  install or upgrade</span><br><span class="line"></span><br><span class="line">--nodeps    no dependency check</span><br><span class="line">--<span class="built_in">test</span>      dry run</span><br><span class="line">--rebuild   build binary pkg (or use: rpmbuild)</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Extract data</strong></p>
<ul>
<li><p>  <strong>rpm files = modified <code>cpio</code> archives</strong></p>
</li>
<li><p>Usage</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install this</span></span><br><span class="line">sudo apt install rpm2cpio</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert to cpio</span></span><br><span class="line">rpm2cpio samba.src.rpm &gt; samba.src.cpio</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract data</span></span><br><span class="line">cpio -i --make-directories &lt; samba.src.cpio</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use pipe to convert &amp; extract to CURRENT dir (no intermediate cpio file)</span></span><br><span class="line">rpm2cpio samba.src.rpm | cpio -i --make-directories</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>RPM config Files</strong></p>
<p>Main rpm config file: <code>/usr/lib/rpm/rpmc</code></p>
<ul>
<li><p>Mostly related to <strong>CPU optimization</strong></p>
<blockquote>
<p>  Optimize code from your CPU model, by passing appropriate compiler options</p>
</blockquote>
</li>
<li><p>  Make global changes: edit file  <code>/etc/rpmrc</code></p>
</li>
<li><p>Build source rpm into <strong>binary</strong> rpm:</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># athlon: AMD athlon processor</span></span><br><span class="line"><span class="comment"># rpm pass (-02 -g -march=-686) to compiler, whenever building athlon</span></span><br><span class="line">optflags: athlon -02 -g -marchi686</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Rpm can determine system architecture, </p>
<p>  but in <code>/etc/rpmrc</code>, the <code>buildarchtranslate</code> lines cause <code>rpmbuild</code> to use <u><strong>one set of optimizations for a CPU family</strong></u> .    e.g. For x86 systems</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">buildarchtranslate: athlon:</span> <span class="string">i386</span></span><br><span class="line"><span class="attr">buildarchtranslate: i686:</span>   <span class="string">i386</span></span><br><span class="line"><span class="attr">buildarchtranslate: i386:</span>   <span class="string">i386</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>  By specifying below, will have a slight performance boost, but reduced portability</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">buildarchtranslate: athlon:</span> <span class="string">athlon</span></span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<br>

<h3 id="2-Yum"><a href="#2-Yum" class="headerlink" title="2 - Yum"></a>2 - Yum</h3><blockquote>
<p>  <u>RPM meta-pkg</u>, Yum (Yellow Dog Updater - Modified)</p>
<ul>
<li>  Pro: Group pkgs together for distribution</li>
</ul>
</blockquote>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">yum install</span><br><span class="line"></span><br><span class="line"><span class="comment"># upgrade pkg (these 2 are nearly identical)</span></span><br><span class="line">yum update</span><br><span class="line">yum upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># check if updates are available</span></span><br><span class="line">yum check-update</span><br><span class="line"></span><br><span class="line"><span class="comment"># also remove dependencies</span></span><br><span class="line">yum remove</span><br><span class="line"></span><br><span class="line"><span class="comment"># display pkg info</span></span><br><span class="line">yum list</span><br><span class="line">yum info</span><br><span class="line"></span><br><span class="line"><span class="comment"># search pkg</span></span><br><span class="line">yum search</span><br><span class="line"></span><br><span class="line"><span class="comment"># clean cache di</span></span><br><span class="line">yum clean</span><br><span class="line"></span><br><span class="line"><span class="comment"># enter shell mode</span></span><br><span class="line">yum shell</span><br><span class="line"></span><br><span class="line"><span class="comment"># show the file belongs to what pkg</span></span><br><span class="line">yum provides</span><br><span class="line"></span><br><span class="line"><span class="comment"># display pkg matching specified dependency</span></span><br><span class="line">yum resolvedep</span><br><span class="line"></span><br><span class="line"><span class="comment"># display deps list</span></span><br><span class="line">yum deplist</span><br></pre></td></tr></table></figure>



<p>Obtain pkg:   <code>yumdownloader</code>  (download to the current dir)</p>
<p>GUI tools: </p>
<ul>
<li>  <code>yum install yumex</code></li>
<li>  <code>yum install kyum</code></li>
</ul>
<br>



<p><strong>Yum config files</strong></p>
<ul>
<li>  Main file:    <code>/etc/yum.conf</code></li>
<li>  Additional conf:    <code>/etc/yum.repos.d/</code></li>
</ul>
<p>Yum use files in <code>/etc/yum.repos.d</code> to locate repos.<br>So adding new repos: <u>add files to this directory manually, or installing an rpm</u>   (just like <strong>apt</strong>)</p>
<br>



<h3 id="3-ZYpp"><a href="#3-ZYpp" class="headerlink" title="3 - ZYpp"></a>3 - ZYpp</h3><blockquote>
<p>  openSUSE’s own pkg management</p>
</blockquote>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show all available plg update</span></span><br><span class="line">zypper list-updates</span><br><span class="line"></span><br><span class="line"><span class="comment"># show repo info</span></span><br><span class="line">zypper lr</span><br><span class="line"></span><br><span class="line"><span class="comment"># install</span></span><br><span class="line">zypper <span class="keyword">in</span> xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># uninstall (remove)</span></span><br><span class="line">zypper re xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># search pkg</span></span><br><span class="line">zypper se xx</span><br></pre></td></tr></table></figure>



<br>

<br>

<h2 id="Deb-pkg"><a href="#Deb-pkg" class="headerlink" title="# Deb pkg"></a># Deb pkg</h2><blockquote>
<ul>
<li>  <code>apt-cache</code></li>
<li>  <code>apt-get</code></li>
<li>  <code>dpkg</code></li>
<li>  Text-based &amp; GUI tools   (  <code>dselect</code>, <code>aptitue</code>, <code>synaptic</code>  )</li>
</ul>
</blockquote>
<br>

<h3 id="1-apt-cache"><a href="#1-apt-cache" class="headerlink" title="1 - apt-cache"></a>1 - <code>apt-cache</code></h3><blockquote>
<p>Provide info about Debian pkg <strong>database</strong>  (package <strong>cache</strong>)</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show pkg info</span></span><br><span class="line">apt-cache showpkg xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># show stats</span></span><br><span class="line">apt-cache stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># show unmet deps</span></span><br><span class="line">apt-cache unmet</span><br><span class="line"></span><br><span class="line"><span class="comment"># show deps</span></span><br><span class="line">apt-cache depends xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># show pkgs that depend on xx</span></span><br><span class="line">apt-cache rdepends xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># find all pkgs that begin with sa</span></span><br><span class="line">apt-cache pkgnames sa</span><br></pre></td></tr></table></figure>



<br>

<h3 id="2-apt-get"><a href="#2-apt-get" class="headerlink" title="2 - apt-get"></a>2 - <code>apt-get</code></h3><blockquote>
<ul>
<li>  Config file:  <code>/etc/apt/sources.list</code></li>
<li>  Controls apt &amp; dselect options:  <code>/etc/apt/apt.conf</code></li>
</ul>
</blockquote>
<br>

<p><strong>Commands</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># after dselect</span></span><br><span class="line">apt-get dselect-upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># smart conflict resolution</span></span><br><span class="line">apt-get dist-upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># get newest available source pkg (in sources.list)</span></span><br><span class="line">apt-get <span class="built_in">source</span> xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># check for broken source pkg</span></span><br><span class="line">apt-get check</span><br><span class="line"></span><br><span class="line"><span class="comment"># housekeeping the list</span></span><br><span class="line">apt-get clean</span><br><span class="line">apt-get autoclean 	 <span class="comment"># only clean pkgs that cannot be downloaded</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># get copies of dpkg files</span></span><br><span class="line">apt-get download xx</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Options</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fix broken</span></span><br><span class="line">apt-get -f install / remove xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># dry run</span></span><br><span class="line">apt-get -s install xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile source pkg (in sources.list)</span></span><br><span class="line">apt-get -b <span class="built_in">source</span> xx</span><br></pre></td></tr></table></figure>



<br>

<h3 id="3-dpkg"><a href="#3-dpkg" class="headerlink" title="3 - dpkg"></a>3 - <code>dpkg</code></h3><blockquote>
<ul>
<li>  Format: <code>dpkg [option] [action] [pkg]</code></li>
</ul>
</blockquote>
<br>

<h4 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ignore deps info</span></span><br><span class="line">dpkg --ignore-depends=[pkg] -i / -r xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># dry run</span></span><br><span class="line">dpkg --no-act -i / -r xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># install all that match wildcard name</span></span><br><span class="line">dpkg --recursive -i xx</span><br></pre></td></tr></table></figure>

<br>

<h4 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h4><br>

<p><strong>Basic</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">dpkg -i xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove pkg only (Do this before UPGRADE pkg)  &lt;==</span></span><br><span class="line">dpkg -r xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove pkg &amp; config file</span></span><br><span class="line">dpkg -P / --purge xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># search for partially installed pkg</span></span><br><span class="line">dpkg -C / --audit</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Advanced</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show all CURRENTLY installed pkg   &lt;==</span></span><br><span class="line">dpkg --get-selections | sort -k 2 -r</span><br><span class="line"></span><br><span class="line"><span class="comment"># list all installed pkgs that match name pattern (here: jq)</span></span><br><span class="line">dpkg -l jq</span><br><span class="line"></span><br><span class="line"><span class="comment"># show info about installed pkg</span></span><br><span class="line">dpkg -p xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># show info about **uninstalled pkg</span></span><br><span class="line">dpkg -I xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># check status &amp; verify deps</span></span><br><span class="line">dpkg -s / --status</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Other</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reconfig installed pkg</span></span><br><span class="line">dpkg --configure xx</span><br><span class="line">dpkg-reconfigure xx</span><br><span class="line"></span><br><span class="line"><span class="comment"># show pkg </span></span><br><span class="line">sudo debconf-show cups</span><br></pre></td></tr></table></figure>



<br>

<h3 id="4-Tools"><a href="#4-Tools" class="headerlink" title="4 - Tools"></a>4 - Tools</h3><ul>
<li><p>  <code>dselect</code>  (high level pkg browser)</p>
</li>
<li><p><code>aptitude</code>  (combines interactive <code>dselect</code> &amp; cmd-line options of <code>apt-get</code>)</p>
<blockquote>
<ul>
<li>  <code>aptitude search xx</code></li>
<li>  <code>aptitude install xx</code></li>
</ul>
</blockquote>
</li>
<li><p>  <code>synaptic</code> (GUI tool)</p>
</li>
</ul>
<br>



<p><strong>Compare Deb pkg &amp; other pkg formats</strong></p>
<ul>
<li><p>Deb source pkg are groups of files</p>
<blockquote>
<ul>
<li>  source <strong>tarball</strong></li>
<li>  <strong>patch</strong> file  (support only <strong>one</strong> patch file)   |   Rpm pkg can contain <strong>multiple</strong> patch files</li>
<li>  <code>.dsc</code> file (digital signature, for pkg verification) </li>
</ul>
</blockquote>
</li>
</ul>
<br>

<p><strong>Configure dpkg</strong> </p>
<ul>
<li><p>Main dpkg config file: <code>/etc/dpkg/dpkg.cfg</code></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># alwasy dry run before install</span></span><br><span class="line"><span class="comment"># add this line in dpkg.cfg</span></span><br><span class="line">no-act</span><br></pre></td></tr></table></figure></li>
<li><p>dpkg rely on files in <code>/var/lib/dpkg</code>  (list of available &amp; installed pkgs)</p>
<blockquote>
<p>  This is the Debian installed file <strong>database</strong></p>
</blockquote>
</li>
</ul>
<br>



<h3 id="5-Pkg-deps-amp-Conflicts"><a href="#5-Pkg-deps-amp-Conflicts" class="headerlink" title="5 - Pkg deps &amp; Conflicts"></a>5 - Pkg deps &amp; Conflicts</h3><br>

<p><strong>Convert between pkg formats (<code>alien</code>)</strong></p>
<blockquote>
<p>  Convert between: rpm, deb, tarballs</p>
</blockquote>
<ul>
<li><p><code>alien</code> requires <strong>both</strong> rpm &amp; dpkg to be installed</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default is to .deb (--to-deb)</span></span><br><span class="line">alien xx.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># deb to rpm</span></span><br><span class="line">alien --to-rpm xx.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># deb to tarball</span></span><br><span class="line">alien --to-tgz xx.deb</span><br></pre></td></tr></table></figure></li>
<li><p>Convert tarball to rpm</p>
<blockquote>
<p>  Convert a tarball: convert files in the dir structure of original tarball, use system’s <strong>root dir</strong> as base</p>
</blockquote>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># unpack</span></span><br><span class="line">tar xvzf xx.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># rename dir</span></span><br><span class="line"><span class="comment"># when create new tarball, will have file in correct locations such as /usr/bin, /usr/lib</span></span><br><span class="line">mv xx-files usr</span><br><span class="line"></span><br><span class="line"><span class="comment"># pack</span></span><br><span class="line">tar cvzf xx.tgz usr</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove folder</span></span><br><span class="line">rm -r usr</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert to rpm</span></span><br><span class="line">alien --ro-rpm xx.tgz</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<p><strong>Deps problems</strong></p>
<ul>
<li>  Missing libs / support programs</li>
<li>  Incompatible libs / support programs</li>
<li>  Duplicate files / features</li>
<li>  Mismatched names</li>
</ul>
<br>

<p><strong>Workarounds</strong></p>
<ul>
<li><p><strong>Force</strong> installation</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ignore failed deps</span></span><br><span class="line">rpm -i xx --nodeps</span><br><span class="line"></span><br><span class="line"><span class="comment"># ignore other errors</span></span><br><span class="line">rpm -i xx --force</span><br><span class="line"></span><br><span class="line"><span class="comment"># for dpkg</span></span><br><span class="line">dpkg --ignore-depends=[pkg] -i xx</span><br><span class="line">dpkg --force-depends -i xx</span><br><span class="line">dpkg --force-conflicts -i xx</span><br></pre></td></tr></table></figure></li>
<li><p>  <strong>Upgrade</strong> / replace the depend-on pkg</p>
</li>
<li><p><strong>Rebuild</strong> problematic pkg</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">rpmbuild --rebuild xx.src.rpm</span><br></pre></td></tr></table></figure></li>
<li><p>  Locate another <strong>version</strong> of the pkg</p>
</li>
</ul>
<br>



<p><strong>Startup Scripts Problem</strong></p>
<ul>
<li>  This problem only affect <strong>servers</strong></li>
<li>  Old Linux use <strong>SysV</strong> startup scripts</li>
<li>local startup scripts: <ul>
<li>  <code>/etc/rc.d/rc.local</code></li>
<li>  <code>/etc/rc.d/boot.local</code></li>
</ul>
</li>
</ul>
<br>

<br>

<h2 id="Manage-shared-libs"><a href="#Manage-shared-libs" class="headerlink" title="# Manage shared libs"></a># Manage shared libs</h2><blockquote>
<p>  Libraries are chosen by programmers, NOT by users.</p>
<p>  <strong>Cannot substitute</strong> one library for another.</p>
</blockquote>
<br>

<h3 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1 - Overview"></a>1 - Overview</h3><p><strong>Linux Libraries</strong></p>
<ul>
<li>  Multiple application that use same functions, can share same library files</li>
<li>Two types of libs:<ul>
<li>  <strong>Static</strong> Libs (statically linked libs, functions copied into <strong>applications</strong> when it’s compiled)</li>
<li>  <strong>Shared</strong> Libs (dynamic libs, functions loaded into <strong>memory</strong> and bound to application, when program is launched)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Library Principles</strong></p>
<ul>
<li>Provide commonly used program fragments (use one copy multiple times)<ul>
<li>  Linux widget sets: Qt, GTK+ (GIMP Tool Kit)</li>
<li>  Linux C library:  <strong>glibc</strong> (GNU C library, <code>/lib/x86_64-linux-gnu/libc.so.6</code>)   </li>
</ul>
</li>
<li>Most programs use libs as <strong>shared</strong> libraries (<strong>dynamic</strong> libraries)<ul>
<li>  Executable include <strong>references</strong> to shared lib files</li>
</ul>
</li>
<li>May increase program load time, and other issues:<ul>
<li>  programs must be able to <strong>locate</strong> shared libs</li>
<li>  If an important shared lib become inaccessible (due to overwritten), system might not even boot</li>
</ul>
</li>
</ul>
<blockquote>
<p>  Linux shared libs are similar to Windows <strong>DLLs</strong> (Dynamic Link Libraries,  <code>.dll</code>)</p>
<p>  Linux <strong>shared</strong> libs: <code>.so</code>  (shared objects )<br>  Linux <strong>static</strong> libs:    <code>.a</code>   (used by linkers for inclusion in programs)</p>
</blockquote>
<br>

<h3 id="2-Locate-lib-files"><a href="#2-Locate-lib-files" class="headerlink" title="2 - Locate lib files"></a>2 - Locate lib files</h3><p>System search for function’s lib file in a specific order</p>
<ul>
<li>  <code>LD_LIBRARY_PATH</code> env var</li>
<li>  Program’s <code>PATH</code> env var</li>
<li>  Directory  <code>/etc/ld.so.conf.d</code></li>
<li>  File  <code>/etc/ld.so.conf</code></li>
<li>  Directory  <code>/lib*/</code>  and  <code>/usr/lib*/</code></li>
</ul>
<blockquote>
<p>  Note: </p>
<ul>
<li>  <code>/etc/ld.so.conf</code> loads config file from directory <code>/etc/ld.so.conf.d</code></li>
<li><code>/lib*/</code> directories are for libs needed by <strong>system utilities</strong>, that reside in <code>/bin/</code> and <code>/sbin/</code><br>  <code>/usr/lib*/</code> are for libs needed by <strong>additional software</strong>  (e.g. MySQL DB utilities)</li>
</ul>
</blockquote>
<br>

<div class="note primary"><p>If another library is located in <code>/etc/ld.so.conf</code>, and listed above <code>include</code>,<br>Then system will search that lib directory, before files in  <code>/etc/ld.so.conf.d</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat /etc/ld.so.conf</span><br><span class="line">&gt;&gt; include /etc/ld.so.conf.d/*.conf</span><br></pre></td></tr></table></figure>
</div>

<br>

<p><strong>Configure library path</strong> (<strong>global</strong> config file / env var)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># original /etc/ld.so.conf file (load all file in ld.so.conf.d)</span></span><br><span class="line">include /etc/ld.so.conf.d/*.conf</span><br><span class="line"><span class="comment"># then add lib path under this line</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># after adding, update config</span></span><br><span class="line">ldconfig</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Change path temporarily</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># add 2 dirs</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">&quot;/usr/loca/testlib:/opt/newlib&quot;</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Correcting problems</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># If system cannot find the lib file, usually because lib isn&#x27;t installed</span></span><br><span class="line"><span class="comment"># If lib file is available, need to add to LD_LIBRARY_PATH</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Another way: create a symbolic link (if there&#x27;s difference in version)</span></span><br><span class="line">sudo ln -s xxlib.so.5.2 xxlib.so.5</span><br><span class="line">ldconfig</span><br></pre></td></tr></table></figure>



<br>

<h3 id="3-Loading-Dynamically"><a href="#3-Loading-Dynamically" class="headerlink" title="3 - Loading Dynamically"></a>3 - Loading Dynamically</h3><p>When program starts, <strong>dynamic linker</strong> is responsible for finding program’s needed lib functions.</p>
<p>After they’re located, dynamic linker will copy them into <strong>memory</strong>, and <strong>bind</strong> to programs.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># locate dynamic linker executable</span></span><br><span class="line">locate ld-linux</span><br><span class="line"></span><br><span class="line"><span class="comment"># manually load a program &amp; its libs</span></span><br><span class="line">/usr/lib64/ld-linux-x86-64.so.2 /usr/bin/<span class="built_in">echo</span> <span class="string">&quot;Hello!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># View program&#x27;s needed libs (for trouble shooting) **</span></span><br><span class="line">ldd /usr/bin/<span class="built_in">echo</span></span><br></pre></td></tr></table></figure>



<br>

<div class="note success"><p><strong>Summary</strong></p>
<ul>
<li>  Shared libs (<strong>dynamic</strong> libs)</li>
<li>  Load library:  search <code>LD_LIBRARY_PATH</code> first</li>
<li>  Update lib cache:  <code>ldconfig</code></li>
<li>  View libs required by a program:  <code>ldd</code></li>
</ul>
</div>



<br>





<h3 id="4-Commands-to-manage-libs"><a href="#4-Commands-to-manage-libs" class="headerlink" title="4 - Commands to manage libs"></a>4 - Commands to manage libs</h3><blockquote>
<ul>
<li>  <code>ldd</code> :  show program’s shared lib</li>
<li>  <code>ldconfig</code>:  update system’s cache &amp; links</li>
</ul>
</blockquote>
<br>

<p><strong>Show shared lib deps</strong></p>
<blockquote>
<ul>
<li><p>  <code>ldd</code> attempts to find <strong>true library</strong> (denote by <code>=&gt;</code>)</p>
</li>
<li><p>When us <code>ldd</code> to track down problems,<br>  ensure to check the <u>needs of program’s all libs</u>, and <u>all libs used by first-tier libs</u></p>
</li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ldd /bin/ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># display version info</span></span><br><span class="line">ldd -v /bin/ls</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Update lib cache</strong></p>
<p>Library <strong>cache</strong> is a <strong>catalog</strong> of lib directories &amp; all the various libs contained within.</p>
<blockquote>
<ul>
<li>  Manage lib loading: <code>ld.so</code>,  <code>ld-linux.so</code></li>
<li>  Programs above don’t read from <code>ld.so.conf</code> every time, but from <strong>cached list</strong> (<code>/etc/ld.so.cache</code>)</li>
<li>  Need to <strong>update</strong> cache, every time when add / remove libs (<code>ldconfig</code>)</li>
<li>  rpm &amp; dpkg will run <code>ldconfig</code> automatically, after install / remove pkgs</li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># print current info</span></span><br><span class="line">ldconfig -p</span><br><span class="line"></span><br><span class="line"><span class="comment"># verbose (for trouble shooting)</span></span><br><span class="line">ldconfig -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example (-v)</span></span><br><span class="line">ldconfig -v 2&gt; /dev/null | grep libmysqlclient</span><br></pre></td></tr></table></figure>

<br>

<div class="note success"><p><strong>Develop New Libs</strong></p>
<ul>
<li><p>Add path to env var <code>LD_LIBRARY_PATH</code></p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/home/kk/devs</span><br></pre></td></tr></table></figure></li>
<li><p>  After testing, move it to <code>/usr/lib*/</code></p>
</li>
<li><p>  Create lib config file in <code>/etc/ld.so.conf.d/</code>, which points to lib file’s location</p>
</li>
<li><p>  Update lib cache  (<code>sudo ldconfig</code>)</p>
</li>
</ul>
</div>



<br>

<br>

<h2 id="Manage-Process"><a href="#Manage-Process" class="headerlink" title="# Manage Process"></a># Manage Process</h2><blockquote>
<ul>
<li>  <code>uname</code></li>
<li>  <code>ps</code></li>
<li>  <code>top</code></li>
<li>  <code>jobs</code>, <code>nice</code>, <code>kill</code></li>
</ul>
</blockquote>
<br>

<h3 id="1-Overview-1"><a href="#1-Overview-1" class="headerlink" title="1 - Overview"></a>1 - Overview</h3><p>When Linux system first boots, a special process is started (<strong>init process</strong>).</p>
<p>This is the <strong>core</strong> of Linux system.</p>
<br>

<p><strong>Understand Kernel</strong></p>
<blockquote>
<p>  <code>uname</code>:  print system info</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># node name</span></span><br><span class="line">uname -n</span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel version</span></span><br><span class="line">uname -vr</span><br><span class="line"></span><br><span class="line"><span class="comment"># machine (CPU code)</span></span><br><span class="line">uname -m</span><br><span class="line"></span><br><span class="line"><span class="comment"># print all</span></span><br><span class="line">uname -a</span><br></pre></td></tr></table></figure>



<br>

<h3 id="2-Multiple-Screens"><a href="#2-Multiple-Screens" class="headerlink" title="2 - Multiple Screens"></a>2 - Multiple Screens</h3><blockquote>
<p>  In a text-based system, use <strong>terminal multiplexer</strong> to perform operations on multiple screens<br>  (use <strong>pts</strong> terminal, pseudo-terminal)</p>
<ul>
<li>  screen</li>
<li>  tmux</li>
</ul>
</blockquote>
<br>

<h4 id="screen"><a href="#screen" class="headerlink" title="screen"></a>screen</h4><blockquote>
<ul>
<li><p>  Prefix shortcut: <code>Ctrl + A</code> (C - A)</p>
</li>
<li><p>  Need to create <strong>window</strong> in each <strong>focus</strong></p>
</li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see screen list</span></span><br><span class="line">screen ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># detach</span></span><br><span class="line">C-A   D</span><br><span class="line"></span><br><span class="line"><span class="comment"># reattach</span></span><br><span class="line">screen -r [pid]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------- #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vertical split</span></span><br><span class="line">C-A   |</span><br><span class="line"></span><br><span class="line"><span class="comment"># horizontal split</span></span><br><span class="line">C-A   Shift + S</span><br><span class="line"></span><br><span class="line"><span class="comment"># create window</span></span><br><span class="line">C-A   C</span><br><span class="line"></span><br><span class="line"><span class="comment"># jump to next window</span></span><br><span class="line">C-A   Tab</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill all window</span></span><br><span class="line">C-A   \</span><br></pre></td></tr></table></figure>

<br>

<p>Example: Steps to create <strong>screen with 3 windows</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. vertical split</span></span><br><span class="line">C-A   |</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. jump &amp; create window</span></span><br><span class="line">C-A   Tab</span><br><span class="line">C-A   C</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. jump back</span></span><br><span class="line">C-A   Tab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. horizontal split</span></span><br><span class="line">C-A   Shift + S</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. jump &amp; create window</span></span><br><span class="line">C-A   Tab</span><br><span class="line">C-A   C</span><br></pre></td></tr></table></figure>

<br>

<div class="note primary"><p>Stress test system’s CPU &amp; memory (<code>stress-ng</code>)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">stress-ng --class cpu -a 10 -b 5 -t 3m \</span><br><span class="line">          --matrix 0 -m 3 --vm-bytes 256m</span><br></pre></td></tr></table></figure>
</div>



<br>

<h4 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h4><blockquote>
<ul>
<li>  <code>screen</code> 2.0 version</li>
<li>  Prefix shortcut: <code>Ctrl + B</code> (C - B)</li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see window list</span></span><br><span class="line">tmux ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># detach</span></span><br><span class="line">C-B   D</span><br><span class="line"></span><br><span class="line"><span class="comment"># reattach</span></span><br><span class="line">tmux attach-session -t [session number]</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------- #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vertical split</span></span><br><span class="line">C-B   %</span><br><span class="line"></span><br><span class="line"><span class="comment"># horizontal split</span></span><br><span class="line">C-B   <span class="string">&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># next window</span></span><br><span class="line"><span class="string">C-B   O</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># help</span></span><br><span class="line"><span class="string">C-B   ?</span></span><br></pre></td></tr></table></figure>

<br>

<p>Example: Steps to create <strong>tmux with 3 windows</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. vertical split</span></span><br><span class="line">C-B   %</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. jump back</span></span><br><span class="line">C-B   O</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. horizontal split</span></span><br><span class="line">C-B   <span class="string">&quot;</span></span><br></pre></td></tr></table></figure>

<br>



<h3 id="3-Process-Status"><a href="#3-Process-Status" class="headerlink" title="3 - Process Status"></a>3 - Process Status</h3><blockquote>
<p>  <code>ps auxwf | grep bash</code></p>
</blockquote>
<br>

<p><code>ps</code> supports 3 different styles of cmd-line options (historical reasons)</p>
<ul>
<li>  BSD style (<code>xx</code>)</li>
<li>  Unix style (<code>-xx</code>)</li>
<li>  GNU long options (<code>--xx</code>)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># all process by current shell (default)</span></span><br><span class="line">ps</span><br><span class="line"></span><br><span class="line"><span class="comment"># all running process</span></span><br><span class="line">ps -ef</span><br><span class="line"></span><br><span class="line"><span class="comment"># all process owned by a specific user</span></span><br><span class="line">ps U kk</span><br><span class="line"></span><br><span class="line"><span class="comment"># all process associated with tty terminal</span></span><br><span class="line">ps a</span><br><span class="line"></span><br><span class="line"><span class="comment"># extra info</span></span><br><span class="line">ps u</span><br><span class="line"></span><br><span class="line"><span class="comment"># process tree view</span></span><br><span class="line">ps f</span><br><span class="line"></span><br><span class="line"><span class="comment"># wide output (complete command, more than 80 char)</span></span><br><span class="line">ps w</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Select Process with <code>ps</code></strong></p>
<blockquote>
<p>  During trouble shooting: View only a <strong>selected</strong> subset of processes</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># remove restriction of association with terminal</span></span><br><span class="line"><span class="comment"># usually used with &quot;ps a&quot;</span></span><br><span class="line">ps x</span><br><span class="line"></span><br><span class="line"><span class="comment"># only show processes running command in cmd-list</span></span><br><span class="line">ps -C [cmd-list]</span><br><span class="line"></span><br><span class="line"><span class="comment"># only show running processes</span></span><br><span class="line">ps -r </span><br><span class="line"></span><br><span class="line"><span class="comment"># only show processes associated with current tty terminal</span></span><br><span class="line">ps -T</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------- #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># only show processes, whose current real group is in the list</span></span><br><span class="line">ps -G [list]</span><br><span class="line"></span><br><span class="line"><span class="comment"># only show processes, whose current effective group is in the list</span></span><br><span class="line">ps -g [list]</span><br></pre></td></tr></table></figure>

<div class="note info"><p>Real &amp; effective groups / users:</p>
<ul>
<li>  <strong>REAL</strong> (<strong>upper</strong> case):  This is the user / group the account is associated with, when log into system</li>
<li>  <strong>effective</strong> (<strong>lower</strong> case):  user / group uses temporary <strong>alternative</strong> user / group ID (SUID / GUID)</li>
</ul>
<p>If you want to see all process, use <strong>both</strong> effective &amp; real options.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ps -u kk -U kk</span><br></pre></td></tr></table></figure>
</div>



<br>

<p><strong>Displayed info</strong></p>
<ul>
<li>  <strong>PPID</strong>  :  parent process ID</li>
<li>  <strong>TTY</strong>  :   teletype (identify a terminal)</li>
<li>  <strong>C</strong>:  processor utilization over process lifetime</li>
<li>  <strong>STIME</strong>:  system time (when process starts)</li>
<li>  CPU Priority:  default is <code>0</code>.  <strong>Negative</strong> values have <strong>higher</strong> priority (need to set as root, for values &lt; 0)</li>
<li>  <strong>RSS</strong>  :  resident set size (memory used by the program &amp; its data)</li>
<li>  <strong>CMD</strong>: commands to launch the process</li>
</ul>
<br>

<p><strong>Process States</strong></p>
<div class="note primary"><p><code>ps -ef</code> : Some CMD are shown in brackets.</p>
<p>These processes are currently <strong>swapped</strong> out from <strong>physical</strong> memory into <strong>virtual</strong> memory on the hard drive  (Process state: <strong>sleeping</strong>).</p>
</div>



<p>Linux kernel puts a process to <strong>sleep</strong> mode, while process is waiting for an event. When event triggers, kernel sends process a <strong>signal</strong>. </p>
<ul>
<li>  <strong>Interruptible</strong> sleep:  process receives signal immediately, and wake up</li>
<li>  <strong>Uninterruptible</strong> sleep:  process only wakes up based on external event (e.g. hardware becomes available)</li>
</ul>
<blockquote>
<p>  <strong>Zombie</strong> process: Parent process does not recognize process’ termination signal </p>
</blockquote>
<br>

<h3 id="4-top"><a href="#4-top" class="headerlink" title="4 - top"></a>4 - top</h3><blockquote>
<p>  <code>top</code> is the  <strong>dynamic</strong> <code>ps</code> variant</p>
<p>  GUI variant; <code>kpm</code>,  <code>gnome-system-monitor</code></p>
</blockquote>
<br>

<p>Only to check system uptime:</p>
<blockquote>
<p>  Shows system <strong>load</strong>, but not CPU</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">uptime</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Benchmark</strong>: familiar with purposes &amp; normal habits of programs running on your system</p>
<blockquote>
<p>  <code>top</code> sorts processes based on <strong>%CPU</strong> by <strong>default</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># refresh rate (default is 5 sec)</span></span><br><span class="line">top -d 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># by pid</span></span><br><span class="line">top -p [pid]</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------- In the top interface -------- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># color mode</span></span><br><span class="line">z</span><br><span class="line"></span><br><span class="line"><span class="comment"># highlight sort field</span></span><br><span class="line">x</span><br><span class="line"></span><br><span class="line"><span class="comment"># toggle columns sort &amp; set priority</span></span><br><span class="line">f</span><br><span class="line"></span><br><span class="line"><span class="comment"># reverse sort</span></span><br><span class="line">R</span><br><span class="line"></span><br><span class="line"><span class="comment"># sort by CPU</span></span><br><span class="line">P</span><br><span class="line"></span><br><span class="line"><span class="comment"># sort by memory</span></span><br><span class="line">M</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># show full command</span></span><br><span class="line">c</span><br><span class="line"></span><br><span class="line"><span class="comment"># show threads</span></span><br><span class="line">H</span><br><span class="line"></span><br><span class="line"><span class="comment"># show idle processes</span></span><br><span class="line">i</span><br><span class="line"></span><br><span class="line"><span class="comment"># show specific user process</span></span><br><span class="line">u</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill process</span></span><br><span class="line">k</span><br><span class="line"></span><br><span class="line"><span class="comment"># write current setting to config file</span></span><br><span class="line">W</span><br><span class="line"></span><br><span class="line"><span class="comment"># show cumulative CPU</span></span><br><span class="line">S</span><br></pre></td></tr></table></figure>

<br>

<p><strong>load average</strong>: can equal to number of CPU cores, before competition for CPU time begins  (1-min, 5-min. 15-min)</p>
<blockquote>
<p>  e.g. Quad-core CPU (can be as high as <strong>4.0</strong>)</p>
</blockquote>
<div class="note warning"><p>It’s common for 1-min load to be high (short burst of activities)</p>
<p>If the <strong>15-min</strong> load average is high, system might be in trouble</p>
</div>

<br>

<p><strong>CPU info</strong></p>
<ul>
<li>  Process owner (<strong>us</strong>er / <strong>sy</strong>stem process)</li>
<li>  Process state (running / <strong>id</strong>le / <strong>wa</strong>iting)</li>
</ul>
<br>

<p><strong>Columns</strong></p>
<ul>
<li>  <strong>PR</strong>: process priority</li>
<li>  <strong>NI</strong>:  nice value</li>
<li>  <strong>VIRT</strong>:  total virtual memory</li>
<li>  <strong>RES</strong>:  total physical memory</li>
<li>  <strong>SHR</strong>:  total memory shared with other processes</li>
<li>  <strong>%CPU</strong>:  share of CPU time</li>
<li>  <strong>%MEM</strong>:  share of available physical memory</li>
<li>  TIME+:  total CPU time used, since process starts</li>
<li><strong>S</strong>: process status<ul>
<li>  <code>D</code>:  interruptible sleep</li>
<li>  <code>I</code>:  idle</li>
<li>  <code>R</code>:  running</li>
<li>  <code>S</code>:  sleeping</li>
<li>  <code>T</code>:  traced / stopped</li>
<li>  <code>Z</code>:  zombie</li>
</ul>
</li>
</ul>
<br>

<div class="note info"><p>Use <code>watch</code> for monitoring (refresh every 2 sec). </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">watch uptime</span><br></pre></td></tr></table></figure>
</div>



<br>

<h3 id="5-jobs"><a href="#5-jobs" class="headerlink" title="5 - jobs"></a>5 - jobs</h3><ul>
<li><p>  Summarize process launched from your <strong>current shell</strong></p>
</li>
<li><p>  Provide job ID numbers</p>
</li>
<li><p>Ensure all programs have terminated, before logging out</p>
<blockquote>
<p>  <u>No background process is running, that’s launched from the current shell</u></p>
</blockquote>
</li>
</ul>
<br>

<p><strong><code>jobs</code> command</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-l	<span class="comment"># check job PID</span></span><br><span class="line">-p	<span class="comment"># only list job PIDs</span></span><br><span class="line"></span><br><span class="line">-n	<span class="comment"># only list jobs that have status change</span></span><br><span class="line">-r	<span class="comment"># only list running jobs</span></span><br><span class="line">-s	<span class="comment"># only list stopped jobs</span></span><br></pre></td></tr></table></figure>



<br>

<h4 id="fg-amp-bg"><a href="#fg-amp-bg" class="headerlink" title="fg &amp; bg"></a>fg &amp; bg</h4><p>Move <strong>paused</strong> program to <strong>foreground</strong>: </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pause program</span></span><br><span class="line">Ctrl + Z</span><br><span class="line"></span><br><span class="line"><span class="comment"># check job number</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># check job PID</span></span><br><span class="line"><span class="built_in">jobs</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># move to foreground</span></span><br><span class="line"><span class="built_in">fg</span> [number]</span><br><span class="line"></span><br><span class="line"><span class="comment"># restart job in foreground (use job number)</span></span><br><span class="line"><span class="built_in">fg</span> 2</span><br></pre></td></tr></table></figure>

<br>

<p>Send <strong>running</strong> program to <strong>background</strong>:</p>
<blockquote>
<p>  Each background process is tied to the <strong>session’s terminal</strong>  📌 </p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pause program</span></span><br><span class="line">Ctrl + Z</span><br><span class="line"></span><br><span class="line"><span class="comment"># check job number</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># check job PID</span></span><br><span class="line"><span class="built_in">jobs</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># move to background  (% + job number)</span></span><br><span class="line"><span class="built_in">bg</span> %[number]</span><br><span class="line"></span><br><span class="line"><span class="comment"># restart job in background (use job number)</span></span><br><span class="line"><span class="built_in">bg</span> 2</span><br></pre></td></tr></table></figure>



<div class="note success"><p>Note: </p>
<ul>
<li>  <code>+</code> sign:  last job added to bg stack</li>
<li>  <code>-</code> sign:  second-to-last job added to bg stack</li>
</ul>
<p>All previously added jobs will show no sign.</p>
</div>



<br>

<p>Other commands:</p>
<blockquote>
<p>  Redirect nohup output messages - <code>nohup.out</code></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># run a job in background</span></span><br><span class="line">gedit &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># bring bg jobs to fg  (% + job number)</span></span><br><span class="line"><span class="built_in">fg</span> %2</span><br><span class="line"></span><br><span class="line"><span class="comment"># stop bg job</span></span><br><span class="line"><span class="built_in">kill</span> %[number]</span><br><span class="line"></span><br><span class="line"><span class="comment"># continue running after log out</span></span><br><span class="line">nohup [program] &amp;</span><br></pre></td></tr></table></figure>



<div class="note primary"><p><code>nohup</code> will force the application to <strong>ignore</strong> any input from <code>stdin</code>.<br>It dis-associates process from terminal, and the process loses the <strong>output link</strong> to the monitor.</p>
<p>By default, <code>stdout</code> and <code>stderr</code> are <strong>redirected</strong> to <code>~/nohup.out</code></p>
</div>



<br>



<h3 id="6-Process-priorities"><a href="#6-Process-priorities" class="headerlink" title="6 - Process priorities"></a>6 - Process priorities</h3><blockquote>
<ul>
<li>  <code>nice</code></li>
<li>  <code>renice</code></li>
</ul>
</blockquote>
<br>

<h4 id="nice"><a href="#nice" class="headerlink" title="nice"></a>nice</h4><ul>
<li>  Range:  <code>[-20, 19]</code>  (<code>nice</code> default is <code>10</code>)</li>
<li>  Only <strong>root</strong> may <strong>launch</strong> program with <strong>negative</strong> priority value</li>
<li>  Default for program run without <code>nice</code> is <code>0</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># assign 12 to program, and pass to txt</span></span><br><span class="line">nice -12  program  data.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent</span></span><br><span class="line">nice -12</span><br><span class="line">nice -n 12 </span><br><span class="line">nice --adjustment=12</span><br></pre></td></tr></table></figure>

<br>

<h4 id="renice"><a href="#renice" class="headerlink" title="renice"></a>renice</h4><blockquote>
<ul>
<li>  Only <strong>root</strong> can modify other user’s process priority</li>
<li>  Only <strong>root</strong> can <strong>decrease</strong> priority value </li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># assign 7 to pid 2390, for all process owned by kk</span></span><br><span class="line">renice 7 2390 -u kk</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Summary: Normal user <u>cannot set value &lt; 0</u> in <code>nice</code>, <u>cannot decrease value</u> in <code>renice</code></p>
</blockquote>
<br>

<h3 id="7-Kill-Process"><a href="#7-Kill-Process" class="headerlink" title="7 - Kill Process"></a>7 - Kill Process</h3><br>



<h4 id="Process-Signals"><a href="#Process-Signals" class="headerlink" title="Process Signals"></a>Process Signals</h4><blockquote>
<p>  Signals are also written as <code>SIG</code> + Name. </p>
<p>  e.g. <code>TERM</code>  -&gt;  <code>SIGTERM</code></p>
</blockquote>
<table>
<thead>
<tr>
<th>Number</th>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>SIGHUP</code></td>
<td>Hang Up</td>
</tr>
<tr>
<td>2</td>
<td><code>SIGINT</code></td>
<td>Ctrl + C - Interrupt</td>
</tr>
<tr>
<td>9</td>
<td><code>SIGKILL</code></td>
<td><code>kill</code> - Force kill</td>
</tr>
<tr>
<td>15</td>
<td><code>SIGTERM</code></td>
<td>Soft kill</td>
</tr>
<tr>
<td>11</td>
<td><code>SIGSEGV</code></td>
<td>Segments violation</td>
</tr>
<tr>
<td>3</td>
<td><code>SIGQUIT</code></td>
<td>Stop running</td>
</tr>
<tr>
<td>20</td>
<td><code>SIGTSTP</code></td>
<td>Ctrl + Z - Stop (but does not terminate, program is still in memory)</td>
</tr>
<tr>
<td>18</td>
<td><code>SIGCONT</code></td>
<td><strong>Restart</strong> a stopped process</td>
</tr>
</tbody></table>
<br>





<h4 id="Kill"><a href="#Kill" class="headerlink" title="Kill"></a>Kill</h4><blockquote>
<p>  <code>1  SIGHUP</code>  :  terminates interactive program, cause daemons to re-read config file</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># view all numbered signals</span></span><br><span class="line"><span class="built_in">kill</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill process (default: 15 SIGTERM)</span></span><br><span class="line"><span class="built_in">kill</span> -s 15 [pid]</span><br><span class="line"></span><br><span class="line"><span class="comment"># server with this pid to reload its config file</span></span><br><span class="line"><span class="built_in">kill</span> -s 1 [pid]</span><br></pre></td></tr></table></figure>



<div class="note success"><p>Kill a process </p>
<ul>
<li>  Try <code>TERM</code> first</li>
<li>  Then <code>HUP</code>  /  <code>INT</code></li>
<li>  Use <code>KILL</code> as last resort (might lead to corrupted files)</li>
</ul>
</div>



<br>

<p><strong>Killall</strong>: Variant of <code>kill</code> (kills process based on <strong>name</strong>, but not pid)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kill all process with name vim</span></span><br><span class="line"><span class="comment"># -i: confirmation, before killing</span></span><br><span class="line">killall -i vim</span><br><span class="line"></span><br><span class="line"><span class="comment"># check open files before killall</span></span><br><span class="line">lsof | grep [pid]</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Pkill</strong>: Variant of <code>kill</code>  (use selection criteria)</p>
<blockquote>
<p>  Use <code>pgrep</code> to test out selection criteria prior to sending signals</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># all process attached to terminal 2</span></span><br><span class="line">pgrep -t tty2</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill all process attached to terminal 2 (SIGTERM by default)</span></span><br><span class="line">pkill -t tty2</span><br></pre></td></tr></table></figure>



<br>

<br>

<h2 id="Practice"><a href="#Practice" class="headerlink" title="# Practice"></a># Practice</h2><br>

<p><strong>Source pkg &amp; Binary pkg</strong></p>
<ul>
<li><p>  Source pkg requires more time to compile (must be compiled prior to installation)</p>
</li>
<li><p>Both rpm &amp; dpkg provide tools to create binary pkg (can be installed directly) from source code </p>
<blockquote>
<p>  Binary pkg creation is useful, if you’re <u>running Linux on a peculiar CPU</u><br>  (But <strong>cannot <u>recompile</u> for different CPU architecture</strong>)</p>
</blockquote>
</li>
<li><p>  <strong>Tarballs</strong> are preferred, when distribute for other platforms (universal)</p>
</li>
</ul>
<br>

<p><strong>More About Source pkg &amp; Binary pkg</strong></p>
<ul>
<li>Source package include a <strong>tarball</strong> of the application’s source code, and <strong>instructions</strong> on building it<br>  When you install the package, it <strong>builds</strong> and <strong>compiles</strong> everything on-site, then installs</li>
<li>  <strong>[FAST] Binary packages</strong> have everything already built, and installing the package just takes everything out of it</li>
</ul>
<br>



<p><strong>Rpm &amp; Dpkg</strong></p>
<ul>
<li><p>  Databases for these two are <strong>separate</strong>. Hence these two are <strong>incompatible</strong> with one another</p>
</li>
<li><p>  Pkg management system don’t share info, and databases don’t actively conflict</p>
</li>
<li><p>  Dpkg often provides <u>more extensive initial setup</u> options</p>
</li>
<li><p>For problematic pkgs: </p>
<ul>
<li>  rpm can rebuild from source (<code>rpmbuild --rebuild</code>)</li>
<li>Debian source pkgs are rare. Less likely to rebuild dpkg from source</li>
</ul>
</li>
</ul>
<br>

<br>

<br>



]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>LPIC - 101 Command Line</title>
    <url>/2022/LPIC-101/</url>
    <content><![CDATA[<div class="note default"><p><strong>Objective</strong></p>
<ul>
<li>  <a href="/2022/LPIC-101/#Work-on-the-command-line">Work on the command line</a></li>
<li>  <a href="/2022/LPIC-101/#Basic-file-editing">Basic file editing</a></li>
<li>  <a href="/2022/LPIC-101/#Streams-pipes-redirects">Streams, pipes, redirects</a></li>
<li>  <a href="/2022/LPIC-101/#Process-text-streams-with-filters">Process text streams with filters</a></li>
<li>  <a href="/2022/LPIC-101/#Search-text-files-with-regex">Search text files with regex</a></li>
</ul>
</div>

<span id="more"></span> 

<br>



<h2 id="Work-on-the-command-line"><a href="#Work-on-the-command-line" class="headerlink" title="Work on the command line"></a><p align="center">Work on the command line</p></h2><br>

<p><strong>Linux shell types</strong></p>
<ul>
<li>  <strong>bash</strong> / bsh</li>
<li>  tcsh / csh (c-shell)</li>
<li>  ksh (korn shell)</li>
<li>  <strong>zsh</strong> </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># which shell that /bin/sh points to</span></span><br><span class="line">readlink /bin/sh </span><br><span class="line"></span><br><span class="line"><span class="comment"># shell metacharacters</span></span><br><span class="line">*  ?  <span class="string">&#x27;  &quot;  ;  &amp;  |  \  $  ^  [  ]  (  )  &lt;  &gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Note: Adjusting bash config files (<code>~/.bashrc</code>) only affects <strong>bash</strong></p>
</blockquote>
<br>

<p><strong>Other notes</strong></p>
<ul>
<li><p>  Directory structure: <strong>virtual</strong> directory, with one single base directory (<strong>root dir</strong>)</p>
</li>
<li><p>Check shell Built-in commands</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">type</span> <span class="built_in">echo</span></span><br><span class="line"><span class="comment"># echo is a shell builtin</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">type</span> uname</span><br><span class="line"><span class="comment"># uname is /usr/bin/uname</span></span><br></pre></td></tr></table></figure></li>
<li><p>Common env vars</p>
<blockquote>
<ul>
<li>  Use <code>set</code> to display active env vars</li>
<li>  Use <code>unset</code> to reverse edit</li>
<li>  Use <code>env</code> or <code>printenv</code> to view env vars</li>
</ul>
</blockquote>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default editor</span></span><br><span class="line">EDITOR</span><br><span class="line"></span><br><span class="line"><span class="comment"># default screen-based editor (e.g. nano, vim)</span></span><br><span class="line">VISUAL</span><br><span class="line"></span><br><span class="line"><span class="comment"># system hostname</span></span><br><span class="line">HOSTNAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># Primary cmdline prompt string</span></span><br><span class="line">PS1</span><br><span class="line"></span><br><span class="line"><span class="comment"># current shell level</span></span><br><span class="line">SHLVL</span><br><span class="line"></span><br><span class="line"><span class="comment"># user time zone</span></span><br><span class="line">TZ</span><br></pre></td></tr></table></figure>

  <br></li>
</ul>
<br>

<p><strong><code>PATH</code> env var</strong></p>
<ul>
<li>  root path should never include current dir (<code>./</code>)</li>
<li>  Append new path to the end of path, so standard programs take precedence</li>
<li>  Env var: modify program behavior</li>
</ul>
<br>

<p><strong>Shell command tricks</strong></p>
<ul>
<li>  <code>Ctrl+R</code>:  search command history  (use <code>ESC</code> or <code>Ctrl+G</code> to exit)</li>
<li>  <code>Ctrl+ ←/→</code>: move one word per time</li>
<li>  <code>Ctrl+K</code>: delete cursor to end</li>
<li>  <code>Ctrl+X</code> &amp; <code>Backspace</code>:  delete start to cursor</li>
<li>  <code>Ctrl+XE</code>: open editor to edit commands ( <code>export EDITOR=/usr/bin/vim</code> )</li>
</ul>
<br>

<p><strong>Shell history</strong></p>
<ul>
<li>  Clean history: <code>history -c</code></li>
<li>  Execute command from history:  <code>!200</code></li>
<li>  View last 10 commands:  <code>history 10</code></li>
<li>  Display without line number: <code>history | cut -c 8-</code></li>
</ul>
<br>

<p><strong>Shell config</strong></p>
<ul>
<li>  global: <code>/etc/bash.bashrc</code></li>
<li>  <code>$TERM</code>:   <code>xterm-256color</code></li>
<li>  Display all env vars: <code>env</code></li>
</ul>
<br>

<br>





<h2 id="Basic-file-editing"><a href="#Basic-file-editing" class="headerlink" title="Basic file editing"></a><p align="center">Basic file editing</p></h2><blockquote>
<p>  Many utilities do not change texts within a file, <strong>unless redirection</strong> (e.g. sed, cut)</p>
<p>  They only display modified text to <strong>stdout</strong></p>
</blockquote>
<br>



<p><strong>Message Digest (Integrity)</strong></p>
<ul>
<li>  <code>md5sum</code></li>
<li>  <code>sha256sum</code></li>
<li>  <code>sha512sum</code>  (<strong>best</strong>)</li>
</ul>
<br>



<h3 id="1-Vim"><a href="#1-Vim" class="headerlink" title="1 - Vim"></a><p align="center">1 - Vim</p></h3><p><strong>Notes</strong></p>
<ul>
<li>  <code>vi</code> editor was a Unix text editor. Vim is <code>vi improved</code></li>
<li>3 standard modes<ul>
<li>  <strong>Command</strong> mode (normal)</li>
<li>  <strong>Insert</strong> mode (edit, entry)</li>
<li>  <strong>Ex</strong> mode (colon commands)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Shortcuts</strong> </p>
<blockquote>
<p>  Guides:  <code>vimtutor</code></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">^	line start</span><br><span class="line">$	line end</span><br><span class="line"></span><br><span class="line">gg	file start</span><br><span class="line">G	file end</span><br><span class="line"></span><br><span class="line">?	forward search</span><br><span class="line">/	backward search</span><br><span class="line"></span><br><span class="line">A	insert at line end</span><br><span class="line">o	insert new line below cursor</span><br><span class="line"></span><br><span class="line">:!	execute shell <span class="built_in">command</span> &amp; display results, but not quitting vim</span><br><span class="line">:r	<span class="built_in">read</span> file contents, include <span class="keyword">in</span> editor buffer area</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Ctrl + ZZ, :x,  :wq	save &amp; quit</span><br></pre></td></tr></table></figure>



<br>

<br>



<h2 id="Streams-pipes-redirects"><a href="#Streams-pipes-redirects" class="headerlink" title="Streams, pipes, redirects"></a><p align="center">Streams, pipes, redirects</p></h2><br>

<p><strong>Redirection</strong></p>
<ul>
<li>  <code>&gt;&gt;</code>  : append (create new file if doesn’t exist) </li>
<li>  <code>2&gt;</code>  : new file with stderr</li>
<li>  <code>2&gt;&gt;</code>  : append stderr</li>
<li>  <code>&amp;&gt;</code>  : new file with <strong>stdout &amp;  stderr</strong></li>
<li>  <code>&lt;&lt;</code>   : heredoc  (terminate input: <code>Ctrl+D</code>)</li>
</ul>
<blockquote>
<p>  A trick:  Redirect stdout to <code>/dev/null</code>  (get rid of data)</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">whine 2&gt; /dev/null</span><br></pre></td></tr></table></figure>
</blockquote>
<ul>
<li><p><code>tee</code>  </p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Program:</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tee: store &amp; view the output</span></span><br><span class="line">python hello.py | tee output.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># append texts:</span></span><br><span class="line">python hello.py | tee -a output.txt</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong>Pipe</strong></p>
<p><code>xargs</code>: build command from stdin</p>
<ul>
<li><p>  <code>-d &quot;\n&quot;</code> : xargs use both spaces&amp; newlines as <strong>item delimiters</strong></p>
</li>
<li><p>e.g.</p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Remove all files with ~</span></span><br><span class="line">find ./ -name <span class="string">&quot;*~&quot;</span> | xargs -d <span class="string">&quot;\n&quot;</span> rm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Equals: (`: separate command)</span></span><br><span class="line">rm `find ./ -name <span class="string">&quot;*~&quot;</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment"># Equals: Shell expansion (命令嵌套，可嵌套多个)</span></span><br><span class="line">rm $(find ./ -name <span class="string">&quot;*~&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Output of above command is passed to <code>rm</code>, as if <strong>it’s typed in the shell</strong></p>
</blockquote>
</li>
</ul>
<br>

<br>



<h2 id="Process-text-streams-with-filters"><a href="#Process-text-streams-with-filters" class="headerlink" title="Process text streams with filters"></a><p align="center">Process text streams with filters</p></h2><br>

<h3 id="1-Combine-files"><a href="#1-Combine-files" class="headerlink" title="1 - Combine files"></a><p align="center">1 - Combine files</p></h3><blockquote>
<ul>
<li>  <code>cat</code></li>
<li>  <code>join</code></li>
<li>  <code>paste</code></li>
</ul>
</blockquote>
<br>

<p><code>cat</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tac: reverse lines</span></span><br><span class="line">tac 1.txt 2.txt &gt; combined.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use tee to view stdout &amp; store</span></span><br><span class="line">cat 1.txt 2.txt | tee combined.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number lines: (-n, --number) </span></span><br><span class="line">cat -n 1.txt 2.txt | tee -a combined.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete number lines</span></span><br><span class="line">cat 1.txt | cut -c 4-</span><br><span class="line"></span><br><span class="line"><span class="comment"># see file ending (LF, linefeed)</span></span><br><span class="line">cat -E 1.txt</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li>  Number non-blank lines  <code>(-b, --number-nonblank)</code></li>
<li>  Show end of file with <code>$</code> <code>(-E, --show-end)</code></li>
<li>  Compress blank lines <code>(-s, --squeeze-blank)</code></li>
</ul>
</blockquote>
<br>

<p><code>join</code></p>
<blockquote>
<p>  Need to have similarities of fields (columns) between file 1 &amp; 2</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Note: files cannot have blank lines, else will display error:</span></span><br><span class="line"><span class="comment"># &gt; join: 1.txt:11: is not sorted</span></span><br><span class="line">join 1.txt 2.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># File a &amp; b. Use 3rd column in 1, 4th column in 2</span></span><br><span class="line">join -1 3 -2 4 a.txt b.txt</span><br></pre></td></tr></table></figure>

<br>

<p><code>paste</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># merge files line by line</span></span><br><span class="line">paste 1.txt 2.txt</span><br></pre></td></tr></table></figure>

<br>

<br>



<h3 id="2-Transform-files"><a href="#2-Transform-files" class="headerlink" title="2 - Transform files"></a><p align="center">2 - Transform files</p></h3><blockquote>
<ul>
<li>  <code>expand</code>  /  <code>unexpand</code></li>
<li>  <code>od</code></li>
<li>  <code>sort</code></li>
<li>  <code>split</code></li>
<li>  <code>tr</code></li>
<li>  <code>uniq</code></li>
</ul>
</blockquote>
<br>

<p><code>expand</code>  /  <code>unexpand</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Convert tabs to space</span></span><br><span class="line">expand 1.txt -t 4</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert space to tabs</span></span><br><span class="line">unexpand 1.txt --tabs=4</span><br></pre></td></tr></table></figure>

<br>

<p><code>od</code>   (octal dump)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Display file dump in hex</span></span><br><span class="line">od -h 1.txt </span><br></pre></td></tr></table></figure>

<br>

<p><code>sort</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sort by field (-k, --key=)</span></span><br><span class="line">sort 1.txt -k 2		<span class="comment"># sort by 2nd column</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># numeric sort, output to file, -o</span></span><br><span class="line">sort -n -o new.txt old.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># numeric sort, output to file, redirection</span></span><br><span class="line">sort -n old.txt &gt; new.txt	</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li>  ignore case     <code>(-f, --ignore-case)</code></li>
<li>  Numeric sort   <code>(-n, --numeric-sort)</code></li>
<li>  Reverse order <code>(-r, --reverse)</code></li>
</ul>
</blockquote>
<br>

<p><code>uniq</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># remove duplicate lines, use with sort</span></span><br><span class="line">sort 1.txt | uniq</span><br></pre></td></tr></table></figure>

<br>

<p><code>split</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># split by bytes (-b, --bytes=)</span></span><br><span class="line">split -b 30 1.txt 	 <span class="comment"># 30 bytes each file, default prefix (xaa, xab, ...)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># split by lines (-l, --lines=)</span></span><br><span class="line">split -l 4 1.txt N-	 <span class="comment"># 4 lines each file, with prefix (N-aa, N-ab, ...)</span></span><br></pre></td></tr></table></figure>

<br>

<p><code>tr</code></p>
<blockquote>
<p>  change individual chars from stdin</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change letter h, i to H, J</span></span><br><span class="line">tr hi HJ &lt; 1.txt </span><br><span class="line"></span><br><span class="line"><span class="comment"># delete chars</span></span><br><span class="line">tr -d h &lt; 1.txt 	<span class="comment"># delete h from file</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># delete all numbers</span></span><br><span class="line">tr -d [:digit:] &lt; 1.txt</span><br></pre></td></tr></table></figure>

<br>

<br>

<h3 id="3-Format-files"><a href="#3-Format-files" class="headerlink" title="3 - Format files"></a><p align="center">3 - Format files</p></h3><blockquote>
<ul>
<li>  <code>fmt</code></li>
<li>  <code>nl</code></li>
<li>  <code>pr</code></li>
</ul>
</blockquote>
<br>

<p><code>fmt</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># No more than 80 char wide</span></span><br><span class="line">fmt 1.txt -w 80</span><br></pre></td></tr></table></figure>

<br>

<p><code>nl</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Number all non-blank lines</span></span><br><span class="line">nl 1.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number all lines (-b, --body-numbering)</span></span><br><span class="line">nl -b a 1.txt		<span class="comment"># style: all</span></span><br></pre></td></tr></table></figure>

<br>

<p><code>pr</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># prepare file for print</span></span><br><span class="line">pr 1.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># print out, numbered, double-spaced, 50 lines per page</span></span><br><span class="line">cat -n 1.txt | pr -dfl 50 | lpr</span><br></pre></td></tr></table></figure>

<br>

<br>



<h3 id="4-View-files"><a href="#4-View-files" class="headerlink" title="4 - View files"></a><p align="center">4 - View files</p></h3><blockquote>
<ul>
<li>  <code>head</code>  /  <code>tail</code></li>
<li>  <code>more</code>  /  <code>less</code></li>
</ul>
</blockquote>
<br>

<p><code>head</code>  /  <code>tail</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">head -n 5</span><br><span class="line">tail -n 10		<span class="comment"># equals:  head -n -10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cut chars in a pipe</span></span><br><span class="line">head -c 5</span><br><span class="line">tail -c 5</span><br><span class="line"></span><br><span class="line"><span class="comment"># stream logs (-f, --follow)</span></span><br><span class="line">tail -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract portions with head + tail</span></span><br><span class="line"><span class="comment"># Display line 11 - 15</span></span><br><span class="line">head -n 15 1.txt | tail -n 5</span><br></pre></td></tr></table></figure>

<br>

<br>

<p><code>more</code>  /  <code>less</code></p>
<blockquote>
<p>  <code>less</code> is a better version of <code>more</code></p>
</blockquote>
<p><strong>Basic</strong>:</p>
<ul>
<li>  Move forward: <code>f</code></li>
<li>  Move backward: <code>b</code></li>
<li>  Search forward: <code>N</code></li>
<li>  Search backward: <code>Shift + N</code></li>
<li>  Move to line 50: <code>g50</code></li>
<li>  Backward search mode: <code>?</code>   (<code>N</code> will search backward)</li>
<li>  Help inside less: <code>h</code></li>
</ul>
<br>

<p><strong>Visual</strong> mode: <code>v</code>        (Edit current file with <code>$EDITOR</code>)</p>
<ul>
<li>  Exit visual mode: <code>:q</code></li>
</ul>
<br>

<br>

<h3 id="5-Summarize-files"><a href="#5-Summarize-files" class="headerlink" title="5 - Summarize files"></a><p align="center">5 - Summarize files</p></h3><blockquote>
<ul>
<li>  <code>cut</code></li>
<li>  <code>wc</code></li>
</ul>
</blockquote>
<br>

<p><code>cut</code></p>
<blockquote>
<ul>
<li>  By char: <code>-c</code>  </li>
<li>  By field: <code>-f</code> (a field is a tab-delimited section of a line)</li>
<li>  Change delimiter: <code>-d char</code></li>
<li>  Numbers: can choose a range  (<code>cut -c 2-4</code>)</li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get ether address of wlan</span></span><br><span class="line">ifconfig wlp2s0 | grep ether | cut -c 15-31	<span class="comment"># 9c:b6:d0:9c:35:37</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># cut selected char</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;foobar&quot;</span> | cut -c 1,6	<span class="comment"># fr</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># field delimiter: use space &#x27; &#x27; to separate fields</span></span><br><span class="line">cut -d <span class="string">&#x27; &#x27;</span> -f1</span><br><span class="line">cut -f1 <span class="string">&#x27;-d &#x27;</span>  <span class="comment"># same as above</span></span><br></pre></td></tr></table></figure>

<br>

<p><code>wc</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wc 1.txt</span><br><span class="line"><span class="comment"># 12  	 47 	257	1.txt</span></span><br><span class="line"><span class="comment"># lines, words, bytes </span></span><br><span class="line"><span class="comment"># -l	 -w     -c</span></span><br></pre></td></tr></table></figure>

<br>

<br>

<h2 id="Search-text-files-with-regex"><a href="#Search-text-files-with-regex" class="headerlink" title="Search text files with regex"></a><p align="center">Search text files with regex</p></h2><blockquote>
<ul>
<li><code>grep</code> <ul>
<li>  Find matching text within a file &amp; print out result</li>
<li>  Cannot use grep to make changes</li>
</ul>
</li>
<li>  <code>sed</code></li>
</ul>
</blockquote>
<br>

<p><strong>Regex</strong> (basic &amp; extended)</p>
<blockquote>
<p>  Quotation marks are <strong>not</strong> regex chars</p>
</blockquote>
<ul>
<li><p>  <code>^</code>   line start</p>
</li>
<li><p>  <code>$</code>   line end</p>
</li>
<li><p><code>[]</code>  match any char inside</p>
<blockquote>
<p>  <code>b[aei]g</code>  –&gt;  <code>bag, beg, big</code></p>
</blockquote>
</li>
<li><p><code>-</code>  range</p>
<blockquote>
<p>  <code>a[2-4]z</code> –&gt; <code>a2z, a3z, a4z</code></p>
</blockquote>
</li>
<li><p><code>.</code>  any single char (except newline)</p>
<blockquote>
<p>  <code>a.z</code> –&gt; <code>a2z, abz, aQz</code>  (and any other 3-char string that’s <code>a.z</code>)</p>
</blockquote>
</li>
<li><p><code>* </code>  appears <strong>≥ 0</strong> times    </p>
<blockquote>
<p>  Use <code>.*</code>  for substring match</p>
</blockquote>
</li>
<li><p>  <code>+</code>  appears <strong>≥ 1</strong> times</p>
</li>
<li><p>  <code>?</code>   0 or 1 match</p>
</li>
<li><p>  <code>|</code>   multiple possible matches</p>
</li>
<li><p>  <code>()</code>  group expressions</p>
</li>
<li><p>  <code>\</code>   escape char</p>
</li>
</ul>
<br>

<p><strong>Chracter classes</strong></p>
<blockquote>
<p>  predefined names</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[:alnum:]	<span class="comment"># alpha &amp; numeric</span></span><br><span class="line">[:alpha:]</span><br><span class="line">[:digit:]</span><br><span class="line"></span><br><span class="line">[:lower:]</span><br><span class="line">[:upper:]</span><br><span class="line"></span><br><span class="line">[:blank:]	<span class="comment"># blank char (e.g. tab)</span></span><br><span class="line">[:space:]	<span class="comment"># space char (e.g. space)</span></span><br><span class="line">[:punct:]</span><br></pre></td></tr></table></figure>



<br>

<h3 id="1-grep"><a href="#1-grep" class="headerlink" title="1 - grep"></a><p align="center">1 - <code>grep</code></p></h3><blockquote>
<ul>
<li>  Count matching lines <code>-c, --count</code></li>
<li>  Ignore case   <code>-i, --ignore-case</code></li>
<li>  Recursive search   <code>-r, --recursive</code>  (or:  <strong>rgrep</strong>)</li>
<li>  Extended regex <code>-E</code>  (or:  <strong>egrep</strong>)</li>
</ul>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use char class, double brackets</span></span><br><span class="line">grep [[:digit:]] int.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># find all files that contain 0 or 1 in eth (rgrep, grep -r)</span></span><br><span class="line">sudo rgrep eth[01] /etc/*</span><br><span class="line"></span><br><span class="line"><span class="comment"># grep OR</span></span><br><span class="line">egrep <span class="string">&#x27;E1 | E2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># grep AND</span></span><br><span class="line">egrep <span class="string">&#x27;E1.*E2&#x27;</span></span><br><span class="line">grep <span class="string">&#x27;E1&#x27;</span> | grep <span class="string">&#x27;E2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># grep NOT	(v means inverse grep)</span></span><br><span class="line">grep -v <span class="string">&#x27;E1&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Grep AND, OR, NOT: <a href="https://www.thegeekstuff.com/2011/10/grep-or-and-not-operators/">https://www.thegeekstuff.com/2011/10/grep-or-and-not-operators/</a></p>
</blockquote>
<br>

<h3 id="2-sed"><a href="#2-sed" class="headerlink" title="2 - sed"></a><p align="center">2 - <code>sed</code></p></h3><ul>
<li><p>  Directly modifies file content from <strong>stdin</strong> &amp; send edited file to <strong>stdout</strong>  (<strong>Stream</strong> editor)</p>
</li>
<li><p>Sed operates on <strong>addresses</strong> (line numbers)  </p>
<blockquote>
<p>   If no address: Operate on <strong>entire</strong> file</p>
</blockquote>
</li>
</ul>
<p>Usage</p>
<ul>
<li>  <code>i\txt</code>   insert txt to file</li>
<li>  <code>c\txt</code>   replace with provided text</li>
<li>  <code>ADDRcTEXT</code>   see usage below</li>
<li>  <code>s/regex/replace</code>   <strong>substitute</strong> text that matches regex</li>
<li>  <code>pattern/d</code>     delete lines</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># modify stdin	(donuts donuts)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;cake cake&quot;</span> | sed <span class="string">&#x27;s/cake/donuts/g&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># replace 1st occurrence of 2012 on each line with 2013</span></span><br><span class="line">sed -i <span class="string">&#x27;s/2012/2013/&#x27;</span> 1.txt &gt; 2.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># global search (replace all, doesn&#x27;t matter if it&#x27;s 1st)</span></span><br><span class="line">sed <span class="string">&#x27;s/2012/2013/g&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># delete 1st line contains cake</span></span><br><span class="line">sed <span class="string">&#x27;/cake/d&#x27;</span> cake.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># address is line number. Insert Hello at line 4</span></span><br><span class="line">sed <span class="string">&#x27;4cHello&#x27;</span> cake.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># use extended regex in script</span></span><br><span class="line">sed -r / --regexp-extended</span><br><span class="line"></span><br><span class="line"><span class="comment"># use multiple scripts</span></span><br><span class="line">sed -e <span class="string">&#x27;s/2012/2013/ ; s/cake/donuts/g&#x27;</span> cake.txt</span><br></pre></td></tr></table></figure>



<div class="note success"><p>Slash (<code>/</code>) isn’t the only delimiter in sed. </p>
<p>You can use <strong>any character</strong> as a <strong>delimiter</strong> that’s not part of either string. (e.g.  <code>|</code>,  <code>:</code>)</p>
</div>

<br>

<br>



<h2 id="Practice"><a href="#Practice" class="headerlink" title="Practice"></a><p align="center">Practice</p></h2><p><code>exec</code>: rest of command to replace current shell</p>
<blockquote>
<p>  Exit from program: <code>xterm</code> window will close</p>
</blockquote>
<br>

<p>Limit of <code>pipe</code>:  based on input buffer size</p>
<br>

<p><strong>Text file record</strong>: single file line that ends in newline (ASCII char <strong>LF</strong>)</p>
<br>

<p>A <strong>file descriptor</strong> is a number that represents process’s open files</p>
<br>

<p><strong>stdout</strong> goes to the <strong>current</strong> termianl (<code>/dev/tty</code>)</p>
<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LPIC</tag>
        <tag>Shell</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Assembly - 101 Bases &amp; Conversion</title>
    <url>/2021/Assembly-101/</url>
    <content><![CDATA[<p>This post is the first one in the series about x86 Assembly. Topics to cover:</p>
<ul>
<li>  Bases &amp; Conversion</li>
</ul>
<span id="more"></span> 

<br>





<div class="note primary"><p>The most you can <strong>carry</strong> out of a <u>single-column addition of 2 numbers</u> is <strong>1</strong></p>
</div>

<h3 id="Base-8-Octal"><a href="#Base-8-Octal" class="headerlink" title="Base 8 (Octal)"></a>Base 8 (Octal)</h3><table>
<thead>
<tr>
<th>Octal</th>
</tr>
</thead>
<tbody><tr>
<td>1 = 8<sup>0</sup></td>
</tr>
<tr>
<td>10 = 8<sup>1</sup></td>
</tr>
<tr>
<td>100 = 8<sup>2</sup></td>
</tr>
<tr>
<td>1000 = 8<sup>3</sup></td>
</tr>
</tbody></table>
<p>Base 8  – Base 10</p>
<blockquote>
<p>  76225 (base 8)<br>  = 8<sup>0</sup> * 5<br>  + 8<sup>1</sup> * 2<br>  + 8<sup>2</sup> * 2<br>  + 8<sup>3</sup> * 6<br>  + 8<sup>4</sup> * 7<br>  = 31893 (base 10)</p>
</blockquote>
<br>

<h3 id="Base-16-Hex"><a href="#Base-16-Hex" class="headerlink" title="Base 16 (Hex)"></a>Base 16 (Hex)</h3><p>Base 16  – Base 10</p>
<blockquote>
<p>  8DB3H (base 16)<br>  = 16<sup>0</sup> * 3<br>  + 16<sup>1</sup> * 11<br>  + 16<sup>2</sup> * 13<br>  + 16<sup>3</sup> * 8<br>  = 36275 (base 10)</p>
</blockquote>
<br>

<p>Base 10  – Base 16 (余数法, next smallest number)</p>
<blockquote>
<p>  413 (base 10)<br>  = 16<sup>2</sup> * 1<br>  + 16<sup>1</sup> * 9<br>  + 16<sup>0</sup> * 13<br>  = 19DH (base 16)</p>
</blockquote>
<br>

<h3 id="Base-2-Binary"><a href="#Base-2-Binary" class="headerlink" title="Base 2 (Binary)"></a>Base 2 (Binary)</h3><div class="note success"><p>In <strong>real world</strong>, counting tells <strong>how many</strong> are there;<br>In <strong>CS</strong>, counting is about <strong>naming</strong> them,</p>
</div>

<p>In binary, a column’s value is either <strong>present (1)</strong> or <strong>not present (0)</strong>.</p>
<br>

<h4 id="Hex-as-Shorthand-for-Binary"><a href="#Hex-as-Shorthand-for-Binary" class="headerlink" title="Hex as Shorthand for Binary"></a>Hex as Shorthand for Binary</h4><table>
<thead>
<tr>
<th>Decimal</th>
<th>Hex</th>
<th>Binary</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0000</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0001</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>0010</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>0011</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>0100</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>0101</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>0110</td>
</tr>
<tr>
<td>7</td>
<td>7</td>
<td>0111</td>
</tr>
<tr>
<td>8</td>
<td>8</td>
<td>1000</td>
</tr>
<tr>
<td>9</td>
<td>9</td>
<td>1001</td>
</tr>
<tr>
<td>10</td>
<td>A</td>
<td>1010</td>
</tr>
<tr>
<td>11</td>
<td>B</td>
<td>1011</td>
</tr>
<tr>
<td>12</td>
<td>C</td>
<td>1100</td>
</tr>
<tr>
<td>13</td>
<td>D</td>
<td>1101</td>
</tr>
<tr>
<td>14</td>
<td>E</td>
<td>1110</td>
</tr>
<tr>
<td>15</td>
<td>F</td>
<td>1111</td>
</tr>
</tbody></table>
<p>Converting every 4 binary digits (<u><strong>right to left</strong></u>) into a single hex digit.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Decimal    218</span><br><span class="line">Binary  1101 1010</span><br><span class="line">Hex        D A</span><br></pre></td></tr></table></figure>



<br>

<br>

<br>]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Assembly</tag>
      </tags>
  </entry>
  <entry>
    <title>LC Binary Tree (Java)</title>
    <url>/2021/LC-Java-BT/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid passcode." data-whm="Unverified decryption.">
  <script id="hbeData" type="hbeData" data-hmacdigest="cd42cac9e71a6e575e108b06f8586e5935d39d7d7d3dc949f9635caf24d6ea0b">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-wave">
      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-wave"><p style="text-align:center; font-size:0.8em; font-weight:100;">Passcode please.</p></span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>中文</tag>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>LC DP (Java)</title>
    <url>/2021/LC-Java-DP/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid passcode." data-whm="Unverified decryption.">
  <script id="hbeData" type="hbeData" data-hmacdigest="d0044d1314680adbb676a666358cf75b4ee787590d55f13639bc1e42f39f982a">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-wave">
      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-wave"><p style="text-align:center; font-size:0.8em; font-weight:100;">Passcode please.</p></span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>中文</tag>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>アニメ</title>
    <url>/Notes/Anime/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid passcode." data-whm="Unverified decryption.">
  <script id="hbeData" type="hbeData" data-hmacdigest="11a0aaeeed8a9faad374720d67f4d82cae1e29b80460552003eec403fb240da1">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-wave">
      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-wave"><p style="text-align:center; font-size:0.8em; font-weight:100;">Passcode please.</p></span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>AWS - 13 Five Security-related Services</title>
    <url>/2020/AWS-Five-Security-Services/</url>
    <content><![CDATA[<p>In the thirteenth post of the AWS series, we’re going to talk about 5 security-related services:</p>
<ul>
<li>  <strong>Cognito</strong> (Auth)</li>
<li>  <strong>Config</strong> (Config overall management)</li>
<li>  <strong>System Manager</strong> (Centralize operational data)</li>
<li>  <strong>KMS</strong> (Key Management Service)</li>
<li>  <strong>Secrets Manager</strong> (Auto key rotation)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="Cognito"><a href="#Cognito" class="headerlink" title="Cognito"></a><a href="https://tutorialsdojo.com/amazon-cognito-user-pools-and-identity-pools-explained/">Cognito</a></h2><ul>
<li>  User management &amp; authentication service, integrated with web / mobile apps</li>
<li>  Authenticate users through an <strong>external identity provider</strong>, provides <strong>temporary security credentials</strong></li>
<li>  Cognito ID is represented as <strong>JWT</strong> (JSON web token). Cognito uses JWT for token authentication</li>
</ul>
<img data-src="/img/04.png" style="zoom: 77%;" />

<br>

<p><strong>User pools</strong></p>
<ul>
<li>  User directories that provide <u>sign-up and sign-in options</u> for app users</li>
<li>  Use <strong>aliasing feature</strong> to enable your users to sign up or sign in with email &amp; password, or phone number &amp; password</li>
<li>  User pools are each created in one AWS Region, and they store the user profile data only in that region. You can also send user data to a different AWS Region</li>
<li>  User Pools groups lets you manage your users and their access to resources by <strong>mapping IAM roles to groups</strong> </li>
</ul>
<br>

<p><strong>Signup</strong> auth flow chart</p>
<img data-src="/img/05.png" style="zoom: 67%;" />

<br>

<p><strong>Sign in</strong> flow chart</p>
<ul>
<li><p>After a successful user pool sign-in, your web or mobile app will receive <strong>user pool tokens</strong> from Amazon Cognito. You can use those tokens to control access to your server-side resources</p>
  <img data-src="/img/06.png" style="zoom: 50%;" /></li>
<li><p>Access resources with <strong>API Gateway and Lambda</strong> with a User Pool. API Gateway validates the tokens from a successful user pool authentication, and uses them to grant your users access to resources, including Lambda functions</p>
  <img data-src="/img/07.png" style="zoom: 70%;" />

<ul>
<li>  After a successful user pool authentication, your app will receive user pool tokens from Amazon Cognito. You can <u>exchange them for temporary access to other AWS services with an identity pool</u></li>
</ul>
  <img data-src="/img/08.png" style="zoom: 75%;" />

<ul>
<li>  Grant your users access to AWS <strong>AppSync</strong> resources with tokens from a successful Amazon Cognito authentication (from a user pool or an identity pool). Cognito is also commonly used together with <strong>AWS Amplify</strong></li>
</ul>
</li>
</ul>
<br>

<br>

<p><strong>Identity pools</strong></p>
<ul>
<li><p>  Grant your users <strong>temporary AWS credentials</strong> to access AWS services, such as Amazon S3 and DynamoDB</p>
</li>
<li><p>  To save user profile information, your identity pool needs to be <strong>integrated with a user pool</strong></p>
</li>
<li><p>Support <strong>anonymous guest users</strong></p>
<blockquote>
<p>  <em>Support unauthenticated identities by providing a <strong>unique identifier</strong> and <strong>AWS credentials</strong> for users who do not authenticate with an identity provider</em></p>
</blockquote>
</li>
<li><p>  The permissions for each authenticated and non-authenticated user are controlled through <strong>IAM roles</strong> that you create</p>
</li>
</ul>
<br>

<p> <strong>User pools &amp; Identity pools</strong></p>
<ul>
<li>  User pools are for <strong>user authentication</strong> (sign up / sign in)</li>
<li>  Identity pools for  <strong>user authorization</strong> (temp AWS credentials to access resources). Rules to map users to different <strong>IAM roles</strong></li>
</ul>
<br>

<p><strong>Cognito Sync</strong></p>
<ul>
<li>  Store and sync data across devices</li>
<li>  Trigger the sync of data sets between client devices and the Amazon Cognito sync store by using the <code>synchronize()</code> method in the AWS Mobile SDK (<code>synchronized()</code> reads then writes <strong>latest version</strong> of user data)</li>
<li>  Cognito Sync store is a <strong>key/value pair store</strong> linked to an Amazon Cognito identity</li>
<li>  With <strong>Cognito Streams</strong>, you can push sync store data to a <strong>Kinesis stream</strong> in your AWS account</li>
</ul>
<br>

<p><strong>Cognito &amp; Lambda</strong></p>
<ul>
<li>  You can create an AWS Lambda function and then <strong>trigger</strong> that function during user pool operations such as user sign-up, confirmation, and <u>sign-in (authentication)</u> with a <strong><u>Lambda trigger</u></strong></li>
<li>  You can create a Lambda function as a <strong>backend to Cognito</strong> that serves <strong>auth challenges</strong> to users signing in</li>
<li>  Cognito invokes Lambda functions <strong>synchronously</strong>. When called, your Lambda function must respond within <strong>5s</strong>. If it does not, Amazon Cognito retries the call. After <strong>3</strong> unsuccessful attempts, the function <strong>times out</strong></li>
</ul>
<br>



<hr>
<h2 id="AWS-Config"><a href="#AWS-Config" class="headerlink" title="AWS Config"></a><a href="https://tutorialsdojo.com/aws-config/">AWS Config</a></h2><ul>
<li><p>  A fully managed service that provides you with an <u>AWS resource inventory, configuration history, and configuration change notifications</u> to enable security and governance</p>
</li>
<li><p>  Provides <strong>pre-built rules</strong> to evaluate your AWS resource configurations and configuration changes, or create your own custom rules in AWS <strong>Lambda</strong> that define your internal best practices and guidelines for resource configurations.</p>
</li>
</ul>
<br>

<ul>
<li>  <strong>Config rules</strong>: change details to AWS resources to provide you with a configuration history, and auto deliver it to the specified <strong>S3 bucket</strong></li>
<li>Config enables you to <strong>record software configuration changes</strong> within your EC2 instances and on-premise servers<ul>
<li>  OS configs</li>
<li>  System-level updates</li>
<li>  Installed applications</li>
<li>  Network configs</li>
</ul>
</li>
</ul>
<br>

<ul>
<li><p>  Provides <strong>configuration snapshot</strong>: a point-in-time (PIT) capture of all your resources and their configurations</p>
</li>
<li><p><strong>Configuration item</strong>: A record of the configuration of a resource in your AWS account.</p>
<blockquote>
<p>  <em>Config creates a <u>configuration item whenever it detects a change</u> to a resource type that it is recording</em></p>
</blockquote>
</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  SNS</li>
<li>  CW Events: detect and react to changes in the status of AWS Config events</li>
<li>  CT: capture all API calls to Config</li>
</ul>
<br>



<hr>
<h2 id="System-Manager"><a href="#System-Manager" class="headerlink" title="System Manager"></a><a href="https://tutorialsdojo.com/aws-systems-manager/">System Manager</a></h2><div class="note success"><p><strong>Centralize operational data</strong> from multiple AWS services, and <strong>automate tasks</strong> across your AWS resources</p>
</div>



<ul>
<li>  You can select a resource group and view its recent API activity, resource configuration changes, related notifications, operational alerts, software inventory, and patch compliance status</li>
<li>  Allows you to safely <strong>automate</strong> common and repetitive IT operations and management tasks across AWS resources</li>
<li>  Schedule windows of time to run <strong>administrative and maintenance tasks</strong> across your instances</li>
</ul>
<br>

<p><strong>SSM Agent</strong></p>
<ul>
<li>  Processes Systems Manager requests and configures machine as specified in the request</li>
<li>  Must be <strong>installed on each instance</strong> you want to use with Systems Manager. </li>
<li>  On newer AMIs and instance types, SSM Agent is <strong>installed by default</strong></li>
</ul>
<br>

<p><strong>State Manager</strong></p>
<ul>
<li>  A service that <strong>automates</strong> the process of keeping your <u>EC2 and hybrid infrastructure in a state that you define</u></li>
</ul>
<br>

<p> 🧡 <strong>Parameter Store</strong>  (With CF: <strong>retrieve AMI ID</strong>, <code>update-stack</code> API in <strong>CF</strong>)</p>
<ul>
<li>  Provides secure, hierarchical <strong>storage for configuration data and secrets management</strong></li>
<li>  Store values as plain text or encrypted data</li>
<li>  Parameters work with Systems Manager capabilities such as <u>Run Command, State Manager, and Automation</u></li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  <strong>SSM Agent</strong> writes information about executions, scheduled actions, errors, and health statuses to log files on each instance</li>
<li>  More efficient: config SSM Agent / CW Agent send log data to <strong>CW logs</strong></li>
<li>  <strong>CW logs</strong>: monitor log data in real-time, search and filter log data by creating one or more metric filters, and archive and retrieve historical data when you need it</li>
<li>  <strong>CT</strong>: log System Manager API calls</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  System Manager is linked to IAM directly for access controls</li>
</ul>
<br>

<hr>
<h2 id="KMS"><a href="#KMS" class="headerlink" title="KMS"></a>KMS</h2><ul>
<li>  A managed service that enables you to easily encrypt your data</li>
<li>  highly available key storage, management, and auditing solution, encrypt data within your own applications and <u>control the encryption of stored data across AWS services</u></li>
</ul>
<br>

<ul>
<li>  Integrated with <strong>CloudTrail</strong>, which provides you the ability to <strong>audit</strong> who used which keys, on which resources, and when</li>
<li>Customer master keys (<strong>CMK</strong>) <ul>
<li>  To <u>control access to data encryption keys</u> that encrypt and decrypt your data</li>
<li>  Generate, encrypt &amp; decrypt the data keys that you use <strong>outside of KMS</strong> to encrypt your data</li>
<li>  Master keys are 256-bits in length.</li>
</ul>
</li>
<li>  KMS automatically <strong>rotate</strong> master keys created within KMS once per year <u>without the need to re-encrypt data</u></li>
<li>  KMS stores <strong>multiple copies</strong> of encrypted versions of your keys in systems</li>
</ul>
<br>

<p> <strong>CMK Types</strong></p>
<ul>
<li>  <strong>Customer managed CMK</strong>: keys that user create, own &amp; manage</li>
<li>  <strong>Amazon managed CMK</strong>: keys in your account that are created, managed, and used on your behalf by an AWS service that integrates with KMS. User cannot manage CMKs or change permissions</li>
<li>  <strong>AWS owned CMKs</strong> are not in your account</li>
</ul>
<br>

<hr>
<h2 id="Secrets-Manager"><a href="#Secrets-Manager" class="headerlink" title="Secrets Manager"></a><a href="https://tutorialsdojo.com/aws-secrets-manager/">Secrets Manager</a></h2><ul>
<li>  A <strong>secret management service</strong> enables you to easily <u>rotate, manage, and retrieve</u> database credentials, API keys, and other secrets throughout their lifecycle</li>
<li>  Encrypts secrets at rest using <strong>encryption keys</strong> that you own and store in KMS (<strong>CMK</strong>). When you retrieve a secret, Secrets Manager decrypts the secret and transmits it securely over TLS to your local environment</li>
<li>  Rotate secrets on a schedule or on demand by using the Secrets Manager console, AWS SDK, or AWS CLI</li>
<li>  🧡 Natively supports <strong>rotating credentials for databases</strong> hosted on RDS &amp; DocumentDB, and clusters hosted on Redshift</li>
</ul>
<br>

<ul>
<li>  A <strong>secret</strong> consists of a set of <u>credentials</u> (user name and password), and the <u>connection details</u> used to access a secured service</li>
<li>A secret also contains <strong>metadata &amp; versions</strong><ul>
<li>  Multiple versions exist when you rotate the credentials</li>
<li>  Each version has an encrypted copy of the secret value</li>
</ul>
</li>
</ul>
<br>

<ul>
<li>  To retrieve secrets, you simply <u>replace secrets in plain text in your applications with code</u> to pull in those secrets programmatically using the Secrets Manager APIs</li>
<li>  Secrets can be <strong>cached</strong> on the <strong>client side</strong>, and <strong>updated</strong> only during a secret rotation</li>
</ul>
<br>

<p> <strong>Secret Rotation</strong></p>
<ul>
<li>When rotating secrets on <u>natively supported services</u>, Secrets Manager uses <strong>CloudFormation</strong> to build the rotation function and configure the network connection between the two.<ul>
<li>  DB runs in a VPC, <u>not publicly accessible</u>: CF templates configs the <strong>Lambda rotation function</strong> to run in the same VPC. The rotation function can communicate with the protected service <u>directly within the VPC</u></li>
<li>  <u>Publicly accessible</u> resource: CF configs the Lambda rotation function <strong>not to run in the VPC</strong>. Lambda rotation function communicates with the protected service via the <strong>publicly accessible connection point</strong></li>
</ul>
</li>
</ul>
<br>

<ul>
<li><p> 🧡 By default, the Secrets Manager endpoints run on the <u>public Internet</u>. If you run your Lambda rotation function and protected database or service in a <strong>VPC</strong>, then you must perform one of the following steps:</p>
<ul>
<li><p>  <u>Add a <strong>NAT gateway</strong> to your VPC</u> (Enables traffic that originates in your VPC to reach the public Secrets Manager endpoint)</p>
</li>
<li><p><u>Configure Secrets Manager service endpoints directly within your VPC</u> </p>
<blockquote>
<p>  <em>Configures your VPC to intercept any request addressed to the public regional endpoint, and redirect the request to the private service endpoint running within your VPC</em></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  By default, Secrets Manager <strong>does not write or cache</strong> the secret to persistent storage</li>
<li>  By default, Secrets Manager only accepts requests from hosts that use <strong>TLS</strong> and Perfect <strong>Forward Secrecy</strong></li>
<li>  Control access to the secret with <strong>IAM</strong></li>
<li>  Tag secrets individually and apply tag-based access controls</li>
<li>  Secrets Manager <strong>does not immediately delete secrets</strong>. Instead, Secrets Manager immediately makes the secrets <strong>inaccessible</strong> and scheduled for deletion after a recovery window of a minimum of 7 days</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 12 CloudFormation &amp; SAM</title>
    <url>/2020/AWS-CF-SAM/</url>
    <content><![CDATA[<p>In the twelfth post of the AWS service components series, we’re going to talk about 2 services that serve the purpose of Infrastructure-as-Code (<strong>IaC</strong>):</p>
<ul>
<li>  <strong>CloudFormation</strong></li>
<li>  <strong>SAM</strong> (Serverless Application Model)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="CloudFormation"><a href="#CloudFormation" class="headerlink" title="CloudFormation"></a><a href="https://tutorialsdojo.com/aws-cloudformation/">CloudFormation</a></h2><ul>
<li>  Easy way to create a collection of related AWS resources, and <strong>provision</strong> them in an orderly and predictable fashion</li>
<li>  Model your entire infrastructure in a JSON / yaml file (<strong>Templates</strong>)</li>
<li>  CF <strong>automates</strong> the provisioning and updating of your infrastructure in a safe and controlled manner. You can use <b>Rollback Triggers</b> to specify <strong>CW alarms</strong> that CF should monitor during the stack creation and update process. If any of the alarms are breached, <u>CF rolls back the entire stack operation to a previous deployed state</u></li>
</ul>
<br>

<ul>
<li>  <strong>CF change sets</strong>: Preview how proposed changes to a stack might impact your running resources</li>
<li><strong>Stacks</strong>: <ul>
<li>  Manage related resources as single unit</li>
<li>  All the resources in a stack are defined by the stack’s CF template</li>
<li>  Config drift detection</li>
</ul>
</li>
<li>  <strong>StackSets</strong>: Provision a common set of AWS resources <u>across multiple accounts and regions</u> with a single CF template. StackSets takes care of automatically and safely provisioning, updating, or deleting stacks in multiple accounts and across multiple regions</li>
<li>  CF enables you to build <strong>custom extensions to your stack template using Lambda</strong></li>
</ul>
<br>

<p><strong>CF &amp; Beanstalk</strong></p>
<ul>
<li>  Eb provides an <strong>environment</strong> to deploy &amp; run apps</li>
<li>  CF is a <strong>provisioning mechanism</strong> for AWS resources</li>
<li>  Both EB &amp; CF only <strong>deploy apps to the cloud</strong>, NOT on-premise</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  CF is integrated with CT (CT captures API calls for CF as <strong>events</strong>)</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li><p>   A <strong>service role</strong> is an IAM role that allows CF make calls to resources on your behalf</p>
</li>
<li><p>Improve security by config CF to use an <strong>interface VPC endpoint</strong></p>
  <br></li>
</ul>
<hr>
<h2 id="SAM"><a href="#SAM" class="headerlink" title="SAM"></a>SAM</h2><ul>
<li>  An open-source framework for building serverless applications (A <strong>specification</strong>)</li>
<li>  Shorthand syntax to express functions, APIs, databases, and event source mappings (JSON / yaml)</li>
<li>  During deployment, SAM transforms and expands the SAM syntax into <strong>CF syntax</strong></li>
</ul>
<br>

<p><strong>SAM CLI</strong></p>
<ul>
<li>  Lambda-like execution environment that lets you locally build, test, and debug applications defined by SAM templates</li>
<li>  Deploy your applications to AWS</li>
</ul>
<br>

<p><strong>Syntax</strong></p>
<ul>
<li><code>AWS::Serverless::Api</code><ul>
<li>  API Gateway</li>
</ul>
</li>
<li><code>AWS::Serverless::Application</code><ul>
<li>  Embed as serverless app, from S3 (<strong>nested</strong> application), deployed as <strong>nested stacks</strong></li>
</ul>
</li>
<li><code>AWS::Serverless::Function</code><ul>
<li>  Config  info for creating a Lambda function</li>
<li>  Describe any <strong>event source</strong> to attach: S3, DynamoDB Streams, Kinesis Data Streams</li>
</ul>
</li>
<li><code>AWS::Serverless::LayerVersion</code><ul>
<li>  Lambda layer version</li>
</ul>
</li>
</ul>
<br>

<p><strong>Control access to APIs</strong></p>
<p><strong>1. Cognito user pool</strong>: User directories</p>
<p><strong>2. Lambda authorizer</strong></p>
<ul>
<li>A Lambda function that you provide to <strong>control access to your API</strong>. When your <u>API is called, this Lambda function is invoked</u> with a <strong>request context / authorization token</strong> that are provided by the client application. Tow types of authorizer:<ul>
<li>  <strong>Token</strong>-based: JWT / OAuth</li>
<li>  <strong>Request parameter</strong> based: Receives the caller&#8217;s identity in a combination of <u>headers, query string parameters, <code>stageVariables</code>, and <code>$context</code> variables</u></li>
</ul>
</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 11 Cloud Pipeline Components</title>
    <url>/2020/AWS-Pipeline/</url>
    <content><![CDATA[<p>In the eleventh post of the AWS series, we’re going to talk about 5 services services that are components of the CI / CD pipeline in the cloud:</p>
<ul>
<li>  <strong>CodeCommit</strong></li>
<li>  <strong>CodeBuild</strong></li>
<li>  <strong>CodeDeploy</strong></li>
<li>  <strong>CodePipeline</strong></li>
<li>  <strong>CodeStar</strong></li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="CodeCommit"><a href="#CodeCommit" class="headerlink" title="CodeCommit"></a>CodeCommit</h2><ul>
<li>  <strong>Source-control service</strong>, host Git-based repositories (<strong>AWS’s version of GitHub</strong>)</li>
<li>  CodeCommit stores repos in <strong>S3 &amp; DynamoDB</strong></li>
</ul>
<br>

<p>Git to CodeCommit (HTTPS / SSH)</p>
<ul>
<li>  Clone</li>
<li>  Mirror</li>
<li>  Migrate branches</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  <strong>IAM</strong> to control &amp; monitor who can have access</li>
<li>  CT &amp; CW, SNS</li>
</ul>
<br>



<hr>
<h2 id="CodeBuild"><a href="#CodeBuild" class="headerlink" title="CodeBuild"></a><a href="https://tutorialsdojo.com/aws-codebuild/">CodeBuild</a></h2><p><strong>1.  Continuous Integration (CI)</strong> service</p>
<ul>
<li>  Compile sources code</li>
<li>  Run tests</li>
<li>  Produce software packages</li>
</ul>
<br>

<p><strong>2.  Concepts</strong></p>
<ul>
<li>  <strong>Build project</strong>: <u>defines how CodeBuild will run a build</u>. It includes information such as where to get the source code, which build environment to use, the build commands to run, and where to store the build output</li>
<li>  <strong>Build specification (<code>buildspec.yml</code>)</strong>: Choose the commands to run at each phase of the build and other settings</li>
</ul>
<br>

<p><strong>3.  Features</strong></p>
<ul>
<li>  Stores artifacts in <strong>S3</strong></li>
<li>  Integrate CodeBuild into existing <strong>CI/CD pipelines</strong> using its source integrations, build commands, or Jenkins integration</li>
<li>  CodeBuild connect with <strong>CodeCommit</strong> / GitHub / DockerHub / ECR to pull source code for builds</li>
<li>  <strong>Access past build results</strong> through the console, CW, or the API. The results include outcome (success or failure), build duration, output artifact location, and log location</li>
<li>  <strong>Automate</strong> release process by using <b>CodePipeline</b> to test your code and run your builds with CodeBuild</li>
</ul>
<br>

<p><strong>4.  Caching</strong></p>
<ul>
<li>  S3</li>
<li>Local: store cache locally on a build host. Cache modes:<ul>
<li>  Source</li>
<li>  Docker layer</li>
<li>  Custom</li>
</ul>
</li>
</ul>
<br>

<p><strong>5.  Monitoring &amp; Security</strong></p>
<ul>
<li>  Specify key stored in KMS to encrypt artifacts</li>
<li>  Security and separation at the <strong>infrastructure</strong> and <strong>execution</strong> levels</li>
<li>Use CW to watch the builds. Monitor builds at 2 levels:<ul>
<li>  <strong>Project level</strong>: These metrics are for all builds in the specified project only</li>
<li>  <strong>AWS account level</strong>: These metrics are for all builds in one account</li>
</ul>
</li>
</ul>
<br>

<hr>
<h2 id="CodeDeploy"><a href="#CodeDeploy" class="headerlink" title="CodeDeploy"></a><a href="https://tutorialsdojo.com/aws-codedeploy/">CodeDeploy</a></h2><p><strong>Deployment service</strong>. Automates software deployments to a variety of <strong>compute services</strong> such as EC2, Lambda, and on-premises servers</p>
<p>CodeDeploy deploys the app on the <strong>compute platform</strong> (EC2, ECS, Lambda, on-premise servers)</p>
<br>

<p><code>Appspec.yml</code> (Application specification):  Manage each deployment as a series of <strong>lifecycle event hooks</strong></p>
<br>

<p><strong>Deployment group</strong> contains individually tagged instances, EC2 instances in AS groups, or both</p>
<ul>
<li><p>  <strong>Lambda (<code>appspec.yml</code>)</strong>:  defines a set of <u>CodeDeploy configurations for future deployments</u> of an AWS Lambda function</p>
</li>
<li><p><strong>ECS</strong>: Deployment group specifies <u>ECS service, LB, test listener (optional), and two target groups</u>. It also specifies when to reroute traffic to the replacement task set, and when to terminate the original task set and ECS application after a successful deployment</p>
</li>
</ul>
<br>

<p> <strong>Two Types of deployment</strong></p>
<ul>
<li><strong>In-place (Only EC2 / On-premise)</strong><ul>
<li>  Instances in the deployment group are <u>updated with the latest application revision</u></li>
<li>  Current application is stopped, new version is installed &amp; started</li>
</ul>
</li>
<li><strong>Blue / Green (EC2, ECS, Lambda)</strong><ul>
<li>  Traffic is <u>rerouted from one set of instances to another</u> by <u>deregistering the original instances from a <strong>LB</strong></u> and <strong>registering a replacement set of instances</strong> that typically has the latest application revision already installed</li>
<li>  CodeDeploy <strong>shift traffic</strong> from blue (old) to green (new) according to specifications</li>
</ul>
</li>
</ul>
<br>

<p><strong>Blue / Green for ECS, EC2, Lambda</strong></p>
<ul>
<li>  <strong>ECS</strong>: Traffic shifts from your ECS service&#8217;s original task set to a replacement task set <strong>all at once</strong></li>
<li><strong>EC2</strong><ul>
<li>   <strong>CodeDeploy agent</strong> must be installed on each instance</li>
<li>   More than one EC2 instances, with EC2 tags / EC2 AS group, and correct IAM instance profile</li>
<li>During replacement: <ul>
<li>  Use EC2 AS group you specify as a <strong>template</strong> for the replacement environment</li>
<li>  Specify the replacement instance using EC2 instance <strong>tags</strong>, EC2 AS <strong>group names</strong>, or both</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Lambda (3种)</strong> - Control how traffic is shifted</p>
<ul>
<li>  <strong>Canary</strong>: Shift traffic by percentage</li>
<li>  <strong>Linear</strong>: Shift traffic equally</li>
<li>  <strong>All at once</strong>: All traffic is shifted from the original Lambda function to the updated Lambda version</li>
</ul>
</li>
<li><p><strong>Pros</strong></p>
<ul>
<li>  Apps can be installed and <u>tested in the new replacement environment</u>, and deployed to production simply by <strong>re-routing traffic</strong></li>
<li>  EC2 / On-premise, rollback to previous version is fast &amp; reliable (just route traffic back)</li>
</ul>
</li>
</ul>
<br>

<br>

<p> <strong>EC2 Deployment Configuration</strong> (<code>CodeDeployDefault</code>)</p>
<blockquote>
<p>  <em>e.g. <code>CodeDeployDefault.AllAtOnce</code></em></p>
</blockquote>
<ul>
<li><code>.AllAtOnce</code><ul>
<li>  In-place: downtime</li>
<li>  Blue / Green: route all traffic at once</li>
</ul>
</li>
<li><code>.HalfAtATime</code><ul>
<li>  In-place: Replace only a half </li>
<li>  Blue / Green: Route half</li>
</ul>
</li>
<li><code>.OneAtATime</code> (<strong>default</strong>)<ul>
<li>  In-place: deploy 1 instance per time</li>
<li>  Blue / Green: Routes traffic to 1 instance in the replacement environment per time. Succeeds if traffic is rerouted to all replacements</li>
</ul>
</li>
</ul>
<br>

<p><strong>Lambda Deployment Configuration</strong> (<code>CodeDeployDefault.Lambda</code>)</p>
<blockquote>
<p>  <em>e.g. <code>CodeDeployDefault.LambdaCanary10PercentXMinutes</code></em></p>
</blockquote>
<ul>
<li>  <code>Canary10PercentXMinutes</code>: Shift 10% traffic first, shift 90% X min later</li>
<li>  <code>Canary10PercentEveryXMinutes</code>: Shift 10% traffic every X minutes</li>
<li>  <code>AllAtOnce</code>: Shift all at once</li>
</ul>
<br>

<p><strong>Deployment Revision</strong></p>
<ul>
<li>  <strong>Lambda</strong>: Revision stored in S3</li>
<li>  <strong>ECS</strong>: Specifies ECS task definition for deployment, container name, port mapping (route traffic), Lambda functions (optional)</li>
<li>  <strong>EC2 / On-premise</strong>: Source content &amp; application specification file, revision stored in S3</li>
</ul>
<br>

<p><strong>Deployment Lifecycle</strong></p>
<ul>
<li>  <code>ApplicationStop</code></li>
<li>  <code>DownloadBundle</code></li>
<li>  <code>BeforeInstall</code></li>
<li>  <code>Install</code></li>
<li>  <code>AfterInstall</code></li>
<li>  <code>ApplicationStart</code></li>
<li>  <code>ValidateService</code></li>
</ul>
<br>

<p><strong>Features</strong></p>
<ul>
<li>Prevent <strong>downtime</strong><ul>
<li>  Rolling updates</li>
<li>  Deployment health tracking</li>
</ul>
</li>
<li>  Model: <strong>file and command-based install</strong></li>
<li>  CodeDeploy integrates with <strong>AS</strong> (scale EC2 capacity based on traffic, new instance place behind <strong>ELB</strong>)</li>
<li>  On-premise server: Connect to AWS <strong>public endpoints</strong></li>
</ul>
<br>

<p><strong>Deployment Notes</strong></p>
<ul>
<li>  Lambda &amp; EC2: CodeDeploy implements <strong>rollbacks by redeploying</strong></li>
<li>  ECS: <strong>rollbacks by re-routing traffic</strong> from replacement task set to original task set</li>
<li>CodeDeploy monitors the instance health in the deployment group. 2 health status:<ul>
<li>  <strong>Revision</strong> health (application revision currently installed) - current / old / unknown</li>
<li>  <strong>Instance</strong> health (if deployment is successful) - healthy / unhealthy</li>
</ul>
</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  Need to at least monitor: <strong>Events &amp; status</strong> of deployment and instance</li>
<li>Tools:<ul>
<li>  CW Alarms, Events &amp; Logs</li>
<li>  CT, SNS</li>
<li>  CodeDeploy console</li>
</ul>
</li>
</ul>
<br>



<hr>
<h2 id="CodePipeline"><a href="#CodePipeline" class="headerlink" title="CodePipeline"></a><a href="https://tutorialsdojo.com/aws-codepipeline/">CodePipeline</a></h2><img data-src="/img/15.png" style="zoom: 70%;" />

<p><strong>Continuous Delivery (CD)</strong> service</p>
<ul>
<li>  Automate release pipelines</li>
<li>  Integrate with 3rd party services (GitHub, Jenkins)</li>
</ul>
<br>

<p><strong>Concepts</strong></p>
<ul>
<li>  <strong>Pipeline</strong>: Defines your release process workflow, and describes how a new code change progresses through your release process</li>
<li>  A pipeline has a series of <strong>stages</strong> (build, test, deploy)</li>
</ul>
<br>

<hr>
<h2 id="CodeStar"><a href="#CodeStar" class="headerlink" title="CodeStar"></a>CodeStar</h2><ul>
<li>  Quickly develop, build &amp; test apps on AWS</li>
<li>  Used with CodeCommit, CodeBuild, CodeDeploy, CodePipeline for <strong>robust CI / CD</strong> toolchain</li>
<li>  Provide project template to start with</li>
<li>  CodeStar Roles: Owner, Contributor, Viewer</li>
</ul>
<img data-src="/img/16.png" style="zoom: 60%;" />












<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 10 Blue / Green Deployment and CI / CD</title>
    <url>/2020/AWS-Deployment-CICD/</url>
    <content><![CDATA[<p>In today’s post, I’m going to cover doing blue / green deployment on AWS, and share some notes about building Ci/ CD pipelines on AWS. Since this is my summary from the AWS whitepapers, the entire post isn’t necessarily written in English.</p>
<span id="more"></span>

<br>

<hr>
<h2 id="Blue-Green-Deployment"><a href="#Blue-Green-Deployment" class="headerlink" title="Blue / Green Deployment"></a>Blue / Green Deployment</h2><p><strong>Blue / Green</strong>: Release apps by shifting traffic between 2 identical env, running different versions of the app</p>
<ul>
<li>  Near zero downtime</li>
<li>  <strong>Easy rollback</strong> (revert traffic back to the still-operating blue)</li>
<li>  Isolation between blue &amp; green application</li>
</ul>
<br>

<p> 🧡 <strong>Goal of B / G: Achieve <u>Immutable Infrastructure</u></strong> (Need not make changes to application after deployment)</p>
<br>

<h3 id="B-G-with-AWS-services"><a href="#B-G-with-AWS-services" class="headerlink" title="B / G with AWS services"></a><u>B / G with AWS services</u></h3><p><strong>1) Route 53</strong></p>
<ul>
<li>  DNS, classic approach</li>
<li>  Direct traffic by updating DNS records, set shorter TTL</li>
</ul>
<br>

<p><strong>2) ELB</strong></p>
<ul>
<li>  Health check against EC2 resources, increase fault tolerance</li>
</ul>
<br>

<p><strong>3) Auto Scaling</strong></p>
<ul>
<li>   Enable B/G: Attach <strong>different versions of the launch configuration to AS group</strong></li>
<li>   Add ELB: <strong>balance traffic across EC2 instances running in AS groups</strong></li>
<li>   <strong>Standby state / termination policies</strong>: quick rollback</li>
</ul>
<br>

<p><strong>4) Beanstalk</strong></p>
<ul>
<li>  EB supports AS &amp; ELB for B/G</li>
<li>  Run multiple versions by swapping environment URLs</li>
</ul>
<br>

<p><strong>5) OpsWorks</strong></p>
<ul>
<li>  Based on Chef</li>
<li>  Simplifies cloning entire stack</li>
</ul>
<br>

<p><strong>6) CF</strong></p>
<ul>
<li>  Describe the AWS resources they need through JSON / yaml</li>
<li>  Provision B/G, switch traffic via Route 53 / ELB</li>
<li>  Infrastructure as code: Version control &amp; CI</li>
</ul>
<br>

<p><strong>7) CW</strong></p>
<ul>
<li>  Collect &amp; track metrics</li>
<li>  Collect &amp; monitor logs</li>
<li>  Set alarms</li>
<li>  System-wide visibility into resource utilization, application performance &amp; operational health</li>
</ul>
<br>

<h3 id="B-G-Technique"><a href="#B-G-Technique" class="headerlink" title="B / G Technique"></a><u>B / G Technique</u></h3><p><strong>1) Update DNS routing with Route 53</strong></p>
<ul>
<li>  DNS routing through record updates (<strong>Aliases</strong>)</li>
<li>  Express <strong>endpoint</strong> into the environment as a DNS name / IP</li>
<li>  Can do a <strong>weighted</strong> distribution (gradual shift with Route 53), define traffic percentage (canary analysis)</li>
<li>  <strong>Rollback</strong> by updating DNS record, to shift traffic back to blue (TTL, how long clients cache query results)</li>
<li>Applies to:<ul>
<li>  Public / Elastic IP, or expose IP / DNS endpoint</li>
<li>  EC2 Instances / ECS clusters behind ELB, or in AS groups with ELB as frontend</li>
<li>  EB web tiers</li>
</ul>
</li>
</ul>
<br>

<p><strong>2) Swap AS groups behind ELB</strong></p>
<ul>
<li><p>  <strong>ELB</strong>: health check (New instances auto added to the LB pool, if they pass health check)</p>
</li>
<li><p>  <strong>AS</strong>: replace unhealthy instances</p>
</li>
<li><p>  Health check occurs at <strong>configurable</strong> intervals</p>
</li>
<li><p>  <strong>Deploy: Attach green group to LB, put blue in Standby state</strong></p>
</li>
</ul>
<br>    

<p><strong>3) Update AS group Launch configurations</strong></p>
<ul>
<li><p>  A <strong>launch configuration</strong>: AMI ID (Amazon Machine Image), instance type, key pair, security groups, etc.</p>
</li>
<li><p>  Associate only <strong>one</strong> launch config with an AS group, <u>unchangeable after you create it</u></p>
</li>
<li><p>  Change launch config: <strong>Replace</strong> existing config with a new one</p>
</li>
<li><p>  Default termination policy: Remove instances with <strong>oldest</strong> launch config</p>
</li>
<li><p><strong>Deploy</strong></p>
<ul>
<li>  Update AS group with <strong>new launch config</strong></li>
<li>  Scale AS group *** 2**</li>
<li>  <strong>Shrink</strong> As group back to original size (instances with old configs `are removed)</li>
</ul>
</li>
<li><p>Instances with <strong>standby</strong> state: quick <strong>rollback</strong></p>
<ul>
<li>  Update AS group with old launch config</li>
<li>  Do the steps above in reverse</li>
</ul>
</li>
</ul>
<br>

<p><strong>4) Swap Environment of EB application</strong></p>
<ul>
<li>  In-place update on existing instances (downtime during update)</li>
<li><strong>Immutable</strong> deployment using new instance sets<ul>
<li>  <strong>Swap Environment URLs</strong> from <strong>Actions</strong></li>
<li>  EB performs a <strong>DNS switch</strong></li>
</ul>
</li>
</ul>
<br>

<p><strong>5) Clone a Stack in OpsWorks &amp; Update DNS</strong></p>
<ul>
<li><p>  <strong>Stacks</strong>: logical grouping of AWS resources, one or more <strong>layers</strong></p>
</li>
<li><p><strong>Deploy</strong>: Update DNS records to point to green (stack’s LB)</p>
</li>
</ul>
<br>

<h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a><u>Other</u></h3><p><strong>Best Practice for Data Sync &amp; Schema Change</strong></p>
<ul>
<li>Decoupling schema change from code change<ul>
<li>  Additive: changed first</li>
<li>  Deletive: changed last</li>
</ul>
</li>
<li>  Need to consider <strong>state</strong> (<strong>DB contains much state</strong>, but comparatively little logic &amp; structure)</li>
</ul>
<br>

<p><strong>When NOT to use B / G</strong></p>
<ul>
<li>  Introduce additional points of failure</li>
<li>  Schema change is too complex, problem with data sync</li>
</ul>
<hr>
<h2 id="CI-CD-on-AWS"><a href="#CI-CD-on-AWS" class="headerlink" title="CI / CD on AWS"></a>CI / CD on AWS</h2><p><strong>1. CodeStar</strong></p>
<p>Rapidly orchestrate an <strong>end-to-end</strong> software release workflow (pipeline)</p>
<br>

<p><strong>2. Tests</strong></p>
<ul>
<li><p>  <strong>Unit tests should make up the bulk of testing strategy (70%)</strong></p>
</li>
<li><p><strong>Staging Phase</strong> (Full environments are created to mirror real production environment)</p>
<ul>
<li>  <strong>Integration</strong> test (interface between components)</li>
<li>  <strong>Component</strong> test (message passing between components)</li>
<li>  <strong>System</strong> test (end-to-end)</li>
<li>  <strong>Performance</strong> test (load / stress / spike tests)</li>
<li>  <strong>Compliance</strong> test </li>
<li>  User Acceptance Test (<strong>UAT</strong>, e2e business flow)</li>
</ul>
</li>
<li><p>  Production: <strong>Canary</strong> test</p>
</li>
</ul>
<br>

<p><strong>3. Build the Pipeline</strong></p>
<ul>
<li>  CI / CD stages: Source, build, staging, production</li>
<li>  <code>buildspec.yml</code></li>
</ul>
<br>

<p><strong>4. Deployment methods</strong></p>
<blockquote>
<p>  <em>除了 deploy in place, 其它四种都是近乎 <strong>zero downtime</strong></em></p>
</blockquote>
<p><strong>1)  Deploy in place</strong> </p>
<ul>
<li>  All at once</li>
<li>  Downtime during updates</li>
<li>  Deploy: <u>existing instances</u></li>
<li>  Rollback: Redeploy</li>
</ul>
<p><strong>2)  Rolling</strong></p>
<ul>
<li>  Single batch out of service </li>
<li>  Deploy: <u>existing instances</u></li>
<li>  Rollback: Redeploy</li>
<li>  Variation: <strong>Canary release</strong></li>
</ul>
<p><strong>3)  Rolling with additional batch</strong></p>
<ul>
<li>  <strong>Beanstalk ONLY</strong></li>
<li>  Deploy: <u>new &amp; existing instances</u></li>
<li>  Rollback: Redeploy</li>
</ul>
<p><strong>4)  Immutable</strong></p>
<ul>
<li>  Deploy: <u>new instances</u></li>
<li>  Rollback: Redeploy</li>
</ul>
<p><strong>5) Blue / Green</strong></p>
<ul>
<li>  Deploy: <u>new instances</u></li>
<li>  <strong>Rollback: Switch back to old environment</strong> </li>
</ul>
<br>

<p><strong>Best Practices</strong></p>
<ul>
<li>  Infrastructure as code, pipeline as code</li>
<li>  No long-running feature branches</li>
<li>  Build unit tests toward 100% coverage, takes 70% of overall testing</li>
<li>  Role-based security</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 09 ElastiCache &amp; CloudFront</title>
    <url>/2020/AWS-ElastiCache-CloudFront/</url>
    <content><![CDATA[<p>In the ninth post of the AWS series, we’re going to talk about 2 services:</p>
<ul>
<li>  <strong>ElastiCache</strong> (Memcached &amp; Redis)</li>
<li>  <strong>CloudFront</strong> (Cloud CDN)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="ElastiCache"><a href="#ElastiCache" class="headerlink" title="ElastiCache"></a>ElastiCache</h2><div class="note primary"><p><strong>Only ElastiCache &amp; RDS have read replicas.</strong></p>
<p><strong>DynamoDB &amp; CloudFront DO NOT have read replicas.</strong></p>
</div>



<ul>
<li>  Distributed in-memory cache, supports Redis &amp; Memcached</li>
<li>  Can be used for storing <strong>session states</strong></li>
<li>  Monitor events with <strong>ElastiCache Events</strong></li>
<li>  Redis is more <strong>HA</strong> than Memcached</li>
</ul>
<br>

<h3 id="For-Redis"><a href="#For-Redis" class="headerlink" title="For Redis"></a><u>For Redis</u></h3><ul>
<li>  Existing applications that use Redis can use ElastiCache with almost no modification</li>
<li>  Automatic detection and recovery from cache node failures</li>
<li>  For improved fault tolerance, have at least two nodes in a Redis cluster and enabling <b>Multi-AZ with automatic failover</b></li>
</ul>
<br>

<ul>
<li>  Supports data partition up to 250 shards</li>
<li>  Data encryption in transit &amp; at rest</li>
<li>  <strong>Persistent data</strong>, can be used as data store</li>
<li>  <strong>Single-threaded</strong></li>
</ul>
<br>

<p><strong>Cache data if:</strong></p>
<ul>
<li>  It is slow or expensive to acquire when compared to cache retrieval</li>
<li><span
  style="font-weight: 400;">It is accessed with sufficient frequency</span></li>
<li>  It is relatively static, or if rapidly changing, staleness is not a significant issue</li>
</ul>
<br>

<ul>
<li>   🧡 Redis <strong>publish / subscribe</strong>: recipients of the messages subscribe to the publisher</li>
<li>   Redis <strong>hashes</strong> map string names to string values</li>
</ul>
<br>

<p><strong>Nodes, shards &amp; clusters</strong></p>
<ul>
<li><p>  A <strong>node</strong> is a fixed-size chunk of <u>secure, network-attached RAM</u>. A node can exist in isolation / relation to other nodes</p>
</li>
<li><p>Every node within a cluster is the same instance type and runs the same cache engine. Each cache node has its own DNS name and port</p>
<blockquote>
<p>  <em>Replica nodes use <strong>asynchronous replication</strong> to keep <strong>synchronized</strong> with the primary node</em></p>
</blockquote>
</li>
</ul>
<br>

<ul>
<li><p><strong>Shard</strong>:  A grouping of 1- 6 related nodes</p>
<ul>
<li>  Cluster mode off: A Redis cluster always has one shard</li>
<li>  Cluster mode on: A Redis cluster can have 1–90 shards</li>
</ul>
</li>
<li><p>  If there is more than one node in a shard, the shard supports replication with one node being the <u>read/write primary node</u> and the others <u>read-only replica nodes</u>.</p>
</li>
<li><p>  <strong>Cluster</strong>: a logical grouping of one or more ElastiCache for Redis Shards. Data is partitioned across the shards in a Redis cluster (cluster mode on).</p>
</li>
</ul>
<br>

<p><strong>Parameter groups</strong></p>
<p>Parameters are used to control memory usage, eviction policies, item sizes, and more.</p>
<br>

<p><strong>Security</strong></p>
<p><strong>Redis AUTH</strong>: Improve data security by requiring the user to <u>enter a password before they are granted permission</u> to execute Redis commands on a password-protected Redis server (<code>--auth-token</code>)</p>
<br>

<h3 id="Caching"><a href="#Caching" class="headerlink" title="Caching"></a><u>Caching</u></h3><p><strong>ElastiCache Auto Discovery</strong> only available for Memcached (identify all nodes in a cache cluster)</p>
<br>

<h4 id="Caching-Strategy"><a href="#Caching-Strategy" class="headerlink" title="Caching Strategy"></a>Caching Strategy</h4><blockquote>
<p>  By adding <strong>TTL</strong> to each write, we have advantages of each strategy, and largely <u>avoid cluttering up the cache with too many data</u></p>
<p>  <em>If there are no cache records to begin with, then use <strong>write through</strong> first.</em></p>
</blockquote>
<br>

<p><strong>1. Lazy loading (for GET, read-heavy)</strong></p>
<ul>
<li>  Loads data into cache only when necessary</li>
<li>  Only requested data is cached</li>
<li>  <strong>Cons</strong>: cache miss, <strong>stale</strong> data</li>
</ul>
<br>

<p><strong>2. Write through (for CUD)</strong></p>
<ul>
<li>  Adds / updates data in the cache whenever data is written to the database</li>
<li>  Cache data is never stale</li>
<li>  Each write involves 2: <u>write to cache &amp; write to DB (add / update)</u></li>
<li>  <strong>Cons</strong>: data miss, cache churn</li>
</ul>
<br>



<hr>
<h2 id="CloudFront"><a href="#CloudFront" class="headerlink" title="CloudFront"></a>CloudFront</h2><div class="note success"><p>Cannot directly upload files to CloudFront. Must have <strong>origin servers</strong>, e.g. S3, EC2.</p>
</div>



<ul>
<li>  Delivers content through a worldwide network of data centers (= <strong>edge locations</strong>)</li>
<li>  When a user requests content that you&#8217;re serving with CloudFront, the user is <u>routed to the edge location that provides the lowest latency</u>, so that content is delivered with the best possible performance</li>
</ul>
<br>

<h3 id="Deliver-Content"><a href="#Deliver-Content" class="headerlink" title="Deliver Content"></a><u>Deliver Content</u></h3><ul>
<li>You specify <b>origin servers</b><span
  style="font-weight: 400;">, like an <u>S3 bucket / EC2 / your own HTTP server</u>, from which CloudFront gets your files which will then be distributed from <strong>CloudFront edge locations</strong> all over the world.</span></li>
<li>  Upload files (objects), cached for <strong>24h</strong> by default</li>
<li>  Create <strong>CloudFront Distribution</strong></li>
</ul>
<br>

<ul>
<li><p>  CloudFront supports <strong>WebSocket protocol</strong> &amp; <strong>HTTP protocol</strong></p>
</li>
<li><p>Use <strong>Lambda@Edge</strong> &amp; CloudFront enables a variety of ways to <u>customize</u> the content that CloudFront delivers</p>
<blockquote>
<p>  <em>It can help you configure your <strong>CloudFront distribution</strong> to serve private content from your own custom origin, as an option to using signed URLs or signed cookies</em></p>
</blockquote>
</li>
<li><p>   CloudFront can cache different versions of your content based on the values of <strong>query string parameters</strong></p>
</li>
</ul>
<br>

<h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a><u>Other</u></h3><p><strong>HA</strong></p>
<ul>
<li>  CloudFront allows you to set up multiple origins to enable redundancy with <b>Origin Failover</b> (a distribution with &gt;= 2 origins)</li>
</ul>
<br>

<p><strong>HTTPS</strong></p>
<ul>
<li>  Between viewers &amp; CloudFront, and between CloudFront &amp; origins</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  Cloud Front own reports: Cache Statistics / Viewers / Usage etc.</li>
<li>  AWS Config to <strong>record configuration changes</strong> for CloudFront distribution settings changes</li>
<li>  Integrates with <strong>CW metrics</strong></li>
<li>  CloudTrail to <strong>capture API requests</strong> (only logging, not analyze)</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  CloudFront &amp; Shield &amp; WAF &amp; Route 53  (layered security protection)</li>
<li>  <strong>Origin Access Identity (OAI)</strong>: Restrict access to an S3 bucket to only be accessible from CloudFront</li>
<li>  <strong>Field-level encryption</strong>:  Securely upload user-submitted data (e.g. credit card numbers) to your origin servers</li>
</ul>
<br>

<p><strong>Notice</strong></p>
<p>Many companies that distribute content over the Internet want to <strong>restrict access</strong> to documents, business data, media streams, or content that is intended for selected users, for example, users who have paid a fee. To securely serve this private content by using CloudFront, you can do the following:</p>
<ul>
<li>  Require that your users access your private content by using special <strong>CloudFront signed URLs or signed cookies</strong> 🧡 </li>
<li>  Require that your users access your Amazon S3 content by <strong>using CloudFront URLs</strong>, not Amazon S3 URLs. Requiring CloudFront URLs isn’t necessary, but it is recommended to <u>prevent users from bypassing the restrictions</u> that you specify in signed URLs or signed cookies.</li>
</ul>
<blockquote>
<p>  <em>All objects and buckets by default are private. The presigned URLs are useful if you want your user/customer to be able to upload a specific object to your bucket, but you <u>don&#8217;t require them to have AWS security credentials or permissions</u>. You can <u>generate a presigned URL programmatically</u> using the AWS SDK. Anyone who receives a valid presigned URL can then programmatically upload an object.</em></p>
</blockquote>
<br>

<p><strong>Signed cookies</strong> feature is primarily used if you want to <strong>provide access to multiple restricted files</strong>.</p>
<p>For example, all of the files for a video in HLS format or all of the files in the subscribers&#8217; area of website. In addition, this solution is not complete since the users can <u>bypass the restrictions by simply using the direct S3 URLs.</u></p>
<br>

<p> <strong>Origin Access Identity (OAI)</strong> will require your client to access the files <u>only by using the CloudFront URL</u> and not through a direct S3 URL. This can be a possible solution if it mentions the use of <u>Signed URL or Signed Cookies.</u></p>
<ul>
<li>  <strong>正确做法：</strong> Use <strong>S3 pre-signed URLs</strong> to ensure that only their client can access the files. <u>Remove permission to use Amazon S3 URLs to read the files for anyone else</u>.</li>
<li>  <strong>另一种：</strong>  OAI + Signed URL / Signed cookies</li>
</ul>
<br>

<p>Provide best user experience (for pushing updates to clients):</p>
<ul>
<li>  Store the <strong>update file on an S3 bucket</strong>. Configure CloudFront to <strong>use the bucket as the origin</strong> to cache the update file to edge locations</li>
</ul>
<blockquote>
<p>  Upload once to S3, CloudFront cache to edge locations worldwide</p>
</blockquote>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 08 Monitoring Services</title>
    <url>/2020/AWS-Monitoring/</url>
    <content><![CDATA[<p>In the eighth post of the AWS series, we’re going to talk about three monitoring services today:</p>
<ul>
<li>  <strong>CloudWatch</strong> (Metrics &amp; Logs)</li>
<li>  <strong>X-Ray</strong> (Traces)</li>
<li>  <strong>CloudTrail</strong> (Audit)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="General"><a href="#General" class="headerlink" title="General"></a>General</h2><p><strong>Observability:</strong></p>
<ul>
<li>  CloudWatch (<strong>Metrics &amp; Logs</strong>)</li>
<li>  X-Ray  (<strong>Traces</strong>)</li>
</ul>
<blockquote>
<p>  <strong>CloudTrail</strong> only tracks client API calls. <strong>X-Ray</strong> traces within the AWS service.</p>
</blockquote>
<br>

<p>Since the errors are being received <strong>intermittently</strong>, it’s better to <strong>collect and aggregate</strong> the results at <strong>regular intervals</strong> and then send the data to CloudWatch.</p>
<br>

<p><strong>X-Ray</strong>: </p>
<ul>
<li>  <strong>Trace and analyze</strong> user requests as they travel through GW APIs to the underlying services</li>
<li>  <u>API Gateway supports AWS X-Ray tracing</u> for all API Gateway endpoint types (regional, edge-optimized, and private)</li>
<li>  X-Ray gives you an <strong>end-to-end view of an entire request</strong>, so you can analyze latencies in your APIs and their backend services</li>
</ul>
<blockquote>
<p>  <em>You can use an <strong>X-Ray service map</strong> to view the latency of an entire request, and latency of the downstream services integrated with X-Ray. And you can configure sampling rules to tell X-Ray which requests to record, at what sampling rates, according to criteria that you specify.</em></p>
</blockquote>
<br>

<p><strong>区别 :</strong></p>
<ul>
<li><p>  <strong>CloudTrail</strong> is primarily used for <strong>API logging</strong> of all of your AWS resources</p>
</li>
<li><p>  <strong>CloudWatch</strong> is a <strong>monitoring and management</strong> service. It <u>does not have the capability to trace and analyze user requests</u> as they travel through APIs</p>
</li>
<li><p>  <strong>VPC flow logs</strong> enable you to <u>capture information about the IP traffic going to and from network interfaces in your entire VPC</u></p>
</li>
</ul>
<blockquote>
<p>  <em>Although it can capture some details about the incoming user requests, it is still better to use AWS <strong>X-Ray</strong> as it is a better way to debug and analyze your microservices applications with request tracing, so you can find the root cause of your issues and performance.</em></p>
</blockquote>
<br>



<hr>
<h2 id="CloudWatch-Metrics-amp-Logs"><a href="#CloudWatch-Metrics-amp-Logs" class="headerlink" title="CloudWatch (Metrics &amp; Logs)"></a>CloudWatch (Metrics &amp; Logs)</h2><div class="note success"><p><strong>In essence, CW is a metric repository</strong></p>
</div>

<br>

<ul>
<li>  Monitoring tool for your AWS resources and applications</li>
<li>  CW metrics are <strong>not shared across regions</strong></li>
<li>  Display metrics &amp; create alarms that watch the metrics and send notifications or automatically make changes to the resources you are monitoring, when a threshold is breached</li>
</ul>
<img data-src="/img/10.png" style="zoom: 70%;" />

<p><strong>Concepts</strong></p>
<ul>
<li>  <strong>Namespaces</strong>: Container for CW metrics</li>
<li><strong>Metrics</strong>: ordered time-series data<ul>
<li>  Cannot be deleted, but auto expire after 15 months</li>
<li>  Each metric data point is marked with a <strong>timestamp</strong></li>
<li>  <strong>CW Detailed monitoring</strong>: publish your own application metrics</li>
<li>  EC2 metrics: CW <u>does not collect memory utils and disk space usage metrics automatically</u>. Need to install <strong>CloudWatch Agent</strong> in your instances first to retrieve these metrics</li>
</ul>
</li>
<li>  <strong>Dimension</strong>: Name-value pair that uniquely identifies a metric</li>
<li>  <strong>Statistics</strong>: metric data aggregation</li>
</ul>
<br>

<p> <strong>CW Events</strong></p>
<ul>
<li>  Deliver near real-time stream of system events that describe changes in AWS resources</li>
<li>  <strong>Events</strong>: change in the AWS environment</li>
<li>  <strong>Targets</strong>: process events</li>
<li>  <strong>Rules</strong>: Matches incoming events &amp; route them to targets for processing</li>
</ul>
<br>

<p><strong>CW Logs</strong></p>
<ul>
<li>  Monitor logs from EC2 instances in real-time</li>
<li>  Monitor CT logged events</li>
<li>  By default, logs are kept indefinitely and never expire</li>
<li>  <strong>CW Log Insights</strong>: interactively search and analyze your log data in CloudWatch Logs using queries</li>
</ul>
<br>

<p><strong>CW Agent</strong></p>
<ul>
<li>  Collect more logs and system-level metrics from EC2 instances and your on-premises servers</li>
<li>  Needs to be <strong>installed first</strong></li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  IAM users / roles</li>
<li>  Dashboard permissions, IAM identity-based policies, service-linked roles</li>
</ul>
<br>

<hr>
<h2 id="X-Ray-Performance-Monitoring"><a href="#X-Ray-Performance-Monitoring" class="headerlink" title="X-Ray (Performance Monitoring)"></a><a href="https://tutorialsdojo.com/aws-x-ray/">X-Ray (Performance Monitoring)</a></h2><ul>
<li>  X-Ray analyzes and debugs apps, such as those built using a microservices architecture. With X-Ray, you can <u>identify performance bottlenecks, edge case errors, and other hard to detect issues</u></li>
<li><strong>X-Ray daemon</strong> buffers segments in a queue, and uploads them to X-Ray in <strong>batches</strong> <ul>
<li>  Listens for UDP traffic (port 2000)</li>
<li>  Gathers raw segment data</li>
<li>  Relays to X-Ray API</li>
</ul>
</li>
</ul>
<br>

<p><strong>X-Ray SDK</strong> does not send data directly to X-Ray!</p>
<ul>
<li><p>  To avoid calling the service <u>every time</u> your application serves a request, the <u>SDK sends the trace data to a <strong>daemon</strong></u>, which collects segments for multiple requests and uploads them in batches. </p>
</li>
<li><p>  To properly instrument your application hosted in an EC2 instance, you have to <u><strong>install the X-Ray daemon</strong></u> by using a <u>user data script</u>. This will <u>install and run the daemon <strong>automatically</strong></u> when you launch the instance. </p>
</li>
</ul>
<blockquote>
<p>  <em>To use the daemon on Amazon EC2, create a new instance profile role or add the managed policy to an existing one. This will grant the daemon permission to upload trace data to X-Ray.</em></p>
</blockquote>
<br>

<p><strong>Amazon Inspector</strong>: Automated <u>security assessment service</u> that helps improve application security and compliance deployed on AWS</p>
<br>

<p><strong>Concepts</strong></p>
<ul>
<li><p>  <strong>Segment</strong>: Provides the name of the compute resources running your application logic, details about the request sent by your application, and details about the work done</p>
</li>
<li><p>  X-Ray uses the data that your application sends to generate a <b>service graph</b> (JSON document). Each AWS resource that sends data to X-Ray appears as a service in the graph</p>
</li>
<li><p><strong>Trace</strong> collects all the segments generated by a single request</p>
<blockquote>
<p>  <em>The request is typically an HTTP GET or POST request that travels through a load balancer, hits your application code, and generates downstream calls to other AWS services or external web APIs</em></p>
</blockquote>
</li>
<li><p>  Use <strong>filter expression</strong> for advanced tracing</p>
</li>
<li><p>  <strong>Groups</strong> are a collection of traces that are defined by a filter expression (identified by name or ARN)</p>
</li>
<li><p> 🧡 <strong>Annotations</strong> are simple <strong>key-value pairs</strong> that are <u>indexed for use with filter expressions</u>. Use annotations to record data that you want to bundle traces by groups</p>
<ul>
<li>  A segment can contain multiple annotations</li>
<li>  <u>System-defined annotations</u> include <strong>data</strong> added to the segment by AWS services, whereas <u>user-defined annotations</u> are <strong>metadata</strong> added to a segment by a developer</li>
</ul>
</li>
</ul>
<br>

<p><strong>Features</strong></p>
<ul>
<li>  X-Ray can be used with Lambda, EC2, ECS, Beanstalk (integrate X-Ray SDK in the application, and install <strong>X-Ray Agent</strong>)</li>
<li>  Provide end-to-end, cross-service, application-centric view of requests flowing through your application, by <strong>aggregating</strong> the data gathered from individual services of the application <u>into a single unit called <strong>trace</strong></u></li>
<li>  X-Ray SDK captures <strong>metadata</strong> for requests made to <u>RDS &amp; DynamoDB, and SQS &amp; SNS</u></li>
<li>  Set <strong>trace sampling rate</strong>: X-Ray continually traces requests made to the application, and stores a sampling of the requests for analysis</li>
<li>  X-Ray creates a map of services used by your application with trace data</li>
</ul>
<br>

<p><strong>流程</strong></p>
<ul>
<li>X-Ray receives data from services as <i><span
  style="font-weight: 400;"><strong>segments</strong></span></i></li>
<li>X-Ray then groups segments that have a common request into <i><span
  style="font-weight: 400;"><strong>traces</strong></span></i></li>
<li>X-Ray processes the traces to generate a <i><span
  style="font-weight: 400;"><strong>service graph</strong></span></i> that provides a <strong>visual representation</strong> of your application.</li>
</ul>
<img data-src="/img/17.png" style="zoom: 80%;" />

<br> 

<p><strong>Types of X-Ray integration</strong></p>
<ul>
<li>  <strong>Active instrumentation</strong>: Samples and instruments incoming requests</li>
<li>  <strong>Passive instrumentation</strong>: Instrument requests that have been sampled by another service</li>
<li>  <strong>Request tracing</strong>: Adds a tracing header to all incoming requests and propagates it downstream</li>
<li>  <strong>Tooling</strong>: Runs the X-Ray daemon to receive segments from the X-Ray SDK</li>
</ul>
<br>

<p><strong>X-Ray integration with AWS services</strong></p>
<ul>
<li><p><strong>Lambda</strong></p>
<ul>
<li>  Active and passive instrumentation of incoming requests on all runtimes </li>
<li>  Lambda adds two nodes to your service map, one for the AWS Lambda service, and one for the function</li>
</ul>
</li>
<li><p><strong>API Gateway</strong></p>
<ul>
<li>  Active and passive instrumentation. </li>
<li>  GW uses sampling rules to determine which requests to record, and adds a node for the gateway stage to your <strong>service map</strong></li>
</ul>
</li>
<li><p><strong>ELB</strong></p>
<ul>
<li>  Request tracing on ALBs</li>
<li>  ALB adds the <strong>trace ID</strong> to the <strong>request header</strong> before sending it to a <strong>target group</strong></li>
</ul>
</li>
<li><p><strong>Beanstalk</strong></p>
<ul>
<li>  Tooling</li>
</ul>
</li>
<li><p><strong>EC2</strong></p>
<ul>
<li>  Use a user data script to install the <strong>X-Ray daemon</strong></li>
</ul>
</li>
</ul>
<br>



<hr>
<h2 id="CloudTrail-Log-Management"><a href="#CloudTrail-Log-Management" class="headerlink" title="CloudTrail (Log Management)"></a>CloudTrail (Log Management)</h2><p><strong>CT: logs</strong> (CT triggers CW logs)</p>
<p><strong>CW: metrics</strong></p>
<br>

<p>View events in <strong>Event History</strong> (actions taken by user / role / services)</p>
<p><strong>CT Trails:</strong></p>
<ul>
<li>  One region</li>
<li>  all regions  (<strong>default</strong>)</li>
<li>  Organization trail</li>
</ul>
<br>

<ul>
<li>  By default, CloudTrail event log files are <strong>encrypted</strong> using <strong>S3 server-side encryption</strong>. You can also encrypt log files with <strong>KMS</strong></li>
<li>  Use <strong>SNS</strong> for log delivery &amp; validation</li>
<li>  CT publish logs every <strong>5 min</strong></li>
</ul>
<br>

<p><strong>Events</strong></p>
<ul>
<li><p>Management events</p>
<ul>
<li>  Logged (default)</li>
<li>  Insight, <strong>control plane operations</strong></li>
</ul>
</li>
<li><p>Data events</p>
<ul>
<li>  Not logged (default)</li>
<li>  Data plane ops</li>
<li>High-volume activities</li>
</ul>
</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li><p><strong>CW Logs to monitor log data</strong></p>
<blockquote>
<p>  CT does not capture error logs in EC2 instance; Need CW logs for this.</p>
</blockquote>
</li>
<li><p>  CT events that are sent to CW Logs can <strong>trigger alarms</strong> according to the metric filters you define</p>
</li>
<li><p>  <strong>CT log file integrity validation</strong>: Determine whether a log file was modified / deleted after CT delivers it</p>
</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 07 Kinesis, SQS &amp; SNS</title>
    <url>/2020/AWS-Kinesis-SQS-SNS/</url>
    <content><![CDATA[<p>In the seventh post of the AWS series, we’re going to talk about 3 <strong>message-delivering</strong> related services:</p>
<ul>
<li>  <strong>Kinesis</strong></li>
<li>  <strong>SQS</strong> (Simple Queue Service)</li>
<li>  <strong>SNS</strong> (Simple Notification Service)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="Kinesis"><a href="#Kinesis" class="headerlink" title="Kinesis"></a><a href="https://tutorialsdojo.com/amazon-kinesis/">Kinesis</a></h2><div class="note success"><p>Easily collect, process, and analyze <strong>real-time, streaming data</strong></p>
</div>

<br>

<h3 id="Kinesis-Data-Stream"><a href="#Kinesis-Data-Stream" class="headerlink" title="Kinesis Data Stream"></a><u><a href="https://tutorialsdojo.com/kinesis-scaling-resharding-and-parallel-processing/">Kinesis Data Stream</a></u></h3><img data-src="/img/13.png" style="zoom: 70%;" />

<ul>
<li>  A massively scalable, highly durable <u>data ingestion and processing service</u> optimized for streaming data. You can configure hundreds of thousands of data producers to continuously put data into a Kinesis data stream</li>
<li><strong>Data producer</strong><ul>
<li>  An application that typically <strong>emits data records</strong> as they are generated to a Kinesis data stream</li>
<li>  Data producers assign partition keys to records</li>
<li>  Partition keys ultimately determine which shard ingests the data record for a data stream</li>
</ul>
</li>
<li><strong>Data consumer</strong><ul>
<li>  A distributed Kinesis application or AWS service <strong>retrieving data from all shards in a stream</strong> as it is generated. Most data consumers are retrieving the <strong>most recent data in a shard</strong>, enabling real-time analytics or handling of data</li>
</ul>
</li>
<li><strong>Data stream</strong><ul>
<li>  <strong>logical grouping of shards</strong></li>
</ul>
</li>
</ul>
<br>

<p><strong>Shard</strong></p>
<ul>
<li><p>  <u>Base throughput unit of a Kinesis data stream</u></p>
</li>
<li><p>  Append-only log and a unit of streaming capability. A shard contains an <u>ordered sequence of records ordered by arrival time</u></p>
</li>
<li><p> <u>Add or remove shards</u> from your stream <strong>dynamically</strong> as your data throughput changes</p>
<blockquote>
<p>  Increase capacity: <strong>Resharding</strong>, e.g. <code>UpdateShardCount</code>, or <u>split every shard in the stream</u></p>
</blockquote>
</li>
<li><p>  <strong>Enhanced fan-out</strong>: for <u>each registered data consumer</u> </p>
</li>
</ul>
<img data-src="/img/14.png" style="zoom: 70%;" />

<br>

<p><strong>Kinesis agent</strong></p>
<ul>
<li>  Pre-built Java application that offers an easy way to collect and send data to Kinesis data stream</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  Monitor shard-level metrics in Kinesis Data Streams (CW, Kinesis Agent)</li>
<li>  CT: log API calls</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  Kinesis Data Streams can automatically encrypt sensitive data as a producer enters it into a stream (<strong>KMS</strong>)</li>
<li>  <strong>IAM</strong>: managing access control</li>
<li>  <strong>Interface VPC endpoint</strong> to keep traffic between your <u>VPC and Kinesis Data Streams</u> from leaving the Amazon network</li>
</ul>
<br>

<h3 id="Kinesis-Data-Firehose"><a href="#Kinesis-Data-Firehose" class="headerlink" title="Kinesis Data Firehose"></a><u>Kinesis Data Firehose</u></h3><img data-src="/img/11.png" style="zoom: 70%;" />

<ul>
<li>   The easiest way to <strong>load streaming data into data stores</strong> and analytics tools</li>
<li>   It is a fully managed service that automatically scales to match the throughput of your data</li>
<li>   Batch, compress &amp; encrypt data before loading</li>
</ul>
<br>

<p><strong>Features</strong></p>
<ul>
<li>  Load streaming data into <strong>S3, Redshift, ES, Splunk</strong>; Enable <strong>real-time analytics</strong></li>
<li>  Firehose can convert the format of incoming data from JSON to ORC formats before storing the data in <strong>S3</strong></li>
<li>  Configure Firehose to <u>prepare your streaming data before it is loaded to data stores</u></li>
<li>  Pre-built <strong>Lambda blueprints</strong> for <u>converting common data sources (system logs) to JSON / CSV</u></li>
</ul>
<br>

<p><strong>Buffer size &amp; buffer interval</strong></p>
<p>Firehose <strong>buffers incoming streaming data to a certain size</strong> or for a certain period of time, before delivering it to destinations. Buffer Size is in <strong>MBs</strong> and Buffer Interval is in <strong>seconds</strong></p>
<br>

<p><strong>Firehose Stream sources</strong></p>
<ul>
<li>  Kinesis data stream</li>
<li>  Kinesis Agent</li>
<li>  Firehose API using AWS SDK</li>
<li>  CW logs, CW events, IoT</li>
</ul>
<br>

<p><strong>Data delivery frequency</strong></p>
<ul>
<li>  <strong>S3 / ES</strong>: S3 / ES buffer size &amp; buffer interval</li>
<li>  <strong>Redshift</strong>: how fast Redshift finish <code>COPY</code> command</li>
<li>  <strong>Splunk</strong>: Firehose buffers incoming data before delivering it to Splunk. The buffer size is 5 MB, and the buffer interval is 60 seconds</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  CW monitor Firehose metrics</li>
<li>  <strong>Kinesis Agent publishes custom CW metrics</strong>, and helps assess whether the agent is healthy, submitting data into Kinesis Data Firehose as specified, and consuming the appropriate amount of CPU and memory resources on the data producer</li>
<li>  <strong>CT</strong>: log API calls</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  Auto encrypt data after it is uploaded to the destination</li>
<li>  Resource access with <strong>IAM</strong></li>
</ul>
<br>

<h3 id="Kinesis-Data-Analytics"><a href="#Kinesis-Data-Analytics" class="headerlink" title="Kinesis Data Analytics"></a>Kinesis Data Analytics</h3><img data-src="/img/12.png" style="zoom: 70%;" />

<p><strong>Analyze</strong> streaming data, gain actionable insights, and respond to your business and customer needs in real time. </p>
<p>接收 <strong>Firehose / Data Stream</strong> 传过来的 data，并进行处理</p>
<br>

<p><strong>Features</strong></p>
<ul>
<li>  <strong>Serverless</strong>, takes care of everything required to continuously run your application</li>
<li>  <strong>Scales</strong> applications to keep up with any volume of data in the incoming data stream</li>
<li>  Delivers <u>sub-second processing latencies</u>, so you can generate real-time alerts, dashboards, and actionable insights</li>
<li>  Supports <strong>standard SQL for query</strong></li>
</ul>
<br>

<p>Running application storage is used for <b>saving application state using checkpoints</b></p>
<p>It is also accessible to your application code to use as <b>temporary disk for caching data</b> or any other purpose</p>
<br>



<hr>
<h2 id="SQS-amp-SNS"><a href="#SQS-amp-SNS" class="headerlink" title="SQS &amp; SNS"></a>SQS &amp; SNS</h2><br>

<h3 id="SNS-Push"><a href="#SNS-Push" class="headerlink" title="SNS (Push)"></a><u><a href="https://tutorialsdojo.com/amazon-sns/">SNS (Push)</a></u></h3><ul>
<li>  Makes it easy to set up, operate, and send notifications from the cloud</li>
<li>  <strong>Publish-subscribe</strong> (pub-sub) messaging paradigm, <strong>event-driven</strong></li>
<li>  Notifications delivered to clients using <strong>push</strong> (clients are passive receiver), rather than periodically check or <strong>poll</strong> (clients need action)</li>
</ul>
<br>

<p> <strong>Event-driven computing</strong></p>
<ul>
<li><p>  A model, in which <strong>subscriber</strong> services automatically perform work in response to events <strong>triggered</strong> by <strong>publisher</strong> services</p>
</li>
<li><p>  <strong>Automate workflows</strong> while <strong>decoupling</strong> the services that collectively and independently work to fulfill these workflows</p>
</li>
<li><p>  AWS <strong>event sources</strong>: EC2, S3, RDS</p>
</li>
<li><p>  AWS <strong>event destinations</strong>: Lambda, SQS</p>
</li>
</ul>
<br>

<p><strong>Features</strong></p>
<ul>
<li>  Message <strong>filtering</strong>: create filter policy</li>
<li>  <strong>Message fanout</strong> occurs when a message is sent to a topic and then <u>replicated and pushed to multiple endpoints</u>. Fanout provides <strong>asynchronous</strong> event notifications, which in turn allows for parallel processing</li>
<li>  Durable storage for all received messages, customized <strong>TTL</strong> values</li>
<li>Send alerts<ul>
<li>  Application &amp; system alerts</li>
<li>  SNS mobile notification (Fanout, async, SMS &amp; SMTP)</li>
<li>  Push email &amp; texts</li>
</ul>
</li>
</ul>
<br>

<p><strong>Publisher &amp; Subscriber</strong></p>
<ul>
<li>  Publishers communicate <strong>asynchronously</strong> with subscribers by producing and sending a message to a <strong>topic</strong>, which is a <u>logical access point</u> and communication channel</li>
<li>  Subscribers consume or receive the message or notification over one of the supported protocols when they are <strong>subscribed to the topic</strong></li>
<li>  Publishers <strong>create topics</strong> to send messages, while subscribers subscribe to topics to receive messages</li>
<li>  SNS supports SQS <strong>standard queues</strong>, but <u>does not support forwarding messages to SQS FIFO queues</u></li>
</ul>
<img data-src="/img/18.png" style="zoom: 60%;" />

<br>

<p><strong>Topics</strong></p>
<ul>
<li>  Instead of including a specific destination address in each message, a publisher sends a message to a <strong>topic</strong>  </li>
<li>  Each topic has a <strong>unique name</strong> that identifies the SNS endpoint for publishers to post messages and subscribers to register for notifications</li>
<li>  A topic can support <strong>subscriptions and notification deliveries</strong> over multiple transports</li>
<li>  SNS delivers messages to the subscriber <u>in the order they were published into the topic</u></li>
</ul>
<br>

<p>SNS also logs the the <strong>delivery status</strong> of notification messages sent to topics with the following SNS endpoints:</p>
<ul>
<li>  Lambda</li>
<li>  SQS</li>
<li>  HTTP</li>
<li>  Application</li>
</ul>
<br>

<p><strong>Monitor &amp; Security</strong></p>
<ul>
<li>  <strong>CW</strong> to monitor SNS topics</li>
<li>  <strong>CT</strong> for logging SNS API calls</li>
<li>  <strong>X-Ray</strong> for messages passing through SNS, easier to <strong>trace and analyze</strong> messages as they travel through to the downstream services</li>
<li>  SNS provides server-side encryption to encrypt topics </li>
<li>  SNS supports <strong>VPC Endpoints</strong> via AWS <strong>PrivateLink</strong>. You can use VPC Endpoints to privately publish messages to SNS topics, from a VPC, without traversing the public internet</li>
</ul>
<br>

<h3 id="SQS-Poll"><a href="#SQS-Poll" class="headerlink" title="SQS (Poll)"></a><u><a href="https://tutorialsdojo.com/amazon-sqs/">SQS (Poll)</a></u></h3><ul>
<li>  A hosted queue that lets you integrate and decouple distributed software systems and components</li>
<li>  Standard &amp; FIFO queues</li>
<li>  <strong>Poll-based</strong>. SNS use push-based</li>
<li>  Access SQS using <strong>VPC endpoints</strong> via AWS <strong>PrivateLink</strong>, without using public IPs, and without needing to traverse the public internet</li>
</ul>
<br>

<p><strong>Benefits</strong></p>
<ul>
<li>  Server-side encryption</li>
<li>  Redundant infrastructure for high-concurrent access &amp; HA for producing &amp; consuming messages</li>
<li>  SQS locks your messages during processing, so that multiple producers can send and multiple consumers can receive messages at the same time</li>
</ul>
<br>

<p><strong>Standard queue</strong></p>
<ul>
<li>  All regions</li>
<li>  Unlimited throughput</li>
<li>  <u>At least once delivery</u></li>
<li>  <u>Best effort ordering</u></li>
</ul>
<br>

<p><strong>FIFO queue</strong></p>
<ul>
<li>  Some regions</li>
<li>  High throughput</li>
<li>  <u>Exactly once processing</u>, no duplication</li>
<li>  <u>Preserve the order which the messages are received</u></li>
<li>  Support <strong>message groups</strong> (allow multiple ordered message groups within a single queue)</li>
</ul>
<br>

<p> <strong>Polling</strong></p>
<ul>
<li>  <strong>Short polling</strong> (default): <u>returns immediately</u>, even if the message queue being polled is empty</li>
<li><strong>Long polling</strong>:  <ul>
<li>  Reduce the cost by <u>eliminating number of empty responses</u> and false empty responses</li>
<li>  Does not return a response until a message arrives in the message queue, or the long poll times out</li>
</ul>
</li>
</ul>
<br>

<p><strong>Visibility timeout</strong></p>
<ul>
<li>  Prevent other consumers from processing a message redundantly</li>
<li>  Set a period of time SQS prevents <u>other consumers from receiving and processing the message</u></li>
</ul>
<br>

<p><strong>Dead Letter Queue (DLQ)</strong></p>
<ul>
<li>  Other queues can target DLQ for messages that can&#8217;t be processed successfully</li>
</ul>
<br>

<p> <strong>Delay Queue</strong></p>
<ul>
<li>  Postpone the delivery of new messages to a queue for a number of seconds</li>
</ul>
<br>

<p><strong>Best Practice</strong></p>
<ul>
<li><p>  Extend the message&#8217;s <strong>visibility timeout</strong> to the maximum time it takes to process and delete the message</p>
</li>
<li><p>  Using the appropriate polling mode (short / long)</p>
</li>
<li><p>Configure DLQ to capture problematic messages</p>
<blockquote>
<p>  <em>To avoid inconsistent message processing by standard queues, avoid setting max receives number to 1 when configure DLQ</em></p>
</blockquote>
</li>
<li><p>  Reduce cost by <strong>batching</strong> message actions</p>
</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  CW for monitor, CT for logging API calls</li>
<li>  Automate notifications from AWS Services to SQS using <strong>CW Events</strong></li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 06 Lambda &amp; API Gateway &amp; Step Functions</title>
    <url>/2020/AWS-Lambda-API-GW-SF/</url>
    <content><![CDATA[<p>In the sixth post of the AWS series, we’re going to talk about 3 <strong>serverless</strong>-related services:</p>
<ul>
<li>  <strong>Lambda</strong> (Serverless Functions)</li>
<li>  <strong>API Gateway</strong> (Part of Serverless Stack)</li>
<li>  <strong>Step Functions</strong> (Serverless Orchestration)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h2><p> <strong>Stage variables are name-value pairs</strong> that you can define as configuration attributes associated with a <strong>deployment stage</strong> of an API. </p>
<p>They act like <strong>environment variables</strong> and can be used in your API setup and mapping templates.</p>
<br>

<p><strong>Active tracing with X-Ray is only available in Lambda</strong></p>
<br>

<ul>
<li>  Serverless compute service, scales automatically</li>
<li>  <strong>Lambda functions are stateless</strong></li>
<li>  Lambda supports <strong>sync &amp; async</strong> invocation of Lambda function</li>
</ul>
<br>

<p><strong>Components</strong></p>
<ul>
<li>  <strong>Event source</strong> publishes events, triggers Lambda function. And the Lambda <strong>Function</strong> is the custom code to process events</li>
<li><strong>Event source mapping</strong><ul>
<li>  <u>Maps an event source to a Lambda function</u></li>
<li>  It enables <strong>automatic invocation</strong> of your Lambda function when events occur</li>
</ul>
</li>
<li><strong>Runtimes</strong><ul>
<li>  Lambda runtimes allow functions in different languages to run in the same base execution environment. </li>
<li>  The runtime sits in-between the Lambda service and your function code, relaying invocation events, context information, and responses between the two</li>
</ul>
</li>
<li><strong>Layer</strong><ul>
<li>  Lambda layers are a <strong>distribution mechanism</strong> for libraries, custom runtimes, and other function dependencies</li>
<li>  Use layers to manage your function&#8217;s <strong>dependencies</strong> independently and keep your deployment package small</li>
</ul>
</li>
<li><strong>Downstream resource</strong><ul>
<li>  AWS service that your Lambda function calls once it is triggered</li>
</ul>
</li>
<li><strong>Log stream</strong><ul>
<li>   While <u>Lambda automatically monitors your function invocations and reports metrics to CloudWatch</u>, you can <strong>annotate</strong> your function code with custom logging statements that allow you to analyze the execution flow and performance of your Lambda function</li>
</ul>
</li>
</ul>
<br>

<p><strong>Difference</strong></p>
<ul>
<li>  <strong>Environment vars</strong>: always encrypt at rest, can be encrypted in transit</li>
<li>  <strong>Versions &amp; aliases</strong>: Secondary resources, manage function deployment &amp; invocation</li>
</ul>
<br>

<p><strong>Lambda@Edge</strong></p>
<img data-src="/img/19.png" style="zoom: 60%;" />

<ul>
<li>  Run Lambda functions to customize content that CloudFront delivers, executing the functions in AWS locations <strong>closer to the viewer</strong></li>
<li>  The functions run <strong>in response to CloudFront events</strong>, without provisioning or managing servers</li>
<li>  Automate with CodeDeploy &amp; CodePipeline</li>
<li>  Lambda will <strong>automatically track</strong> the behavior of your Lambda function invocations, and provide feedback that you can monitor. In addition, it provides <strong>metrics</strong> that allows you to analyze the full function invocation spectrum, including <strong>event source integration</strong> and whether <strong>downstream</strong> resources perform as expected</li>
</ul>
<br>





<p><strong>Metrics that Lambda monitor</strong> (then reports through CW)</p>
<ul>
<li>  <code>Invocations</code></li>
<li>  <code>Duration</code></li>
<li>  <code>Throttles</code></li>
<li>  <code>IteratorAge</code></li>
<li>  <code>Error count &amp; success rate</code></li>
<li>  <code>DeadLetterErrors</code></li>
</ul>
<br>

<p><strong>Lambda Layers</strong></p>
<img data-src="/img/20.png" style="zoom: 65%;" />





<br>

<h3 id="Lambda-amp-DynamoDB-Streams"><a href="#Lambda-amp-DynamoDB-Streams" class="headerlink" title="Lambda &amp; DynamoDB Streams"></a><u>Lambda &amp; DynamoDB Streams</u></h3><p><strong>DynamoDB Streams</strong></p>
<ul>
<li><p>  Capture <strong>data modification events</strong> in DynamoDB tables</p>
</li>
<li><p>Each event is represented by a <strong>stream record</strong>, captures when new item is CUDed</p>
<ul>
<li>  Stream records (24h) are organized into groups (<strong>shards</strong>). Each shard acts as a container for multiple stream records</li>
</ul>
</li>
<li><p>DynamoDB Stream &amp; Lambda:</p>
<blockquote>
<p>   <strong>Trigger</strong>: Code that executes automatically when an event of interest appears in a stream</p>
</blockquote>
</li>
<li><p>Use: </p>
<ul>
<li>   Data replication across regions</li>
<li>   Materialized view of tables</li>
<li>   Data analysis with Kinesis</li>
</ul>
</li>
</ul>
<br>

<p>With triggers, we can build applications that <strong>react to data modifications in DynamoDB tables</strong></p>
<br>

<p><strong>DynamoDB Stream + Lambda</strong></p>
<ul>
<li><p>  After you enable DynamoDB Streams on a table, <u>associate the DynamoDB table with a Lambda function</u>. AWS Lambda polls the stream and invokes your Lambda function <strong>synchronously</strong> when it detects new stream records</p>
</li>
<li><p>Configure the <span
  style="font-weight: 400;"><strong>StreamSpecification</strong></span> you want for your DynamoDB Streams</p>
<ul>
<li>  <code>StreamEnabled</code></li>
<li>  <code>StreamViewType</code> (what info is written to the stream for this table)</li>
</ul>
  <br></li>
</ul>
<hr>
<h2 id="API-Gateway"><a href="#API-Gateway" class="headerlink" title="API Gateway"></a>API Gateway</h2><p><strong>Concepts</strong></p>
<ul>
<li>API <strong>endpoints</strong>: Host name API in GW, deployed to a specific region<ul>
<li>  Edge optimized</li>
<li>  Regional</li>
<li>  Private</li>
</ul>
</li>
<li>  API key: (similar to github blog deploy key)</li>
<li>  API stage: a stage in the API lifecycle</li>
<li><strong>Proxy integration</strong><ul>
<li>  HTTP proxy: GW passes the <u>entire request and response</u> between the frontend and an HTTP backend</li>
<li>  Lambda proxy: GW sends the entire request as an input to a backend Lambda function</li>
</ul>
</li>
</ul>
<br>

<p><strong>Features</strong></p>
<ul>
<li><p>  GW can execute Lambda code in your account, start <strong>Step Functions state machines</strong>, or make calls to Elastic Beanstalk, EC2, or web services outside of AWS with publicly accessible HTTP endpoints</p>
</li>
<li><p>  GW helps you manage traffic to your backend by setting <strong>throttling rules</strong> based on the number of requests per second for each HTTP method in your APIs</p>
</li>
<li><p>  Set up a <strong>cache</strong> with customizable <strong>keys and TTL</strong> for your API data to avoid hitting your backend services for each request</p>
</li>
<li><p>  Run multiple versions of the same API simultaneously with <strong>API Lifecycle</strong></p>
</li>
<li><p>  All APIs expose <strong>HTTPS endpoints</strong> only (all encrypted, does not support unencrypted HTTP)</p>
</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li>  GW is integrated with CW <strong>Metrics</strong>: API calls, latency, error rates</li>
<li>  GW also log API execution errors to CW Logs</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  Authorize &amp; verify API requests: Signature v4 (IAM &amp; access policies)</li>
<li>  Enable WAF for APIs</li>
</ul>
<br>

<hr>
<h2 id="Step-Functions-SF"><a href="#Step-Functions-SF" class="headerlink" title="Step Functions (SF)"></a>Step Functions (SF)</h2><ul>
<li>  <strong>Serverless orchestration</strong>: Coordinate multiple AWS services into <strong>serverless workflows</strong>, so you can build &amp; update apps quickly</li>
<li>  SF has <strong>built-in fault tolerance and maintains service capacity across multiple AZs in each region</strong></li>
<li>  SF scales automatically</li>
</ul>
<br>

<p><strong>Concepts</strong></p>
<ul>
<li><p>Step Functions is based on <u><strong>tasks &amp; state machines</strong></u> </p>
<ul>
<li>  <u>Task</u>: Performs work by using an activity / Lambda function, or by passing parameters to the API actions of other services</li>
<li>  <u>Finite state machine</u>: Express an algorithm as a number of states, their relationships, and their input and output</li>
</ul>
<blockquote>
<p>  <em>Define state machines with <strong>JSON-based Amazon States Language</strong></em></p>
</blockquote>
</li>
</ul>
<img data-src="/img/21.png" style="zoom: 75%;" />

<br>

<p><strong>Features</strong></p>
<ul>
<li><p>  <strong>State machine execution</strong> occurs when a state machine runs and performs its tasks. Each Step Functions state machine can have <u>multiple simultaneous executions</u></p>
</li>
<li><p>  <strong>State machine updates</strong> in SF are <strong>eventually consistent</strong></p>
</li>
<li><p>  By default, when a state reports an error, AWS Step Functions causes the execution to <strong>fail entirely</strong></p>
</li>
<li><p>  Define workflows as <strong>state machines</strong>: transform complex code into easy to understand statements and diagrams</p>
</li>
</ul>
<img data-src="/img/22.png" style="zoom: 80%;" />

<br>

<p><strong>Common use cases</strong></p>
<ul>
<li>  Ensure that long-running, multiple ETL jobs execute in order and complete successfully, instead of manually orchestrating those jobs or maintaining a separate application</li>
<li>  By using SF to handle a few tasks in your codebase, you can approach the <u>transformation of monolithic applications into <strong>microservices</strong> as a series of small steps</u></li>
<li>  Use SF to easily <strong>automate recurring tasks</strong> such as patch management, infrastructure selection, and data synchronization; SF will automatically scale, respond to timeouts, and retry failed tasks</li>
<li>  Combine multiple Lambda functions into <strong>responsive serverless applications and microservices</strong>, without having to write code for workflow logic, parallel processes, error handling, timeouts or retries</li>
<li>  Orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 05 Serverless on AWS</title>
    <url>/2020/AWS-Serverless/</url>
    <content><![CDATA[<p>In this post, we’re going to talk about running serverless applications on AWS. Below are some of the points from AWS whitepapers.</p>
<span id="more"></span>

<br>

<hr>
<h2 id="Optimize-Economics-with-Serverless"><a href="#Optimize-Economics-with-Serverless" class="headerlink" title="Optimize Economics with Serverless"></a>Optimize Economics with Serverless</h2><p>Event-driven computing　 ─ 　FaaS　 ─ 　Serverless FaaS (Lambda)</p>
<blockquote>
<p>  <em>Function as the unit of deployment &amp; execution.</em></p>
</blockquote>
<br>

<p><strong>Serverless</strong></p>
<ul>
<li>  <u>Functional &amp; microservice</u> approach, where business logic is <u>triggered only when required</u></li>
<li>  <strong>Async, event-based</strong></li>
<li>  Lambda: Receive events / client invocation, then instantiate &amp; run the code</li>
<li>  Scale automatically, built-in fault tolerance</li>
</ul>
<br>

<p><strong>Serverless use case</strong></p>
<ul>
<li>  Web / mobile backends</li>
<li>  Media &amp; log processing (compute-heavy workloads)</li>
<li>  <strong>Automation</strong> (functions can be attached to alarms &amp; monitors)</li>
<li>Near real-time streaming data processes<ul>
<li>  Big data: parallelize with a serverless approach</li>
<li>  Low latency: moving serverless event handling to the internet edge (Lambda@Edge)</li>
</ul>
</li>
</ul>
<br>

<p><strong>SAM</strong></p>
<ul>
<li>  Open <strong>specification</strong> / blueprint. Application modeling framework</li>
<li>  Orchestration &amp; state management (<strong>serverless is stateless</strong>)</li>
<li>  <strong>Manage all the steps in the SDLC</strong></li>
<li>  <strong>Deploy SAM apps with CF</strong> (<strong>SAM is specification, CF is implementation</strong>)</li>
<li>  Edge locations: Key to low-latency serverless computing</li>
<li>  <strong>Role-based &amp; access-based</strong> permissions, and API-based authentication &amp; access control</li>
</ul>
<br>

<p><strong>Lambda</strong></p>
<ul>
<li>  Lambda@Edge is available in all edge locations</li>
<li>  Auto retries for async &amp; ordered events</li>
<li>  <strong>DLQ</strong>: capture events that weren’t processed successfully</li>
<li>  End user: Cognito</li>
</ul>
<br>

<p><strong>Serverless components</strong></p>
<ul>
<li><strong>Developer tools</strong><ul>
<li>  <strong>CF</strong> for deployment</li>
<li>  <strong>X-Ray</strong> for diagnostics (cross-service request tracing &amp; performance analysis)</li>
<li>  <strong>CW &amp; CW Logs</strong> for monitoring </li>
</ul>
</li>
<li><strong>Orchestration</strong><ul>
<li>  <strong>Step Functions</strong> (create long-running workflows, <strong>state machines</strong>)</li>
<li>  <strong>CW Events</strong> (respond to events)</li>
</ul>
</li>
<li><strong>Streaming data</strong>: <ul>
<li>  Kinesis Streams: near real-time analytics engine</li>
<li>  Kinesis Firehose: With Lambda</li>
</ul>
</li>
<li>  <strong>Compute</strong>: Lambda &amp; Lambda@Edge (cloud logic layer)</li>
<li>  <strong>API Proxy</strong>: API Gateway (HTTP endpoints)</li>
<li>  <strong>Database</strong>: DynamoDB</li>
<li>  <strong>Storage</strong>: S3 (Lambda function can be used as automatic event <strong>triggers</strong>, when changes on the object)</li>
</ul>
<br>

<p><strong>Construct serverless application</strong></p>
<ul>
<li>  <strong>S3</strong>: static content</li>
<li>  <strong>Lambda &amp; API Gateway</strong>: Dynamic API requests</li>
<li>  <strong>DynamoDB</strong>: store session &amp; user state</li>
<li>  <strong>Cognito</strong>: end-user registration, authentication (user pool), and access control to resources (identity pool)</li>
<li>  <strong>SAM</strong>: describe elements of the app</li>
<li>  <strong>CodeStar</strong>: CI / CD pipeline</li>
</ul>
<br>

<p><strong>Data processing</strong> (<strong>Lambda itself is stateless</strong>)</p>
<ul>
<li>  Lambda &amp; Kinesis</li>
<li>  Lambda &amp; S3: trigger computation in response to object creation / event updates</li>
<li>  Step Functions: <strong>stateful</strong> long-running workflows</li>
</ul>
<br>

<br>

<hr>
<h2 id="Serverless-amp-Lambda"><a href="#Serverless-amp-Lambda" class="headerlink" title="Serverless &amp; Lambda"></a>Serverless &amp; Lambda</h2><br>

<h3 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a><u>Lambda</u></h3><ul>
<li>  <strong>FaaS</strong>: Build <strong>reactive, event-driven</strong> system</li>
<li>  Multiple, simultaneous events: Run more copies of the function in parallel</li>
<li>  Lambda executes in a <strong>container</strong> (sandbox) that isolates it from other functions</li>
<li>  Lambda also provides a <strong>RESTful</strong> API, which can <u>directly invoke</u> a Lambda function</li>
</ul>
<br>

<p><strong>Lambda function</strong></p>
<ul>
<li>  Code</li>
<li>  Configuration</li>
<li>  <strong>Event sources</strong> (detect events &amp; invoke function, e.g. API Gateway, SNS)</li>
</ul>
<br>

<p><strong>Run the code package</strong></p>
<ul>
<li>  Download from S3 bucket</li>
<li>  Install in the Lambda runtime environment (based on Amazon Linux AMI)</li>
<li>  Invoke as needed</li>
</ul>
<br>

<p> 🧡 <strong>Handler</strong></p>
<ul>
<li>  Specific code method. Specify the handler when create the Lambda function</li>
<li>  Handler can call other methods &amp; functions within the files &amp; classes you’ve uploaded</li>
<li>  <strong>Event object</strong></li>
<li><strong>Context object</strong>: allows function code to interact with the Lambda execution environment<ul>
<li>  AWS <code>RequestId</code></li>
<li>  Remaining time</li>
<li>  Logging: Stream log statements to CW logs</li>
</ul>
</li>
</ul>
<br>

<p><strong>Lambda: Statelessness &amp; Reuse</strong></p>
<ul>
<li>  <strong>Warm container</strong>: already active, invoked before (faster code execution)</li>
<li>  <strong>Cold start</strong>: create &amp; invoke for the first time (slower)</li>
</ul>
<br>

<h4 id="Event-Sources"><a href="#Event-Sources" class="headerlink" title="Event Sources"></a>Event Sources</h4><p> <strong>Invocation patterns</strong></p>
<ul>
<li>  <strong>Push Model</strong> (passive user)</li>
<li><strong>Pull Model</strong> (active user)<ul>
<li>  Polls data source, batching new records together in a single function invocation</li>
</ul>
</li>
</ul>
<br>

<p> Lambda functions can be executed <strong>async / sync</strong>. Choose <code>InvocationType</code> parameter. It has 3 possible values:</p>
<ul>
<li>  <code>RequestResponse</code>: <strong>Sync</strong></li>
<li>  <code>Event</code>: <strong>Async</strong></li>
<li>  <code>DryRun</code>: Test, not actually executing</li>
</ul>
<br>

<p><strong>Push model event source</strong> (Trigger Lambda)</p>
<ul>
<li>  <strong>S3</strong> (Async)</li>
<li><strong>API Gateway</strong> (Async / sync)<ul>
<li>  Sync: API as Lambda proxy</li>
<li>  Async: API as AWS service proxy (return immediately with empty response)</li>
</ul>
</li>
<li>  <strong>SNS</strong> (Async): Automated response to CW alarms</li>
<li>  <strong>CF</strong> (Sync)</li>
<li>  <strong>CW Events</strong> (Async): AWS services publish resource state changes to CW Events (for event-driven ops automation)</li>
</ul>
<br>

<p><strong>Pull model event source</strong> (Lambda trigger them, <strong>all are sync</strong>)</p>
<ul>
<li><strong>DynamoDB</strong> (Sync)<ul>
<li>  Workflows triggered as changes occur in a DynamoDB table</li>
<li>  Replicate DynamoDB table to another Region</li>
</ul>
</li>
<li>  <strong>Kinesis Streams</strong> (Sync): Real-time data processing </li>
</ul>
<br>

<h4 id="Lambda-Config"><a href="#Lambda-Config" class="headerlink" title="Lambda Config"></a>Lambda Config</h4><p> <strong>Aliases (Versioning)</strong></p>
<p>To version the Lambda functions: <strong>Aliases</strong> (Pointer to a specific Lambda version)</p>
<ul>
<li>  live / prod / active</li>
<li>  blue / green</li>
<li>  debug</li>
</ul>
<br>

<p><strong>Environment Variables (Config)</strong> </p>
<ul>
<li>  Use env var with Lambda: Separate code &amp; config</li>
<li>  Lambda enables user to <strong>dynamically</strong> pass data to function code</li>
<li>  <strong>Key-value</strong> pairs, encrypted at rest</li>
<li>  Encrypt with <strong>KMS</strong> before creating the function, store cyphertext as variable value</li>
<li><strong>Use cases</strong><ul>
<li>  Log setting (INFO, DEBUG, etc)</li>
<li>  <u>Dependency &amp; database connection credentials</u></li>
</ul>
</li>
</ul>
<br>

<p><strong>IAM role</strong></p>
<ul>
<li>  Policies can be associated with <strong>IAM roles</strong></li>
<li>  Assign IAM <strong>execution role</strong> to Lambda functions</li>
<li>  Source code is <strong>decoupled</strong> from the security aspect, does not need any credential check / rotation</li>
</ul>
<br>

<p><strong>Function permissions</strong></p>
<ul>
<li><strong>Pull model</strong> event sources ONLY<ul>
<li>  Make sure actions are permitted</li>
<li>  AWS provides a set of IAM roles associated with each of the pull-based event sources</li>
</ul>
</li>
</ul>
<br>

<p><strong>Outbound Network Connectivity</strong></p>
<ul>
<li><p>  <strong>Default</strong>: VPC managed by Lambda, not private connection</p>
</li>
<li><p><strong>VPC</strong>: Communicate via <strong>ENI</strong> (Elastic Network Interface), connect to private resources </p>
<ul>
<li><p>  ENIs can be assigned security groups</p>
</li>
<li><p>Route traffic based on the route tables of ENIs’ subnets</p>
  <div class="note success"><p><em>If you choose VPC, you need to manage:</em></p>
<ul>
<li>  <em>Subnets, ensure multi-AZ</em></li>
<li>  <em>Allocate IP addresses to each subnet</em></li>
<li>  <em>VPC network design</em></li>
<li>  <em>Code start time increase, if invocation requires new ENI to be created just in time</em></li>
</ul>
<p>​    </p>
</div></li>
</ul>
</li>
</ul>
<br>

<p> <strong>DLQ</strong> (Dead Letter Queue)</p>
<ul>
<li>  SNS topic / SQS queue</li>
<li>  Destination for all filed invocation events</li>
<li>  Use DLQ if you need <strong>all</strong> Lambda invocation complete <strong>eventually</strong>, even if execution is delayed</li>
</ul>
<br>

<p><strong>Timeout</strong>: </p>
<ul>
<li>  Time limit for a single invocation of a Lambda function (300 s)</li>
<li>  Sometimes need to <strong>fail fast</strong></li>
<li>  Should not rely on <strong>background / async processes</strong> for critical activities</li>
</ul>
<br>

<h3 id="Architecture-Best-Practices"><a href="#Architecture-Best-Practices" class="headerlink" title="Architecture Best Practices"></a><u>Architecture Best Practices</u></h3><br>

<h4 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h4><p><strong>General</strong></p>
<ul>
<li><p>  One IAM role per function (1 : 1 relations, decouple the IAM role)</p>
</li>
<li><p>Use temporary AWS credentials (SDK, manage retrieval &amp; rotation)</p>
<blockquote>
<p>   <em>For <strong>cross-account</strong> cases, grant <strong>execution role</strong> to <code>AssumeRole</code> API within <strong>STS</strong> (Security Token Service)</em> </p>
</blockquote>
</li>
<li><p>  Store user session data in DynamoDB / ElastiCache, to reduce latency</p>
</li>
<li><p>  Secrets should always only exist in <strong>memory</strong>, and never logged / written to disk</p>
</li>
<li><p>  <strong>VPC security</strong>: Lambda-specific subnets, NACL, route tables</p>
</li>
</ul>
<br>

<p><strong>Persisting secrets</strong></p>
<ul>
<li>Lambda env var with encryption helpers<ul>
<li>  Pro: Directly to runtime (no latency)</li>
<li>  Con: Coupled to function version</li>
</ul>
</li>
<li><strong>EC2 Systems Manager Parameter Store</strong><ul>
<li>  Pro: Decoupled from function version</li>
<li>  Con: Add latency (for retrieval)</li>
</ul>
</li>
</ul>
<br>

<p><strong>API auth</strong></p>
<ul>
<li>  API Gateway as Lambda’s event source: You have ownership to authorize &amp; authenticate your API clients</li>
<li>  SigV4 authentication</li>
<li>  <strong>Lambda Authorizer</strong></li>
</ul>
<br>

<p><strong>Deployment access control</strong></p>
<ul>
<li>  <code>UpdateFunctionCode</code> API call: code deployment</li>
<li>  <code>UpdateAlias</code> API call: code release</li>
<li>  Eliminate <strong>direct user access</strong> to the above APIs for any function (use <strong>automation</strong>)</li>
</ul>
<br>

<h4 id="Reliability"><a href="#Reliability" class="headerlink" title="Reliability"></a>Reliability</h4><ul>
<li>  <strong>HA</strong>: Subnets have adequate IPs to support many concurrent functions</li>
<li>  <strong>Fault tolerance</strong>: Multi-region coordinates failover across all tiers of app stack </li>
<li>  <strong>Recovery</strong>: For async, use <strong>DLQ</strong> (store during outage, process after recovery)</li>
</ul>
<br>

<h4 id="Performance-Efficiency"><a href="#Performance-Efficiency" class="headerlink" title="Performance Efficiency"></a>Performance Efficiency</h4><blockquote>
<p>  <strong>If use case can be achieved async, then do not need to concern the performance</strong></p>
</blockquote>
<ul>
<li><p>   Use event <code>InvocationType</code>, or <strong>pull</strong>-based model</p>
</li>
<li><p>  Allow application logic to proceed, while Lambda process event separately</p>
</li>
<li><p>Optimize Lambda execution time</p>
<ul>
<li>  Resources allocation in the function configuration</li>
<li>  Language runtime</li>
<li>  The code you write (warm container reuse, minimize initial cost of cold start)</li>
</ul>
</li>
<li><p>Choose optimal <strong>memory size</strong> (RAM impacts CPU time &amp; network bandwidth)</p>
<blockquote>
<p>  <em>Monitor memory usage in CW Logs</em></p>
<p>  <em>Use <strong>X-Ray</strong> to trace full lifecycle of application request, through each of its component parts.</em></p>
</blockquote>
</li>
</ul>
<br>

<h4 id="Operational-Excellence"><a href="#Operational-Excellence" class="headerlink" title="Operational Excellence"></a>Operational Excellence</h4><br>

<p><strong>General</strong></p>
<ul>
<li>  Use Lambda env var to create <strong>log level var</strong></li>
<li>  Enable investigation with <strong>logging</strong>, use <strong>X-Ray</strong> to profile applications</li>
<li>  Create Lambda <strong>aliases</strong> that represent operational activities such as integration testing, performance testing, debugging, etc</li>
</ul>
<br>

<p><strong>Metrics</strong></p>
<ul>
<li>  Create alarm thresholds (high &amp; low) for <strong>each</strong> Lambda function, on <strong>all</strong> provided metrics through CW</li>
<li>  Create <strong>custom metric</strong>, and integrate directly with API required from Lambda</li>
<li>Capture metric with Lambda function code, and log it using provided logging mechanisms in Lambda<ul>
<li>  Then create <strong>CW Log metric filter</strong> on the function stream, to extract the metric, and make it available in CW</li>
<li>  Create another Lambda as a <strong>subscription</strong> filter on the CW Log stream to push filtered log statements to another metrics</li>
</ul>
</li>
</ul>
<br>

<p><strong>Deployment</strong></p>
<ul>
<li>Steps:<ul>
<li>  Upload new function code</li>
<li>  Publish the new version</li>
<li>  <strong>update the alias</strong></li>
</ul>
</li>
<li>  Parallel version invocations</li>
<li>  Deployment schedule (do not choose peak time)</li>
<li>  Rollback </li>
</ul>
<br>

<h4 id="Cost-Optimization"><a href="#Cost-Optimization" class="headerlink" title="Cost Optimization"></a>Cost Optimization</h4><ul>
<li>  Right sizing (might pay more due to longer execution time)</li>
<li>  Distributed &amp; async architecture (Each decoupled architecture component takes less compute time to conduct the work)</li>
<li>  Many Lambda event sources fit well with distributed systems</li>
</ul>
<br>

<h3 id="Development-Best-Practices"><a href="#Development-Best-Practices" class="headerlink" title="Development Best Practices"></a><u>Development Best Practices</u></h3><br>

<p><strong>1. Infrastructure as code</strong></p>
<ul>
<li>  CF requires large amount of JSON / yaml, so we use <strong>SAM</strong> (open specification abstraction <strong>layer on top of CF</strong>)</li>
<li>  Use SAM &amp; CF together</li>
</ul>
<br>

<p><strong>2. Load testing</strong></p>
<ul>
<li>  SAM Local to test serverless functions &amp; apps locally (use Docker)</li>
</ul>
<br>

<p><strong>3. Coding</strong></p>
<ul>
<li><p>Put business logic outside the Handler</p>
<blockquote>
<p>  <em>Lambda starts execution at the handler function, then it pass the parameters (event &amp; context) to another function to parse into new vars / objects that are <strong>contextualized</strong> to your app.</em></p>
</blockquote>
</li>
<li><p><strong>Warm containers</strong>: Caching / Keepalived / Reuse</p>
<blockquote>
<p>  <em><strong>Scoping</strong></em> <em>vars in a way that they &amp; their contents can be reused on subsequent invocations.</em></p>
</blockquote>
</li>
<li><p>  Control dependencies</p>
</li>
<li><p><strong>Fail fast</strong></p>
<ul>
<li>  Short timeout for external dependencies &amp; Lambda overall timeout</li>
</ul>
</li>
<li><p>Handling exceptions (for async)</p>
<ul>
<li>  Some exception goes to DLQ for reprocessing</li>
<li>  Some just logged</li>
</ul>
</li>
</ul>
<br>

<p><strong>4. Code Management</strong></p>
<ul>
<li>Code repository organization (1 : 1)<ul>
<li>  Make sure Lambda function is independently versioned &amp; committed to</li>
</ul>
</li>
<li>Release branches<ul>
<li>  Correlate Lambda function deployment with incremental commits on a release branch</li>
</ul>
</li>
</ul>
<br>

<p><strong>5. Testing</strong></p>
<p><strong>1) Unit Test</strong></p>
<ul>
<li>  Scope all unit tests down to a single code path, within a single logical function</li>
<li>  Focus mostly on the business logic outside the handler function</li>
<li>  Unit test the ability to parse <strong>mock objects</strong> for the event sources</li>
<li>  Local test automation with SAM Local</li>
</ul>
<p><strong>2) Integration test</strong></p>
<ul>
<li>  Integration test: test integration of the code to its dependencies in an env that mimics the live env</li>
<li>  Create lower lifecycle version of the Lambda function</li>
</ul>
<br>

<p><strong>6. Continuous Delivery</strong></p>
<ul>
<li>  <strong>CodeCommit</strong>: hosted private Git repos</li>
<li>  <strong>CodePipeline</strong>: Declarative steps in the pipeline</li>
<li>  <strong>CodeBuild</strong>: Build the code, run unit tests, and create code package</li>
<li>  <strong>SAM</strong>: Integrate with CodeBuild, push code package to <strong>S3</strong>, and <strong>push new package to Lambda via CF</strong></li>
<li>  <strong>CodeStar</strong>: = Commit + Pipeline + Build. A CD toolchain, manage all aspects of the SDLC</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 04 RDS &amp; DynamoDB</title>
    <url>/2020/AWS-RDS-Dynamo/</url>
    <content><![CDATA[<p>In the fourth post of the AWS series, we’re going to talk about 2 services today:</p>
<ul>
<li>  Relational Database Service (<strong>RDS</strong>)</li>
<li>  <strong>DynamoDB</strong> (NoSQL)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="RDS"><a href="#RDS" class="headerlink" title="RDS"></a>RDS</h2><ul>
<li>  Basic building block of RDS: DB <strong>instance</strong> (isolated DB environment in the cloud)</li>
<li>  Each DB instance runs a DB engine</li>
<li>  An <strong>RDS Tag</strong> is a name-value pair</li>
<li>  <strong>Multi-AZ</strong> deployment for HA</li>
</ul>
<br>

<p><strong>Sync data replication in RDS</strong></p>
<p>RDS DB instance running as <u>Multi-AZ deployment</u></p>
<ul>
<li><p>   Auto provision &amp; maintain synchronous <strong>standby replica</strong> in a different AZ</p>
</li>
<li><p>   Updates to your DB Instance are <strong>synchronously replicated across AZs</strong> to the <strong>standby</strong> in order to keep both in sync and protect your latest database updates against DB instance failure</p>
</li>
</ul>
<br>

<p><strong>Async data replication</strong></p>
<p> Use <u>Read Replicas</u></p>
<ul>
<li>  All read replicas are active / accessible</li>
<li>  No backups by default</li>
<li>  Manually promoted to standalone DB instance</li>
</ul>
<br>

<p><strong>DB instance</strong></p>
<p>Class types</p>
<ul>
<li>  Standard</li>
<li>  Memory Optimized</li>
<li>  Burstable Performance</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li><p>Groups</p>
<ul>
<li>  DB</li>
<li>  VPC</li>
<li>  EC2</li>
</ul>
</li>
<li><p>  Assign individual <strong>IAM</strong> account to each person who manages RDS resources</p>
</li>
<li><p>  Use IAM groups, and rotate credentials regularly</p>
</li>
<li><p>  Use <strong>security groups</strong> to control what IP addresses / EC2 instances can connect to your DB instance</p>
</li>
</ul>
<br>

<p><strong>Monitoring</strong></p>
<ul>
<li><p>  CW</p>
</li>
<li><p>  RDS Events</p>
</li>
<li><p>  DB logs: Audit / Error / General / <strong>Slow query log</strong> (troubleshoot queries that  take a long time)</p>
</li>
<li><p> <strong>Enhance monitoring</strong> for DB instances. Metrics:</p>
<ul>
<li><p>  IOPS (I/O operations per second)</p>
</li>
<li><p>  Latency</p>
</li>
<li><p>  Throughput</p>
</li>
<li><p>Queue Depth (number of I/O requests in the queue waiting to be serviced)</p>
  <div class="note success"><p><em>CW gathers metrics about CPU utilization <b>from the hypervisor</b> for a DB instance</em></p>
<p><em>Enhanced Monitoring gathers its metrics <b>from an agent</b> on the instance</em></p>
</div></li>
</ul>
</li>
<li><p>  <strong>CloudTrail</strong> captures all API calls to RDS as <strong>events</strong></p>
</li>
</ul>
<br>

<hr>
<h2 id="DynamoDB"><a href="#DynamoDB" class="headerlink" title="DynamoDB"></a>DynamoDB</h2><h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a><u>Concepts</u></h3><p><strong>DAX</strong> is DynamoDB’s caching solution. (Cache reads). </p>
<p>Delivers microsecond response times for <strong>accessing eventually consistent data</strong></p>
<br>

<p><strong>1.  Overview</strong></p>
<ul>
<li>  Encryption at rest, on-demand back-up, and point-in-time recovery</li>
<li>  Data stored in partitions, backed by SSDs, and auto replicated in multiple AZs</li>
</ul>
<br>

<p><strong>2.  Components</strong></p>
<ul>
<li><p>  <strong>Tables</strong>: no schema, 256 per Region</p>
</li>
<li><p><strong>Items</strong>: collection of attributes</p>
<ul>
<li><p><strong>Primary key</strong> to uniquely identify each item</p>
<blockquote>
<p>  One PK: partition key</p>
<p>  <strong>Composite</strong> PK: partition key + sort key</p>
</blockquote>
</li>
<li><p><strong>Secondary index</strong> to make queries faster</p>
<blockquote>
<p>  <strong>Global</strong>: different partition &amp; sort key</p>
<p>  <strong>Local</strong>: same partition key, different sort key</p>
</blockquote>
</li>
</ul>
</li>
<li><p>  <strong>Attributes</strong>: fundamental data element</p>
</li>
</ul>
<br>

<p><strong>3.  DynamoDB Streams</strong></p>
<ul>
<li><p>   Capture <strong>data modification events</strong> in DynamoDB tables</p>
</li>
<li><p>Each event is represented by a <strong>stream record</strong>, captures when new item is CUDed</p>
<ul>
<li>  Stream records (24h) are organized into groups (<strong>shards</strong>). Each shard acts as a container for multiple stream records</li>
</ul>
</li>
<li><p>DynamoDB Stream &amp; Lambda:</p>
<blockquote>
<p>   <strong>Trigger</strong>: Code that executes automatically when an event of interest appears in a stream</p>
</blockquote>
</li>
<li><p>Use: </p>
<ul>
<li>  <strong>Data replication across regions</strong></li>
<li>  Materialized view of tables</li>
<li>  Data analysis with Kinesis</li>
</ul>
</li>
</ul>
<br>

<p><strong>4.  Data type</strong></p>
<ul>
<li>  Scalar</li>
<li>  Document</li>
<li>  Set</li>
</ul>
<br>

<p><strong>5.  Read &amp; Write</strong></p>
<ul>
<li><p>  <strong>Strongly consistent</strong> read: return with most up-to-date data (no stale data)</p>
</li>
<li><p>When create table / index, first provision throughput capacity:</p>
<ul>
<li>  <strong>WCU</strong> (write capacity unit): 1KB</li>
<li>  <strong>RCU</strong> (read capacity unit): 4KB</li>
</ul>
</li>
<li><p><strong>Throttling</strong>: prevents your application from <u>consuming too many capacity units</u>. DynamoDB can throttle read or write requests that exceed the throughput settings for a table, and can also throttle read requests exceeds for an index</p>
<blockquote>
<p>  When request is throttled, the HTTP return code is <strong>400 Bad Request</strong></p>
</blockquote>
</li>
<li><p>  DynamoDB <strong>Auto Scaling</strong> is enabled by default</p>
</li>
</ul>
<br>

<p><strong>6.  Items</strong></p>
<ul>
<li>  Use <code>UpdateItem</code> to create <strong>Atomic counter</strong>: numeric attribute that is incremented unconditionally, not interfere with other write requests</li>
<li>  <strong>Conditional writes</strong> for CUD (A conditional write only succeeds, if the item attributes meet one or more expected conditions)</li>
<li>  Conditional writes can be <strong>idempotent</strong> if the conditional check is on the same attribute that is being updated</li>
</ul>
<br>

<p><strong>7.  Other Properties</strong></p>
<ul>
<li><p>   <strong>Projection</strong> expression: GET only a few items    ( a string that identifies the attributes you want )</p>
</li>
<li><p>  <strong>Condition</strong> expression: determine which should be written for CUD</p>
</li>
<li><p>  <strong>TTL</strong>: Items are auto deleted when expire </p>
</li>
<li><p>  <strong>Filter</strong> expression: Refine query results (only return filtered results, others are discarded)</p>
</li>
<li><p>  Query results are <strong>paginated</strong></p>
</li>
<li><p><strong>Batch operations</strong>: Wrappers for multiple read or write requests. </p>
<blockquote>
<p>  Batch operations are primarily used when you want to <u>retrieve or submit multiple items</u> in DynamoDB <u>through a single API call</u>, which reduces the number of network round trips from your application to DynamoDB</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>8.  Scans</strong></p>
<ul>
<li>  Reads every item in a table or a secondary index (return all results by default)</li>
<li>  By default, a Scan operation performs <strong>eventually consistent reads</strong>, and process data <strong>sequentially</strong></li>
</ul>
<br>

<p><strong>9.  On-demand backup &amp; restore</strong></p>
<ul>
<li>  Use IAM to restrict DynamoDB backup and restore actions for some resources</li>
<li>  All backup and restore actions are captured &amp; recorded in <strong>CloudTrail</strong></li>
<li>  Restore backups to a new table</li>
</ul>
<br>

<p><strong>10.  Transactions</strong></p>
<ul>
<li><p>  Simplify the developer experience of making coordinated, all-or-nothing changes to multiple items both within and across tables</p>
</li>
<li><p>  Transactions provide atomicity, consistency, isolation, and durability (<strong>ACID</strong>) in DynamoDB, help to maintain data correctness</p>
</li>
<li><p>You can group multiple Put, <span
  style="font-weight: 400;">Update</span><span
  style="font-weight: 400;">, </span><span
  style="font-weight: 400;">Delete</span><span
  style="font-weight: 400;">, and </span><span
  style="font-weight: 400;">ConditionCheck</span><span
  style="font-weight: 400;"> actions. You can then submit the actions as a single </span><span
  style="font-weight: 400;"><code>TransactWriteItems</code></span> operation that <strong>either succeeds or fails as a unit</strong></p>
</li>
<li><p>You can group and submit multiple <span
  style="font-weight: 400;">Get</span><span
  style="font-weight: 400;"> actions as a single </span><code>TransactGetItem</code>s operation</p>
</li>
</ul>
<br>

<p><strong>11.  Global Tables</strong></p>
<ul>
<li>  To ensure eventual consistency, DynamoDB global tables use a “<em>last writer win</em>” reconciliation between concurrent updates, where DynamoDB makes a best effort to determine the <strong>last writer</strong></li>
</ul>
<br>

<p><strong>12.  Security</strong></p>
<ul>
<li>  Encrypt data use <strong>KMS managed keys</strong></li>
<li>Permission policy (identity based)<ul>
<li>  Attach a permissions policy to a user or a group in your account</li>
<li>  Attach a permissions policy to a role (grant cross-account permissions)</li>
</ul>
</li>
</ul>
<br>

<p><strong>13.  Monitoring</strong></p>
<ul>
<li>  <strong>CW alarms</strong>: Watch a single metric over a time period that you specify, and perform one or more actions based on the value of the metric relative to a given threshold over a number of time periods</li>
<li>  <strong>CW events</strong>: Match events and route them to one or more <strong>target functions</strong> or streams to make changes, capture state information, and take corrective action.</li>
<li>  <strong>CW logs</strong>: Monitor, store, and <strong>access logs from CT</strong></li>
<li>  <strong>CT log monitoring</strong>: Share log files between accounts, <u>monitor CT logs in real time by sending them to CW Logs</u></li>
</ul>
<br>

<p><strong>14.  Best practices</strong></p>
<ul>
<li>  Maintain as few tables as possible in a DynamoDB application. Most well designed applications require <b>only one</b> table</li>
<li>Understand access patterns:<ul>
<li>  Data size</li>
<li>  Data shape</li>
<li>  Data velocity</li>
</ul>
</li>
<li>  DynamoDB applies <strong>adaptive capacity</strong> in real time in response to changing application traffic patterns (maintain performance)</li>
</ul>
<br>

<p><strong>15.  Pricing</strong></p>
<ul>
<li>  Charge for: DAX, RCU, WCU, Reserved capacity, etc.</li>
</ul>
<br>

<p><strong>16.  Partition key</strong></p>
<p>The partition key of a table&#8217;s primary key determines the <strong>logical partitions</strong> in which a table&#8217;s data is stored. This in turn affects the underlying physical partitions. Provisioned I/O capacity for the table is divided evenly among these physical partitions. Therefore a partition key design that doesn’t distribute I/O requests evenly can create &#8220;hot&#8221; partitions that result in throttling and use your provisioned I/O capacity inefficiently.</p>
<p>The <u>optimal usage of a table&#8217;s provisioned throughput</u> depends not only on the <strong>workload patterns</strong> of individual items, but also on the <strong>partition key design</strong>. One example for this is the use of partition keys with <strong>high-cardinality</strong> attributes, which have a <strong>large number of distinct values</strong> for each item.</p>
<br>

<p>Note that the <u>more distinct partition key values the workload access, the more those requests are <strong>spread across</strong> the partitioned space.</u> </p>
<br>

<h3 id="History"><a href="#History" class="headerlink" title="History"></a><u>History</u></h3><p>Relational DB is a great way to <strong>reduce storage cost</strong> (relational data, reduce redundancy), in the 70s and 80s, when the storage device is very expensive.</p>
<p>But relational DB <strong>increase CPU costs</strong>, because of the complex queries (joins) it executes to present a denormalized view of data that your application consumes.</p>
<p>Now the most expensive resource in the data center is the <strong>CPU</strong>, but not storage. So why do we want to use the technology (relational DB) that optimizes the least expensive resource in the data center ?!</p>
<img data-src="/img/1/01.png" style="zoom:60%;" />

<br>

<p>So here comes NoSQL (Denormalized data model)</p>
<blockquote>
<p>  <strong>How to model data correctly in NoSQL</strong></p>
</blockquote>
<img data-src="/img/1/02.png" style="zoom:50%;" />

<p><strong>OLTP</strong>: Online Transaction Processing. (repeatable, consistent, simple)</p>
<p><strong>OLAP</strong>: Online Analytical Processing</p>
<br>



<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><blockquote>
<p>   Wide column key-value store (support document attribute type)</p>
</blockquote>
<br>

<p>Table: catalog (contains many items)</p>
<ul>
<li>Mandatory partition key (uniquely identify)    -   Think of partition as folder / bucket<ul>
<li>  Distribute items across key space (i.e. tables)</li>
<li>  Choose partition key that has a large number of distinct values (to fully distribute out)</li>
<li>  <strong>Space</strong>: Make sure access is evenly spread over the key space</li>
</ul>
</li>
<li>  Optional sort key (orders the item within that folder)</li>
</ul>
<img data-src="/img/1/03.png" style="zoom:60%;" />

<br>

<p><strong>LSI &amp; GSI</strong>  (support secondary access patterns)</p>
<ul>
<li>  Local: <strong>resort</strong> the data in the partitions (must use the same partition key, so only resorting)</li>
<li>  Global:  <strong>regroup</strong> the data (regroup the data by other attributes in the entire table)</li>
</ul>
<br>

<p><strong>Elasticity with AS</strong></p>
<img data-src="/img/1/04.png" style="zoom:50%;" />

<br>

<h3 id="NoSQL-Data-Modeling-Access-Patterns"><a href="#NoSQL-Data-Modeling-Access-Patterns" class="headerlink" title="NoSQL Data Modeling (Access Patterns)"></a>NoSQL Data Modeling (Access Patterns)</h3><p>Select <strong>partition key:</strong></p>
<ul>
<li>  Large number of distinct values</li>
<li>  e.g. Customer ID</li>
</ul>
<br>

<p>Select <strong>sort key:</strong></p>
<ul>
<li>  Model 1:N &amp; N:N relations</li>
<li>  e.g. Orders &amp; Order Items</li>
</ul>
<img data-src="/img/1/05.png" style="zoom:55%;" />

<br>

<p><strong>With NoSQL:</strong></p>
<ul>
<li>  Need to first understand every access pattern, what the application is doing</li>
<li>  Model based on access patterns</li>
<li>  Nature of application: OLAP / OLTP / DSS</li>
<li>  NoSQL is efficient, but <strong>not flexible</strong>: Data modeling is tightly coupled with the access pattern of a specific application</li>
</ul>
<br>

<p><strong>DynamoDB Stream + Lambda</strong></p>
<ul>
<li>  Stream is the change log for the DynamoDB table</li>
<li>  Once data is in the stream, can invoke a lambda function</li>
<li>Lambda, 2 IAM roles:<ul>
<li>  <strong>Invocation</strong> role: define what it can see / read from the stream</li>
<li>  <strong>Execution</strong> role: define what it can do </li>
</ul>
</li>
</ul>
<br>

<p><strong>Composite Keys</strong></p>
<ul>
<li>  <strong>Most people use NoSQL as a key-value store, but that’s not the most efficient way to use NoSQL DB</strong></li>
<li>  Because we want to store <strong>hierarchical</strong> data in the table</li>
<li>  Sort condition before the read, filter condition after the read</li>
<li>  Create composite sort keys, for faster queries on a small number of items</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 03 S3 &amp; ECS</title>
    <url>/2020/AWS-S3-ECS/</url>
    <content><![CDATA[<p>In the third post of the AWS series, we’re going to talk about 2 services today:</p>
<ul>
<li>  Simple Storage Service (<strong>S3</strong>)</li>
<li>  EC2 Container Service (<strong>ECS</strong>)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h2><ul>
<li>  Object: data &amp; key &amp; metadata (system &amp; user-defined)</li>
<li>  Key:    <strong>unique identifier</strong> for an object within a bucket</li>
</ul>
<br>

<ul>
<li>  Bucket name must be <strong>globally unique DNS-compliant name</strong> (no dots)</li>
<li>  After create the bucket, cannot change name / Region</li>
<li>  Up to <strong>100</strong> buckets (soft limit)</li>
</ul>
<br>

<ul>
<li>  Host static sites with S3 (configure it for static hosting)</li>
<li>  Read-after-write data consistency</li>
<li><strong>Eventual consistency</strong>  <ul>
<li>  read-after-write (GET, HEAD)</li>
<li>  overwrite (PUT, DELETE)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Storage class</strong></p>
<ul>
<li>Standard: general-purpose<ul>
<li>  Standard_IA:  long-lived, less frequently accessed</li>
</ul>
</li>
<li>  Reduced_redundancy(RRS): Cost more than standard</li>
</ul>
<br>

<p><strong>Glacier</strong></p>
<ul>
<li>  Glacier objects are <strong>visible through S3 only</strong></li>
<li>  Glacier Deep Archive</li>
</ul>
<br>

<p><strong>S3 Select</strong></p>
<ul>
<li>  Pull out only the data you need <strong>from an object</strong> (improve performance)</li>
<li>  Format: CSV / JSON</li>
<li>  <u>CloudWatch Metrics with S3 Select</u></li>
</ul>
<br>

<p><strong>S3 Transfer Acceleration</strong>: use <u>edge locations</u> to speed up</p>
<br>

<p><strong>Security</strong></p>
<ul>
<li><p>Resources</p>
<ul>
<li>  Bucket policies (centralize access control)</li>
<li>  ACLs</li>
</ul>
</li>
<li><p>Server-side encryption:</p>
<ul>
<li>  SSE-C (customer provided)</li>
<li>  SSE-KMS</li>
<li>  SSE-S3 (managed by S3)</li>
</ul>
</li>
<li><p>Client-side:</p>
<ul>
<li>  KMS-managed customer master key</li>
<li>  Client-side master key</li>
</ul>
</li>
</ul>
<br>

<h3 id="S3-Bucket-policy-for-VPC-endpoints"><a href="#S3-Bucket-policy-for-VPC-endpoints" class="headerlink" title="S3 Bucket policy for VPC endpoints"></a><u>S3 Bucket policy for VPC endpoints</u></h3><ul>
<li><p>  Amazon S3 is a service that <u>is not used within a VPC</u>. This means that traffic <u>does not pass through VPC</u> resources such as internet gateways or NAT gateways.</p>
</li>
<li><p>  For <strong>security</strong>, instead of using security groups and network ACLs, you have <strong>bucket policies and S3 ACLs</strong> for managing access to your S3 bucket and objects.</p>
</li>
<li><p>  Amazon S3 traffic passes through the public internet. If you want your traffic to run only within the Amazon network then you will have to employ <strong>VPC endpoints.</strong></p>
</li>
</ul>
<br>

<ul>
<li>   A <strong>VPC endpoint</strong> is what you use to <strong>privately connect</strong> your VPC to AWS services (e.g. EC2). It adds a <strong>gateway entry</strong> in your VPC’s <strong>route table</strong> so that communication between your AWS resources and your S3 bucket pass through the <strong>gateway</strong> <u>instead of the public internet</u>. As a result, VPC endpoint is a <strong>regional service</strong>. You should create the endpoint in the same region as the VPC you want to use.</li>
<li>   VPC endpoints are best used when you have <u>compliance requirements or sensitive information stored in S3</u> that should not leave the Amazon network</li>
<li>   A VPC endpoint is also a better option for <strong>private network connections in AWS</strong>, as compared to using <strong>VPN / NAT</strong>, since it is <strong>easier to setup</strong> and offers you more network bandwidth at your disposal</li>
</ul>
<br>

<ul>
<li>  <u>VPC endpoint access policies &amp; S3 bucket policies</u>: Refine access control</li>
</ul>
<br>

<hr>
<h2 id="ECS"><a href="#ECS" class="headerlink" title="ECS"></a>ECS</h2><ul>
<li><p>  Manage Docker containers on a cluster, A <strong>Regional</strong> service</p>
</li>
<li><p>  After a cluster is up and running, you can define <strong>task definitions</strong> and services that <u>specify which Docker container images to run across your clusters</u>.</p>
</li>
</ul>
<br>

<h3 id="Components"><a href="#Components" class="headerlink" title="Components"></a><u>Components</u></h3><p>Containers created from images (read-only), images built from Dockerfile, stored in registry</p>
<br>

<p> <strong>Task definitions</strong> (JSON) specify <u>various parameters for your application</u>. It describes 1 - 10 containers that form the application</p>
<ul>
<li><p>  IAM task role</p>
</li>
<li><p>  Container definitions (image, CPU, memory)</p>
</li>
<li><p>  <strong>Volumes</strong> (share data between containers, even persist the data on the container instance, when containers are no longer running)</p>
</li>
<li><p><strong><u>Launch types</u> (EC2 / Fargate)</strong></p>
<ul>
<li>  Fargate as serverless container - Does not need to manage infrastructure (EC2 needs manual maintenance)</li>
<li>  Fargate price is based on task size</li>
</ul>
</li>
</ul>
<br>

<p><strong>Task &amp; Scheduling</strong></p>
<ul>
<li><p>  A <strong>task</strong> is the <strong>instantiation of a task definition</strong> within a cluster</p>
</li>
<li><p>After create task definition, specify the <u>number of tasks</u> that will run on your cluster</p>
<ul>
<li>  Each task that uses the <strong>Fargate</strong> launch type has its <u>own isolation boundary</u>, and <u>does not share</u> the underlying kernel, CPU resources, memory resources, or elastic network interface with another task</li>
</ul>
</li>
<li><p><strong>Task scheduler</strong>: cron. placing task within the cluster</p>
<ul>
<li>  <strong>Replica</strong>: spreads tasks across AZs</li>
<li>  <strong>Daemon</strong>: deploys exactly one task on each active container; No need to specify a desired number of tasks &amp; task placement strategy</li>
</ul>
</li>
<li><p>  Upload a new version of <u>task definition</u>, and the ECS <u>scheduler automatically starts new containers</u> using the updated image and stop containers running the previous version</p>
</li>
</ul>
<br>

<p><strong>Clusters</strong></p>
<ul>
<li>  Place tasks in ECS in a <strong>cluster</strong> (logical grouping of resources)</li>
<li>  Clusters can contain tasks use both EC2 &amp; Fargate</li>
<li>  Before delete a cluster, must first <u>delete services and deregister container instances</u> inside that cluster</li>
</ul>
<br>

<p><strong>Services</strong></p>
<ul>
<li>  Run &amp; maintain a specified number of instances of a task definition simultaneously in a cluster</li>
<li>Two <strong>deployment</strong> strategies<ul>
<li>  <strong>Rolling update</strong> (downtime)</li>
<li>  <strong>Blue / Green</strong> (no downtime, need Application LB / Network LB)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Container agent</strong></p>
<ul>
<li>  Runs on each infrastructure resource within an ECS cluster</li>
<li>  Only supported in <strong>EC2 launch type</strong></li>
</ul>
<br>

<h3 id="Fargate-Serverless-Container"><a href="#Fargate-Serverless-Container" class="headerlink" title="Fargate (Serverless Container)"></a><u>Fargate (Serverless Container)</u></h3><ul>
<li>  Use Fargate with ECS to run containers <u>without having to manage servers or clusters of EC2 instances</u></li>
<li>  Fargate only supports images on DockerHub / ECR</li>
</ul>
<br>

<ul>
<li>  A serverless compute engine for containers that works with <strong>ECS &amp; EKS</strong>; A <strong>managed service for container cluster management</strong></li>
<li>  No manual provisioning, patching, cluster capacity management, or any infrastructure management </li>
</ul>
<img data-src="/img/09.png" style="zoom: 80%;" />

<br>

<p> <strong>Task definition for Fargate launch type</strong></p>
<ul>
<li><p>  Network use <code>awsvpc</code>, which provides each task with its own <strong>ENI</strong> (elastic network interface)``</p>
</li>
<li><p>  Specify CPU &amp; memory at task level</p>
</li>
<li><p><code>awslogs</code>: send log to CloudWatch Logs</p>
<blockquote>
<p>  <em>Other log drivers: <strong>Splunk, Firelens, Fluentd</strong></em> </p>
</blockquote>
</li>
<li><p>  Task storage is <strong>ephemeral</strong>, when task stops, storage is deleted (think of how docker container works)</p>
</li>
<li><p>  Put multiple containers in the same task definition if:  <u>Share resources / data volumes / lifecycle</u></p>
</li>
</ul>
<br>

<p><strong>Task definition for EC2 launch type</strong></p>
<ul>
<li>  Data volumes: Docker &amp; Bind</li>
<li>  Private repos are only supported by EC2</li>
</ul>
<br>

<ul>
<li>If you have a service with running tasks and want to <u>update their platform version</u>, you can update your service, specify a new platform version, and choose <span
  style="font-weight: 400;"><strong>Force new deployment</strong></span><span
  style="font-weight: 400;">. Your tasks are redeployed with the </span><b>latest</b> platform version</li>
<li>  If your service is scaled up without updating the platform version, those tasks receive the platform version that was specified on the service&#8217;s <u>current deployment</u></li>
</ul>
<br>

<h3 id="Task-Placement-Strategies"><a href="#Task-Placement-Strategies" class="headerlink" title="Task Placement Strategies"></a><u>Task Placement Strategies</u></h3><p>A <strong>task placement strategy</strong> is an algorithm for selecting instances for task placement or tasks for termination. </p>
<br>

<p><strong>1. Binpack</strong></p>
<ul>
<li>  Place tasks based on the least available amount of CPU or memory</li>
<li>  Cost efficient</li>
</ul>
<br>

<p><strong>2. Random</strong></p>
<ul>
<li>  Randomly (when task placement / termination doesn’t matter)</li>
</ul>
<br>

<p><strong>3. Spread</strong></p>
<ul>
<li>  Place tasks evenly based on the specified value</li>
<li>  Accepted values are attribute key-value pairs, <code>instanceId</code>, or host</li>
<li>  Achieve <strong>high availability</strong> by making sure that multiple copies of a task are scheduled across multiple instances</li>
<li>  <strong><u>Fargate default: spread across multiple AZs</u></strong></li>
</ul>
<br>

<h3 id="Monitoring-amp-Other"><a href="#Monitoring-amp-Other" class="headerlink" title="Monitoring &amp; Other"></a><u>Monitoring &amp; Other</u></h3><ul>
<li>  Send log info to CW Logs</li>
<li>  With CW Alarms, monitor single metric over a specified time period</li>
<li>  Share log files between accounts, monitor <strong>CloudTrail log files</strong> in real time by sending them to CloudWatch Logs</li>
</ul>
<br>

<ul>
<li>  <strong>Tagging</strong>: ECS resources are assigned with unique ID &amp; ARN (Amazon Resource Name). Tagged with self-defined values to identify.</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 02 EC2 Load Balancer &amp; Auto Scaling</title>
    <url>/2020/AWS-ELB-AS/</url>
    <content><![CDATA[<p>In the next few posts, I will go through some AWS service components. Today we’re going to cover: </p>
<ul>
<li>  Elastic Load Balancer (ELB) </li>
<li>  EC2 Auto Scaling (AS)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="ELB"><a href="#ELB" class="headerlink" title="ELB"></a>ELB</h2><ul>
<li><p>  Distributes incoming application or network traffic across multiple targets, such as <strong>EC2, ECS, and IP addresses</strong>, in multiple AZs</p>
</li>
<li><p>  When you create a load balancer, you must specify <strong>one public subnet from at least 2 AZs</strong>. You can specify only 1 public subnet per AZ</p>
</li>
</ul>
<br>

<p><strong>Notice:</strong></p>
<ul>
<li><p>For <u>automatic scaling of your compute capacity</u>, you need another service called <strong>AWS Auto Scaling</strong> to go with your LB</p>
<blockquote>
<p>  <em>Auto-scaling handles the scaling of capacity for you, so that your instances are not being overwhelmed</em></p>
</blockquote>
</li>
<li><p>  ELBs do not boost website performance</p>
</li>
<li><p>  NLB is used for applications that need <strong>extreme network performance and static IP</strong></p>
</li>
</ul>
<br>

<p><strong>Features</strong></p>
<ul>
<li><p>  Accepts incoming traffic from clients and routes requests to its <strong>registered</strong> targets</p>
</li>
<li><p>  Monitors the health of its registered targets and <u>routes traffic only to <strong>healthy</strong> targets</u></p>
</li>
<li><p>Enable <strong>deletion protection</strong> to prevent your load balancer from being deleted accidentally (Disabled by default)</p>
<blockquote>
<p>  <em>Deleting ELB won’t delete the instances registered to it</em></p>
</blockquote>
</li>
<li><p>  <strong>Cross Zone LB</strong>:  Each LB node distributes traffic across the registered targets in all enabled AZs</p>
</li>
<li><p>  Supports <strong>SSL Offloading</strong>, a feature that allows the <u>ELB to bypass the SSL termination</u> by removing the SSL-based encryption from the incoming traffic</p>
</li>
</ul>
<br>

<h3 id="3-types-of-LB"><a href="#3-types-of-LB" class="headerlink" title="3 types of LB"></a><u>3 types of LB</u></h3><h4 id="Application-LB-ALB"><a href="#Application-LB-ALB" class="headerlink" title="Application LB (ALB)"></a>Application LB (ALB)</h4><img data-src="/img/01.png" style="zoom: 67%;" />

<ul>
<li>  Work at the application layer (layer 7)</li>
<li>  HTTP &amp; HTTPS</li>
<li>  Must have &gt;= 2 subnets</li>
</ul>
<br>

<ul>
<li>  Serve as single point of contact with client</li>
<li>  <strong>Listener</strong>: checks for connection requests from clients. Define default rule for each listener that has a <u>target group, condition, and priority</u></li>
<li>  <strong>Target group</strong> routes requests to one or more registered targets. You can register a target with multiple target groups, and configure health checks on a per target group basis</li>
</ul>
<br>

<ul>
<li><p> <strong>Path-based / host-based routing</strong> (define host conditions / path conditions, <strong>Only ALB</strong>)</p>
<blockquote>
<p>  <em>Host-based routing defines rules that forward requests to <strong>different target groups</strong> based on the host name in the host header, instead of the URL</em></p>
</blockquote>
</li>
<li><p>  <strong>Cross-zone LB</strong>, WebSocket support</p>
</li>
<li><p>  Support for routing requests to multiple applications on a single EC2 instance</p>
</li>
<li><p>  Support for <strong>registering targets by IP address</strong>, including targets outside the VPC for the LB</p>
</li>
<li><p>  Supports load balancer-generated cookies only for sticky sessions</p>
</li>
</ul>
<br>

<p><strong>Monitor</strong> the health of each service independently</p>
<ul>
<li>  <strong>CW metrics</strong>: retrieve statistics about data points for your LB &amp; targets as an <strong>ordered set of time-series data</strong> ( <strong>metrics</strong> )</li>
<li>  <strong>CloudTrail logs</strong>: capture detailed information about the calls made to ELB API, and store them as <strong>logs in S3</strong></li>
<li>  <strong>Access logs</strong>: capture detailed information about the requests made to LB and store them as <strong>logs in S3</strong></li>
<li>  <strong>Request tracing</strong>: track HTTP requests</li>
</ul>
<br>

<h4 id="Network-LB-NLB"><a href="#Network-LB-NLB" class="headerlink" title="Network LB (NLB)"></a>Network LB (NLB)</h4><ul>
<li>  Layer 4, TCP / UDP connections</li>
<li>  At least 1 subnet must be specified, but the recommended number is 2</li>
<li>  Same as ALB, single point of contact, listener, target groups</li>
</ul>
<br>

<ul>
<li>  Support for static IP addresses for the LB, or assign one Elastic IP address per subnet enabled for the LB</li>
<li>  <strong>Cross-zone LB disabled by default</strong></li>
<li>  Same as last 3 points in ALB</li>
<li>  <u>Support connections from clients over inter-region VPC peering, AWS managed VPN, and third-party VPNs</u></li>
</ul>
<br>

<ul>
<li>  CANNOT enable or disable AZs for a NLB after you create it</li>
<li>  Use Proxy Protocol v2 to send additional connection information such as the source and destination</li>
<li>  Automatically provides a <strong>static IP per AZ (subnet)</strong> that can be used by applications as the front-end IP of the load balancer</li>
<li>  If NLB is unresponsive, integration with <strong>Route 53</strong> will remove the unavailable NLB IP address from service and direct traffic to an alternate NLB in another region</li>
<li>  Supports <strong>TLS termination on NLB</strong>. Additionally, NLB preserve the source IP of the clients to the back-end applications, while terminating TLS on the LB</li>
</ul>
<br>

<p><strong>Monitor</strong> health independently</p>
<ul>
<li>  <strong>CW metrics &amp; CT logs</strong>: Same as ALB</li>
<li>  <strong>VPC flow logs</strong>: Capture detailed information about the traffic going to and from NLB (<strong>Access logs in ALB</strong>)</li>
</ul>
<br>

<h4 id="Classic-LB-CLB"><a href="#Classic-LB-CLB" class="headerlink" title="Classic LB (CLB)"></a>Classic LB (CLB)</h4><img data-src="/img/02.png" style="zoom: 50%;" />

<ul>
<li>  Distributes incoming application traffic across multiple EC2 instances in multiple AZs</li>
<li>  For use with EC2 classic only. Register instances with CLB. <strong>AWS recommend using ALB / NLB</strong> instead</li>
</ul>
<br>

<ul>
<li>  Support EC2-classic, TCP/SSL listeners</li>
<li>  Sticky sessions using application-generated cookies</li>
<li>  An <strong>Internet-facing LB</strong> has a publicly resolvable DNS name, so it can route requests from clients over the Internet to the EC2 instances that are registered with the load balancer. <strong>Classic load balancers are always Internet-facing</strong></li>
</ul>
<br>

<p><strong>Monitor</strong></p>
<ul>
<li>  CW metrics</li>
<li>  CT logs</li>
<li>  Access logs</li>
</ul>
<br>

<h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a><u>Other</u></h3><ul>
<li>Choose whether to make an <strong>internal LB</strong> or <strong>internet-facing LB</strong> (CLB)<ul>
<li>  Nodes of internet-facing LB: public IPs</li>
<li>  Nodes of internal LB: private IPs</li>
</ul>
</li>
</ul>
<br>

<p><strong>LB states</strong></p>
<ul>
<li>  <strong>Provisioning</strong>: being set up</li>
<li>  <strong>Active</strong>: fully set up, ready to route traffic</li>
<li>  <strong>Failed</strong>: cannot be set up</li>
</ul>
<br>

<ul>
<li>  <strong>ELB timeout</strong>: 60s  (Backend: enable HTTP <strong>keep-alive</strong> for EC2)</li>
<li>  Listeners define <strong>port &amp; protocol</strong> to listen on</li>
<li>  <strong>Slow start mode</strong> gives target time to <u>warm up</u></li>
<li>  <strong>Sticky sessions</strong> route requests to the same target in a target group. You <u>enable sticky sessions at the target group level</u>. You can also set the duration for the stickiness of the load balancer-generated cookie, in seconds.</li>
<li><strong>Health checks</strong> verify the status of your targets<ul>
<li>  initial</li>
<li>  healthy</li>
<li>  unhealthy</li>
<li>  unused</li>
<li>  draining</li>
</ul>
</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  Use IAM policies to grant permissions</li>
<li>  Resource-level permissions, security groups (all)</li>
<li>  Tag-based permissions (ALB &amp; NLB)</li>
</ul>
<br>

<hr>
<h2 id="EC2-Auto-Scaling-AS"><a href="#EC2-Auto-Scaling-AS" class="headerlink" title="EC2 Auto Scaling (AS)"></a>EC2 Auto Scaling (AS)</h2><ul>
<li>Configure automatic scaling for the AWS resources quickly through a scaling plan that uses <b>dynamic scaling</b><span
  style="font-weight: 400;"> and </span><strong>predictive scaling</strong></li>
<li>  Optimized for <strong>availability, cost</strong>, and balance of availability &amp; cost</li>
</ul>
<br>

<p><strong>1. Use cases</strong></p>
<ul>
<li>  Cyclical traffic such as high use of resources during regular business hours and low use of resources overnight</li>
<li>  On and off traffic patterns, such as batch processing, testing, or periodic analysis</li>
<li>  Variable traffic patterns, such as software for marketing campaigns with periods of spiky growth</li>
</ul>
<br>

<p><strong>2. Features</strong></p>
<ul>
<li>  Launch / terminate EC2 instances in AS groups</li>
<li>  Enable a DynamoDB table or a <strong>global secondary index</strong> to increase or decrease its provisioned read and write capacity to handle increases in traffic without throttling</li>
<li>  <strong>Dynamic Scaling</strong>: add and remove capacity for resources to maintain resource utilization at the specified target value</li>
<li>  <strong>Predictive Scaling</strong>: forecast future load demands by analyzing your historical records for a metric</li>
<li>  AS scans your environment and <strong>automatically</strong> discovers the scalable cloud resources, so you don’t have to manually identify these resources through individual service interfaces</li>
</ul>
<br>

<p><strong>3. AS Group</strong></p>
<ul>
<li><p>  Contains <u>a collection of EC2 instances</u> that share similar characteristics and are treated as a <strong>logical grouping</strong> for the purposes of instance scaling and management</p>
</li>
<li><p> Use <strong>launch configuration</strong> as a template for its EC2 instances. </p>
   <div class="note success"><p><em>When you create a launch configuration, you can specify information such as the AMI ID, instance type, key pair, security groups, and block device mapping for your instances</em></p>
</div></li>
<li><p>  <strong>Launch configuration</strong>: An <strong>instance configuration template</strong> that an AS group uses to launch EC2 instances, and you specify information for the instances</p>
</li>
</ul>
<br>

<p><strong>4. Scaling type</strong></p>
<ul>
<li>  <strong>Target tracking</strong> scaling: Scale a resource based on a target value for a specific CW metric</li>
<li>  <strong>Step</strong> scaling: Scale a resource based on a set of scaling adjustments that vary based on the size of the alarm breach (<strong>step adjustments</strong>)</li>
<li>  <strong>Simple</strong> scaling</li>
<li>  <strong>Scheduled</strong> scaling: based on date &amp; time  (<strong>If you know the exact peak hours already, then use Scheduled scaling!</strong>)</li>
</ul>
<br>

<p><strong>5. Cooldown period</strong></p>
<p>A configurable setting that helps ensure to <u>not launch or terminate additional instances before previous scaling activities take effect</u></p>
<br>

<p><strong>6. Application AS</strong></p>
<ul>
<li>  ECS</li>
<li>  DynamoDB tables &amp; global secondary index</li>
<li>  Aurora replicas</li>
</ul>
<br>

<p><strong>7. Monitoring</strong></p>
<ul>
<li>Health checks<ul>
<li>  EC2 status check (default)</li>
<li>  ELB health checks</li>
<li>  Custom</li>
</ul>
</li>
<li>  CW metrics</li>
<li>  CW Events</li>
<li>  CT logs</li>
<li>  SNS notifications</li>
</ul>
<br>

<p><strong>8. Security</strong></p>
<p>By default, a <strong>brand new IAM user has NO permissions to do anything</strong>. To grant permissions to call Auto Scaling actions, you <strong>attach an IAM policy</strong> to the IAM users or groups that require the permissions it grants.</p>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS - 01 Microservices</title>
    <url>/2020/AWS-Microservices/</url>
    <content><![CDATA[<p>This is the first post from the AWS series. We will go through some notes and points about running microservices applications on AWS. All details can be found in the AWS whitepapers.</p>
<span id="more"></span>

<br>

<hr>
<h2 id="Microservices-on-AWS-Distributed"><a href="#Microservices-on-AWS-Distributed" class="headerlink" title="Microservices on AWS (Distributed)"></a>Microservices on AWS (Distributed)</h2><p><strong>Infrastructure as code</strong></p>
<p><strong>CF</strong>: describe the whole infrastructure as code, and <strong>version control</strong> it (Fast rollback)</p>
<br>

<p><strong>Microservices structure</strong></p>
<p>ELB (ALB)  –   ECS + AS   –   RDS / DynamoDB</p>
<br>

<p><strong>ECS</strong></p>
<ul>
<li>  Create <strong>task definition</strong> in JSON</li>
<li><strong>Container placement strategies &amp; constraints</strong><ul>
<li>  Task placement constraint: Rule considered during task placement, based on <strong>attributes</strong> (key-value pairs)</li>
</ul>
</li>
<li>  Use <strong>ECR</strong> to register container</li>
</ul>
<br>

<p><strong>Data store</strong></p>
<ul>
<li>  ElastiCache <strong>(Memcached is multi-threaded</strong>, Redis is single-threaded)</li>
<li>  <strong>DAX</strong>: caching, eventually consistent data</li>
</ul>
<br>

<p><strong>Reduce operational complexity</strong></p>
<ul>
<li><p>  <strong>Throttle</strong> requests to protect backend</p>
</li>
<li><p>CloudFront Point of Presence (<u>PoP) &amp; Regional Edge Cache</u>: minimize latency</p>
<blockquote>
<p>  <em>GW first check if the <strong>GET</strong> request is in the cache at edge location / Regional Edge Cache / GW response cache.</em></p>
<p>  <em>After backend processes the request, <strong>API call metrics</strong> are logged in CW.</em></p>
</blockquote>
</li>
<li><p>  <strong>SAM</strong> is natively supported by CF; Use CF to config serverless apps, SAM simplifies the amount of yaml you need to write</p>
</li>
</ul>
<br>

<h3 id="Distributed-system-components"><a href="#Distributed-system-components" class="headerlink" title="Distributed system components"></a><u>Distributed system components</u></h3><h4 id="I-Service-discovery"><a href="#I-Service-discovery" class="headerlink" title="I.  Service discovery"></a>I.  Service discovery</h4><ul>
<li><strong>Best: key-value store</strong> (e.g. Eureka, Consul)<ul>
<li>  AWS: use <strong>DynamoDB</strong> to propagate status changes (key-value)</li>
<li>  Does not have DNS caching issues</li>
<li>  Works well with client-side LB (Netflix Ribbon), eliminate bottlenecks &amp; simplify management</li>
</ul>
</li>
<li>  Client-side service discovery</li>
<li>  ALB-based</li>
<li>  DNS-based</li>
<li>  Using <strong>ECS Event Stream</strong></li>
<li>  Using configuration management tools (OpsWorks / Chef / Ansible)</li>
</ul>
<br>

<h4 id="II-Distributed-data-management"><a href="#II-Distributed-data-management" class="headerlink" title="II.  Distributed data management"></a>II.  Distributed data management</h4><p> <strong>1. Event sourcing</strong></p>
<ul>
<li>  Represent &amp; persist every application change as an <strong>event record</strong></li>
<li>  Data is stored as a <strong>stream of events</strong></li>
<li>  <strong>Examples</strong>: DB transaction logging, version control systems</li>
<li><strong>Pros</strong><ul>
<li>  State can be determined &amp; reconstructed any point in time</li>
<li>  Produce persistent audit trail (easy for debugging)</li>
</ul>
</li>
</ul>
<br>

<p><strong>2. Event sourcing &amp; microservices</strong></p>
<ul>
<li><p>  Decouple: <strong>publish / subscribe</strong> pattern</p>
</li>
<li><p>  Feeds the same event data into different data models for separate microservices</p>
</li>
<li><p>  Decouple read from write: <strong>CQRS</strong> (Command Query Responsibility Segregation)</p>
</li>
<li><p><strong>Kinesis Streams</strong> as the <strong>central event store</strong> (capture application changes as <strong>events</strong>, and persist on S3)</p>
<blockquote>
<p>  <em>Publish event by writing message to Kinesis Streams. All microservices read the message copy, filter based on relevancy, and forward to Lambda / Kinesis Firehose for further processing.</em></p>
</blockquote>
</li>
</ul>
<br>

<p><strong>3. No containers</strong></p>
<p> <a href="https://www.lightbend.com/reactive-programming-versus-reactive-systems">The key to building resilient, self-healing systems</a> is to <strong>allow failures to be contained</strong>, refined as <strong>messages</strong>, sent to other components (that act as supervisors), and managed from a safe context outside the failed component. </p>
<p><strong>Event sourcing</strong>: Here, being <strong>message-driven</strong> is the enabler. The idea is to <strong>decouple</strong> the management of failures from the call chain, freeing the client from the responsibility of handling the failures of the server. No container or orchestration tooling will help you to integrate this. </p>
<br>



<h4 id="III-Async-communication"><a href="#III-Async-communication" class="headerlink" title="III.  Async communication"></a>III.  Async communication</h4><ul>
<li><strong>REST can be sync / async</strong>, REST relies on:<ul>
<li>  <strong>Stateless</strong> communication</li>
<li>  Uniform interfaces</li>
<li>  Standard methods (e.g. HTTP GET, POST, etc.)</li>
</ul>
</li>
<li><strong>Message passing</strong><ul>
<li>  If async, does not need service discovery</li>
<li>Exchange message via a queue (SQS / SNS): <ul>
<li>   <strong>Subscribe an SQS queue to an SNS topic</strong></li>
<li>   Publish a message to the topic, and SNS sends a message to the subscribed SQS queue</li>
<li>   Message (<strong>JSON</strong>) contains: subject, message, metadata</li>
</ul>
</li>
</ul>
</li>
</ul>
<br>

<p><strong>Orchestration &amp; state management</strong></p>
<ul>
<li>  <strong>Step functions</strong> (state machines): coordinate components of distributed applications &amp; microservices</li>
<li>  SF supports orchestration of Lambda functions (sequential &amp; parallel)</li>
<li>  <strong>Amazon States Language</strong></li>
</ul>
<br>

<h4 id="IV-Distributed-Monitoring-Tracing-amp-Auditing"><a href="#IV-Distributed-Monitoring-Tracing-amp-Auditing" class="headerlink" title="IV.  Distributed Monitoring, Tracing &amp; Auditing"></a>IV.  Distributed Monitoring, Tracing &amp; Auditing</h4><p><strong>1. Distribute monitoring</strong> - CW </p>
<ul>
<li><strong>Centralize logs</strong> <ul>
<li>  Primary destination: S3 / CW Logs</li>
<li>  Application running on <strong>EC2</strong>: <strong>Daemon</strong> ship logs to CW Logs</li>
<li>  <strong>Lambda</strong> natively ship logs to CW Logs</li>
<li>  <strong>ECS</strong> support <code>awslogs</code>, centralize container logs to CW Logs</li>
</ul>
</li>
<li>  Search &amp; analyze logs: ES &amp; Kibana, Athena (query logs from S3)</li>
</ul>
<br>

<p><strong>2. Distributed tracing</strong> - X-Ray</p>
<p><strong>X-Ray</strong>: end-to-end view of requests</p>
<ul>
<li>  Use <strong>correlation IDs</strong>: unique identifiers attached to all requests &amp; messages related to a specific event chain</li>
<li>  <strong>Trace ID</strong> is added to HTTP requests in specific <strong>tracing headers</strong> (<code>X-Amzn-trace-Id</code>)</li>
<li>  Works with EC2, ECS, Lambda, EB</li>
</ul>
<br>

<p><strong>3. Log analysis</strong></p>
<ul>
<li><strong>EC2 / ECS / Lambda   –   CW Logs   –   ES &amp; Kibana</strong><ul>
<li>  Config <strong>CW to stream log entries to ES</strong> in near real time, via <strong>CW subscription</strong></li>
<li>  Send SNS notice, emails, JIRA tickets</li>
</ul>
</li>
<li><strong>EC2 / ECS / Lambda   –  CW Logs   –  Kinesis Firehose   –   Redshift   –   QuickSight</strong><ul>
<li>  QuickSight can only query from data services (e.g. Redshift)</li>
<li>  🧡 CW as <strong>centralized store</strong> for log data</li>
<li>  Stream log entries to <strong>Firehose</strong> (deliver real-time streaming data to S3 / ES / Redshift)</li>
</ul>
</li>
<li>  <strong>CW Logs  –   Firehose   –   S3   –  DynamoDB   –   QuickSight</strong></li>
<li><strong>CW Logs  –   Lambda   –   S3  –   DynamoDB   –   QuickSight</strong><ul>
<li>  CW Logs: Centralize logs</li>
<li>  S3: Store logs</li>
<li>  QS: Last step</li>
</ul>
</li>
</ul>
<br>

<p><strong>4. Auditing - CT</strong></p>
<ul>
<li><p>  Tracking changes in microservices, pass to CW Logs / S3</p>
</li>
<li><p>  Allow multiple trails for the same account</p>
</li>
<li><p><strong>Aggregate</strong> in a single <strong>S3</strong> bucket</p>
<blockquote>
<p>  <strong>Pros:</strong> <em>New files can trigger SNS / start Lambda to parse the log file, data auto archived to <strong>Glacier</strong> via lifecycle policies.</em></p>
</blockquote>
</li>
<li><p><strong>Store in CW Logs</strong></p>
<blockquote>
<p>  <strong>Pros:</strong> <em>Trail data is generated in real time, reroute to ES for search &amp; visualization.</em></p>
</blockquote>
</li>
</ul>
<br>

<p><strong>5. Events &amp; real-time actions</strong></p>
<ul>
<li>  CW Events deliver near real-time stream of system events that describe changes in AWS resources</li>
<li>  <strong>CT + S3 + CW Events</strong>: Generate events for all changing API calls across all AWS services</li>
</ul>
<br>

<p><strong>6. Resource Inventory &amp; change management</strong></p>
<ul>
<li><strong>AWS Config</strong><ul>
<li>  Provide AWS resource inventory, config history, and config change notifications </li>
<li>  Create rules that auto check the config of AWS resources recorded by AWS Config</li>
</ul>
</li>
<li><strong>SNS</strong><ul>
<li>  Send email to specific groups</li>
<li>  Add a message to SQS queue (message picked up by SQS, compliant state is restored by GW configuration)</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Containerized-Microservices"><a href="#Containerized-Microservices" class="headerlink" title="Containerized Microservices"></a>Containerized Microservices</h2><p><strong>Layer caching: Docker only build the layer that was changed.</strong></p>
<br>

<ul>
<li>  <strong>K8S Pods  = ECS Tasks = Container sets</strong> (collaborate using links / volumes)</li>
<li>  <strong>Scheduler</strong> maintain the desired count of tasks / container sets</li>
</ul>
<br>

<p>Treating software as always-improving <strong>products</strong> instead of projects.</p>
<br>

<p><strong>Smart endpoints &amp; dumb pipes</strong></p>
<ul>
<li><p>  <strong>Sync:   Request / Response</strong></p>
</li>
<li><p><strong>Async: Publish / Subscribe</strong></p>
<ul>
<li>  Event-based architecture</li>
</ul>
</li>
<li><p>  Endpoints that produce &amp; consume messages are smart, but the pipe between endpoints are dumb</p>
</li>
</ul>
<br>

<p><strong>Infrastructure automation</strong></p>
<ul>
<li>  Infrastrtucture as code (easy rollbacks, instantiated from description)</li>
<li>  Deploy in <strong>phases</strong>: <strong>blue / green, canary</strong> (Lambda)</li>
</ul>
<br>

<p><strong>Design for failures</strong></p>
<ul>
<li>  Self-healing infrastructure (automation)</li>
<li>  Treat container instances as <strong>immutable</strong> servers</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Certified Developer Exam - I Passed!</title>
    <url>/2020/DVA-C01/</url>
    <content><![CDATA[<p>Today I just passed the AWS Certified Developer Exam (DVA-C01)! </p>
<p>So here I’m going to write down some thoughts and tips I have for the exam.</p>
<span id="more"></span> 

<p>I’ve spent around a month to study for this exam, since I didn’t take the Solutions Architect (SAA) prior to this, while Developer Associate is definitely harder than SAA.</p>
<p><strong>My Preparations:</strong></p>
<ul>
<li><p>  Read all whitepapers and take notes</p>
</li>
<li><p>  Watched a lot of re:Invent videos</p>
</li>
<li><p>  Practice Exams (5 - 6 sets), and heavily reviewed afterwards</p>
</li>
<li><p>Take notes, and review frequently (30k words of notes in total)</p>
</li>
</ul>
<br>

<p><strong>Some topics from the exam:</strong></p>
<ul>
<li>  IAM Role Policy (<code>GetRole</code> &amp; <code>PassRole</code>)</li>
<li>  S3 Encryption &amp; KMS (Encryption in general)</li>
<li>  Cognito use cases (with hands-on experience)</li>
<li>  AWS <strong>CLI</strong> for development</li>
<li>  VPC &amp; Network connectivity</li>
<li>  X-Ray &amp; CloudWatch</li>
<li>  SNS &amp; Event sources to trigger Lambda (Push)</li>
</ul>
<br>


<br>

]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>End of Evangelion</title>
    <url>/Notes/Evangelion/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid passcode." data-whm="Unverified decryption.">
  <script id="hbeData" type="hbeData" data-hmacdigest="151b680e633ef236b48da1eab2b4b2aee9345018d8c0e2a7d54d969370db5dc1">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-wave">
      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-wave"><p style="text-align:center; font-size:0.8em; font-weight:100;">Passcode please.</p></span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>Spring Framework Concepts</title>
    <url>/2020/Spring/</url>
    <content><![CDATA[<p>This post includes a compilation of the common concepts regarding the Spring framework. Some noteworthy points:</p>
<ul>
<li>  Dispatcher Servlet</li>
<li>  Inversion of Control &amp; Dependency Injection (IoC &amp; DI)</li>
<li>  Scope of Beans</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="Dispatcher-Servlet"><a href="#Dispatcher-Servlet" class="headerlink" title="Dispatcher Servlet"></a>Dispatcher Servlet</h2><p>Spring MVC is designed around the <strong>front controller pattern</strong> where a central <code>Servlet</code>, the <code>DispatcherServlet</code> provides a shared algorithm for request processing, while actual work is performed by configurable delegate components. </p>
<p>This model is flexible and supports diverse workflows.</p>
<br>



<p>The <code>DispatcherServlet</code> needs to be <strong>declared and mapped</strong> according to the Servlet specification in <code>web.xml</code>. In turn, the <code>DispatcherServlet</code> uses Spring configuration to discover the delegate components it needs for request mapping, view resolution, exception handling.</p>
<br>



<p><code>DispatcherServlet</code> expects a <code>WebApplicationContext</code> for its own configuration. </p>
<p><code>WebApplicationContext</code> has a link to the <code>ServletContext</code> and the <code>Servlet</code> with which it is associated. It is also bound to the <code>ServletContext</code> such that applications can use static methods on <code>RequestContextUtils</code> to look up the <code>WebApplicationContext</code> if they need access to it.</p>
<img data-src="https://docs.spring.io/spring/docs/5.2.x/spring-framework-reference/images/mvc-context-hierarchy.png" style="zoom: 67%;" />



<br>

<p>The <code>DispatcherServlet</code> processes requests as follows:</p>
<ul>
<li>  The <strong><code>WebApplicationContext</code></strong> is searched for and bound in the request as an attribute that the controller and other elements in the process can use. It is bound by default under the <code>DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE</code> key.</li>
<li>  The <strong>locale resolver</strong> is bound to the request to let elements in the process resolve the locale to use when processing the request (rendering the view, preparing data, and so on). If you do not need locale resolving, you do not need the locale resolver.</li>
<li>  The <strong>theme resolver</strong> is bound to the request to let elements such as views determine which theme to use. If you do not use themes, you can ignore it.</li>
<li>  If you specify a <strong>multipart file resolver</strong>, the request is wrapped in a <code>MultipartHttpServletRequest</code> for further processing by other elements in the process.</li>
<li>  An appropriate <strong>handler</strong> is searched for. If a handler is found, the execution chain associated with the handler (preprocessors, postprocessors, and controllers) is executed in order to prepare a model or rendering. Alternatively, for annotated controllers, the response can be rendered (within the <code>HandlerAdapter</code>) instead of returning a view.</li>
<li>  If a <strong>model</strong> is returned, the <strong>view</strong> is rendered. If no model is returned (e.g. request interception), no view is rendered, because the request could already have been fulfilled.</li>
</ul>
<p>The <strong><code>HandlerExceptionResolver</code></strong> beans declared in the <code>WebApplicationContext</code> are used to resolve exceptions thrown during request processing. </p>
<br>



<h3 id="Connection-Pool"><a href="#Connection-Pool" class="headerlink" title="Connection Pool"></a><u>Connection Pool</u></h3><p>A cache of database connections maintained, so that the connections can be reused when future requests to the database are required.</p>
<br>





<hr>
<h2 id="Dependency-Injection-Related"><a href="#Dependency-Injection-Related" class="headerlink" title="Dependency Injection Related"></a>Dependency Injection Related</h2><h4 id="Component-amp-Bean"><a href="#Component-amp-Bean" class="headerlink" title="@Component &amp; @Bean"></a><a href="https://stackoverflow.com/questions/10604298/spring-component-versus-bean">@Component &amp; @Bean</a></h4><ul>
<li>  <strong>@Component</strong>: <u><strong>For component scanning and autowiring</strong></u>. Spring auto-detect and auto-configure beans using classpath scanning, implicit one-to-one mapping between the annotated class and the bean (i.e. one bean per class).</li>
<li>  <strong>@Bean + @Configuration</strong>: <em>explicitly</em> declare a single bean, rather than letting Spring do it automatically. The <strong>@Bean</strong> annotation <strong>returns an object</strong> that spring should register as a bean in the Spring application context. </li>
</ul>
<br>



<h4 id="Constructor-Based-Dependency-Injection"><a href="#Constructor-Based-Dependency-Injection" class="headerlink" title="Constructor-Based Dependency Injection"></a><a href="https://www.baeldung.com/constructor-injection-in-spring">Constructor-Based Dependency Injection</a></h4><ul>
<li><p>  classes with a single constructor can omit the <code>@Autowired</code> annotation</p>
</li>
<li><p>  constructor-based injection can be leveraged in <code>@Configuration</code> annotated classes</p>
</li>
<li><p>e.g.</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Car</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// Constructor Injection</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Car</span><span class="params">(Engine engine, Transmission transmission)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.engine = engine;</span><br><span class="line">        <span class="keyword">this</span>.transmission = transmission;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>



<h4 id="Scope-of-Beans-6"><a href="#Scope-of-Beans-6" class="headerlink" title="Scope of Beans (6)"></a><a href="https://stackoverflow.com/a/46725406/13408151">Scope of Beans (6)</a></h4><blockquote>
<p>  前面两个最重要   <strong>什么情况下用singleton，什么情况下用 prototype</strong></p>
</blockquote>
<p><strong>Six Types:</strong> </p>
<ul>
<li>  <strong>Singleton</strong></li>
<li><strong>Prototype</strong>: <u>a single bean definition to any number of object instances</u><ul>
<li>  Used in STATEFUL services, creates new instance for each use case.</li>
<li>  Thread-safe</li>
</ul>
</li>
<li>  Request</li>
<li>  Session</li>
<li>  Application</li>
<li>  Web socket</li>
</ul>
<br>

<ul>
<li>  <strong>Singleton</strong>:  <u>a single bean definition to a single object instance</u> per Spring IoC container  (<strong>REST 用的大多数是 Singleton</strong>)</li>
</ul>
<br>

<ul>
<li><strong>How to implement a singleton pattern?</strong>   <ul>
<li>  private constructor, restrict other classes</li>
<li>  private static singleton variable</li>
<li>  another public static (another var, returns the instance of the var)</li>
</ul>
</li>
</ul>
<br>

<p>The most popular approach is to <strong><a href="https://www.geeksforgeeks.org/singleton-class-java/">implement a Singleton by creating a regular class</a></strong> and making sure it has:</p>
<ul>
<li>  A private constructor</li>
<li>  A static field containing its only instance</li>
<li>  A static factory method for obtaining the instance</li>
</ul>
<p>Use <strong>synchronized</strong> for protection</p>
<br>

<br>

]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 07 Consuming REST Services</title>
    <url>/2020/SpringBoot-07/</url>
    <content><![CDATA[<p>This is the seventh post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English. </p>
<p>In the last post, we went through how to <strong>produce</strong> REST services. In this post, we will see how to <strong>consume</strong> REST services via <code>RestTemplate</code>, and how to navigate REST APIs using Traverson.</p>
<span id="more"></span>

<br>

<p>It’s not uncommon for Spring applications to both <u>provide an API</u> and <u>make requests to another application’s API</u>. This is widely used in microservices.  A Spring application can consume a REST API with:</p>
<ul>
<li>  <strong>RestTemplate</strong>: A straightforward, <strong>synchronous</strong> REST client provided by the core Spring Framework.</li>
<li>  <strong>Traverson</strong>:  A hyperlink-aware, <strong>synchronous</strong> REST client provided by Spring HATEOAS. </li>
<li>  <strong>WebClient</strong>: A <strong>reactive, asynchronous</strong> REST client introduced in Spring 5.</li>
</ul>
<p>In this post, we will focus on Rest Template and Traverson.</p>
<br>

<hr>
<h2 id="Normal-API-with-Rest-Template"><a href="#Normal-API-with-Rest-Template" class="headerlink" title="Normal API with Rest Template"></a>Normal API with Rest Template</h2><p>Working with consuming REST services form the client’s perspective, we need a lot of boilerplate code to handle the low-level stuff. The client needs to:</p>
<ul>
<li>  Create a client instance &amp; a request object</li>
<li>  Execute the request &amp; Interpret the response</li>
<li>  Map the response to domain objects</li>
<li>  Handle any exceptions that may be thrown along the way</li>
</ul>
<p>To avoid this, Spring has <code>RestTemplate</code>, which provides 41 methods in total. We will list the 12 unique operations below, each can be overloaded to equal the complete set of 41 methods:</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><code>delete</code></td>
<td>DELETE resource data at a specified URL</td>
</tr>
<tr>
<td><code>put</code></td>
<td>PUT resource data to a specified URL</td>
</tr>
<tr>
<td><code>exchange</code></td>
<td>Executes a specified HTTP method against a URL, return <code>ResponseEntity</code> containing an object mapped from the response body</td>
</tr>
<tr>
<td><code>execute</code></td>
<td>Executes a specified HTTP method against a URL, returning an object mapped from the response body</td>
</tr>
<tr>
<td>.</td>
<td></td>
</tr>
<tr>
<td><code>headForHeaders</code></td>
<td>Sends an HTTP HEAD request, returning the HTTP headers for the specified resource URL</td>
</tr>
<tr>
<td><code>optionsForAllow</code></td>
<td>Sends an HTTP OPTIONS request, returning the Allow header for the specified URL</td>
</tr>
<tr>
<td>.</td>
<td></td>
</tr>
<tr>
<td><code>postForLocation</code></td>
<td>POST data to a URL, returning the URL of the newly created resource</td>
</tr>
<tr>
<td><code>postForEntity</code></td>
<td>POST data to a URL, returning a <code>ResponseEntity</code> containing an object mapped from the response body</td>
</tr>
<tr>
<td><code>postForObject</code></td>
<td>POST data to a URL, returning an object mapped from the response body</td>
</tr>
<tr>
<td><code>getForEntity</code></td>
<td>Sends an HTTP GET request, returning a <code>ResponseEntity</code> containing an object mapped from the response body</td>
</tr>
<tr>
<td><code>getForObject</code></td>
<td>Sends an HTTP GET request, returning an object mapped from a response body</td>
</tr>
<tr>
<td><code>patchForObject</code></td>
<td>Sends an HTTP PATCH request, returning the resulting object mapped from the response body</td>
</tr>
</tbody></table>
<p>From the list above, we can see that <code>exchange</code> &amp; <code>execute</code> provide lower-level, general-purpose methods for sending HTTP requests. Most methods mentioned in the table  are overloaded into 3 method forms:</p>
<ul>
<li>  Accepts a <code>String</code> URL specification with URL parameters specified in a <u>variable argument list</u></li>
<li>  Accepts a <code>String</code> URL specification with URL parameters specified in <code>Map&lt;String, String&gt;</code></li>
<li>  Accepts <code>java.net.URI</code> as the URL specification, with no support for parameterized URLs</li>
</ul>
<br>

<p>To use <code>RestTemplate</code>, we can either <strong>create a new instance</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RestTemplate rest = <span class="keyword">new</span> RestTemplate();</span><br></pre></td></tr></table></figure>

<p>Or we can <strong>declare as a bean</strong> and inject where we need it:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RestTemplate <span class="title">restTemplate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> RestTemplate();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Now we will go through the 4 HTTP methods for consuming REST services.</p>
<br>

<h3 id="Get"><a href="#Get" class="headerlink" title="Get"></a><u>Get</u></h3><p>Suppose we want to get an ingredient from the API, and if API doesn’t use HATEOAS, we can use <code>getForObject</code>.:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">getIngredientById</span><span class="params">(String ingredientId)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rest.getForObject(<span class="string">&quot;http://localhost:8080/ingredients/&#123;id&#125;&quot;</span>, Ingredient.class, ingredientId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Here the <code>ingredientId</code> is for the <code>/&#123;id&#125;</code>, and <code>getForObject</code> accepts a String URL, and uses a <strong>variable list</strong> for URL variables. The variable parameters are assigned to the placeholders in the order that they’re given.</p>
<p>The second parameter <code>Ingredeint.class</code> defines the type that the response should be bound to. In this case, the response data (in JSON) should be <strong>deserialized into an <code>Ingredient</code> object</strong>. </p>
<br>

<p>Alternatively, we can use <code>Map</code> to specify the URL variables:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">getIngredientById</span><span class="params">(String ingredientId)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Map&lt;String,String&gt; urlVariables = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    urlVariables.put(<span class="string">&quot;id&quot;</span>, ingredientId);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rest.getForObject(<span class="string">&quot;http://localhost:8080/ingredients/&#123;id&#125;&quot;</span>, Ingredient.class, urlVariables);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In this case, the value of  <code>ingredientId</code> is mapped to a key of  <code>id</code> . When the request is made, <code>&#123;id&#125;</code> is replaced by the map entry whose key is <code>id</code>. </p>
<p>However, using a URI parameter requires us to construct a URI object before calling <code>getForObject()</code>. Otherwise, it’s similar to both of the other variants:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">getIngredientById</span><span class="params">(String ingredientId)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Map&lt;String,String&gt; urlVariables = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    urlVariables.put(<span class="string">&quot;id&quot;</span>, ingredientId);</span><br><span class="line">    </span><br><span class="line">    URI url = UriComponentsBuilder.fromHttpUrl(<span class="string">&quot;http://localhost:8080/ingredients/&#123;id&#125;&quot;</span>)</span><br><span class="line">        .build(urlVariables);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rest.getForObject(url, Ingredient.class);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Here the <code>URI</code> object is defined from a <code>String</code> specification, and its placeholders filled in from entries in a <code>Map</code> , much like the previous variant of <code>getForObject()</code> . </p>
<p>But if the client needs more than the payload body, then we need <code>getForEntity()</code>. It works in much the same way as <code>getForObject()</code>, but <u>instead of returning a domain object that represents the response’s payload</u>, it <u>returns a <code>ResponseEntity </code>object that wraps that domain object</u>. The <code>ResponseEntity</code> gives access to additional response details, such as the response headers.</p>
<p>Suppose that in addition to the ingredient data, we want to inspect the Date header from the response. With <code>getForEntity()</code> that becomes straightforward:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">getIngredientById</span><span class="params">(String ingredientId)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    ResponseEntity&lt;Ingredient&gt; responseEntity =rest.getForEntity(</span><br><span class="line">        <span class="string">&quot;http://localhost:8080/ingredients/&#123;id&#125;&quot;</span>, Ingredient.class, ingredientId);</span><br><span class="line">    </span><br><span class="line">    log.info(<span class="string">&quot;Fetched time: &quot;</span> + responseEntity.getHeaders().getDate());</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> responseEntity.getBody();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The <code>getForEntity()</code> method is overloaded with the same parameters as <code>getForObject()</code>, so we can provide the URL variables as a variable list parameter, or call <code>getForEntity()</code> with a URI object.</p>
<br>





<h3 id="Post"><a href="#Post" class="headerlink" title="Post"></a><u>Post</u></h3><p><strong><code>RestTemplate</code> has 3 ways of sending a POST request</strong>. </p>
<p>If we wanted to receive the newly created Ingredient resource after the POST request, we use <code>postForObject()</code> like this:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Choice 1: Response payload Only</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">createIngredient</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rest.postForObject(<span class="string">&quot;http://localhost:8080/ingredients&quot;</span>, ingredient, Ingredient.class);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>This variant of the <code>postForObject()</code> method takes a String URL specification, the <strong>object</strong> to be posted to the server, and the <strong>domain type</strong> that the response body should be bound to. A fourth parameter could be a <u><code>Map</code> of the URL variable value</u>,  or a <u>variable list of parameters to substitute into the URL</u>.</p>
<br>

<p>If the client has more need for the <strong>location</strong> of the newly created resource, then we can call <code>postForLocation()</code> instead:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Choice 2: Resource location Only</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> URI <span class="title">createIngredient</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rest.postForLocation(<span class="string">&quot;http://localhost:8080/ingredients&quot;</span>, ingredient);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>postForLocation()</code> works much like <code>postForObject()</code>, with the exception that it returns a <strong>URI of the newly created resource</strong> instead of the resource object itself. The URI returned is <u>derived from the response’s <strong>Location header</strong></u>. </p>
<br>

<p>If we need both the location and response payload, we can call <code>postForEntity()</code> :</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Choice 3: Response payload &amp; Resource location</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">createIngredient</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    ResponseEntity&lt;Ingredient&gt; responseEntity = rest.postForEntity(</span><br><span class="line">        <span class="string">&quot;http://localhost:8080/ingredients&quot;</span>, ingredient, Ingredient.class);</span><br><span class="line">    </span><br><span class="line">    log.info(<span class="string">&quot;New resource created at &quot;</span> + responseEntity.getHeaders().getLocation());</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> responseEntity.getBody();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Put"><a href="#Put" class="headerlink" title="Put"></a><u>Put</u></h3><p>All three overloaded variants of <code>put()</code> accept an Object that is to be serialized and sent to the given URL. As for the URL itself, it can be specified as a <strong>URI object</strong> or as a <strong>Strin</strong>g. Just like <code>getForObject()</code> and <code>getForEntity()</code>, the URL variables can be provided as either <u>a variable argument list</u> or as a <u>Map</u> .</p>
<p>Suppose that we want to replace an ingredient resource with the data from a new Ingredient object:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateIngredient</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    rest.put(<span class="string">&quot;http://localhost:8080/ingredients/&#123;id&#125;&quot;</span>, ingredient, ingredient.getId());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Here the URL is given as a <code>String</code>, and has a placeholder that’s substituted by the given Ingredient object’s <code>id</code> property. The data to be sent is the <code>Ingredient</code> object itself. The <strong><code>put()</code> method returns void</strong> , so there’s nothing we need to do to handle a return value.</p>
<br>



<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a><u>Delete</u></h3><p>To completely remove a resource:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteIngredient</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    rest.delete(<span class="string">&quot;http://localhost:8080/ingredients/&#123;id&#125;&quot;</span>, ingredient.getId());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In this example, only the <u>URL (specified as a String)</u> and a <u>URL variable value</u> are given to <code>delete()</code>. But as with the other <code>RestTemplate</code> methods, the URL could be <strong>specified as a URI object</strong> or the <strong>URL parameters given as a Map</strong> .</p>
<br>



<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><u>Summary</u></h3><p>Although the methods of <code>RestTemplate</code> differ in their purpose, they’re quite similar in how they’re used. </p>
<p>On the other hand, if the consumed API  includes hyperlinks in its response, <code>RestTemplate</code> isn’t as helpful. It’s certainly possible to fetch the more detailed resource data with <code>RestTemplate</code> and work with the content and links contained therein, but<br>it’s not trivial to do so. </p>
<p>Rather than struggle while consuming hypermedia APIs with <code>RestTemplate</code>, we can use Traverson instead.</p>
<br>



<hr>
<h2 id="Hypermedia-API-with-Traverson"><a href="#Hypermedia-API-with-Traverson" class="headerlink" title="Hypermedia API with Traverson"></a>Hypermedia API with Traverson</h2><p>Now we will consume an API by traversing the API on relation names.</p>
<p>We start from instantiating a Traverson object with an API’s base URI:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Traverson traverson = <span class="keyword">new</span> Traverson(URI.create(<span class="string">&quot;http://localhost:8080/api&quot;</span>), MediaTypes.HAL_JSON);</span><br></pre></td></tr></table></figure>

<p>The URL(<code>/api</code>) here is the only URL we need to give to Traverson. From there we will navigate the API by link relation names. </p>
<p>We will also specify that the API will <strong>produce JSON responses with HAL-style hyperlinks</strong> so that Traverson knows how to parse the incoming resource data. Like <code>RestTemplate</code> , we can choose to <u>instantiate a Traverson object prior to its use</u>, or <u>declare it as a bean to be injected wherever it’s needed</u>.</p>
<br>

<p>Now we can start consuming an API by following links. Suppose we want to retrieve a list of all ingredients. From the last post, we know that the ingredients link has an <code>href</code> property that links to the ingredients resource:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ParameterizedTypeReference&lt;Resources&lt;Ingredient&gt;&gt; ingredientType = </span><br><span class="line">    <span class="keyword">new</span> ParameterizedTypeReference&lt;Resources&lt;Ingredient&gt;&gt;() &#123;&#125;;</span><br><span class="line"></span><br><span class="line">Resources&lt;Ingredient&gt; ingredientRes = traverson.follow(<span class="string">&quot;ingredients&quot;</span>).toObject(ingredientType);</span><br><span class="line"></span><br><span class="line">Collection&lt;Ingredient&gt; ingredients = ingredientRes.getContent();</span><br></pre></td></tr></table></figure>

<p>By calling the <code>follow()</code> method on the Traverson object, we can navigate to the resource whose link’s relation name is <code>ingredients</code>. After we navigated to there, we need to ingest the contents of that resource by calling <code>toObject()</code> .</p>
<p>The <code>toObject()</code> method requires that we tell it what kind of object to read the data into. This can get a little tricky, since we need to read it in as a <code>Resources&lt;Ingredient&gt;</code> object, and Java <strong>type erasure</strong> makes it difficult to provide type information for a generic type. But creating a <code>ParameterizedTypeReference</code> helps with that.</p>
<blockquote>
<p>  As an analogy, imagine that instead of a REST API, this were a homepage on a website. And instead of REST client code, imagine that it’s you viewing that homepage in a browser. You see a link on the page that says Ingredients and you follow that link by clicking it. </p>
<p>  Upon arriving at the next page, you read the page, which is analogous to Traverson ingesting the content as a <code>Resources&lt;Ingredient&gt;</code> object.</p>
</blockquote>
<br>

<p>Now if we want to fetch the most recently created tacos, then starting at the home resource, we can navigate to the recent tacos resource like this:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ParameterizedTypeReference&lt;Resources&lt;Taco&gt;&gt; tacoType =</span><br><span class="line">    <span class="keyword">new</span> ParameterizedTypeReference&lt;Resources&lt;Taco&gt;&gt;() &#123;&#125;;</span><br><span class="line"></span><br><span class="line">Resources&lt;Taco&gt; tacoRes = traverson.follow(<span class="string">&quot;tacos&quot;</span>).follow(<span class="string">&quot;recents&quot;</span>).toObject(tacoType);</span><br><span class="line"></span><br><span class="line">Collection&lt;Taco&gt; tacos = tacoRes.getContent();</span><br></pre></td></tr></table></figure>

<p>Here we follow the <code>Tacos</code> link, and then follow the <code>Recents</code> link. That brings you to the resource you’re interested in, so a call to <code>toObject()</code> with an appropriate <code>ParameterizedTypeReference</code> gets us what we want. </p>
<p>The <code>.follow()</code> method can be simplified by listing a trail of relation names to follow:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Resources&lt;Taco&gt; tacoRes = traverson.follow(<span class="string">&quot;tacos&quot;</span>, <span class="string">&quot;recents&quot;</span>).toObject(tacoType);</span><br></pre></td></tr></table></figure>

<p>As we can see, Traverson makes it easy to navigate a HATEOAS-enabled API and consuming its resources. </p>
<p>But <u>one thing it doesn’t do is offer any methods for writing to or deleting from those APIs</u>. In contrast, <code>RestTemplate</code> can write and delete resources, but <u>doesn’t make it easy to navigate an API</u>.</p>
<p><strong>When we need to both navigate an API and update or delete resources, we’ll need to use <code>RestTemplate</code> and Traverson together.</strong> Traverson can still be used to navigate to the link where a new resource will be created. Then <code>RestTemplate</code> can be<br>given that link to do a HTTP request (GET, POST, etc).</p>
<p>Suppose we want to add a new <code>Ingredient</code> to the Taco Cloud menu. The following <code>addIngredient()</code> method uses both Traverson and <code>RestTemplate</code> to <strong>post</strong> a new Ingredient to the API:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Ingredient <span class="title">addIngredient</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    String ingredientsUrl = traverson.follow(<span class="string">&quot;ingredients&quot;</span>).asLink().getHref();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rest.postForObject(ingredientsUrl, ingredient, Ingredient.class);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>After following the <code>Ingredients</code> link, we ask for the link itself by calling <code>asLink()</code>. From that link, we ask for the link’s URL by calling <code>getHref()</code>. </p>
<p>With a URL in hand, we then have everything we need to call <code>postForObject()</code> on the <code>RestTemplate</code> instance and save the new ingredient.</p>
<br>

<br>

]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 06 Producing REST Services</title>
    <url>/2020/SpringBoot-06/</url>
    <content><![CDATA[<p>This is the sixth post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English. </p>
<p>In this post, I am going to cover how to define REST endpoints in Spring, and auto generate <strong>repository-based REST endpoints</strong> with <strong>Spring Data REST</strong>. This post describes how to <strong>produce</strong> REST services, and in the next post, we will talk about how to <strong>consume</strong> REST services.</p>
<span id="more"></span>

<br>

<hr>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>  Controller handler methods can either be annotated with <code>@ResponseBody</code>, or return <code>ResponseEntity</code> objects to bypass the model &amp; view, and <strong>write data directly to the response body</strong>. However if we use <code>@RestController</code>, we don’t need these.</li>
</ul>
<br>

<ul>
<li>  <strong>Spring HATEOAS</strong> enables hyperlinking of resources returned from Spring MVC controllers.</li>
</ul>
<br>

<ul>
<li>  Spring Data repositories can automatically expose REST APIs via Spring Data REST.</li>
</ul>
<br>

<hr>
<h2 id="Rest-Controllers"><a href="#Rest-Controllers" class="headerlink" title="Rest Controllers"></a>Rest Controllers</h2><blockquote>
<p>   Spring MVC creates traditional <strong>MPA</strong> (MultiPage Application), while Angular creates <strong>SPA</strong> (Single Page Application). </p>
</blockquote>
<p>Since presentation is largely <strong>decoupled</strong> from backend processing in a SPA, it affords the opportunity to develop more than one UI (such as a native mobile application) for the same backend functionality. It can also integrate with other applications that can consume the API. But MPA is a simpler design if all you need is to <u>display information on a web page</u>.</p>
<p>The Angular client code will communicate with an API via HTTP requests. </p>
<br>

<h3 id="Get"><a href="#Get" class="headerlink" title="Get"></a><u>Get</u></h3><p><strong>Angular code for GET:</strong></p>
<figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; Component, OnInit, Injectable &#125; <span class="keyword">from</span> <span class="string">&#x27;@angular/core&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; Http &#125; <span class="keyword">from</span> <span class="string">&#x27;@angular/http&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; HttpClient &#125; <span class="keyword">from</span> <span class="string">&#x27;@angular/common/http&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span>(&#123;</span><br><span class="line">    <span class="attr">selector</span>: <span class="string">&#x27;recent-tacos&#x27;</span>,</span><br><span class="line">    <span class="attr">templateUrl</span>: <span class="string">&#x27;recents.component.html&#x27;</span>,</span><br><span class="line">    <span class="attr">styleUrls</span>: [<span class="string">&#x27;./recents.component.css&#x27;</span>]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="meta">@Injectable</span>()</span><br><span class="line"><span class="keyword">export</span> <span class="class"><span class="keyword">class</span> <span class="title">RecentTacosComponent</span> <span class="title">implements</span> <span class="title">OnInit</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="attr">recentTacos</span>: <span class="built_in">any</span>;</span><br><span class="line">    <span class="function"><span class="title">constructor</span>(<span class="params"><span class="keyword">private</span> httpClient: HttpClient</span>)</span> &#123; &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Get recently designed tacos from server</span></span><br><span class="line">    <span class="comment">// Note: HttpClient, subscribe</span></span><br><span class="line">    <span class="function"><span class="title">ngOnInit</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.httpClient.get(<span class="string">&#x27;http://localhost:8080/design/recent&#x27;</span>)</span><br><span class="line">            .subscribe(<span class="function"><span class="params">data</span> =&gt;</span> <span class="built_in">this</span>.recentTacos = data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Controller to GET recent designs:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意 produces，明确表示是 json</span></span><br><span class="line"><span class="comment">// Only handle requests if the Accept header includes &quot;application/json&quot;</span></span><br><span class="line"><span class="meta">@RequestMapping(path=&quot;/design&quot;, produces=&quot;application/json&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Enable CORS: Cross Origin Resource Sharing</span></span><br><span class="line"><span class="meta">@CrossOrigin(origins=&quot;*&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DesignTacoController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> TacoRepository tacoRepo;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    EntityLinks entityLinks;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DesignTacoController</span><span class="params">(TacoRepository tacoRepo)</span> </span>&#123;</span><br><span class="line">    	<span class="keyword">this</span>.tacoRepo = tacoRepo;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterable&lt;Taco&gt; <span class="title">recentTacos</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">        <span class="keyword">return</span> tacoRepo.findAll(page).getContent();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>



<div class="note primary"><p><strong><code>@RestController = @Controller + @ResponseBody</code></strong></p>
<ul>
<li>  Marks a class for auto discovery by component scanning</li>
<li>  All returned value should be written directly to the <strong>response body</strong>.</li>
</ul>
</div>



<br>

<p><strong>Offer an endpoint that GET a single taco by ID</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注意： @PathVariable</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Taco <span class="title">tacoById</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// id is passed to findById() in Repository</span></span><br><span class="line">    <span class="comment">// Optional, because there may not be a taco with the given ID</span></span><br><span class="line">    Optional&lt;Taco&gt; optTaco = tacoRepo.findById(id);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (optTaco.isPresent())</span><br><span class="line">    	<span class="keyword">return</span> optTaco.get();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Problem:</strong></p>
<p>If we return <code>null</code>, the client receives a response with an <u>empty body and 200 OK</u>. The response cannot be used (since it’s empty), while the status indicates that everything is fine. So it’s better to return 404 for <code>null</code>.</p>
<br>

<p><strong>Improvement: Use <code>ResponseEntity</code> to indicate status</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ResponseEntity&lt;Taco&gt; <span class="title">tacoById</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Optional&lt;Taco&gt; optTaco = tacoRepo.findById(id);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (optTaco.isPresent())</span><br><span class="line">    	<span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;&gt;(optTaco.get(), HttpStatus.OK);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;&gt;(<span class="keyword">null</span>, HttpStatus.NOT_FOUND);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Post"><a href="#Post" class="headerlink" title="Post"></a><u>Post</u></h3><p><strong>Angular code for POST</strong></p>
<figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// onSubmit calls httpClient.POST</span></span><br><span class="line"><span class="function"><span class="title">onSubmit</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.httpClient.post(<span class="string">&#x27;http://localhost:8080/design&#x27;</span>,</span><br><span class="line">    	<span class="built_in">this</span>.model, &#123;</span><br><span class="line">    		<span class="attr">headers</span>: <span class="keyword">new</span> HttpHeaders().set(<span class="string">&#x27;Content-type&#x27;</span>, <span class="string">&#x27;application/json&#x27;</span>),</span><br><span class="line">   		&#125;).subscribe(<span class="function"><span class="params">taco</span> =&gt;</span> <span class="built_in">this</span>.cart.addToCart(taco));</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">this</span>.router.navigate([<span class="string">&#x27;/cart&#x27;</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Controller to POST client input</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注意，这里用的是 consumes，因为 receive input from client</span></span><br><span class="line"><span class="meta">@PostMapping(consumes=&quot;application/json&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// HTTP 201 CREATED, most descriptive than 200 OK</span></span><br><span class="line"><span class="meta">@ResponseStatus(HttpStatus.CREATED)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Taco <span class="title">postTaco</span><span class="params">(<span class="meta">@RequestBody</span> Taco taco)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> tacoRepo.save(taco);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong><code>@RequestBody</code></strong>: Ensures that <u>JSON in the request body is bound to the <code>Taco</code> object</u>. Without <code>@RequestBody</code>, Spring will bound request parameters to the <code>Taco</code> object.</p>
<br>

<p><strong><code>@ResponseStatus</code></strong>: Communicate with more descriptive and accurate status to the client.</p>
<br>

<h3 id="Put-amp-Patch"><a href="#Put-amp-Patch" class="headerlink" title="Put &amp; Patch"></a><u>Put &amp; Patch</u></h3><p>It’s true that PUT is often used to update resource data, but PUT is actually the <strong>semantic opposite of GET</strong> . GET requests are for transferring data from the server to the client, and PUT requests are for sending data from the client to the server.</p>
<p>In a sense, PUT is really intended to perform a <strong>wholesale replacement operation</strong> rather than an update operation. In contrast, the purpose of <strong>PATCH</strong> is to perform a <strong>patch or partial update</strong> of resource data. </p>
<p>Suppose we want to change the order’s address. One way is to use a PUT request like this:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PutMapping(&quot;/&#123;orderId&#125;&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Order <span class="title">putOrder</span><span class="params">(<span class="meta">@RequestBody</span> Order order)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> repo.save(order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <strong>Note:</strong> The request path. This is the same way paths are handled by GET.</p>
</blockquote>
<p>It would work, but it requires the client to submit the <strong>complete data</strong> in the PUT request. If any of the order’s properties are omitted, that property’s value would be <strong>overwritten to <code>null</code></strong>. </p>
<p>In this case, we will use PATCH for a partial update. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PatchMapping(path=&quot;/&#123;orderId&#125;&quot;, consumes=&quot;application/json&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Order <span class="title">patchOrder</span><span class="params">(<span class="meta">@PathVariable(&quot;orderId&quot;)</span> Long orderId, <span class="meta">@RequestBody</span> Order patch)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Order order = repo.findById(orderId).get();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (patch.getDeliveryName() != <span class="keyword">null</span>)</span><br><span class="line">    	order.setDeliveryName(patch.getDeliveryName());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (patch.getCcExpiration() != <span class="keyword">null</span>)</span><br><span class="line">    	order.setCcExpiration(patch.getCcExpiration());</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> repo.save(order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Even though PATCH semantically implies a partial update, it’s up to us to write code in the handler method that <u>actually performs such an update</u>. PATCH allows client to only send the properties that should be changed, and enables the server to retain other existing data.</p>
<p>However, PATCH has the following limitations:</p>
<ul>
<li>  If <code>null</code> means no change, then how will the client indicate that a field should be set to <code>null</code>?</li>
<li>  There’s no way of removing / adding a subset of items in a collection. If client wants to modify a collection, the entire altered collection should be sent.</li>
</ul>
<br>

<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a><u>Delete</u></h3><p><strong>Delete an order:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@DeleteMapping(&quot;/&#123;orderId&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Annotation! HTTP 204 No Content, but not 404!</span></span><br><span class="line"><span class="meta">@ResponseStatus(code=HttpStatus.NO_CONTENT)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Note: public VOID!</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteOrder</span><span class="params">(<span class="meta">@PathVariable(&quot;orderId&quot;)</span> Long orderId)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123; repo.deleteById(orderId); &#125; </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// catch the exception</span></span><br><span class="line">    <span class="keyword">catch</span> (EmptyResultDataAccessException e) &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Why <strong>catch that exception and do nothing</strong> with it: If you delete a resource that doesn’t exist, the outcome is the same as deleting it, so whether it existed before or not doesn’t matter. </p>
<p><strong>HTTP 204</strong>: Typically, DELETE requests have no body, and should only communicate the <strong>status code</strong> to let the client know not to expect any content.</p>
<br>

<h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a><u>Comparison</u></h3><p>Compare 5 types of HTTP requests in the controller:</p>
<div class="tabs" id="tab"><ul class="nav-tabs"><li class="tab"><a href="#tab-1"><b>Get</b></a></li><li class="tab active"><a href="#tab-2"><b>Post</b></a></li><li class="tab"><a href="#tab-3"><b>Put</b></a></li><li class="tab"><a href="#tab-4"><b>Patch</b></a></li><li class="tab"><a href="#tab-5"><b>Delete</b></a></li></ul><div class="tab-content"><div class="tab-pane" id="tab-1"><p><strong>GET 1:  Pagination</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Get recent designs</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(path=&quot;/design&quot;, produces=&quot;application/json&quot;)</span></span><br><span class="line"><span class="meta">@CrossOrigin(origins=&quot;*&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DesignTacoController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> TacoRepository tacoRepo;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DesignTacoController</span><span class="params">(TacoRepository tacoRepo)</span> </span>&#123;</span><br><span class="line">    	<span class="keyword">this</span>.tacoRepo = tacoRepo;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterable&lt;Taco&gt; <span class="title">recentTacos</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">        <span class="keyword">return</span> tacoRepo.findAll(page).getContent();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>GET 2: Response Entity</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Get signle taco by ID</span></span><br><span class="line"><span class="meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ResponseEntity&lt;Taco&gt; <span class="title">tacoById</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Optional&lt;Taco&gt; optTaco = tacoRepo.findById(id);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (optTaco.isPresent())</span><br><span class="line">    	<span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;&gt;(optTaco.get(), HttpStatus.OK);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;&gt;(<span class="keyword">null</span>, HttpStatus.NOT_FOUND);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane active" id="tab-2"><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Post client input</span></span><br><span class="line"><span class="meta">@PostMapping(consumes=&quot;application/json&quot;)</span></span><br><span class="line"><span class="meta">@ResponseStatus(HttpStatus.CREATED)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Taco <span class="title">postTaco</span><span class="params">(<span class="meta">@RequestBody</span> Taco taco)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> tacoRepo.save(taco);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-3"><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PutMapping(&quot;/&#123;orderId&#125;&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Order <span class="title">putOrder</span><span class="params">(<span class="meta">@RequestBody</span> Order order)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> repo.save(order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-4"><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PatchMapping(path=&quot;/&#123;orderId&#125;&quot;, consumes=&quot;application/json&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Order <span class="title">patchOrder</span><span class="params">(<span class="meta">@PathVariable(&quot;orderId&quot;)</span> Long orderId, <span class="meta">@RequestBody</span> Order patch)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Order order = repo.findById(orderId).get();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (patch.getDeliveryName() != <span class="keyword">null</span>)</span><br><span class="line">    	order.setDeliveryName(patch.getDeliveryName());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (patch.getCcExpiration() != <span class="keyword">null</span>)</span><br><span class="line">    	order.setCcExpiration(patch.getCcExpiration());</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> repo.save(order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-5"><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@DeleteMapping(&quot;/&#123;orderId&#125;&quot;)</span></span><br><span class="line"><span class="meta">@ResponseStatus(code=HttpStatus.NO_CONTENT)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteOrder</span><span class="params">(<span class="meta">@PathVariable(&quot;orderId&quot;)</span> Long orderId)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123; repo.deleteById(orderId); &#125; </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">catch</span> (EmptyResultDataAccessException e) &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></div></div>













<br>



<hr>
<h2 id="Using-Hypermedia"><a href="#Using-Hypermedia" class="headerlink" title="Using Hypermedia"></a>Using Hypermedia</h2><p>Hardcoding API URLs and using string manipulation on them makes the client code brittle. Hence <strong>HATEOAS</strong> (Hypermedia as the Engine of Application State) is for creating <strong>self-describing APIs</strong>, where resources returned from an API contain links to related<br>resources. </p>
<blockquote>
<p>  If the API is enabled with hypermedia, the API will describe its own URLs, relieving the client of needing to be hardcoded with that knowledge.</p>
</blockquote>
<p>This enables clients to navigate an API with <u>minimal understanding of the API’s URLs</u>. Instead, it <u>understands relationships between the resources served by the API</u>, and uses understanding of relationships to discover the API’s URLs, as it traverses those relationships.</p>
<br>

<h3 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a><u>Getting Started</u></h3><p>First, add HATEOAS to the dependency:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-hateoas<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>A comparison between non-Hateoas &amp; Hateoas:</p>
<blockquote>
<p>  The second one with hyperlinks is known as <strong>HAL</strong>  (Hypertext Application Language), a simple and commonly used format for <strong>embedding hyperlinks in JSON responses</strong>.</p>
</blockquote>
<br>

<h4 id="Normal-JSON"><a href="#Normal-JSON" class="headerlink" title="Normal JSON:"></a>Normal JSON:</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;id&quot;:</span> <span class="number">4</span>,</span><br><span class="line">        <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Veg-Out&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;createdAt&quot;:</span> <span class="string">&quot;2018-01-31T20:15:53.219+0000&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;ingredients&quot;:</span> [</span><br><span class="line">            &#123;<span class="attr">&quot;id&quot;:</span> <span class="string">&quot;FLTO&quot;</span>, <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Flour Tortilla&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;WRAP&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="attr">&quot;id&quot;:</span> <span class="string">&quot;COTO&quot;</span>, <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Corn Tortilla&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;WRAP&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="attr">&quot;id&quot;:</span> <span class="string">&quot;TMTO&quot;</span>, <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Diced Tomatoes&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;VEGGIES&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="attr">&quot;id&quot;:</span> <span class="string">&quot;LETC&quot;</span>, <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Lettuce&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;VEGGIES&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="attr">&quot;id&quot;:</span> <span class="string">&quot;SLSA&quot;</span>, <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Salsa&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;SAUCE&quot;</span>&#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">...</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<br>

<h4 id="With-Hyperlink"><a href="#With-Hyperlink" class="headerlink" title="With Hyperlink:"></a>With Hyperlink:</h4><p>Each element includes a property named <code>_links</code> that contains hyperlinks for the client to nagivate the API.</p>
<p>Should a client application need to perform an HTTP request against a taco in the list, it <u>doesn’t need to be developed with any knowledge of the taco resource’s URL</u>. Instead, it knows to <strong>ask for the self link</strong>, which maps to <a href="http://localhost:8080/design/4">http://localhost:8080/design/4</a>. If the client wants to deal with a particular ingredient, it only needs to <u>follow the self link for that ingredient</u>.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_embedded&quot;:</span> &#123;</span><br><span class="line">        <span class="attr">&quot;tacoResourceList&quot;:</span> [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Veg-Out&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;createdAt&quot;:</span> <span class="string">&quot;2018-01-31T20:15:53.219+0000&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;ingredients&quot;:</span> [</span><br><span class="line">                &#123;</span><br><span class="line">                	<span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Flour Tortilla&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;WRAP&quot;</span>,</span><br><span class="line">                	<span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">                		<span class="attr">&quot;self&quot;:</span> &#123; <span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/ingredients/FLTO&quot;</span> &#125;</span><br><span class="line">                	&#125;</span><br><span class="line">            	&#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                	<span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Corn Tortilla&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;WRAP&quot;</span>,</span><br><span class="line">               		<span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">                		<span class="attr">&quot;self&quot;:</span> &#123; <span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/ingredients/COTO&quot;</span> &#125;</span><br><span class="line">                	&#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                	<span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Diced Tomatoes&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;VEGGIES&quot;</span>,</span><br><span class="line">                	<span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">                		<span class="attr">&quot;self&quot;:</span> &#123; <span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/ingredients/TMTO&quot;</span> &#125;</span><br><span class="line">                	&#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                	<span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Lettuce&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;VEGGIES&quot;</span>,</span><br><span class="line">                	<span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">                		<span class="attr">&quot;self&quot;:</span> &#123; <span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/ingredients/LETC&quot;</span> &#125;</span><br><span class="line">                	&#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                	<span class="attr">&quot;name&quot;:</span> <span class="string">&quot;Salsa&quot;</span>, <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;SAUCE&quot;</span>,</span><br><span class="line">                	<span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">                		<span class="attr">&quot;self&quot;:</span> &#123; <span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/ingredients/SLSA&quot;</span> &#125;</span><br><span class="line">                	&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">                <span class="attr">&quot;self&quot;:</span> &#123; <span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/design/4&quot;</span> &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        	<span class="string">...</span></span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">    	<span class="attr">&quot;recents&quot;:</span> &#123;</span><br><span class="line">    		<span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/design/recent&quot;</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Adding-Hyperlinks"><a href="#Adding-Hyperlinks" class="headerlink" title="Adding Hyperlinks"></a><u>Adding Hyperlinks</u></h3><p>Spring HATEOAS provides two primary types that represent hyperlinked resources: <strong>Resource</strong> and <strong>Resources</strong>. The Resource type represents a single resource, whereas Resources is a collection of resources. When returned from a REST controller method, the links will be included in the JSON received by the client.</p>
<p>The <a href="#tab-1">original controller</a>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterable&lt;Taco&gt; <span class="title">recentTacos</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    <span class="keyword">return</span> tacoRepo.findAll(page).getContent();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The original implementation returned a <code>List&lt;Taco&gt;</code> , which was fine at the time. But we need to <strong>return a <code>Resources</code> object</strong> instead. Below is the first step:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();</span><br><span class="line">    </span><br><span class="line">    Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span><br><span class="line">    recentResources.add(<span class="keyword">new</span> Link(<span class="string">&quot;http://localhost:8080/design/recent&quot;</span>, <span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In this new version of <code>recentTacos()</code> , we no longer return the list of tacos directly. Instead, we use <code>Resources.wrap()</code> to wrap the list of tacos as an instance of <code>Resources&lt;Resource&lt;Taco&gt;&gt;</code> , which is ultimately returned from the method. </p>
<p>Before returning the Resources object, we add a link whose relationship name is <code>recents</code>, and whose URL is <a href="http://localhost:8080/design/recent">http://localhost:8080/design/recent</a>. The following JSON is included in the resource returned from the API request:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;_links&quot;:</span> &#123;</span><br><span class="line">    <span class="attr">&quot;recents&quot;:</span> &#123;</span><br><span class="line">    	<span class="attr">&quot;href&quot;:</span> <span class="string">&quot;http://localhost:8080/design/recent&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>At this point, the only added link is to the entire list; No links are added to the taco resources themselves, or to the ingredients of each taco. But first, we need to get rid of the hardcoded <code>localhost:8080</code>. </p>
<p>The Spring HATEOAS <strong>link builder</strong> provides <code>ControllerLinkBuilder</code>, and it knows what the hostname is without having to hardcode it. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();</span><br><span class="line">    Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Rewrite begins: Below is the previous line</span></span><br><span class="line">    <span class="comment">// recentResources.add(new Link(&quot;http://localhost:8080/design/recent&quot;, &quot;recents&quot;));</span></span><br><span class="line">    recentResources.add(ControllerLinkBuilder.linkTo(DesignTacoController.class)</span><br><span class="line">                        </span><br><span class="line">            <span class="comment">// Note slash; withRel: relation name is recents</span></span><br><span class="line">            .slash(<span class="string">&quot;recent&quot;</span>).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Now we get rid of the hardcoded hostname, and we also don’t have to specify the  <code>/design</code> path. Instead, we ask for a link to <code>DesignTacoController</code>, whose base path is <code>/design</code>. <code>ControllerLinkBuilder</code> uses the <u>controller’s base path</u> as the foundation of the Link object we’re creating.</p>
<br>

<p>Now we move one step further, and get rid of the <code>/recent</code> path as well.  We can call <code>linkTo()</code> by giving it a method on the controller to have <code>ControllerLinkBuilder</code> derive the <strong>base URL</strong> from both the controller’s base path and the method’s mapped path:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();  </span><br><span class="line">    Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Get rid of .slash</span></span><br><span class="line">    recentResources.add(linkTo(methodOn(DesignTacoController.class)</span><br><span class="line">                               .recentTacos()).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Now the <strong>entire URL is derived from the controller’s mappings</strong>. The <code>methodOn()</code> takes the controller class, and lets us make a call to the <code>recentTacos()</code> method, which is intercepted by <code>ControllerLinkBuilder</code> and used to determine both the <u>controller’s base path</u> and also the <u>path mapped to <code>recentTacos()</code></u> . </p>
<br>

<h3 id="Creating-Resource-Assemblers"><a href="#Creating-Resource-Assemblers" class="headerlink" title="Creating Resource Assemblers"></a><u>Creating Resource Assemblers</u></h3><p>Now we need to add links to the resource in the list. </p>
<p>One option is to loop through each of the <code>Resource&lt;Taco&gt;</code> elements in the Resources object, adding a Link to each individually. But we need to repeat the loop in the API wherever we return a list of taco resources.</p>
<p>Hence we’re going to define a utility class that <u>converts <code>Taco</code> objects to a new <code>TacoResource</code> object</u>.  The new <code>TacoResource</code> object will be able to <strong>carry links</strong>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// TacoResource: A Resource, Not a Domain!</span></span><br><span class="line"><span class="comment">// Extends: ResourceSupport</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TacoResource</span> <span class="keyword">extends</span> <span class="title">ResourceSupport</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Date createdAt;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Ingredient&gt; ingredients;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TacoResource</span><span class="params">(Taco taco)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = taco.getName();</span><br><span class="line">        <span class="keyword">this</span>.createdAt = taco.getCreatedAt();</span><br><span class="line">        <span class="keyword">this</span>.ingredients = taco.getIngredients();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Extends <code>ResourceSupport</code>: <u>Inherit a list of <code>Link</code> objects and methods</u>, to manage list of links.</p>
<p><strong>Note:</strong> <code>TacoResource</code> does not include the <code>id</code> property from <code>Taco</code>. There’s no need to expose any database-specific IDs in the API. The resource’s <u><code>self</code> link</u> will serve as the resource identifier.</p>
<div class="note primary"><p><strong>Domain &amp; Resource:</strong></p>
<p>Create a <strong>separate resource type</strong>, so that <code>Taco</code> isn’t unnecessarily cluttered with resource links where links aren’t needed. Also, leave the <code>id</code> property out so it won’t be exposed to the API.</p>
</div>



<p>Create a <strong>resource assembler</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Extend the superclass</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TacoResourceAssembler</span> <span class="keyword">extends</span> <span class="title">ResourceAssemblerSupport</span>&lt;<span class="title">Taco</span>, <span class="title">TacoResource</span>&gt; </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Default constructor to inform the superclass</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TacoResourceAssembler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(DesignTacoController.class, TacoResource.class);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> TacoResource <span class="title">instantiateResource</span><span class="params">(Taco taco)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> TacoResource(taco);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TacoResource <span class="title">toResource</span><span class="params">(Taco taco)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Get the ID</span></span><br><span class="line">        <span class="keyword">return</span> createResourceWithId(taco.getId(), taco);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The <strong>default constructor</strong>:  Informs the superclass ( <code>ResourceAssemblerSupport</code> ) that it will use <code>DesignTacoController</code> to <u>determine the base path</u> for any URLs in links it creates, when creating a <code>TacoResource</code>.</p>
<p>The <code>instantiateResource()</code> method is overridden: Given a <code>Taco</code>, instantiate a <code>TacoResource</code>. This method would be optional if <code>TacoResource</code> had a default constructor. In this case, <code>TacoResource</code> requires construction with a Taco , so we’re required to override it.</p>
<p>The <code>toResource()</code> method is the only method that’s <strong>strictly mandatory</strong> when extending <code>ResourceAssemblerSupport</code>. Here we create a <code>TacoResource</code> object from a <code>Taco</code> , and automatically give it a <strong>self link</strong> with the <strong>derived URL</strong> from the <code>id</code> property.</p>
<p>On the surface, <code>toResource()</code> seems similar to <code>instantiateResource()</code>, but they’re different. Under the covers, <code>toResource()</code> will call <code>instantiateResource()</code>.<code>instantiateResource()</code> only <u>instantiates a Resource object</u>, while <code>toResource()</code> both <u>creates the Resource object</u>, and <u>populates it with links</u>. </p>
<br>

<p>Now, use <code>TacoResourceAssembler</code> in the controller:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Rewrite this line below: Use Resource Assembler</span></span><br><span class="line">    <span class="comment">// Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span></span><br><span class="line">    </span><br><span class="line">    List&lt;TacoResource&gt; tacoResources = <span class="keyword">new</span> TacoResourceAssembler().toResources(tacos);</span><br><span class="line">    Resources&lt;TacoResource&gt; recentResources = <span class="keyword">new</span> Resources&lt;TacoResource&gt;(tacoResources);</span><br><span class="line">    </span><br><span class="line">    recentResources.add(linkTo(methodOn(DesignTacoController.class)</span><br><span class="line">                               .recentTacos()).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Rather than return <code>Resources&lt;Resource&lt;Taco&gt;&gt;</code>, <code>recentTacos()</code> now returns <code>Resources&lt;TacoResource&gt;</code> to take advantage of the new <code>TacoResource</code> type. </p>
<p>After fetching the tacos from the repository, we pass the list of Taco objects to the <code>toResources()</code> method on a <code>TacoResourceAssembler</code>, which will cycle through all <code>Taco</code> objects, calling the overridden <code>toResource </code>  method to create a list of <code>TacoResource</code> objects.</p>
<p>With that <code>TacoResource</code> list, we then create a <code>Resources&lt;TacoResource&gt;</code> object, and populate it with the <code>recents</code> links.</p>
<br>

<p>At this point, a GET request to <code>/design/recent</code> will produce a list of tacos, each with a self link and a <code>recents</code> link on the list itself. But the <u>ingredients will still be without a lin</u>k. Therefore, we first create the <strong><code>IngredientResource</code> object</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IngredientResource</span> <span class="keyword">extends</span> <span class="title">ResourceSupport</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> Type type;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IngredientResource</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = ingredient.getName();</span><br><span class="line">        <span class="keyword">this</span>.type = ingredient.getType();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>



<p>Then create a new <strong>resource assembler for ingredients</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IngredientResourceAssembler</span> <span class="keyword">extends</span> <span class="title">ResourceAssemblerSupport</span>&lt;<span class="title">Ingredient</span>, <span class="title">IngredientResource</span>&gt; </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IngredientResourceAssembler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(IngredientController.class, IngredientResource.class);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> IngredientResource <span class="title">toResource</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> createResourceWithId(ingredient.getId(), ingredient);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> IngredientResource <span class="title">instantiateResource</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> IngredientResource(ingredient);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p>Slightly change <code>TacoResource</code>, so it carries <code>IngredientResource</code> objects instead of <code>Ingredient</code> objects:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TacoResource</span> <span class="keyword">extends</span> <span class="title">ResourceSupport</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Uses toResource() to convert a Taco object’s Ingredient list to IngredientResource list</span></span><br><span class="line">    <span class="comment">// Add this</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> IngredientResourceAssembler ingredientAssembler = <span class="keyword">new</span> IngredientResourceAssembler();</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Date createdAt;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Modify this</span></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;IngredientResource&gt; ingredients;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TacoResource</span><span class="params">(Taco taco)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = taco.getName();</span><br><span class="line">        <span class="keyword">this</span>.createdAt = taco.getCreatedAt();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Modify this</span></span><br><span class="line">        <span class="keyword">this</span>.ingredients = ingredientAssembler.toResources(taco.getIngredients());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Now the recent tacos list is completely outfitted with hyperlinks, not only for the <code>recents</code> link, but also for all of its taco entries and the ingredients of those tacos. The response should look a lot like the <a href="#With-Hyperlink">JSON in here</a>.</p>
<br>

<h3 id="Naming-Embedded-Relations"><a href="#Naming-Embedded-Relations" class="headerlink" title="Naming Embedded Relations"></a><u>Naming Embedded Relations</u></h3><p>If we take a closer look at the <a href="#With-Hyperlink">JSON in here</a>. we notice that the top-level elements look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_embedded&quot;:</span> &#123;</span><br><span class="line">        <span class="attr">&quot;tacoResourceList&quot;:</span> [</span><br><span class="line">        &#123;	<span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>The name <code>tacoResourceList</code>was based on creating <code>Resources</code> object from <code>List&lt;TacoResources&gt;</code>. If we were to refactor the<br>name of the <code>TacoResource</code> class to something else, the field name in the resulting JSON would <strong>change to match it</strong>. This would likely <u>break the clients code that were counted on that name</u>.</p>
<p>To tackle this problem, we use <code>@Relation</code> to help <strong>break the coupling</strong> between <u>JSON field name</u> and <u>resource type class names</u>. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Relation(value=&quot;taco&quot;, collectionRelation=&quot;tacos&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TacoResource</span> <span class="keyword">extends</span> <span class="title">ResourceSupport</span> </span>&#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>Here we’ve specified that when a list of <code>TacoResource</code> objects is used in a Resources object, it should be named <strong>tacos</strong>. And a single <code>TacoResource</code> object should be referred to in JSON as <strong>taco</strong> . Now the returned JSON looks like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_embedded&quot;:</span> &#123;</span><br><span class="line">        <span class="attr">&quot;tacos&quot;:</span> [</span><br><span class="line">        &#123;	<span class="string">...</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="Controller-Evolution"><a href="#Controller-Evolution" class="headerlink" title="Controller Evolution"></a><u>Controller Evolution</u></h3><p>The evolution of a controller method with HATEOAS:</p>
<div class="tabs" id="tab"><ul class="nav-tabs"><li class="tab"><a href="#tab-1"><font style="color:white">.</font></a></li><li class="tab"><a href="#tab-2"><font style="color:white">.</font></a></li><li class="tab"><a href="#tab-3"><font style="color:white">.</font></a></li><li class="tab"><a href="#tab-4"><font style="color:white">.</font></a></li><li class="tab"><a href="#tab-5"><font style="color:white">.</font></a></li><li class="tab active"><a href="#tab-6"><b>Original</b></a></li><li class="tab"><a href="#tab-7"><b>Step 1</b></a></li><li class="tab"><a href="#tab-8"><b>Step 2</b></a></li><li class="tab"><a href="#tab-9"><b>Step 3</b></a></li><li class="tab"><a href="#tab-10"><b>Step 4</b></a></li></ul><div class="tab-content"><div class="tab-pane" id="tab-1"></div><div class="tab-pane" id="tab-2"></div><div class="tab-pane" id="tab-3"></div><div class="tab-pane" id="tab-4"></div><div class="tab-pane" id="tab-5"></div><div class="tab-pane active" id="tab-6"><p>Return list of tacos directly.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Get recent designs, with pagination</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterable&lt;Taco&gt; <span class="title">recentTacos</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    <span class="keyword">return</span> tacoRepo.findAll(page).getContent();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-7"><p>Wrap the list, but still has hardcoded URL.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();  </span><br><span class="line">    </span><br><span class="line">    Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Still hardcoded URL</span></span><br><span class="line">    recentResources.add(<span class="keyword">new</span> Link(<span class="string">&quot;http://localhost:8080/design/recent&quot;</span>, <span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-8"><p>Partially get rid of the hardcoded URL.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();  </span><br><span class="line">    </span><br><span class="line">    Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Rewrite: hostname &amp; /design</span></span><br><span class="line">    recentResources.add(ControllerLinkBuilder.linkTo(DesignTacoController.class)</span><br><span class="line">                        .slash(<span class="string">&quot;recent&quot;</span>).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-9"><p>Get rid of all hardcoded URL.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();  </span><br><span class="line">    </span><br><span class="line">    Resources&lt;Resource&lt;Taco&gt;&gt; recentResources = Resources.wrap(tacos);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Rewrite: /recent, use static method of link builder</span></span><br><span class="line">    recentResources.add(linkTo(methodOn(DesignTacoController.class)</span><br><span class="line">                               .recentTacos()).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="tab-10"><p>Add Resource Assembler.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/recent&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Resources&lt;Resource&lt;Taco&gt;&gt; recentTacos() &#123;</span><br><span class="line">    </span><br><span class="line">    PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">    List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Rewrite: Use Resource Assembler</span></span><br><span class="line">    List&lt;TacoResource&gt; tacoResources = <span class="keyword">new</span> TacoResourceAssembler().toResources(tacos);</span><br><span class="line">    Resources&lt;TacoResource&gt; recentResources = <span class="keyword">new</span> Resources&lt;TacoResource&gt;(tacoResources);</span><br><span class="line">    </span><br><span class="line">    recentResources.add(linkTo(methodOn(DesignTacoController.class)</span><br><span class="line">                               .recentTacos()).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> recentResources;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></div></div>





<br>





<hr>
<h2 id="Spring-Data-REST"><a href="#Spring-Data-REST" class="headerlink" title="Spring Data REST"></a>Spring Data REST</h2><p>Spring HATEOAS makes adding links to your API rather straightforward and simple, but it did add several lines of code that we otherwise do not need. However, if we want to be lazy, then let’s see how <strong>Spring Data REST</strong> can automatically create APIs based on the data repositories we’ve created.</p>
<div class="note success"><p>With Spring Data REST, there’s no need to create Rest Controllers.</p>
</div>

<p>Spring Data REST is another member of the Spring Data family that <strong>automatically creates REST APIs for repositories created by Spring Data</strong>. By only adding Spring Data REST to the build, we get an exposed REST API with operations for each repository interface we’ve defined. </p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-rest<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>We need to set a <strong>base path</strong> for the API, so the endpoints are all distinct:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring.data.rest.basepath:</span> <span class="string">/api</span></span><br></pre></td></tr></table></figure>

<p>And make requests such as:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">curl</span> <span class="string">localhost:8080/api</span></span><br><span class="line"><span class="string">curl</span> <span class="string">localhost:8080/api/orders</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Adjust-Resource-Paths-amp-Relation-Names"><a href="#Adjust-Resource-Paths-amp-Relation-Names" class="headerlink" title="Adjust Resource Paths &amp; Relation Names"></a><u>Adjust Resource Paths &amp; Relation Names</u></h3><p>When creating endpoints for Spring Data repositories, Spring Data REST will pluralize the associated entity class. For instance, <code>/users</code> for User Entity, <code>/tacoes</code> for Taco Entity (tacoes, not tacos).</p>
<p>However, the correct spelling should be <code>tacos</code>. Hence we modify the <code>Taco</code> Entity class by adding the following annotation:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestResource(rel=&quot;tacos&quot;, path=&quot;tacos&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Taco</span> </span>&#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>Setting this would give the result:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;tacos&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">    <span class="string">&quot;href&quot;</span> <span class="string">:</span> <span class="string">&quot;http://localhost:8080/api/tacos&#123;?page,size,sort&#125;&quot;</span>,</span><br><span class="line">    <span class="string">&quot;templated&quot;</span> <span class="string">:</span> <span class="literal">true</span></span><br><span class="line">&#125;<span class="string">,</span></span><br></pre></td></tr></table></figure>





<br>

<h3 id="Paging-amp-Sorting"><a href="#Paging-amp-Sorting" class="headerlink" title="Paging &amp; Sorting"></a><u>Paging &amp; Sorting</u></h3><p>We noticed that the link above contains paths to <code>page</code>, <code>size</code>, and <code>sort</code>. By default, requests to a collection resource such as <code>/api/tacos</code> will return <strong>20</strong> items per page. But we can customize it:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 5 items per page, only dispay the 2nd page（页数从0算起）</span></span><br><span class="line"><span class="string">curl</span> <span class="string">localhost:8080/api/tacos?size=5&amp;page=1</span></span><br></pre></td></tr></table></figure>

<p>And HATEOAS will offer links for the <u>first, last, next, previous</u> pages in the response.</p>
<br>

<p>The <code>sort</code> parameter lets us sort the result. For instance, we need to fetch the <u>12 most recently created tacos</u>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">curl</span> <span class="string">localhost:8080/api/tacos?sort=createdAt,desc&amp;page=0&amp;size=12</span></span><br></pre></td></tr></table></figure>

<p>However the only problem left is that, the UI client still uses hardcoded request. So it’s better to make the client <u>look up the URL from a list of links</u>, hence we need to add custom endpoints &amp; links.</p>
<br>

<h3 id="Add-Custom-Endpoints-amp-Links"><a href="#Add-Custom-Endpoints-amp-Links" class="headerlink" title="Add Custom Endpoints &amp; Links"></a><u>Add Custom Endpoints &amp; Links</u></h3><p>When we write our own API controllers along with the ones provided by Spring Data REST, there are 2 problems:</p>
<ul>
<li>  Our own controller endpoints <u>aren’t mapped under Spring Data REST’s base path</u>. We can force mappings to be prefixed with the base path. But if the base path changes, we need to also change the base path in the controllers.</li>
<li>  Any endpoints defined in the controllers won’t be automatically included as hyperlinks. This means that <u>clients won’t be able to discover the custom endpoints with a <strong>relation name</strong></u>.</li>
</ul>
<p>We first solve the problem of the base path. Spring Data REST includes a new controller called <code>@RepositoryRestController</code>. It annotates the controller class, and all mapping will have the same base path as in Spring Data REST. </p>
<p>Then we dump the old <code>DesignTacoController</code> and create the new controller that only contains <code>recentTacos()</code> method:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Make sure the path will be: /api/tacos/recent</span></span><br><span class="line"><span class="meta">@RepositoryRestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RecentTacosController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> TacoRepository tacoRepo;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RecentTacosController</span><span class="params">(TacoRepository tacoRepo)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.tacoRepo = tacoRepo;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// produces: hal &amp; json</span></span><br><span class="line">    <span class="meta">@GetMapping(path=&quot;/tacos/recent&quot;, produces=&quot;application/hal+json&quot;)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Add Response Entity</span></span><br><span class="line">    <span class="comment">// Or: @ResponseBody</span></span><br><span class="line">    <span class="keyword">public</span> ResponseEntity&lt;Resources&lt;TacoResource&gt;&gt; recentTacos() &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 和之前一样</span></span><br><span class="line">        PageRequest page = PageRequest.of(<span class="number">0</span>, <span class="number">12</span>, Sort.by(<span class="string">&quot;createdAt&quot;</span>).descending());</span><br><span class="line">        List&lt;Taco&gt; tacos = tacoRepo.findAll(page).getContent();</span><br><span class="line">        </span><br><span class="line">        List&lt;TacoResource&gt; tacoResources = <span class="keyword">new</span> TacoResourceAssembler().toResources(tacos);</span><br><span class="line">        Resources&lt;TacoResource&gt; recentResources = <span class="keyword">new</span> Resources&lt;TacoResource&gt;(tacoResources);</span><br><span class="line">        </span><br><span class="line">        recentResources.add(linkTo(methodOn(RecentTacosController.class)</span><br><span class="line">                                   .recentTacos()).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 就这一行不一样，因为 Add Response Entity</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;&gt;(recentResources, HttpStatus.OK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Note:</strong></p>
<blockquote>
<p>  <code>@RepositoryRestController</code> doesn’t assures that returned values are written to the response body, hence we need to  either add <code>ResponseEntity</code>, or use the class-level <code>@ResponseBody</code>. </p>
</blockquote>
<br>

<p>Now we deal with the hyperlinks when clients search for relations, to make the custom endpoints appear in the hyperlinks list when client requests <code>/api/tacos</code>. In this case, we need a <strong>resource processor bean</strong>. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringDataRestConfiguration</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Declared as bean to be created in the spring application context</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ResourceProcessor&lt;PagedResources&lt;Resource&lt;Taco&gt;&gt;&gt; tacoProcessor(EntityLinks links) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Defined as anonymous inner class</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ResourceProcessor&lt;PagedResources&lt;Resource&lt;Taco&gt;&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> PagedResources&lt;Resource&lt;Taco&gt;&gt; process(PagedResources&lt;Resource&lt;Taco&gt;&gt; resource) &#123;</span><br><span class="line">                resource.add(links.linkFor(Taco.class).slash(<span class="string">&quot;recent&quot;</span>).withRel(<span class="string">&quot;recents&quot;</span>));</span><br><span class="line">                <span class="keyword">return</span> resource;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Spring HATEOAS will auto discover the <code>ResrouceProcessor</code> Bean(s), and will apply them to the appropriate resources. </p>
<p>In this case, if a <code>PagedResources&lt;Resource&lt;Taco&gt;&gt;</code> is returned from a controller, it will receive a link for the most recently created tacos. This includes the response from requests for <code>/api/tacos</code>.</p>
<br>

<br>

]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Angular</tag>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 05 Configurations</title>
    <url>/2020/SpringBoot-05/</url>
    <content><![CDATA[<p>This is the fifth post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English.  In this post, I am going to cover Spring Boot’s configurations.</p>
<p>Configuration properties are nothing more than <strong>properties on beans in the Spring application context</strong>, that can be set from one of several property sources, including <strong>JVM system properties</strong>, <strong>command-line arguments</strong>, and <strong>environment variables</strong>.</p>
<span id="more"></span> 

<br>



<hr>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>  Spring beans can be annotated with <code>@ConfigurationProperties</code> to enable <strong>injection of values</strong> from one of several property sources.</li>
</ul>
<br>

<ul>
<li>  Configuration properties can be set in command-line arguments, environment variables, JVM system properties, properties files, or <code>yml</code> files.</li>
</ul>
<br>

<ul>
<li>  Configuration properties can be used to <strong>override autoconfig settings</strong>, including the ability to specify a data-source URL and logging levels.</li>
</ul>
<br>

<ul>
<li>  <strong>Spring profiles</strong> can be used with <strong>property sources</strong> to conditionally set configuration properties based on the active profiles.</li>
</ul>
<br>

<br>

<hr>
<h2 id="The-Context"><a href="#The-Context" class="headerlink" title="The Context"></a>The Context</h2><p>There are two different kinds of configurations in Spring, namely:</p>
<ul>
<li>  <strong>Bean wiring</strong>:  Mandate application <u>components to be created as beans</u> in the Spring application context, and how they should be injected into each other.</li>
<li>  <strong>Property  injection</strong>:  sets values on beans in the Spring application context.</li>
</ul>
<p>In Spring’s XML and Java-based configuration, these two types of configurations are often declared explicitly in the same place. In Java configuration, an <code>@Bean</code>-annotated method is likely to both <strong>instantiate a bean</strong> and then <strong>set values to its properties</strong>. </p>
<br>

<p>For example, the following <code>@Bean</code> method declares a <code>DataSource</code> for an embedded H2 database: </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> DataSource <span class="title">dataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> EmbeddedDataSourceBuilder()</span><br><span class="line">        .setType(H2)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// set String properties with the name of SQL scripts</span></span><br><span class="line">        .addScript(<span class="string">&quot;taco_schema.sql&quot;</span>)</span><br><span class="line">        .addScripts(<span class="string">&quot;user_data.sql&quot;</span>, <span class="string">&quot;ingredient_data.sql&quot;</span>)</span><br><span class="line">        .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<div class="note default"><p>The config above only applies in older version. This is completely unnecessary in Spring Boot.</p>
<p>If the H2 dependency is available in the <strong>runtime classpath</strong>, then Spring Boot automatically creates an appropriate <code>DataSource</code> bean in the <u>Spring application context</u>.</p>
</div>

<br>

<p>The <strong>Spring environment abstraction</strong> abstracts the origins of properties, so that beans can consume properties from Spring itself. Spring pulls from several property sources, then <strong>aggregates those properties into a single source</strong> from which Spring beans can be injected.</p>
<ul>
<li>  JVM system properties</li>
<li>  OS environment variables</li>
<li>  Command-line arguments</li>
<li>  Application property configuration files ( <code>application.yml</code> )</li>
</ul>
<p><img data-src="/images/posts/200502-1.png"></p>
<p><strong>Example</strong>: 4 ways of specifying a server port:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. application.properties</span></span><br><span class="line"><span class="string">server.port=9090</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. application.yml</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">9090</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 3. Externally (command-line argument)</span></span><br><span class="line"><span class="string">java</span> <span class="string">-jar</span> <span class="string">cloud-0.0.1-SNAPSHOT.jar</span> <span class="string">--server.port=9090</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Set OS Environment variable</span></span><br><span class="line"><span class="comment">#   (Spring will interpret SERVER_PORT as server.port with no problem)</span></span><br><span class="line"><span class="string">export</span> <span class="string">SERVER_PORT=9090</span></span><br></pre></td></tr></table></figure>



<br>

<hr>
<h2 id="Fine-tuning-Autoconfig"><a href="#Fine-tuning-Autoconfig" class="headerlink" title="Fine-tuning Autoconfig"></a>Fine-tuning Autoconfig</h2><h3 id="Datasource"><a href="#Datasource" class="headerlink" title="Datasource"></a><u>Datasource</u></h3><p>Configure an external database:</p>
<blockquote>
<p>  <em>JDBC driver class is <strong>not needed</strong>. Spring can figure out from the database URL.</em></p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">jdbc:mysql://localhost/cloud</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">password:</span></span><br></pre></td></tr></table></figure>

<p> Spring Boot uses this connection data when <u>autoconfiguring the <code>Datasource</code> bean</u>. This bean will be pooled using Tomcat’s <strong>JDBC connection pool (CP)</strong> if it’s available on the classpath. If it’s not availbale, Spring will choose from other connection pool implementation in the classpath:</p>
<ul>
<li>  HikariCP</li>
<li>  Commons DBCP 2</li>
</ul>
<br>

<p>The way to specify database initialization scripts:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">schema:</span>		<span class="comment"># main/resources</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">schema-1.sql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">schema-2.sql</span></span><br><span class="line">    <span class="attr">data:</span>		<span class="comment"># main/resources</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">data-1.sql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">data-2.sql</span></span><br></pre></td></tr></table></figure>

<br>

<p>Configure datasource in <strong>JNDI</strong>, and have Spring look it up from there.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># JNDI will override other datasource properties</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">jndi-name:</span> <span class="string">java:/comp/env/jdbc/cloudDS</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Embedded-Server"><a href="#Embedded-Server" class="headerlink" title="Embedded Server"></a><u>Embedded Server</u></h3><p>If we set port to 0, then Spring will start on a <strong>randomly chosen available</strong> port. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server.port:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>This is useful when running automated integration tests, to ensure that any concurrently running tests don’t clash on a hard-coded port number.</p>
<br>

<p><strong>Set up the container servlet to handle HTTPS requests.</strong> </p>
<p>First step, create a <strong>keystore</strong> using JDK’s <code>keytool</code>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ keytool -keystore mykeys.jks -genkey -<span class="built_in">alias</span> tomcat -keyalg RSA</span><br></pre></td></tr></table></figure>

<p>Set properties to enable HTTPS:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8443</span></span><br><span class="line">  <span class="attr">ssl:</span></span><br><span class="line">    <span class="comment"># file://URL</span></span><br><span class="line">    <span class="attr">key-store:</span> <span class="string">file:///home/merikanto/mykeys.jks</span></span><br><span class="line">    <span class="attr">key-store-password:</span> <span class="string">passwd</span></span><br><span class="line">    <span class="attr">key-password:</span> <span class="string">passwd</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a><u>Logging</u></h3><p>Spring Boot configures logging via <strong>Logback</strong>, and the logging level is <strong>INFO</strong> by default. </p>
<p>For full control, we can create <code>logback.xml</code> under the <strong>root of classpath</strong> (<code>src/main/resources</code>).</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;STDOUT&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.ConsoleAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span></span><br><span class="line">            	%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n</span><br><span class="line">            <span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">&quot;root&quot;</span> <span class="attr">level</span>=<span class="string">&quot;INFO&quot;</span>/&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">&quot;INFO&quot;</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>Partial config in <code>application.yml</code>:</p>
<blockquote>
<p>  <em>Specify my own path &amp; file name, customize logging levels.</em></p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">logging:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">/home/merikanto/logs/</span></span><br><span class="line">  <span class="attr">file:</span> <span class="string">Cloud.log</span></span><br><span class="line">  <span class="attr">level:</span></span><br><span class="line">    <span class="attr">root:</span> <span class="string">WARN</span></span><br><span class="line">    <span class="attr">org.springframework.security:</span> <span class="string">DEBUG</span></span><br></pre></td></tr></table></figure>



<p>Use special property values, <strong><code>$&#123; &#125;</code></strong> as the placeholder marker.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">greeting:</span></span><br><span class="line">  <span class="attr">welcome:</span> <span class="string">You</span> <span class="string">are</span> <span class="string">using</span> <span class="string">$&#123;spring.application.name&#125;.</span></span><br></pre></td></tr></table></figure>



<br>

<hr>
<h2 id="Create-Custom-Config"><a href="#Create-Custom-Config" class="headerlink" title="Create Custom Config"></a>Create Custom Config</h2><div class="note primary"><p><strong>Configuration properties</strong> are properties of beans, that have been designated to accept configurations from Spring’s environment abstraction.</p>
</div>



<p>Spring Boot use <code>@ConfigurationProperties</code> to support <strong>property injection of configuration properties</strong>. When placed on any Spring bean, it specifies that the properties of that bean can be injected from Spring environment properties. We will use an example to explain the process: <strong>Customize pagination properties</strong>.</p>
<br>



<h3 id="Customize-Pagination"><a href="#Customize-Pagination" class="headerlink" title="Customize Pagination"></a><u>Customize Pagination</u></h3><p><strong>Sample Repository &amp; Controller:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Respository</span></span><br><span class="line"><span class="function">List&lt;Order&gt; <span class="title">findByUserOrderByPlacedAtDesc</span><span class="params">(User user)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Controller</span></span><br><span class="line"><span class="meta">@GetMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ordersForUser</span><span class="params">(<span class="meta">@AuthenticationPrincipal</span> User user, Model model)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    model.addAttribute(<span class="string">&quot;orders&quot;</span>, orderRepo.findByUserOrderByPlacedAtDesc(user));</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;orderList&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Add hard-coded Pagination:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Respository</span></span><br><span class="line"><span class="comment">// Changed the signature of this method by adding @param Pageable</span></span><br><span class="line"><span class="function">List&lt;Order&gt; <span class="title">findByUserOrderByPlacedAtDesc</span><span class="params">(User user, Pageable pageable)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Controller</span></span><br><span class="line"><span class="meta">@GetMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ordersForUser</span><span class="params">(<span class="meta">@AuthenticationPrincipal</span> User user, Model model)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Pagination</span></span><br><span class="line">    Pageable pageable = PageRequest.of(<span class="number">0</span>, <span class="number">20</span>);</span><br><span class="line">    model.addAttribute(<span class="string">&quot;orders&quot;</span>, orderRepo.findByUserOrderByPlacedAtDesc(user, pageable));</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;orderList&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Add <code>pageSize</code>, so pagination is not hard-coded</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Repository is the same as above; Controller is below</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/orders&quot;)</span></span><br><span class="line"><span class="meta">@SessionAttributes(&quot;order&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// This annotation! Custom Configuration!</span></span><br><span class="line"><span class="meta">@ConfigurationProperties(prefix=&quot;taco.orders&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// pageSize, the added property</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> pageSize = <span class="number">20</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPageSize</span><span class="params">(<span class="keyword">int</span> pageSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.pageSize = pageSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">ordersForUser</span><span class="params">(<span class="meta">@AuthenticationPrincipal</span> User user, Model model)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// PageRequest.of</span></span><br><span class="line">        Pageable pageable = PageRequest.of(<span class="number">0</span>, pageSize);</span><br><span class="line">    </span><br><span class="line">        model.addAttribute(<span class="string">&quot;orders&quot;</span>, orderRepo.findByUserOrderByPlacedAtDesc(user, pageable));</span><br><span class="line">    	<span class="keyword">return</span> <span class="string">&quot;orderList&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>@ConfigurationProperties</code> are in fact often placed on beans, whose sole purpose in the application is to be <strong>holders of configuration data</strong>. This keeps configuration-specific details out of the controllers and other application classes. </p>
<br>

<p><strong>Add to <code>application.yml</code></strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">taco.orders.pageSize:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Or export as environmental variable:</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">export</span> TACO_ORDERS_PAGESIZE=10</span><br></pre></td></tr></table></figure>

<div class="note info"><p>Note that in the Controller, we set <code>pageSize = 20</code>. But that doesn’t matter, because properties in <code>application.yml</code> will override the code in controller. </p>
</div>

<br>

<p><strong>Another way: Extract the pagination config to a separate Entity class</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Entity class, using Lombok</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Enable component scanning</span></span><br><span class="line"><span class="comment">// Spring will auto discover and create it as a bean in the application context</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConfigurationProperties(prefix=&quot;taco.orders&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderProps</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> pageSize = <span class="number">20</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Use it in Controller</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/orders&quot;)</span></span><br><span class="line"><span class="meta">@SessionAttributes(&quot;order&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> OrderRepository orderRepo;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> OrderProps props;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Constructor with the two parameters above</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">OrderController</span><span class="params">(OrderRepository orderRepo, OrderProps props)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.orderRepo = orderRepo;</span><br><span class="line">        <span class="keyword">this</span>.props = props;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">ordersForUser</span><span class="params">(<span class="meta">@AuthenticationPrincipal</span> User user, Model model)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 注意右边，改变的是 props.getPageSize()</span></span><br><span class="line">        Pageable pageable = PageRequest.of(<span class="number">0</span>, props.getPageSize());</span><br><span class="line">    </span><br><span class="line">        model.addAttribute(<span class="string">&quot;orders&quot;</span>, orderRepo.findByUserOrderByPlacedAtDesc(user, pageable));</span><br><span class="line">    	<span class="keyword">return</span> <span class="string">&quot;orderList&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>👉 Now Order Controller is no longer responsible for handling its own configuration properties. This keeps the code in Controller neater,  and allows you to <strong>reuse the properties</strong> in <code>OrderProps</code> in any other beans.</p>
<br>

<p><strong>New Rules:</strong> Apply validation to page size.  <strong>Only need to modify <code>OrderProps</code> Entity.</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConfigurationProperties(prefix=&quot;taco.orders&quot;)</span></span><br><span class="line"><span class="meta">@Validated</span>	<span class="comment">// 这个 Annotation 加上</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderProps</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 加上这两行</span></span><br><span class="line">    <span class="meta">@Min(value=5, message=&quot;must be between 5 and 25&quot;)</span></span><br><span class="line">    <span class="meta">@Max(value=25, message=&quot;must be between 5 and 25&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> pageSize = <span class="number">20</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Declare-Property-Metadata"><a href="#Declare-Property-Metadata" class="headerlink" title="Declare Property Metadata"></a><u>Declare Property Metadata</u></h3><p>In <code>application.yml</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pageSize is equivalent to page-size</span></span><br><span class="line"><span class="attr">taco.order.page-size:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p><strong>Warning</strong>: Spring Boot configuration <a href="https://docs.spring.io/spring-boot/docs/2.1.4.RELEASE/reference/html/configuration-metadata.html#configuration-metadata-annotation-processor"><strong>annotation processor not configured</strong></a>.</p>
<p>Because there’s missing metadata about the configuration property. Therefore we add metadata in <code>/resources/META-INF</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;properties&quot;:</span> [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;taco.orders.page-size&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;java.lang.String&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;description&quot;:</span> <span class="string">&quot;Sets maximum number of orders to display in a list.&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">] &#125;</span><br></pre></td></tr></table></figure>



<br>

<hr>
<h2 id="Config-with-Profiles"><a href="#Config-with-Profiles" class="headerlink" title="Config with Profiles"></a>Config with Profiles</h2><p>When applications are deployed to different run-time environments, usually some configuration details differ. Therefore, we can use <strong>Spring profiles</strong> . Profiles are a type of <strong>conditional configuration</strong> where different beans, configuration classes, and configuration properties are applied or ignored based on what profiles are <strong>active</strong> at runtime.</p>
<br>

<h3 id="Define-Profile-Specific-Properties"><a href="#Define-Profile-Specific-Properties" class="headerlink" title="Define Profile-Specific Properties"></a><u>Define Profile-Specific Properties</u></h3><p>Old way of configuring different profiles:</p>
<blockquote>
<p>  Use <code>application-&#123;profile name&#125;.yml</code> for different profiles.</p>
</blockquote>
<br>

<p>An easier way to specify profile-specific properties, in just one file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">logging.level.tacos:</span> <span class="string">DEBUG</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Profile 之间用横线隔开</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="comment"># Production profile, separate from the profile above</span></span><br><span class="line">  <span class="attr">profiles:</span> <span class="string">prod</span>	</span><br><span class="line"></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://localhost/cloud</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">logging.level.tacos:</span> <span class="string">WARN</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Activate-Profiles"><a href="#Activate-Profiles" class="headerlink" title="Activate Profiles"></a><u>Activate Profiles</u></h3><p>If we simply set it this way:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring.profiles.active:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">prod</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">audit</span></span><br></pre></td></tr></table></figure>

<p>Then <code>prod</code> became the default profile, and we didn’t achieve the benefit of separating production-specific profiles from dev ones. Therefore, it’s <strong>better to set the active profiles with environment variables</strong>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">export</span> SPRING_PROFILES_ACTIVE=prod,audit</span><br></pre></td></tr></table></figure>

<p><strong>With <code>JAR</code>:</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ java -jar cloud.jar --spring.profiles.active=prod,audit</span><br></pre></td></tr></table></figure>

<br>

<p>If we deploy to <strong>Cloud Foundry</strong>, a profile named <strong>cloud</strong> is automatically activated. If Cloud Foundry is the production environment, make sure to specify production-specific properties under the <code>cloud</code> profile.</p>
<br>

<h3 id="Conditionally-Create-Beans-with-Profiles"><a href="#Conditionally-Create-Beans-with-Profiles" class="headerlink" title="Conditionally Create Beans with Profiles"></a><u>Conditionally Create Beans with Profiles</u></h3><p>Normally, any bean declared in a Java configuration class is <strong>created regardless of which profile is active</strong>. But we can conditionally create beans with different profiles via annotations as such:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="meta">@Profile(&#123;&quot;dev&quot;, &quot;qa&quot;&#125;)</span>   <span class="comment">// Add this line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The data will only be loaded if the dev or qa profile is active</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CommandLineRunner <span class="title">dataLoader</span><span class="params">(...)</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>To exclude a profile:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Always load the data, when prod is inactive</span></span><br><span class="line"><span class="meta">@Profile(&quot;!prod&quot;)</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Add Profile to an entire configuration class:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Profile(&#123;&quot;!prod&quot;, &quot;!qa&quot;&#125;)</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DevelopmentConfig</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> CommandLineRunner <span class="title">dataLoader</span><span class="params">(...)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
















<br>

<br>


]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Microservices With Spring Cloud</title>
    <url>/2020/Spring-Cloud/</url>
    <content><![CDATA[<p>This post is to introduce Spring Cloud and Microservices. In this post, I will go over the some general concepts and patterns of Microservices. Please also see <a href="https://martinfowler.com/articles/microservices.html">Martin Fowler’s 2014 article</a> that sets the foundation for Microservices.</p>
<p>Note in this post, <strong>clients = client applications = service consumers</strong>.</p>
<span id="more"></span>

<br>



<hr>
<h2 id="Microservice-Architecture"><a href="#Microservice-Architecture" class="headerlink" title="Microservice Architecture"></a>Microservice Architecture</h2><blockquote>
<p>   <strong>Monolithic Architecture</strong>: Single deployable software artifact.</p>
</blockquote>
<br>



<div class="note primary"><p><strong>Microservices Definition:</strong></p>
<p>Microservice are a bunch of <strong>small</strong>, <strong>loosely coupled</strong>, <strong>distributed</strong> services.</p>
<p>Microservices allow us to take a large application and decompose it into easy-to-manage components with narrowly defined responsibilities.</p>
</div>



<br>



<p><img data-src="/images/posts/200428-1.png"></p>
<p><img data-src="/images/posts/200428-2.png"></p>
<br>



<p>A microservice architecture has the following characteristics:</p>
<ul>
<li>  Application logic is <strong>broken down into small-grained components</strong> with well-defined boundaries of responsibility.</li>
<li>  Each component has a small domain of responsibility and is <strong>completely independent of one another</strong>. Also, a microservice should be <strong>reusable</strong> across multiple applications.</li>
<li>  Each instance of the service should be <strong>repeatable</strong> (have same configs), and services should be easily <strong>scalable</strong>.</li>
<li>  Microservices use lightweight communication protocols such as <strong>HTTP and JSON</strong> to exchange data between the service consumer and service provider.</li>
<li>  The underlying technical implementation of the service is irrelevant because the applications always communicate with a technology-neutral protocol ( e.g. JSON). This means an application can be built with <strong>multiple languages and technologies</strong>.</li>
<li>  Small development teams, and each team <strong>completely owns their service code and infrastructure</strong>.</li>
</ul>
<br>



<p>We changed the way we build applications because:</p>
<ul>
<li>  Complexity has gone way up</li>
<li>  Customers want faster delivery</li>
<li>  Customers expect the app to be available all the time</li>
<li>  Performance &amp; Scalability</li>
</ul>
<br>



<div class="note info"><p><em>Small, Simple, and Decoupled Services = Scalable, Resilient, and Flexible Applications</em></p>
</div>



<br>

<hr>
<h2 id="The-Cloud"><a href="#The-Cloud" class="headerlink" title="The Cloud"></a>The Cloud</h2><blockquote>
<p>  <strong>IaaS</strong> (Infrastructure as a Service)</p>
<p>  <strong>PaaS</strong> (Platform as a Service)</p>
<p>  <strong>SaaS</strong> (Software as a Service)</p>
<p>  <strong>FaaS</strong> (Functions as a Service)</p>
<p>  <strong>CaaS</strong> (Container as a Service)</p>
</blockquote>
<br>



<p>Difference among the three:</p>
<blockquote>
<p>  When you eat a meal, you could:</p>
<ul>
<li>  <strong>IaaS</strong>: Buy a pre-made meal, then heat up in a microwave</li>
<li>  <strong>PaaS:</strong> Get delivery</li>
<li>  <strong>SaaS</strong>: Eat at a restaurant</li>
</ul>
</blockquote>
<p><img data-src="/images/posts/200428-3.png"></p>
<p>With a <strong>SaaS</strong> model, you’re a <strong>passive consumer</strong> of the service, and have <strong>no input</strong> on the technology selection or any accountability to maintain the infrastructure for the application. </p>
<br>



<div class="note primary"><p>In order to have the most control, we use <strong>IaaS</strong> for <strong>deployment with Docker containers</strong>.</p>
<p>Note: AWS <strong>EC2 is IaaS</strong>, while Elastic Beanstalk is PaaS.</p>
</div>



<p><strong>Reasons for choosing IaaS:</strong></p>
<ul>
<li>  Have the most control over the services</li>
<li>  Massive horizontal scalability (quickly start service instances)</li>
<li>  High redundancy through geographic distributions (AWS Multi AZs)</li>
<li>  IaaS over PaaS: More work, but <strong>portable across multiple cloud providers</strong> (Packaged as Docker containers)</li>
</ul>
<br>



<hr>
<h2 id="Microservice-Patterns"><a href="#Microservice-Patterns" class="headerlink" title="Microservice Patterns"></a>Microservice Patterns</h2><blockquote>
<ul>
<li>Core development</li>
<li>Routing</li>
<li>Client resiliency</li>
<li>Security </li>
<li>Logging and tracing </li>
<li>Build &amp; deploy</li>
</ul>
</blockquote>
<br>



<p><img data-src="/images/posts/200428-4.png"></p>
<br>



<h3 id="Core-Development"><a href="#Core-Development" class="headerlink" title="Core Development"></a><u>Core Development</u></h3><br>



<p><strong>Service granularity</strong> </p>
<p>What is the right level of responsibility the service should have?</p>
<br>



<p><strong>Communication protocols (JSON)</strong></p>
<p>How your client and service communicate data back and forth? </p>
<br>



<p><strong>Interface design</strong> </p>
<p>How will you expose your service endpoints to clients?</p>
<br>

<p><strong>Configuration management</strong></p>
<p>How your services manage their application-specific configuration, so that the code and configuration are independent entities?</p>
<br>

<p><strong>Event processing / Async messaging (Stream)</strong> </p>
<p>How can you use events to communicate state and data changes between services?</p>
<p>Spring Cloud Stream enables us to integrate <strong>lightweight messaging processing</strong> into the microservice.</p>
<br>



<h3 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a><u>Routing</u></h3><div class="note warning"><p><strong>Service discovery &amp; service routing</strong> are key parts of  any large-scale microservice application.</p>
</div>



<br>



<p><strong>How do I get my client’s service request to a specific instance?</strong></p>
<p>Routing deals with how a client application discovers the service location, and can be routed over it. Hence we need to <strong>abstract away the physical IP</strong>, and have a <strong>single entry point</strong> for service calls, so that we can consistently enforce security and content policies for all service calls.</p>
<br>



<p><strong>Service discovery (Eureka)</strong> </p>
<p>Abstract away the physical location of the service from the client. <u>New microservice instances can be added to scale up, and unhealthy service instances can be transparently removed from the service</u>. Hence client app can find them having the service location hard-coded into the application.</p>
<br>



<p><strong>Service routing (Zuul)</strong></p>
<p>Gateway provides the microservice client a <strong>single logical URL</strong> to talk to, and acts as a policy enforcement point for things like authorization, authentication, and content checking.</p>
<br>



<h3 id="Client-Resiliency"><a href="#Client-Resiliency" class="headerlink" title="Client Resiliency"></a><u>Client Resiliency</u></h3><br>

<p><strong>Client-side load balancing (Ribbon)</strong></p>
<p>How do you <strong>cache the location of your service instances</strong> on the service client, so that calls to <u>multiple instances of a microservice are load balanced to all the healthy instances</u> of that microservice?</p>
<br>



<p><strong>Circuit breakers pattern (Hystrix)</strong></p>
<p>How do you prevent a client from continuing to call a service that’s failing or suffering performance problems? We want failing microservice calls to <strong>fail fast</strong> so that the calling client can quickly respond and take an appropriate action.</p>
<br>



<p><strong>Fallback pattern (Hystrix)</strong></p>
<p>When a service call fails, how do you provide a “plug-in” mechanism that will allow the service client to <strong>carry out its work through alternative means</strong> other than the microservice being called?</p>
<br>

<p><strong>Bulkhead pattern (Hystrix)</strong></p>
<p>Microservice applications use multiple distributed resources to carry out their work. How do you compartmentalize these calls so that the <u>mis-behavior of one service call doesn’t negatively impact the rest</u> of the application?</p>
<br>



<h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a><u>Security</u></h3><br>

<p><strong>Authentication (OAuth2)</strong></p>
<p>How do you determine the service client calling the service is who they claim they are?</p>
<br>



<p><strong>Authorization(OAuth2)</strong></p>
<p>How do you determine whether the service client calling a microservice is allowed to undertake the action they’re trying to undertake?</p>
<br>



<p><strong>Credential management and propagation: (OAuth2 &amp; JWT)</strong></p>
<p>How do you prevent a service client from constantly having to present their credentials for service calls involved in a transaction? </p>
<div class="note success"><p>Using a <strong>token-based security scheme</strong>,  we can implement service authentication and authorization without passing around client credentials.</p>
</div>



<br>



<h3 id="Logging-amp-Tracing"><a href="#Logging-amp-Tracing" class="headerlink" title="Logging &amp; Tracing"></a><u>Logging &amp; Tracing</u></h3><blockquote>
<p>  Downside of microservices: Much more difficult to debug &amp; trace what’s going on within the services.</p>
</blockquote>
<div class="note warning"><p>A well-thought-out logging and tracing strategy makes debugging transactions across multiple services manageable.</p>
</div>



<br>



<p><strong>Log correlation (Sleuth)</strong> </p>
<p>All service log entries have a <strong>correlation ID</strong> that ties the log entry to a single transaction.</p>
<p>With Sleuth, we can integrate <u>unique tracking identifiers into the HTTP calls &amp; message channels</u>.</p>
<br>

<p><strong>Log aggregation (Logstash &amp; ElasticSearch)</strong>  </p>
<p>An aggregation mechanism collects all of the logs from all the services instances. As data comes into a <strong>central data store</strong>, it is <u>indexed and stored in a searchable format</u>. We use correlation ID to assist in searching aggregated logs.</p>
<br>

<p><strong>Microservice transaction tracing (Kibana)</strong> </p>
<p>The DevOps team can query the log data to find individual transactions. They should also be able to <strong>visualize</strong> the flow of all the services involved in a transaction.</p>
<br>



<h3 id="Build-amp-Deploy"><a href="#Build-amp-Deploy" class="headerlink" title="Build &amp; Deploy"></a><u>Build &amp; Deploy</u></h3><blockquote>
<p>  Each instance of a microservice should be identical to all its other instances.</p>
</blockquote>
<br>



<div class="note primary"><p><strong>Immutable Infrastructure</strong></p>
<p>Once a service is deployed, the infrastructure it’s running on should never be touched again by human hands.</p>
<p>We want the deployed microservice and its server to be <strong>one atomic artifact</strong> that’s deployed as a whole between environments.</p>
</div>



<br>



<p><strong>Build and deployment pipeline (Jenkins)</strong></p>
<p>How do you create a <strong>repeatable</strong> build and deployment process that emphasizes one-button builds and deployment to any environment in your organization?</p>
<br>

<p><strong>Infrastructure as code (Docker)</strong></p>
<p>How do you treat the provisioning of your services as code that can be executed and managed under source control? </p>
<p>When the microservice is compiled and packaged, we immediately bake and provision a virtual server or container image with the microservice installed on it.</p>
<br>

<p><strong>Immutable servers (Docker)</strong></p>
<p>Once a microservice image is created, how do you ensure that it’s never changed after it has been deployed?</p>
<br>

<p><strong>Phoenix servers (Docker &amp; Jenkins)</strong></p>
<p>The longer a server is running, the more opportunity for <strong>configuration drift</strong>. How do you ensure that servers that run microservices get torn down on a regular basis and recreated off an immutable image?</p>
<br>



<h2 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h2><blockquote>
<p>  Spring Cloud is <strong>a collection of open source technologies</strong> from companies such as Netflix and HashiCorp that have been “wrapped” with Spring annotations to significantly simplify the setup and configuration of these services.</p>
</blockquote>
<div class="note warning"><p>No industry standards exist for microservices yet. </p>
<p>Microservices take a <strong>principle-based approach</strong> and align with the concepts of REST and JSON .</p>
</div>



<br>

<h3 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a><u>Spring Cloud Config</u></h3><p>Spring Cloud Config handles the management of application configuration data through <strong>a centralized service</strong>, so your application configuration data (particularly your environment specific configuration data) is cleanly separated from your deployed microservice. Spring Cloud can integrate with:</p>
<ul>
<li>  Git</li>
<li>  <a href="https://www.consul.io/">Consul</a> (open-source service discovery)</li>
<li>  Eureka</li>
</ul>
<br>



<h3 id="Spring-Cloud-Service-Discovery"><a href="#Spring-Cloud-Service-Discovery" class="headerlink" title="Spring Cloud Service Discovery"></a><u>Spring Cloud Service Discovery</u></h3><p>With Spring Cloud service discovery, we can abstract away the physical location ( IP and/or server name) of where your servers are deployed from the clients. Service consumers invoke business logic for the servers through a <strong>logical name</strong> rather than a physical location.</p>
<br>



<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a><u>Example</u></h3><br>

<p>A normal controller:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value=&quot;old&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OldController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(value=&quot;/&#123;first&#125;/&#123;last&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">(<span class="meta">@PathVariable(&quot;first&quot;)</span> String first, <span class="meta">@PathVariable(&quot;last&quot;)</span> String last)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello &quot;</span> + first + <span class="string">&quot; &quot;</span> + last;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>Upgraded controller with <strong>service discovery, circuit breaker, bulkhead &amp; client-side load-balancing</strong>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Enable it to use Hystrix &amp; Ribbon</span></span><br><span class="line"><span class="meta">@EnableCircuitBreaker</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Register with Eureka service discovery agent</span></span><br><span class="line"><span class="meta">@EnableEurekaClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SampleController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RestTemplate <span class="title">restTemplate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RestTemplate(); &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">public</span> RestTemplate restTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@HystrixCommand(threadPoolKey = &quot;cloudThreadPool&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">helloRemoteServiceCall</span><span class="params">(String first, String last)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        ResponseEntity&lt;String&gt; restExchange = restTemplate.exchange(</span><br><span class="line">            <span class="string">&quot;http://logical-service-id/name/[ca]&#123;first&#125;/&#123;last&#125;&quot;</span>,</span><br><span class="line">            HttpMethod.GET, <span class="keyword">null</span>, String.class, first, last);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> restExchange.getBody();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(value=&quot;/&#123;first&#125;/&#123;last&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">(<span class="meta">@PathVariable(&quot;first&quot;)</span> String first, <span class="meta">@PathVariable(&quot;last&quot;)</span> String last)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> helloRemoteServiceCall(first, last);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<div class="note danger"><p><a href="https://stackoverflow.com/a/36151777/13408151">Debug: Could not autowire RestTemplate:</a></p>
<p>First need to create the Bean with <strong>@Bean</strong>, then autowire it. </p>
</div>

<br>



<p><strong><code>@HystrixCommand</code>:</strong></p>
<ul>
<li>  This annotation create a thread pool called <code>cloudThreadPool</code> that’s managed by Hystrix. All calls to <code>helloRemoteServiceCall</code> will only occur in this thread pool, and will be isolated from other remote services.</li>
<li>  <u><strong>Circuit Breaker</strong></u>: Anytime <code>helloRemoteServiceCall</code> is called, it won’t be directly invoked. Instead, the method will be <strong>delegated to a thread pool managed by Hystrix</strong>. If the call takes too long, Hystrix will interrupt it.</li>
</ul>
<br>



<p><strong><code>@EnableEurekaClient</code> &amp; <code>RestTemplate</code>:</strong></p>
<ul>
<li>  <code>@EnableEurekaClient</code> tells Spring Boot that we’re going to use a modified <code>RestTemplate</code> class when we make REST service calls. This <code>RestTemplate</code> class allows us to pass in a logical service ID for the service we’re trying to invoke.</li>
<li>  <code>RestTemplate</code> will contact the Eureka service and look up the physical location of the service instances. </li>
<li>  <code>RestTemplate</code>  uses Netflix’s <strong>Ribbon</strong>. <u>Ribbon will retrieve a list of all physical endpoints associated with a service</u>. Every time the service is called by the client, it “<u>round-robins</u>” the call to the different service instances on the client <strong>without having to go through a centralized load balancer.</strong> </li>
<li>  By eliminating a centralized load balancer and moving it to the client, we eliminate another single point of failure in the application infrastructure.</li>
</ul>
<br>



<div class="note primary"><p><strong>Ribbon (client-side load balancing)</strong> replaces the need of using a centralized load balancer.</p>
</div>







<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 04 Spring Security</title>
    <url>/2020/SpringBoot-04/</url>
    <content><![CDATA[<p>This is the fourth post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English. </p>
<p>In this post, I am going to cover the basics of Spring Security.</p>
<span id="more"></span>

<br>

<hr>
<h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><div class="note warning"><p><strong>Do not litter security-unrelated code with security code!</strong></p>
</div>



<br>





<p><strong>Break <a href="https://stackoverflow.com/a/44071058/13408151">Circular Dependency</a>:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Requested bean is currently in creation: Is there an unresolvable circular reference?</span><br></pre></td></tr></table></figure>

<p>Use <strong><code>@Lazy</code></strong> before any of the mentioned <code>@Autowired</code> or <code>@Bean</code>.</p>
<br>





<p><strong>About Roles:</strong></p>
<p>Use <code>hasRole(&quot;User&quot;)</code> instead of <code>hasRole(&quot;ROLE_USER&quot;)</code>, because <code>ROLE_</code> is automatically added.</p>
<br>



<hr>
<h2 id="Basic-Configuration"><a href="#Basic-Configuration" class="headerlink" title="Basic Configuration"></a>Basic Configuration</h2><p>Enable Spring Security (the <strong>ONLY</strong> package needed for all security-related configs):</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p>Spring Security starter provides the following <strong>features</strong>:</p>
<ul>
<li>  All HTTP request paths need authentication</li>
<li>  <u>No specific roles or authorities</u> are required (Only one user, with the username <code>user</code>)</li>
<li>  Login page made by Spring Security</li>
</ul>
<br>

<img data-src="/images/posts/200421.png" style="zoom: 80%;" />





<br>



<hr>
<h2 id="Add-User-Store"><a href="#Add-User-Store" class="headerlink" title="Add User Store"></a>Add User Store</h2><p>What we <strong>need</strong> to configure:</p>
<ul>
<li>  Prompt a customized login page</li>
<li>  Signup page, for multiple users</li>
<li>  Apply <u>different security rules for different request paths</u>.  e.g. The homepage and signup page shouldn’t require authentication at all</li>
</ul>
<br>





<p>Configure a <strong>user store</strong> that handles multiple users:</p>
<ul>
<li>  In-memory</li>
<li>  JDBC-based</li>
<li>  LDAP-backed</li>
<li>  Custom user details service (complete customization)</li>
</ul>
<br>





<p><strong>Barebones config class with <code>@Override</code>:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableWebSecurity</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecurityConfig</span> <span class="keyword">extends</span> <span class="title">WebSecurityConfigurerAdapter</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>





<h3 id="In-memory"><a href="#In-memory" class="headerlink" title="In-memory"></a><u>In-memory</u></h3><blockquote>
<p>  Convenient for testing purposes / simple apps, but doesn’t allow easy editing of users.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Must have the PasswordEncoder in Spring Security 5, otherwise give errors</span></span><br><span class="line">    PasswordEncoder encoder = PasswordEncoderFactories.createDelegatingPasswordEncoder();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 直接在 Config 里面 define username &amp; password</span></span><br><span class="line">    auth.inMemoryAuthentication()</span><br><span class="line">        .withUser(<span class="string">&quot;Merikanto&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Need to add &#123;noop&#125;, to enable NoOpPasswordEncoder</span></span><br><span class="line">        .password(<span class="string">&quot;&#123;noop&#125;123456&quot;</span>)</span><br><span class="line">        .authorities(<span class="string">&quot;ROLE_USER&quot;</span>)</span><br><span class="line">    .and()</span><br><span class="line">        .withUser(<span class="string">&quot;KK&quot;</span>)</span><br><span class="line">        .password(<span class="string">&quot;&#123;noop&#125;123456&quot;</span>)</span><br><span class="line">        .authorities(<span class="string">&quot;ROLE_USER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<br>





<h3 id="LDAP-backed"><a href="#LDAP-backed" class="headerlink" title="LDAP-backed"></a><u>LDAP-backed</u></h3><blockquote>
<p>  LDAP: Lightweight Directory Access Protocol</p>
</blockquote>
<br>





<p>The default strategy for authenticating against LDAP is to perform a <strong>bind operation</strong>, authenticating the user <u>directly to the LDAP server</u>. </p>
<p>Another option is to perform a <strong>comparison operation</strong>. This involves sending the entered password to the LDAP directory and asking the server to compare the password against a user’s password attribute. Because the comparison is done within the LDAP server, the actual password remains secret.</p>
<br>





<p><strong>Basic Config:</strong></p>
<ul>
<li>  By default, users &amp; groups base queries are empty:  the search will be done from the root of LDAP hierarchy.</li>
<li>  With specifying the Base, rather than search from root, search will be done where the <strong>organizational unit</strong> is people.</li>
<li>  Add password comparison, for the <strong>comparison operation</strong>. Plus specify a different password attribute name.</li>
</ul>
<br>





<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    auth.ldapAuthentication()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Filters below: provide base LDAP queries (search for users &amp; groups)</span></span><br><span class="line">        .userSearchFilter(<span class="string">&quot;(uid=&#123;0&#125;)&quot;</span>)</span><br><span class="line">        .groupSearchFilter(<span class="string">&quot;member=&#123;0&#125;&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Specify base queries for finding users &amp; groups</span></span><br><span class="line">        .userSearchBase(<span class="string">&quot;ou=people&quot;</span>)</span><br><span class="line">        .groupSearchBase(<span class="string">&quot;ou=groups&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Name for the password attribute is now: Passphrase</span></span><br><span class="line">        .passwordCompare()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Need another encoder, to prevent MITM interception</span></span><br><span class="line">        .passwordEncoder(<span class="keyword">new</span> BCryptPasswordEncoder())</span><br><span class="line">        .passwordAttribute(<span class="string">&quot;Passphrase&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>





<p><strong>Contact LDAP server:</strong></p>
<blockquote>
<p>   The default LDAP server is on <strong><code>localhost:33389</code></strong>.</p>
</blockquote>
<br>





<p>When the LDAP server starts, it will attempt to load data from any <strong>LDIF files</strong> that it can find in the classpath. <strong>LDIF (LDAP Data Interchange Format)</strong> is a standard way of representing LDAP data in a plain text file. Each record is composed of one or more lines, each containing <u>a <code>name:value</code> pair</u>. Records are separated from each other by blank lines.</p>
<br>





<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Add to the last line</span></span><br><span class="line"></span><br><span class="line">.contextSource</span><br><span class="line">    .root(<span class="string">&quot;dc=tacocloud, dc=com&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Ask the server to load content from the users.ldif file at classpath root</span></span><br><span class="line">    .ldif(<span class="string">&quot;classpath:users.ldif&quot;</span>);</span><br></pre></td></tr></table></figure>



<br>





<p>A sample LDIF file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dn:</span> <span class="string">ou=groups,dc=tacocloud,dc=com</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">top</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">organizationalUnit</span></span><br><span class="line"><span class="attr">ou:</span> <span class="string">groups</span></span><br><span class="line"><span class="attr">dn:</span> <span class="string">ou=people,dc=tacocloud,dc=com</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">top</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">organizationalUnit</span></span><br><span class="line"><span class="attr">ou:</span> <span class="string">people</span></span><br><span class="line"><span class="attr">dn:</span> <span class="string">uid=buzz,ou=people,dc=tacocloud,dc=com</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">top</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">person</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">organizationalPerson</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">inetOrgPerson</span></span><br><span class="line"><span class="attr">cn:</span> <span class="string">Buzz</span> <span class="string">Lightyear</span></span><br><span class="line"><span class="attr">sn:</span> <span class="string">Lightyear</span></span><br><span class="line"><span class="attr">uid:</span> <span class="string">buzz</span></span><br><span class="line"><span class="attr">userPassword:</span> <span class="string">password</span></span><br><span class="line"><span class="attr">dn:</span> <span class="string">cn=tacocloud,ou=groups,dc=tacocloud,dc=com</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">top</span></span><br><span class="line"><span class="attr">objectclass:</span> <span class="string">groupOfNames</span></span><br><span class="line"><span class="attr">cn:</span> <span class="string">tacocloud</span></span><br><span class="line"><span class="attr">member:</span> <span class="string">uid=buzz,ou=people,dc=tacocloud,dc=com</span></span><br></pre></td></tr></table></figure>





<br>







<h3 id="JDBC-based"><a href="#JDBC-based" class="headerlink" title="JDBC-based"></a><u>JDBC-based</u></h3><blockquote>
<p>   Maintain user info in a relational DB with JDBC.</p>
</blockquote>
<br>





<p>Spring Security’s <strong>default user queries</strong>:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- WITH auth.jdbcAuthentication().dataSource(dataSource):</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Authentication: Get username &amp; password</span></span><br><span class="line">public <span class="keyword">static</span> <span class="keyword">final</span> String DEF_USERS_BY_USERNAME_QUERY <span class="operator">=</span></span><br><span class="line">    &quot;select username,password,enabled from users where username = ?&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Authorization: look up user&#x27;s granted authorities</span></span><br><span class="line">public <span class="keyword">static</span> <span class="keyword">final</span> String DEF_AUTHORITIES_BY_USERNAME_QUERY <span class="operator">=</span></span><br><span class="line">    &quot;select username,authority from authorities where username = ?&quot;;</span><br><span class="line">    </span><br><span class="line"><span class="comment">-- Authorization: look up granted user group</span></span><br><span class="line">public <span class="keyword">static</span> <span class="keyword">final</span> String DEF_GROUP_AUTHORITIES_BY_USERNAME_QUERY <span class="operator">=</span></span><br><span class="line">    &quot;select g.id, g.group_name, ga.authority &quot; <span class="operator">+</span></span><br><span class="line">    &quot;from groups g, group_members gm, group_authorities ga &quot; <span class="operator">+</span></span><br><span class="line">    &quot;where gm.username = ? and g.id = ga.group_id and g.id = gm.group_id&quot;;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Customized config:</strong></p>
<blockquote>
<p>  Note: All the queries take username as the only parameter.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Set datasource, for DB access</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">DataSource dataSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Only override the authentication &amp; basic auth queries</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    auth.jdbcAuthentication().dataSource(dataSource)</span><br><span class="line">        .usersByUsernameQuery(</span><br><span class="line">        	<span class="string">&quot;select username, password, enabled from Users &quot;</span> +</span><br><span class="line">        	<span class="string">&quot;where username=?&quot;</span>)</span><br><span class="line">        .authoritiesByUsernameQuery(</span><br><span class="line">        	<span class="string">&quot;select username, authority from UserAuthorities &quot;</span> +</span><br><span class="line">        	<span class="string">&quot;where username=?&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Encoding passwords</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Added to the last line</span></span><br><span class="line">.passwordEncoder(<span class="keyword">new</span> BCryptPasswordEncoder(<span class="string">&quot;merikanto&quot;</span>));</span><br></pre></td></tr></table></figure>



<br>



<p><strong>Other Cryptos:</strong></p>
<blockquote>
<p>  Note: <code>StandardPasswordEncoder</code> using SHA256 is deprecated after Spring Security 5.1.5.</p>
</blockquote>
<ul>
<li>  <strong>NoOp</strong>PasswordEncoder —Applies no encoding</li>
<li>  <strong>BCrypt</strong>PasswordEncoder —Applies bcrypt strong hashing encryption</li>
<li>  <strong>Pbkdf2</strong>PasswordEncoder —Applies PBKDF2 encryption</li>
<li>  <strong>SCrypt</strong>PasswordEncoder —Applies scrypt hashing encryption</li>
</ul>
<br>





<p>The Password encoder <strong>interface</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">PasswordEncoder</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">encode</span><span class="params">(CharSequence rawPassword)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">matches</span><span class="params">(CharSequence rawPassword, String encodedPassword)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<div class="note default"><p><strong>Clarification:</strong></p>
<p>The password in the DB is never decoded. </p>
<p>The plaintext password entered by the user is encoded using the same algorithm, and then compared with the encoded password in the DB (using the <code>matches()</code> method)</p>
</div>





<br>





<h3 id="Custom-User-Detail"><a href="#Custom-User-Detail" class="headerlink" title="Custom User Detail"></a><u>Custom User Detail</u></h3><h4 id="User-Entity"><a href="#User-Entity" class="headerlink" title="User Entity"></a>User Entity</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Entity</span></span><br><span class="line"><span class="meta">@NoArgsConstructor(access= AccessLevel.PRIVATE, force=true)</span></span><br><span class="line"><span class="meta">@RequiredArgsConstructor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意是 implements UserDetails interface from Spring Security</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">UserDetails</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Id</span></span><br><span class="line">    <span class="meta">@GeneratedValue(strategy= GenerationType.AUTO)</span></span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String username;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String password;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String fullname;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String street;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String city;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String state;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String zip;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String phoneNumber;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 下面的方法可以自动生成，点击 implements</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// Return a collection of authorities granted to the user;</span></span><br><span class="line">    <span class="keyword">public</span> Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// In this case, returns a collection indicating that,</span></span><br><span class="line">        <span class="comment">// All users are granted with the ROLE_USER authority </span></span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(<span class="keyword">new</span> SimpleGrantedAuthority(<span class="string">&quot;ROLE_USER&quot;</span>)); &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAccountNonExpired</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">true</span>; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAccountNonLocked</span><span class="params">()</span>  </span>&#123; <span class="keyword">return</span> <span class="keyword">true</span>; &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isCredentialsNonExpired</span><span class="params">()</span>  </span>&#123; <span class="keyword">return</span> <span class="keyword">true</span>; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEnabled</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">true</span>; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<h4 id="User-Repository"><a href="#User-Repository" class="headerlink" title="User Repository"></a>User Repository</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserRepository</span> <span class="keyword">extends</span> <span class="title">CrudRepository</span>&lt;<span class="title">User</span>, <span class="title">Long</span>&gt; </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Look up a user by username</span></span><br><span class="line">    <span class="function">User <span class="title">findByUsername</span><span class="params">(String username)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<h4 id="User-Details-Service"><a href="#User-Details-Service" class="headerlink" title="User Details Service"></a>User Details Service</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserDetailsService</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Either return a UserDetails object, or throw an exception</span></span><br><span class="line">    <span class="function">UserDetails <span class="title">loadByUsername</span><span class="params">(String username)</span> <span class="keyword">throws</span> UsernameNotFoundException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<h4 id="User-Details-Service-Implementation"><a href="#User-Details-Service-Implementation" class="headerlink" title="User Details Service Implementation"></a>User Details Service Implementation</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDetailsServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserDetailsService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> UserRepository userRepo;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ServiceImpl is injected with an instance of UserRepo via the constructor</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UserDetailsServiceImpl</span><span class="params">(UserRepository userRepo)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.userRepo = userRepo;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// loadByUsername: Never return null!</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UserDetails <span class="title">loadByUsername</span><span class="params">(String username)</span> <span class="keyword">throws</span> UsernameNotFoundException </span>&#123;</span><br><span class="line">        User user = userRepo.findByUsername(username);</span><br><span class="line">        <span class="keyword">if</span> (user != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> user;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">&quot;User [ &quot;</span> + username + <span class="string">&quot; ] is not found&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<h4 id="Modify-SecurityConfig"><a href="#Modify-SecurityConfig" class="headerlink" title="Modify SecurityConfig"></a>Modify SecurityConfig</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetailsService;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableWebSecurity</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecurityConfig</span> <span class="keyword">extends</span> <span class="title">WebSecurityConfigurerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注意 autowired 的是 import 的东西，security core 里面的，而不是自己写的 service！</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserDetailsService userDetailsService;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Still need a password encoder</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> PasswordEncoder <span class="title">encoder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Pbkdf2PasswordEncoder(<span class="string">&quot;Merikanto&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        auth.userDetailsService(userDetailsService)</span><br><span class="line">                .passwordEncoder(encoder());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Line 21:</strong><code>.passwordEncoder(encoder());</code></p>
<p>It appears that we call the <code>encoder()</code> method and pass its returned value to <code>passwordEncoder()</code> .</p>
<p>However, since the <code>encoder()</code> method is annotated with <code>@Bean</code> , it will be used to <strong>declare a <code>PasswordEncoder</code> bean in the Spring application context</strong>. Any calls to <code>encoder()</code> will then be <u>intercepted to return the bean instance from the application context</u>.</p>
<br>





<h4 id="User-Controller"><a href="#User-Controller" class="headerlink" title="User Controller"></a>User Controller</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/register&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RegistrationController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> UserRepository userRepo;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> PasswordEncoder passwordEncoder;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RegistrationController</span><span class="params">(UserRepository userRepo, PasswordEncoder passwordEncoder)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.userRepo = userRepo;</span><br><span class="line">        <span class="keyword">this</span>.passwordEncoder = passwordEncoder;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">registerForm</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;registration&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">processRegistration</span><span class="params">(RegistrationForm form)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Pass to toUser (code is below)</span></span><br><span class="line">        userRepo.save(form.toUser(passwordEncoder));</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;redirect:/login&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>





<h4 id="A-Separate-Registration-Form"><a href="#A-Separate-Registration-Form" class="headerlink" title="A Separate Registration Form"></a>A Separate Registration Form</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RegistrationForm</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String username;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">    <span class="keyword">private</span> String fullname;</span><br><span class="line">    <span class="keyword">private</span> String street;</span><br><span class="line">    <span class="keyword">private</span> String city;</span><br><span class="line">    <span class="keyword">private</span> String state;</span><br><span class="line">    <span class="keyword">private</span> String zip;</span><br><span class="line">    <span class="keyword">private</span> String phone;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Note here, toUser uses the above properties to create a new User object</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">toUser</span><span class="params">(PasswordEncoder passwordEncoder)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> User(</span><br><span class="line">            </span><br><span class="line">            	<span class="comment">// First encode the password, then controller saves to the DB </span></span><br><span class="line">                username, passwordEncoder.encode(password),</span><br><span class="line">                fullname, street, city, state, zip, phone);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>





<br>



<hr>
<h2 id="Securing-Web-Requests"><a href="#Securing-Web-Requests" class="headerlink" title="Securing Web Requests"></a>Securing Web Requests</h2><br>





<h3 id="Secure-Requests"><a href="#Secure-Requests" class="headerlink" title="Secure Requests"></a><u>Secure Requests</u></h3><p>Configs with <code>HttpSecurity</code>:</p>
<ul>
<li>  Require that certain security conditions must be met before serving a request</li>
<li>  Configure a custom login page, and enable logout</li>
<li>  Configure cross-site request forgery protection (CSRF)</li>
</ul>
<br>





<p><strong>Specify 2 security rules:</strong></p>
<ul>
<li>  Requests for <code>/design</code> and <code>/orders</code> should be for users with a granted authority of <code>ROLE_USER</code> </li>
<li>  All requests should be permitted to all users</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// HttpSecurity object</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    http.authorizeRequests()</span><br><span class="line">        .antMatchers(<span class="string">&quot;/deign&quot;</span>, <span class="string">&quot;/orders&quot;</span>).hasRole(<span class="string">&quot;USER&quot;</span>)</span><br><span class="line">        .antMatchers(<span class="string">&quot;/&quot;</span>, <span class="string">&quot;/**&quot;</span>).permitAll();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p><strong><u>Important:</u></strong> </p>
<p>The order of the rules are important. <strong>Security rules declared first take precedence over those declared lower down</strong>. </p>
<p>If we reverse the order, all requests would have <code>permitAll()</code> applied to them, and the rule for <code>/design</code> and <code>/orders</code> requests would have no effect.</p>
<br>





<p><strong>Spring Security’s config methods for securing paths:</strong></p>
<blockquote>
<p>  <strong>SpEL</strong>: <em>Spring</em> Expression Language</p>
</blockquote>
<br>





<table>
<thead>
<tr>
<th>Method</th>
<th>What It Does</th>
</tr>
</thead>
<tbody><tr>
<td><code>access(String)</code></td>
<td>Allows access if the given SpEL expression evaluates to true</td>
</tr>
<tr>
<td><code>rememberMe()</code></td>
<td>Allows access for users who are authenticated via remember-me</td>
</tr>
<tr>
<td><code>permitAll()</code></td>
<td>Allows access unconditionally</td>
</tr>
<tr>
<td><code>denyAll()</code></td>
<td>Denies access unconditionally</td>
</tr>
<tr>
<td>.</td>
<td></td>
</tr>
<tr>
<td><code>authenticated()</code></td>
<td>Allows access to authenticated users</td>
</tr>
<tr>
<td><code>fullyAuthenticated()</code></td>
<td>Allows access if the user is fully authenticated (not remembered)</td>
</tr>
<tr>
<td><code>hasAnyAuthority(String...)</code></td>
<td>Allows access if the user has any of the given authorities</td>
</tr>
<tr>
<td><code>hasAnyRole(String...)</code></td>
<td>Allows access if the user has any of the given roles</td>
</tr>
<tr>
<td><code>hasAuthority(String)</code></td>
<td>Allows access if the user has the given authority</td>
</tr>
<tr>
<td><code>hasIpAddress(String)</code></td>
<td>Allows access if the request comes from the given IP address</td>
</tr>
<tr>
<td><code>hasRole(String)</code></td>
<td>Allows access if the user has the given role</td>
</tr>
<tr>
<td>.</td>
<td></td>
</tr>
<tr>
<td><code>not()</code></td>
<td>Negates the effect of any of the other access methods</td>
</tr>
<tr>
<td><code>anonymous()</code></td>
<td>Allows access to anonymous users</td>
</tr>
</tbody></table>
<br>





<br>







<p><strong>Spring Security Extension to SpEL</strong></p>
<table>
<thead>
<tr>
<th>Security Expression</th>
<th>What It Evaluates</th>
</tr>
</thead>
<tbody><tr>
<td><code>authentication</code></td>
<td>The user’s authentication object</td>
</tr>
<tr>
<td><code>isRememberMe()</code></td>
<td><code>true</code> if the user was authenticated via remember-me</td>
</tr>
<tr>
<td><code>denyAll</code></td>
<td>Always evaluates to false</td>
</tr>
<tr>
<td><code>permitAll</code></td>
<td>Always evaluates to true</td>
</tr>
<tr>
<td>.</td>
<td></td>
</tr>
<tr>
<td><code>isAuthenticated()</code></td>
<td><code>true</code> if the user is authenticated</td>
</tr>
<tr>
<td><code>isFullyAuthenticated()</code></td>
<td><code>true</code> if the user is fully authenticated (not with remember-me)</td>
</tr>
<tr>
<td><code>hasAnyRole(list of roles)</code></td>
<td><code>true</code> if the user has any of the given roles</td>
</tr>
<tr>
<td><code>hasRole(role)</code></td>
<td><code>true</code> if the user has the given role</td>
</tr>
<tr>
<td><code>hasIpAddress(IP address)</code></td>
<td><code>true</code> if the request comes from the given IP address</td>
</tr>
<tr>
<td>.</td>
<td></td>
</tr>
<tr>
<td><code>isAnonymous()</code></td>
<td><code>true</code> if the user is anonymous</td>
</tr>
<tr>
<td><code>principal</code></td>
<td>The user’s principal object</td>
</tr>
</tbody></table>
<br>





<p><strong>Example:</strong></p>
<p><u>Only allow authenticated user to place order on Tuesday:</u></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    http.authorizeRequests()</span><br><span class="line">        .antMatchers(<span class="string">&quot;/design&quot;</span>, <span class="string">&quot;/orders&quot;</span>)</span><br><span class="line">        .access(<span class="string">&quot;hasRole(&#x27;USER&#x27;) &amp;&amp; T(java.util.Calendar).getInstance().get(&quot;</span>+</span><br><span class="line">        <span class="string">&quot;T(java.util.Calendar).DAY_OF_WEEK) == &quot;</span> +</span><br><span class="line">        <span class="string">&quot;T(java.util.Calendar).TUESDAY&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        .antMatchers(“/”, <span class="string">&quot;/**&quot;</span>).access(<span class="string">&quot;permitAll&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>









<h3 id="Custom-Login-amp-Logout"><a href="#Custom-Login-amp-Logout" class="headerlink" title="Custom Login &amp; Logout"></a><u>Custom Login &amp; Logout</u></h3><p><strong>Add a ViewController Path in WebConfig:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addViewControllers</span><span class="params">(ViewControllerRegistry registry)</span> </span>&#123;</span><br><span class="line">    registry.addViewController(<span class="string">&quot;/&quot;</span>).setViewName(<span class="string">&quot;home&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 加上这一行</span></span><br><span class="line">    registry.addViewController(<span class="string">&quot;/login&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Add to <code>SecurityConfig</code>:</strong></p>
<blockquote>
<p>  By default, Spring Security listens for login requests at <code>/login</code>, and expects that the username and password fields be named <code>username</code> and <code>password</code> . </p>
<p>  But we can change it through the config below:</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">http.authorizeRequests()</span><br><span class="line">    .antMatchers(<span class="string">&quot;/deign&quot;</span>, <span class="string">&quot;/orders&quot;</span>).access(<span class="string">&quot;hasRole(&#x27;USER&#x27;)&quot;</span>)</span><br><span class="line">    .antMatchers(<span class="string">&quot;/&quot;</span>, <span class="string">&quot;/**&quot;</span>).permitAll()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Login Form 指向 /login</span></span><br><span class="line">    .and().formLogin().loginPage(<span class="string">&quot;/login&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 登陆成功后，将被强行带到 /design 页面（force = true），无论之前在哪个页面</span></span><br><span class="line">    .defaultSuccessUrl(<span class="string">&quot;/design&quot;</span>, <span class="keyword">true</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Customize login, 现在登陆入口变成了 /hello， 用户名和密码的field name也更改了</span></span><br><span class="line">    .loginProcessingUrl(<span class="string">&quot;/hello&quot;</span>)</span><br><span class="line">    .usernameParameter(<span class="string">&quot;uname&quot;</span>)</span><br><span class="line">    .passwordParameter(<span class="string">&quot;pword&quot;</span>);</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Logging Out</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 末尾加上这行</span></span><br><span class="line">.and().logout().logoutSuccessUrl(<span class="string">&quot;/&quot;</span>);</span><br></pre></td></tr></table></figure>





<br>





<h3 id="CSRF"><a href="#CSRF" class="headerlink" title="CSRF"></a><u>CSRF</u></h3><div class="note primary"><p><strong>Spring Security has built-in CSRF protection, and it’s enabled by default</strong>. </p>
</div>



<p>Cross-site request forgery (CSRF) is a common security attack. It involves subjecting a user to visit a maliciously designed web page that <u>automatically &amp; secretly submits a form to another application on behalf of a user</u>. For instance, a user may be presented with a form on an attacker’s website that automatically posts to a URL on the user’s banking website to transfer money. </p>
<p>To protect against such attacks, applications can generate a <strong>CSRF token</strong> upon displaying a form, p<u>lace that token in a hidden field, and then save it for later use on the server</u>. When the form is submitted, the token is sent back to the server along with the rest of the form data. The request is then intercepted by the server and compared with the token that was originally generated. If the token matches, the request is allowed to proceed. </p>
<br>

<hr>
<h2 id="Know-Your-User"><a href="#Know-Your-User" class="headerlink" title="Know Your User"></a>Know Your User</h2><blockquote>
<p>   Link User with Order:</p>
<p>  <strong>Information about the authenticated user</strong> can be obtained via the <u><code>SecurityContext</code> object</u>, or injected into controllers using <u><code>@AuthenticationPrincipal</code></u> .</p>
</blockquote>
<br>





<p>Add this to the <code>Order</code> entity:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ManyToOne</span></span><br><span class="line"><span class="keyword">private</span> User user;</span><br></pre></td></tr></table></figure>



<br>





<p>Determine which  user is associated with which order(s):</p>
<ul>
<li>  Inject a <code>Principal</code> object into the controller method</li>
<li>  Inject an <code>Authentication</code> object into the controller method</li>
<li>  Use <code>SecurityContextHolder</code> to get at the security context</li>
<li>  Use an <u><code>@AuthenticationPrincipal</code></u> annotated method</li>
</ul>
<br>





<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">processOrder</span><span class="params">(<span class="meta">@Valid</span> Order order, Errors errors, SessionStatus sessionStatus, </span></span></span><br><span class="line"><span class="params"><span class="function">	Principal principal)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 加上这些</span></span><br><span class="line">    User user = userRepository.findByUsername(</span><br><span class="line">    principal.getName());</span><br><span class="line">    order.setUser(user);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>上面的方法是没问题的，但这个是 Bad Practice!</strong></p>
<p><strong>Do not litter security-unrelated code with security code!</strong></p>
<br>





<p><strong>方法一</strong>（Cleanest Solution）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// @AuthPrincipal limits the security-specific code to the annotation itself</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">processOrder</span><span class="params">(<span class="meta">@Valid</span> Order order, Errors errors, SessionStatus sessionStatus, </span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="meta">@AuthenticationPrincipal</span> User user)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 换成这一行</span></span><br><span class="line">    order.setUser(user);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>方法二</strong>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Authentication authentication = SecurityContextHolder.getContext().getAuthentication();</span><br><span class="line">User user = (User) authentication.getPrincipal();</span><br></pre></td></tr></table></figure>

<p>此方法的好处是：</p>
<p>It can be <strong>used anywhere in the application</strong>, not only in a controller’s handler methods. This makes it <u>suitable for use in lower levels of the code</u>.</p>
<br>



<br>



]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 03 Spring Data</title>
    <url>/2020/SpringBoot-03/</url>
    <content><![CDATA[<p>This is the third post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English. </p>
<p>In this post, I am going to cover the basics of Spring Data, including <strong>JDBC</strong> (Java DataBase Connectivity) &amp; <strong>JPA</strong> (Java Persistence API).</p>
<span id="more"></span>



<br>



<br>

<hr>
<h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><div class="note primary"><p><strong>By using JPA instead of JDBC, <code>data.sql</code> is not executed &amp; <code>schema.sql</code> is not required.</strong></p>
</div>



<br>



<p>If <code>schema.sql</code>  &amp; <code>data.sql</code> are under <code>main/resources</code>, then either <strong>null</strong> or <strong>filled</strong> with SQL statements. </p>
<p><strong>Commenting out the SQL lines will cause problems.</strong></p>
<blockquote>
<p>  <em>If <code>schema.sql</code> exists under <code>main/resources</code>, JPA will execute DDL based on <code>schema.sql</code>; Otherwise, JPA auto creates the table based on the package <code>domain</code>.</em></p>
</blockquote>
<p><strong>Solution</strong>: Add <strong><code>dataLoader</code></strong> in main application:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CommandLineRunner <span class="title">dataLoader</span><span class="params">(IngredientRepository repo)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CommandLineRunner() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            repo.save(<span class="keyword">new</span> Ingredient(<span class="string">&quot;FLTO&quot;</span>, <span class="string">&quot;Flour Tortilla&quot;</span>, Type.WRAP));</span><br><span class="line">            repo.save(<span class="keyword">new</span> Ingredient(<span class="string">&quot;SRCR&quot;</span>, <span class="string">&quot;Sour Cream&quot;</span>, Type.SAUCE));</span><br><span class="line">            ......  &#125; &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>In <strong><code>application.yml</code></strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">jpa:</span></span><br><span class="line">    <span class="attr">show-sql:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">hibernate:</span></span><br><span class="line">      <span class="attr">ddl-auto:</span> <span class="string">none</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">jdbc:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:h2:mem:testdb</span></span><br></pre></td></tr></table></figure>



<br>



<p><strong>Using H2 Console:</strong></p>
<ul>
<li><p>  JDBC Url: <code>jdbc:h2:mem:testdb</code></p>
</li>
<li><p>  Username: <code>sa</code></p>
</li>
<li><p>Password: <code>&lt;empty&gt;</code></p>
</li>
</ul>
<br>

<p><strong>Hibernate Exception:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">org.hibernate.exception.SQLGrammarException: could not prepare statement</span><br></pre></td></tr></table></figure>

<p>Table name (e.g. <code>Order</code>) is a <a href="https://stackoverflow.com/a/24060905"><strong>reserved</strong> keyword for H2 database.</a></p>
<br>



<p><strong>Hibernate Exception:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">org.hibernate.exception.SQLGrammarException: could not extract ResultSet</span><br></pre></td></tr></table></figure>

<p>When use H2 in-memory DB, we can use <code>@ManytoMany</code>.</p>
<p>But with an external MySQL DB, we <strong>always need a 3rd table</strong>, therefore the annotation is split to: </p>
<ul>
<li>  <code>@OnetoMany</code></li>
<li>  <code>@ManytoOne</code></li>
</ul>
<br>

<p><strong>Exceptions:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 第一种： Hibernate Exception</span></span><br><span class="line">org.hibernate.InstantiationException: </span><br><span class="line">No <span class="keyword">default</span> constructor <span class="keyword">for</span> entity: : demo.taco.domain.Ingredient;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第二种： </span></span><br><span class="line">ERROR <span class="number">12470</span> --- [restartedMain] o.s.boot.SpringApplication: Application run failed</span><br><span class="line">java.lang.IllegalStateException: Failed to execute CommandLineRunner</span><br></pre></td></tr></table></figure>

<p>Must add following <strong>annotations</strong> to <code>domain.Ingredient</code>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Needs a constructor with no arguments, and other constructors with args</span></span><br><span class="line"><span class="meta">@RequiredArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor(access=AccessLevel.PRIVATE, force=true)</span></span><br></pre></td></tr></table></figure>



<br>

<p><strong>Maven install failed:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Failed to execute goal org.apache.maven.plugins:</span><br><span class="line">maven-surefire-plugin:2.12:test (default-test) on project.</span><br></pre></td></tr></table></figure>

<p>Add the <a href="https://stackoverflow.com/a/36429564"><strong>following dependency</strong></a>:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Spring Boot 2.2.6 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.19.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p><strong>JPA error with Entity Manager Factory:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[JPA]</span><br><span class="line">org.springframework.beans.factory.BeanCreationException: </span><br><span class="line">Error creating bean with name &#x27;entityManagerFactory&#x27; defined in class path resource[]: </span><br><span class="line">Invocation of init method failed; Unable to build Hibernate SessionFactory;</span><br></pre></td></tr></table></figure>



<p>Add the <a href="https://stackoverflow.com/a/40058812"><strong>following dependency</strong>:</a></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.xml.bind<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jaxb-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>Add <a href="https://stackoverflow.com/a/54395063"><strong>missing annotations</strong></a>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Id</span></span><br><span class="line"><span class="meta">@GeneratedValue(strategy=GenerationType.AUTO)</span></span><br><span class="line"><span class="keyword">private</span> Long id;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@ManyToMany(targetEntity=Taco.class)</span></span><br><span class="line"><span class="keyword">private</span> List&lt;Taco&gt; tacos = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br></pre></td></tr></table></figure>



<br>

<br>

<hr>
<h2 id="JDBC"><a href="#JDBC" class="headerlink" title="JDBC"></a>JDBC</h2><br>



<h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a><u>Comparison</u></h3><p>Spring JDBC support is rooted in the <strong><code>JdbcTemplate</code></strong> class.</p>
<ul>
<li>  Perform SQL operations against a relational DB without all the clumsy code when working with JDBC directly.</li>
</ul>
<br>



<p><strong>Sample query without <code>JdbcTemplate</code>:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="comment">// find one ingredient</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">findOne</span> <span class="params">(String id)</span> </span>&#123;				</span><br><span class="line">    </span><br><span class="line">    Connection connection = <span class="keyword">null</span>;</span><br><span class="line">    PreparedStatement statement = <span class="keyword">null</span>;</span><br><span class="line">    ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        connection = dataSource.getConnection();		  </span><br><span class="line">        statement = connection.prepareStatement (	<span class="comment">// SQL query is 👇</span></span><br><span class="line">            <span class="string">&quot;select id, name, type from Ingredient where id = ?&quot;</span>);</span><br><span class="line">        statement.setString(<span class="number">1</span>, id);</span><br><span class="line">        rs = statement.executeQuery();</span><br><span class="line">        Ingredient ingredient = <span class="keyword">null</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (rs.next())</span><br><span class="line">            ingredient = <span class="keyword">new</span> Ingredient(rs.getString(<span class="string">&quot;id&quot;</span>), rs.getString(<span class="string">&quot;name&quot;</span>),</span><br><span class="line">                Ingredient.Type.valueOf(rs.getString(<span class="string">&quot;type&quot;</span>)));</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> ingredient;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">catch</span> (SQLException e) &#123; <span class="comment">/* some exceptions */</span> &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (rs != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123; rs.close(); &#125;</span><br><span class="line">            <span class="keyword">catch</span> (SQLException e) &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (statement != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123; statement.close(); &#125;</span><br><span class="line">            <span class="keyword">catch</span> (SQLException e) &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123; statement.close(); &#125;</span><br><span class="line">            <span class="keyword">catch</span> (SQLException e) &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p><strong>Sample query with <code>JdbcTemplate</code>:</strong></p>
<blockquote>
<p>  No statements / connections being created &amp; cleaned up. No try &amp; catch </p>
<p>  Focus on performing the query &amp; mapping results to an <code>Ingredient</code> object</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> JdbcTemplate jdbc;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">findOne</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> jdbc.queryForObject (</span><br><span class="line">        <span class="string">&quot;select id, name, type from Ingredient where id=?&quot;</span>, <span class="keyword">this</span>::mapRowToIngredient, id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Ingredient <span class="title">mapRowToIngredient</span><span class="params">(ResultSet rs, <span class="keyword">int</span> rowNum)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Ingredient(rs.getString(<span class="string">&quot;id&quot;</span>), rs.getString(<span class="string">&quot;name&quot;</span>),</span><br><span class="line">                          Ingredient.Type.valueOf(rs.getString(<span class="string">&quot;type&quot;</span>)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>And adapt <code>Domain</code> for persistence:   Add <strong><code>id</code></strong> to it  (for DB auto-generated  id)</p>
<br>



<h3 id="JdbcTemplate"><a href="#JdbcTemplate" class="headerlink" title="JdbcTemplate"></a><u>JdbcTemplate</u></h3><p><strong>Dependency</strong>: Add <strong>H2 embedded database</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.h2database<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>h2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p><strong>Objective (Repository, Persistence)</strong>: operations needed for <code>Ingredeint</code> object(s) are</p>
<ul>
<li>  Query for all ingredients into a collection of <code>Ingredient</code> objects</li>
<li>  Query for a single object by id</li>
<li>  Save an object</li>
</ul>
<br>



<p><code>IngredientRepository</code> <strong>interface</strong>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IngredientRepository</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function">Iterable&lt;Ingredient&gt; <span class="title">findAll</span><span class="params">()</span></span>;	<span class="comment">// Iterable!</span></span><br><span class="line">    </span><br><span class="line">    <span class="function">Ingredient <span class="title">findOne</span><span class="params">(String id)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function">Ingredient <span class="title">save</span><span class="params">(Ingredient ingredient)</span></span>;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p><code>IngredientRepository</code>  <strong>implementation</strong>: (use <code>JdbcTemplate</code> to query the database)</p>
<ul>
<li><p>Create a constructor:</p>
<blockquote>
<p>  <em>The constructor assigns <code>JdbcTemplate</code> to an instance variable that will be used in other methods to query &amp; insert into the DB.</em></p>
</blockquote>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Injects the RepoImpl with JdbcTemplate, via the @Autowired annotated constructor</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">IngredientRepositoryImpl</span><span class="params">(JdbcTemplate jdbc)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.jdbc = jdbc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<ul>
<li>  Sample Implementation:</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterable&lt;Ingredient&gt; <span class="title">findAll</span><span class="params">()</span> </span>&#123;		</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// query</span></span><br><span class="line">    <span class="keyword">return</span> jdbc.query(<span class="string">&quot;select id, name, type from Ingredient&quot;</span>, <span class="keyword">this</span>::mapRowToIngredient);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 和上面的 findOne 一样</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">findById</span><span class="params">(String id)</span> </span>&#123;			</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// queryForObject</span></span><br><span class="line">    <span class="keyword">return</span> jdbc.queryForObject (</span><br><span class="line">        <span class="string">&quot;select id, name, type from Ingredient where id=?&quot;</span>, <span class="keyword">this</span>::mapRowToIngredient, id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Java 8 method reference &amp; lambdas</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Ingredient <span class="title">mapRowToIngredient</span><span class="params">(ResultSet rs, <span class="keyword">int</span> rowNum)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Ingredient(rs.getString(<span class="string">&quot;id&quot;</span>), rs.getString(<span class="string">&quot;name&quot;</span>),</span><br><span class="line">                          Ingredient.Type.valueOf(rs.getString(<span class="string">&quot;type&quot;</span>)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><code>query()</code>  &amp;  <code>queryForObject</code>:</p>
<ul>
<li>  <code>findById()</code>  returns one single object, use <code>queryForObject()</code>. </li>
<li><code>findAll()</code>  returns a collection of objects, use <code>query()</code>. <ul>
<li>  <code>query()</code>  accepts SQL &amp; impl of Spring’s <code>RowMapper</code>, to <u>map each row in the result set to an object</u></li>
</ul>
</li>
</ul>
<br>





<h3 id="Insert-a-Row"><a href="#Insert-a-Row" class="headerlink" title="Insert a Row"></a><u>Insert a Row</u></h3><p><code>JdbcTemplate</code> ‘s <code>update()</code> method:  Any query that writes / updates data in the DB.</p>
<p>Because it’s not necessary to map <code>ResultSet</code> data to an object, hence <code>update</code> is much simpler than <code>query</code>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Ingredient <span class="title">save</span><span class="params">(Ingredient ingredient)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    jdbc.update (</span><br><span class="line">        <span class="string">&quot;insert into Ingredient (id, name, type) values (?, ?, ?)&quot;</span>,</span><br><span class="line">        ingredient.getId(),</span><br><span class="line">        ingredient.getName(),</span><br><span class="line">        ingredient.getType().toString());</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ingredient;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Update Controller</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">showDesignForm</span><span class="params">(Model model)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    List&lt;Ingredient&gt; ingredients = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    ingredientRepo.findAll().forEach(i -&gt; ingredients.add(i));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 下面都一样</span></span><br><span class="line">    Type[] types = Ingredient.Type.values();</span><br><span class="line">    <span class="keyword">for</span> (Type type : types)</span><br><span class="line">        model.addAttribute(type.toString().toLowerCase(), filterByType(ingredients, type));</span><br><span class="line"></span><br><span class="line">    model.addAttribute(<span class="string">&quot;taco&quot;</span>, <span class="keyword">new</span> Taco());</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;design&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<h3 id="Define-DB-Schema"><a href="#Define-DB-Schema" class="headerlink" title="Define DB Schema"></a><u>Define DB Schema</u></h3><blockquote>
<p>  5 张表， 2个  Many to Many</p>
<p>  3张存实际内容，剩下两张存  Many to Many 关系</p>
</blockquote>
<img data-src="/images/posts/200420.png" style="zoom: 67%;" />

<br>



<p>利用 H2 database (文件名必须保持一致)：</p>
<blockquote>
<p>  <em>SQL will be executed when application starts</em></p>
</blockquote>
<ul>
<li>  Save DDL SQL to <code>resources/schema.sql</code>   </li>
<li>  Save additional data to <code>resources/data.sql</code></li>
</ul>
<br>







<h3 id="Insert-Data-with-FK"><a href="#Insert-Data-with-FK" class="headerlink" title="Insert Data with FK"></a><u>Insert Data with FK</u></h3><p>Two ways to save data with <code>JdbcTemplate</code>:</p>
<ul>
<li>  Directly using the <code>update()</code> method</li>
<li>  Using <code>SimpleJdbcInsert</code> wrapper class</li>
</ul>
<br>



<p>One Step further to complicate the situation: </p>
<p>According to the DB Schema above, when we save data, we also need to update the associated tables.</p>
<br>



<p><strong>With <code>JdbcTemplate</code></strong></p>
<blockquote>
<p>  Use <code>PreparedStatementCreator</code> &amp; <code>KeyHolder</code> together to get the auto generated ID.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Respository</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcTacoRepository</span> <span class="keyword">implements</span> <span class="title">TacoRepository</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> JdbcTemplate jdbc;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JdbcTacoRepository</span><span class="params">(JdbcTemplate jdbc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.jdbc = jdbc;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// save: 只是用来 call other methods</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Taco <span class="title">save</span><span class="params">(Taco taco)</span> </span>&#123;					</span><br><span class="line">        <span class="keyword">long</span> tacoId = saveTacoInfo(taco);</span><br><span class="line">        taco.setId(tacoId);</span><br><span class="line">        <span class="keyword">for</span> (Ingredient ingredient : taco.getIngredients())</span><br><span class="line">            saveIngredientToTaco(ingredient, tacoId);</span><br><span class="line">    </span><br><span class="line">    	<span class="keyword">return</span> taco;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">saveTacoInfo</span><span class="params">(Taco taco)</span> </span>&#123;</span><br><span class="line">        taco.setCreatedAt(<span class="keyword">new</span> Date());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这个是为了 KeyHolder</span></span><br><span class="line">        PreparedStatementCreator psc = <span class="keyword">new</span> PreparedStatementCreatorFactory(</span><br><span class="line">        <span class="string">&quot;insert into Taco(name, createdAt) values(?, ?)&quot;</span>, Types.VARCHAR, Types.TIMESTAMP)</span><br><span class="line">            .newPreparedStatementCreator(Arrays.asList(</span><br><span class="line">            taco.getName(), <span class="keyword">new</span> Timestamp(taco.getCreatedAt().getTime()) ));</span><br><span class="line"></span><br><span class="line">        KeyHolder kh = <span class="keyword">new</span> GeneratedKeyHolder();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// update() 中的两个参数， keyholder 提供 ID. 但为了使用 kh，必须先创建一个 psc</span></span><br><span class="line">        jdbc.update(psc, kh);				</span><br><span class="line">        <span class="keyword">return</span> kh.getKey().longValue();	</span><br><span class="line">        <span class="comment">// return 的是 tacoId （long）</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// update() doesn&#x27;t give us the auto generated tacoID</span></span><br><span class="line">    <span class="comment">// so we need saveTacoInfo to get the ID</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">saveIngredientToTaco</span><span class="params">(Ingredient ingredient, <span class="keyword">long</span> tacoId)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意这里的update（）</span></span><br><span class="line">        jdbc.update(<span class="string">&quot;insert into Taco_ingredients (taco, ingredient)&quot;</span> + <span class="string">&quot;values(?, ?)&quot;</span>,</span><br><span class="line">                   tacoID, ingredient.getId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<p><strong>Update Controller</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/design&quot;)</span></span><br><span class="line"><span class="meta">@SessionAttributes(&quot;order&quot;)</span>				<span class="comment">// 注意这个 annotation</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DesignTacoController</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IngredientRepository ingredientRepo;</span><br><span class="line">    <span class="keyword">private</span> TacoRepository tacoRepo;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Constructor! Assigns both to instance variables</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DesignTacoController</span><span class="params">(IngredientRepository ingredientRepo, TacoRepository tacoRepo)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.ingredientRepo = ingredeintRepo;</span><br><span class="line">        <span class="keyword">this</span>.tacoRepo = tacoRepo;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ensures that an order object will be created in the model</span></span><br><span class="line">    <span class="meta">@ModelAttribute(name = &quot;order&quot;)</span>		</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Order <span class="title">order</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Order();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@ModelAttribute(name = &quot;taco&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Taco <span class="title">taco</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Taco();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@PostMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">processDesign</span> <span class="params">(<span class="meta">@Valid</span> Taco taco, Errors errors, <span class="meta">@ModelAttribute</span> Order order)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (error.hasErrors())</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;design&quot;</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// injected tacoRepo</span></span><br><span class="line">        Taco saved = tacoRepo.save(taco);			</span><br><span class="line">        order.addDesign(saved);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;redirect:/orders/current&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>@SessionAttributes</code> &amp; <code>@ModelAttribute</code>:</p>
<ul>
<li><p>  The class-level <code>@SessionAttributes</code>  specifies that, any model objects ( <code>order</code>  &amp;  <code>taco</code> ) should be kept in session and available across multiple requests</p>
</li>
<li><p>  <code>order</code> is annotated with <code>@ModelAttribute</code>:  <code>order</code> ‘s value should come from the model, and MVC shouldn’t attempt to bind request parameters to it</p>
</li>
<li><p>The <code>Order</code> object isn’t saved to the DB until the user completes &amp; submits the order form.</p>
</li>
</ul>
<br>



<hr>
<h2 id="Simple-JDBC-Insert"><a href="#Simple-JDBC-Insert" class="headerlink" title="Simple JDBC Insert"></a>Simple JDBC Insert</h2><blockquote>
<p>  Improvement of <code>JdbcTemplate</code></p>
</blockquote>
<br>



<p>Rewrite <code>JdbcOrderRepository</code> with <code>SimpleJdbcInsert</code></p>
<blockquote>
<p>  Jackson: for JSON processing</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcOrderRepository</span> <span class="keyword">implements</span> <span class="title">OrderRepository</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Jackson’s ObjectMapper</span></span><br><span class="line">    <span class="keyword">private</span> ObjectMapper objectMapper;	</span><br><span class="line">    <span class="keyword">private</span> SimpleJdbcInsert orderInserter;</span><br><span class="line">    <span class="keyword">private</span> SimpleJdbcInsert oderTacoInserter;</span><br><span class="line">    			</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JdbcOrderRepository</span> <span class="params">(JdbcTemplate jdbc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.orderInserter = <span class="keyword">new</span> SimpleJdbcInserter(jdbc)</span><br><span class="line">            <span class="comment">// 这里 generate ID！</span></span><br><span class="line">            .withTableName(<span class="string">&quot;Taco_Order&quot;</span>).usingGeneratedKeyColumns(<span class="string">&quot;id&quot;</span>);  </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>.OrderTacoInserter = <span class="keyword">new</span> SimpleJdbcInserter(jdbc)</span><br><span class="line">            .withTableName(<span class="string">&quot;Taco_Order_Tacos&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>.objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Insert data</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="comment">// save() doesn&#x27;t save anything, but define the flow for saing an order &amp; associated taco object</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Order <span class="title">save</span><span class="params">(Order order)</span> </span>&#123;</span><br><span class="line">    order.setPlacedAt(<span class="keyword">new</span> Date());</span><br><span class="line">    <span class="keyword">long</span> orderId = saveOrderDetails(order);</span><br><span class="line">    order.setId(orderId);</span><br><span class="line">    List&lt;Taco&gt; tacos = order.getTacos();</span><br><span class="line">    <span class="keyword">for</span> (Taco taco : tacos)</span><br><span class="line">        saveTacoToOrder(taco, orderId);</span><br><span class="line">    <span class="keyword">return</span> order;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">saveOrderDetails</span><span class="params">(Order order)</span> </span>&#123;</span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    Map&lt;String, Object&gt; values = objectMapper.convertValue(order, Map.class);</span><br><span class="line">    values.put(<span class="string">&quot;placedAt&quot;</span>, order.getPlacedAt());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// executeAndReturnKey()!</span></span><br><span class="line">    <span class="keyword">long</span> orderId = orderInserter.executeAndReturnKey(values).longValue();</span><br><span class="line">    <span class="keyword">return</span> orderId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">saveTacoToOrder</span><span class="params">(Taco taco, <span class="keyword">long</span> orderId)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, Object&gt; values = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    values.put(<span class="string">&quot;tacoOrder&quot;</span>, orderId);</span><br><span class="line">    values.put(<span class="string">&quot;taco&quot;</span>, taco.getId());</span><br><span class="line">    orderTacoInserter.execute(values);	<span class="comment">// execute()</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<p><strong>Update Controller</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/orders&quot;)</span></span><br><span class="line"><span class="meta">@SessionAttributes(&quot;order&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderController</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span> OrderRepository orderRepo;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">OrderController</span><span class="params">(OrderRepository orderRepo)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.orderRepo = orderRepo;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@PostMapping</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">processOrder</span><span class="params">(<span class="meta">@Valid</span> Order order, Errors errors, SessionStatus sessionStatus)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (errors.hasErrors()) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;orderForm&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    orderRepo.save(order);</span><br><span class="line">    sessionStatus.setComplete();</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;redirect:/&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>

<hr>
<h2 id="JPA"><a href="#JPA" class="headerlink" title="JPA"></a>JPA</h2><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a><u>Intro</u></h3><p>The Spring Data Project includes:</p>
<ul>
<li>  JPA</li>
<li>  MongoDB (document DB)</li>
<li>  Neo4j (graph DB)</li>
<li>  Redis</li>
<li>  Cassandra</li>
</ul>
<br>



<p>The most useful feature: <strong>Auto create repositories</strong>, based on a repository-specific interface</p>
<br>





<h3 id="Dependency"><a href="#Dependency" class="headerlink" title="Dependency"></a><u>Dependency</u></h3><blockquote>
<p>  <em>The starter dependency transitively includes Hibernate as the JPA implementation</em></p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-jpa<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p>Use a different JPA implementation: <strong>Must exclude Hibernate at first</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-jpa<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hibernate-entitymanager<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.hibernate<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.eclipse.persistence<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>eclipselink<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>





<br>



<h3 id="Domain-Entity-Annotation"><a href="#Domain-Entity-Annotation" class="headerlink" title="Domain / Entity Annotation"></a><u>Domain / Entity Annotation</u></h3><blockquote>
<p>  约定： 如果不用 JPA，就用 Domain；    如果用了 JPA，那就叫 Entity</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@RequiredArgsConstructor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// JPA requires that entities have a no-argument constructor</span></span><br><span class="line"><span class="comment">// 如果写了 @RequiredArgsConstructor，那下面的也必须要。</span></span><br><span class="line"><span class="meta">@NoArgsConstructor(access=AccessLevel.PRIVATE, force=true)</span></span><br><span class="line"><span class="meta">@Entity</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Ingredient</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Id</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String id;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Type type;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> statis <span class="class"><span class="keyword">enum</span> <span class="title">Type</span> </span>&#123;</span><br><span class="line">        WRAP, PROTEIN, VEGGIES, CHEESE, SAUCE</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>The <code>@Data</code> implicitly adds a required argument constructor, but when a <code>@NoArgsConstructor</code> is used, that constructor gets removed. </p>
<p>An explicit <code>@RequiredArgsConstructor</code> ensures that you’ll still have a required arguments constructor, apart from the <code>private</code> no-argument constructor.</p>
<br>



<p>多对多关系：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Entity</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Taco</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Id</span></span><br><span class="line">    <span class="meta">@GeneratedValue(strategy=Generationtype.AUTO)</span></span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotNull</span></span><br><span class="line">    <span class="meta">@Size(min=5, message=&quot;Name must be at least 5 characters long&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ManyToMany(targetEntity=Ingredient.class)</span></span><br><span class="line">    <span class="meta">@Size(min=1, message=&quot;You must choose at least 1 ingredient&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; ingredients;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> Data createdAt;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// set createdAt to the current time before Taco is persisted</span></span><br><span class="line">    <span class="meta">@PrePersist</span>				</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">createdAt</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.createdAt = <span class="keyword">new</span> Date();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>关于 <code>@Table</code>  &amp;  <code>Serializable</code>:  总是成对出现</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Table(name = &quot;Taco_Order&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Order</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure>

<p>为什么这里需要 <code>@Table</code>:</p>
<p>Without <code>@Table</code>, JPA will persist the entities to a table named <code>Order</code>. </p>
<p>But order is a reserved word in SQL. Therefore we need to specify the table.</p>
<br>





<h3 id="JPA-Repositories"><a href="#JPA-Repositories" class="headerlink" title="JPA Repositories"></a><u>JPA Repositories</u></h3><br>



<h4 id="CrudRepository"><a href="#CrudRepository" class="headerlink" title="CrudRepository"></a>CrudRepository</h4><blockquote>
<p>  <strong>When the application starts, Spring Data JPA auto implements the CrudRepo Interface</strong>.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IngredientRepository</span> <span class="keyword">extends</span> <span class="title">CrudRepository</span>&lt;<span class="title">Ingredient</span>, <span class="title">String</span>&gt; </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1st param (Ingredient): entity type to persist (object)</span></span><br><span class="line"><span class="comment">// 2nd param (String): ID type (is string)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TacoRepository</span> <span class="keyword">extends</span> <span class="title">CrudRepositoy</span>&lt;<span class="title">Taco</span> <span class="title">Long</span>&gt; </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// entity type is Taco, ID type is Long</span></span><br></pre></td></tr></table></figure>



<br>



<h4 id="Customization"><a href="#Customization" class="headerlink" title="Customization"></a>Customization</h4><p>When generating the repository implementation, Spring Data parse the method name in the Repository, and attempts to understand the method’s purpose in the context of the persisted object. Spring Data defines <strong>domain-specific language (DSL)</strong> , where persistence details are expressed in <u>repository method signatures</u>.</p>
<p>Repository methods are composed of:</p>
<ul>
<li>  <strong>verb</strong> (e.g. find = get = read,  count)</li>
<li>  <strong>subject</strong> (optional)</li>
<li>  <strong>By</strong> </li>
<li>  <strong>predicate</strong> (e.g.   DeliveryZip)</li>
<li>  <strong>operator</strong>  (条件 / 比较)</li>
</ul>
<br>



<p>Get all orders delivered to a given zip:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Find all Order entities by matching deliveryZip with the param passed in the interface</span></span><br><span class="line"><span class="comment">// String deliveryZip is the passed parameter</span></span><br><span class="line"><span class="function">List&lt;Order&gt; <span class="title">findByDeliveryZip</span><span class="params">(String deliveryZip)</span></span>;</span><br></pre></td></tr></table></figure>



<br>



<p>Get all orders delivered to a given zip within a time range:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// You can write: getPuppies, and it still works. Because subject is optional</span></span><br><span class="line"><span class="comment">// start &amp; end date must fall between the given values</span></span><br><span class="line"><span class="function">List&lt;Order&gt; <span class="title">getOrdersByDeliveryZipAndPlacedAtBetween</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    String deliveryZip, Date startDate, Date endDate)</span></span>;</span><br></pre></td></tr></table></figure>



<br>



<p>Spring Data operators:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 排序. e.g. findByDeliveryCityOrderByDeliveryTo (String city)</span></span><br><span class="line">OrderBy</span><br><span class="line"></span><br><span class="line">IsTrue, True</span><br><span class="line">IsFalse, False</span><br><span class="line"></span><br><span class="line">Is , Equals</span><br><span class="line">IsNot , Not</span><br><span class="line"></span><br><span class="line"><span class="comment">// All: Ignore all cases in all matched strings</span></span><br><span class="line">AllIgnoringCase, AllIgnoresCase</span><br><span class="line">IgnoringCase, IgnoresCase</span><br><span class="line"></span><br><span class="line">IsAfter, After, IsGreaterThan, GreaterThan</span><br><span class="line">IsBefore, Before, IsLessThan, LessThan</span><br><span class="line"></span><br><span class="line">IsGreaterThanEqual, GreaterThanEqual</span><br><span class="line">IsLessThanEqual, LessThanEqual</span><br><span class="line"></span><br><span class="line">IsNull, Null</span><br><span class="line">IsNotNull, NotNull</span><br><span class="line"></span><br><span class="line">IsIn, In</span><br><span class="line">IsNotIn, NotIn</span><br><span class="line"></span><br><span class="line">IsBetween, Between</span><br><span class="line">IsContaining, Containing, Contains</span><br><span class="line"></span><br><span class="line">IsStartingWith, StartingWith, StartsWith</span><br><span class="line">IsEndingWith, EndingWith, EndsWith</span><br><span class="line"></span><br><span class="line">IsLike, Like</span><br><span class="line">IsNotLike, NotLike</span><br></pre></td></tr></table></figure>





<br>



<h4 id="SQL-Query"><a href="#SQL-Query" class="headerlink" title="SQL Query"></a>SQL Query</h4><p>With <code>@Query</code>, we can explicitly specify the query to be performed.  （遇到复杂的情况）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Query(&quot;Order order where order.deliveryCity=&#x27;Seattle&#x27;&quot;)</span></span><br><span class="line"><span class="function">List&lt;Order&gt; <span class="title">getOrdersDeliveredInSeattle</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="Update-Controller"><a href="#Update-Controller" class="headerlink" title="Update Controller"></a>Update Controller</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/orders&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Need @SessionAttributes</span></span><br><span class="line"><span class="meta">@SessionAttributes(&quot;order&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Final</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> OrderRepository orderRepo;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Constructor. Autowired</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">OrderController</span><span class="params">(OrderRepository orderRepo)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.orderRepo = orderRepo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/current&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">orderForm</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;orderForm&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">processOrder</span><span class="params">(<span class="meta">@Valid</span> Order order, Errors errors, SessionStatus sessionStatus)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (errors.hasErrors())</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;orderForm&quot;</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// save() method, save to repo</span></span><br><span class="line">        orderRepo.save(order);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// set to complete</span></span><br><span class="line">        sessionStatus.setComplete();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;redirect:/&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>

<br>

]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 02 MVC</title>
    <url>/2020/SpringBoot-02/</url>
    <content><![CDATA[<p>This is the second post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English. </p>
<p>In this post, I am going to cover the basics of Spring Web MVC.</p>
<span id="more"></span>

<br>



<hr>
<h2 id="Web-MVC"><a href="#Web-MVC" class="headerlink" title="Web MVC"></a>Web MVC</h2><blockquote>
<p>  How to display model data &amp; process form input</p>
</blockquote>
<br>



<p><strong>Template view:</strong></p>
<ul>
<li><p>  <strong>JSP</strong> pages      (<code>main/WEB-INF</code>)</p>
</li>
<li><p><strong>Thymeleaf</strong>    (<code>main/resources/templates</code>)</p>
  <br>
  
</li>
</ul>
<p><strong>Disable template cache</strong>:   </p>
<ul>
<li><p><code>spring.thymeleaf.cache = false</code>     (add this to <code>application.properties</code>)</p>
<p>  ​    (Remember to set back to <code>True</code> in production)</p>
</li>
<li><p>  Use <strong>DevTools</strong> (auto disable cache in dev env, auto enable in production env)</p>
</li>
</ul>
<br>

<hr>
<h2 id="Domain"><a href="#Domain" class="headerlink" title="Domain"></a>Domain</h2><blockquote>
<p>  <strong>Debug</strong>:  Also need to add lombok extension in IDE.</p>
</blockquote>
<br>



<p><strong>Lombok</strong>: Auto generate getter &amp; setter methods and constructors, based on all <code>final</code> properties</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个 annotation 可以不要，因为 @Data 会自动创建相关 constructor</span></span><br><span class="line"><span class="meta">@RequiredArgsConstructor</span>	</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Ingredient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String id;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Type type;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">enum</span> <span class="title">Type</span> </span>&#123;</span><br><span class="line">        WRAP, PROTEIN, VEGGIES, CHEESE, SAUCE</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>Related dependency:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>





<br>

<hr>
<h2 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h2><blockquote>
<p>  Handle HTTP requests from client</p>
</blockquote>
<br>



<h3 id="Handling-GET-requests"><a href="#Handling-GET-requests" class="headerlink" title="Handling GET requests"></a><u>Handling GET requests</u></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Logger</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Component scan</span></span><br><span class="line"><span class="meta">@Controller</span>	</span><br><span class="line"></span><br><span class="line"><span class="comment">// at class level, specify the path</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/design&quot;)</span>	</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DesignTacoController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Only use @RequestMapping at class level. Use new annotations here</span></span><br><span class="line">    <span class="meta">@GetMapping</span>		</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">showDesignForm</span><span class="params">(Model model)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        List&lt;Ingredient&gt; ingredients = Arrays.asList(</span><br><span class="line">                <span class="keyword">new</span> Ingredient(<span class="string">&quot;FLTO&quot;</span>, <span class="string">&quot;Flour Tortilla&quot;</span>, Type.WRAP),</span><br><span class="line">                <span class="keyword">new</span> Ingredient(<span class="string">&quot;SRCR&quot;</span>, <span class="string">&quot;Sour Cream&quot;</span>, Type.SAUCE) );</span><br><span class="line"></span><br><span class="line">        Type[] types = Ingredient.Type.values();</span><br><span class="line">        <span class="keyword">for</span> (Type type : types)</span><br><span class="line">            model.addAttribute(type.toString().toLowerCase(), filterByType(ingredients, type));</span><br><span class="line"></span><br><span class="line">        model.addAttribute(<span class="string">&quot;design&quot;</span>, <span class="keyword">new</span> Taco());</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// return view name &quot;design&quot; (ressources/templates/design.html)</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;design&quot;</span>;	</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> List&lt;Ingredient&gt; <span class="title">filterByType</span><span class="params">(List&lt;Ingredient&gt; ingredients, Type type)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ingredients.stream()</span><br><span class="line">                .filter(x -&gt; x.getType().equals(type))</span><br><span class="line">                .collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><code>@Slf4j</code>:  Simple Logging Facade for Java. </p>
<p>​    Lombok-provided annotation, auto generate logger at runtime</p>
<br>



<p><code>@GetMapping</code>  &amp; class-level <code>@RequestMapping</code>:           </p>
<ul>
<li><p>  When <code>/design</code> receives a HTTP GET request,   <code>showDesignForm()</code>  will be called to handle the request</p>
</li>
<li><p><code>@GetMapping</code>:   New in Spring <strong>4.3</strong>.  Old method:</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// lazy way, leave off the method attribute</span></span><br><span class="line"><span class="meta">@RequestMapping(method = RequestMethod.GET)</span>		 </span><br></pre></td></tr></table></figure></li>
<li><p>  All request-mapping annotations:</p>
</li>
</ul>
<p>​        <code>@RequestMapping</code></p>
<p>​        <code>@GetMapping</code></p>
<p>​        <code>@PostMapping</code></p>
<p>​        <code>@PutMapping</code></p>
<p>​        <code>@DeleteMapping</code></p>
<p>​        <code>@PatchMapping</code></p>
<br>



<p><code>Model</code>:  an object that transfers data between  controller &amp; view. ??</p>
<p>​    Data placed in <code>Model</code> attributes is copied into the servlet response attributes, where the view can find them</p>
<br>



<h3 id="Handling-POST-request"><a href="#Handling-POST-request" class="headerlink" title="Handling POST request"></a><u>Handling POST request</u></h3><blockquote>
<p>   Fields in the form are bound to properties of a <code>Taco</code> object</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Taco passed as a parameter in processDesign</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">processDesign</span><span class="params">(Taco taco)</span> </span>&#123;	</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// log for input data processing</span></span><br><span class="line">    log.info(<span class="string">&quot;Processing design: &quot;</span> + taco);	</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// redirection，直接跳转到 /orders/current</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;redirect:/orders/current&quot;</span>;	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<hr>
<h2 id="Validate-Form-Input"><a href="#Validate-Form-Input" class="headerlink" title="Validate Form Input"></a>Validate Form Input</h2><blockquote>
<p>  The clumsy way: litter the controller with a bunch of  <code>if / then</code></p>
</blockquote>
<br>



<p>Recommended: <strong>Java Bean Validation API</strong>   (JSR-303)</p>
<p>Validation API &amp; its Hibernate implementation are auto added to the project as <strong>transient</strong> dependencies in the <strong>web starter</strong>.</p>
<br>



<p>Steps to apply validation:</p>
<ul>
<li>  Declare validation rules in domain classes</li>
<li>  Specify validation should be performed in controller methods with <code>@PostMapping</code></li>
<li>  Modify views to display validation errors</li>
</ul>
<br>



<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a><u>Example 1</u></h3><p>Taco domain:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Taco</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@NotNull</span></span><br><span class="line">    <span class="meta">@Size(min=5, message=&quot;Name must be at least 5 characters long&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Size(min=1, message=&quot;You must choose at least 1 ingredient&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; ingredients;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>Taco controller (添加 validation):</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里不一样</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">processDesign</span><span class="params">(<span class="meta">@Valid</span> Taco taco, Errors errors)</span> </span>&#123;	</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 还有这里，如果出错，redisplay the form</span></span><br><span class="line">    <span class="keyword">if</span> (errors.hasErrors())	</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;design&quot;</span>;		</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 如果没有出错，再用 log</span></span><br><span class="line">    log.info(<span class="string">&quot;Processing design: &quot;</span> + taco);	</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;redirect:/orders/current&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a><u>Example 2</u></h3><p>Order excerpt:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Only make sure this isn&#x27;t blank</span></span><br><span class="line"><span class="meta">@NotBlank(message=&quot;Name is required&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Annotation here: Hibernate 自带!   —— 算法： Luhn algorithm check</span></span><br><span class="line"><span class="meta">@CreditCardNumber(message=&quot;Not a valid credit card number&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String ccNumber;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Note the regex here! For validating Credit Card exp. date!</span></span><br><span class="line"><span class="meta">@Pattern(regexp=&quot;^(0[1-9]|1[0-2])([\\/])([1-9][0-9])$&quot;, message=&quot;Must be formatted MM/YY&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String ccExpiration;</span><br></pre></td></tr></table></figure>



<p>Order controller:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">processDesign</span><span class="params">(<span class="meta">@Valid</span> Taco taco, Errors errors)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 这一句是模板</span></span><br><span class="line">    <span class="keyword">if</span> (errors.hasErrors())							</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;design&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    log.info(<span class="string">&quot;Processing design: &quot;</span> + taco);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;redirect:/orders/current&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<br>

<hr>
<h2 id="View-Controllers"><a href="#View-Controllers" class="headerlink" title="View Controllers"></a>View Controllers</h2><p>The controllers written so far:</p>
<ul>
<li>  All annotated with <code>@Controller</code>: auto discovered by Spring component scanning, and instantiated as beans in the context</li>
<li>  All annotated with <code>@GetMapping</code>, <code>@PostMapping</code>:  specify which method should handle what requests</li>
</ul>
<br>



<p>A <strong>view controller</strong>: does not process data / input, only <u>forward the <code>GET</code> request to a view</u></p>
<blockquote>
<p>  <em>Create a new config class for each kind of configuration (e.g. web, data, security)</em></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// WebMvcConfigurer interface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebConfig</span> <span class="keyword">implements</span> <span class="title">WebMvcConfigurer</span> </span>&#123;			</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// need to override</span></span><br><span class="line">    <span class="meta">@Override</span>		</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// void!</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addViewControllers</span><span class="params">(ViewControllerRegistry registry)</span> </span>&#123;		</span><br><span class="line">        registry.addViewController(<span class="string">&quot;/&quot;</span>).setViewName(<span class="string">&quot;home&quot;</span>);	</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>  <strong>Registry</strong>: register one or more view controllers</li>
</ul>
<br>

]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot - 01 Intro</title>
    <url>/2020/SpringBoot-01/</url>
    <content><![CDATA[<p>This is the first post in a series of posts to cover different aspects of Spring Boot. Please note that the entire post isn’t necessarily only written in English. </p>
<p>In this post, I am going to cover the basic concepts, and related files in a simple Spring Boot project, so let’s get started.</p>
<span id="more"></span>

<br>



<h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h3><br>




<p><strong>Old times:</strong></p>
<p>The most common types of applications developed were <strong>browser-based web applications</strong>, backed by <strong>relational databases</strong>.</p>
<br>



<p><strong>Nowadays:</strong></p>
<p>Microservices destined for the cloud that persist data in a variety of databases</p>
<p>New interest in <strong>reactive programming</strong>, with non-blocking operations</p>
<br>



<h3 id="Spring-Container-DI-Web-MVC"><a href="#Spring-Container-DI-Web-MVC" class="headerlink" title="Spring:   ( Container + DI + Web MVC )"></a>Spring:   ( Container + DI + Web MVC )</h3><p>Offers a <strong>container</strong>:  the Spring application context  — creates &amp; manages application <strong>components</strong> (= <strong>beans</strong>)</p>
<p>Components are wired together inside the Spring application context (<strong>beans wired in container</strong>)</p>
<br>



<p><strong>Dependency Injection (DI)</strong>:  </p>
<p>A DI application relies on a separate entity (container) to create &amp; manage all beans, and inject those into the beans that need them.</p>
<p>Done through: <u>constructor argument</u>,   <u>property accessor methods</u>.</p>
<br>

<div class="note success"><p>A <strong><a href="https://stackoverflow.com/a/2465052/13408151">DI container</a></strong> wires together independent components into a complete application <strong>at runtime</strong>.</p>
</div>



<p>Dependency injection means <strong>giving an object its instance variables</strong>. The fact that we can <u>statically bind interfaces into the object’s method that instantiates it</u>, serves a purpose for better lookup and stronger support for “<strong>programming to an interface</strong>“. Dynamic language is nothing but <u>injecting dependencies runtime</u> as the object knows nothing about the caller. </p>
<br>

<p>In a non-dependency-injection framework, the application is <strong>decomposed into classes</strong> where each class often has <strong>explicit linkages to other classes</strong> in the application. The linkages are the <strong>invocation of a class constructor</strong> directly in the code. </p>
<div class="note info"><p>Spring is based on the concept of <strong>dependency injection.</strong></p>
<p>A dependency injection framework <strong>externalize the relationship between objects</strong> within the application through convention  &amp; <strong>annotations</strong>, rather than those objects having <u>hard-coded knowledge about each other</u>.</p>
</div>



<br>



<p><strong>Components = Beans</strong> in Spring application context:</p>
<ul>
<li>  Declared explicitly with Xml / Java</li>
<li>  Discovered by component scanning</li>
<li>  Configured by Spring Boot autoconfig</li>
</ul>
<br>



<p><strong>Spring Web MVC</strong>:</p>
<ul>
<li>  Web framework</li>
<li>  Annotation-based   (e.g.  request-handling methods with <code>@RequestMapping</code>, <code>@GetMapping</code>,  return template view name)</li>
<li>  Supports Java Bean Validation API &amp; Hibernate Validator</li>
</ul>
<br>





<h3 id="Spring-Boot-Autoconfig-Starter-dependencies-Runtime-insights"><a href="#Spring-Boot-Autoconfig-Starter-dependencies-Runtime-insights" class="headerlink" title="Spring Boot: ( Autoconfig + Starter dependencies + Runtime insights )"></a>Spring Boot: ( Autoconfig + Starter dependencies + Runtime insights )</h3><p>Start Spring Boot:  log entry saying <code>Tomcat started</code></p>
<ul>
<li>  Spring Boot applications bring everything they need within them</li>
<li>  You never deploy your application to Tomcat, because Tomcat is part of your application</li>
</ul>
<br>



<p>With <code>starter-web</code> &amp; <code>Thymeleaf</code>, when starting the app, <strong>Spring Boot autoconfig</strong> detects those libraries and automatically:</p>
<ul>
<li>  Config the beans in the Spring application context to enable Spring MVC</li>
<li>  Config embedded Tomcat server in the Spring application context</li>
<li>  Config a <strong>view resolver</strong> for Spring MVC view rendering with Thymeleaf</li>
</ul>
<br>



<p><strong>Additional features:</strong></p>
<ul>
<li>  <strong>Spring Boot CLI</strong>: command-line interface,  alternative programming model based on <strong>Groovy scripts</strong></li>
<li>  <strong>Actuator</strong>: provides runtime insight.  (e.g.  metrics, health, thread dump info)</li>
<li>  Additional testing support</li>
<li>  Flexible specification of env properties</li>
</ul>
<br>



<h2 id="Config-（3-Ways）"><a href="#Config-（3-Ways）" class="headerlink" title="Config （3 Ways）"></a>Config （3 Ways）</h2><p><strong>Configure the Spring application context to wire beans</strong>:</p>
<p><strong>XML</strong> file: describe components &amp; their relation to other components</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Declares 2 beans: oneService &amp; twoService --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;oneService&quot;</span>	<span class="attr">class</span>=<span class="string">&quot;demo.OneService&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;twoService&quot;</span> <span class="attr">class</span>=<span class="string">&quot;demo.TwoService&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">ref</span>=<span class="string">&quot;oneService&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Inject (wire) oneService into twoService via the constructor argument --&gt;</span></span><br></pre></td></tr></table></figure>






<br>





<p><strong>Java</strong>-based config:</p>
<blockquote>
<p>  Greater type safety, more refactorable</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// @: indicates config class, provide beans to Spring application context</span></span><br><span class="line"><span class="meta">@Configuration</span>	</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServiceConfig</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// @Bean: returned objects are added as beans in the context</span></span><br><span class="line">    <span class="meta">@Bean</span>	</span><br><span class="line">    <span class="function"><span class="keyword">public</span> OneService <span class="title">oneService</span><span class="params">()</span> </span>&#123;	</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// constructor: return the new service</span></span><br><span class="line">    	<span class="keyword">return</span> <span class="keyword">new</span> OneService();	</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TwoService <span class="title">twoService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    	<span class="keyword">return</span> <span class="keyword">new</span> TwoService(oneService());	<span class="comment">// inject into...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<p><strong>Auto</strong> config:</p>
<ul>
<li><p>  <strong>Component scanning</strong>: auto discover components from application classpath, then create them as beans.</p>
</li>
<li><p><strong>Autowiring</strong>:   auto inject components along with the depended beans.</p>
<blockquote>
<p>  <strong>Spring Boot</strong>: Extension of the Spring framework. Improvement in <strong>autoconfig</strong> (No need Xml / Java config files).</p>
<p>  ​                            Spring Boot can make guesses of what components need to be configured and wired together,</p>
<p>  ​                            based on entries in the classpath, environment vars.</p>
</blockquote>
</li>
</ul>
<br>





<h2 id="Pom-File"><a href="#Pom-File" class="headerlink" title="Pom File"></a>Pom File</h2><p><code>mvnw</code>  &amp; <code>mvnw.cmd</code>:  Maven wrapper scripts</p>
<br>



<p>In <code>pom.xml</code>:  Use <strong>JAR</strong> packaging, instead of WAR.    (Jar is better for the cloud)</p>
<ul>
<li><p><strong>War</strong>: Good for deploying to traditional Java app server (Tomcat), not good for most cloud platforms</p>
<ul>
<li>  War deploy: war packaging + web initializer class (<code>web.xml</code>)</li>
</ul>
  <br>

  

<p>  <strong>Parent pom</strong>: <code>spring-boot-starter-parent</code></p>
<ul>
<li>  Provides dependency management for several libs frequently used in Spring projects.</li>
</ul>
  <br>

  

<p>  <strong>Starter</strong> dependencies:  they don’t have any library code,  but pull from other libraries transitively</p>
<blockquote>
<p>  Web starter:  includes embedded Tomcat</p>
</blockquote>
<ul>
<li>  Smaller build file, easy to manage</li>
<li>  Think of dependencies in terms of capabilities, but not library names</li>
<li>  Stop worrying about library versions &amp; conflicts</li>
</ul>
  <br>

  

<p>  <strong>Maven Plugin</strong>:  </p>
<ul>
<li>  Provides a Maven goal for you to run with Maven</li>
<li>  All dependencies are included within the <u>executable JAR file</u>, and are available on the <u>runtime path</u></li>
<li>  Produces a manifest file in the JAR file: denotes the bootstrap class (<code>main.java</code>) as the main class for the executable JAR</li>
</ul>
</li>
</ul>
<br>





<h2 id="Main-Class"><a href="#Main-Class" class="headerlink" title="Main Class"></a>Main Class</h2><p>The bootstrapped main class:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainApplication</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// the run method: perform the actual bootstrapping, create the Spring application context</span></span><br><span class="line">        SpringApplication.run(MainApplication.class, args);</span><br><span class="line">        <span class="comment">// The two passed params: config class, and command-line arguments (args)</span></span><br><span class="line">    &#125;	</span><br><span class="line">&#125;	</span><br></pre></td></tr></table></figure>

<p>The annotation <code>@SpringBootApplication</code>:     A composite annotation that combines 3 other annotations</p>
<ul>
<li><p>  <code>@SpringBootConfiguration</code>:  This is a config class  (Specialized form of <code>@Configuration</code> )</p>
</li>
<li><p>  <code>@EnableAutoConfiguration</code>:   enable autoconfig (config any components that it thinks you need)</p>
</li>
<li><p><code>@ComponentScan</code>:  </p>
<ul>
<li>  Let you declare other classes with annotations like <code>@Controller</code>, <code>@Service</code></li>
<li>Have Spring auto discover classes and register them as components int he Spring application context</li>
</ul>
</li>
</ul>
<br>



<h2 id="Main-Test-Class"><a href="#Main-Test-Class" class="headerlink" title="Main Test Class"></a>Main Test Class</h2><p>Baseline test class:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"></span><br><span class="line"><span class="comment">// use Spring Boot Runner</span></span><br><span class="line"><span class="meta">@RunWith(SpringRunner.class)</span>	</span><br><span class="line"></span><br><span class="line"><span class="comment">// Spring Boot test</span></span><br><span class="line"><span class="meta">@SpringBootTest</span>		</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TacoCloudApplicationTests</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="comment">// the test method</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextLoads</span><span class="params">()</span> </span>&#123;&#125;	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此 baseline 测试的作用： check if the Spring application context can be loaded successfully.</p>
<br>



<p><code>@RunWith</code>:   a JUnit annotation, provide a test runner that guides JUnit in running tests</p>
<ul>
<li>  相当于： applying a plugin to JUnit to provide custom testing behavior</li>
<li>  上面例子中:  the imported <code>SpringRunner</code>  is a Spring-provided test runner (test the creation of a Spring application context)</li>
<li><code>SpringRunner</code>  =   <code>SpringJUnit4ClassRunner</code><ul>
<li>  Introduced in Spring <strong>4.3</strong>, to remove association with a specific JUnit version</li>
</ul>
</li>
</ul>
<br>



<h2 id="Web-Requests"><a href="#Web-Requests" class="headerlink" title="Web Requests"></a>Web Requests</h2><p><strong>Spring’s web framework: Spring MVC</strong></p>
<p>Central concept of Spring MVC:  <strong>controller</strong>  ——  A class that handles HTTP requests and response   </p>
<ul>
<li>  e.g. respond by optionally populating model data, then passing the request to a View to produce HTML</li>
</ul>
<br>



<p>A sample controller:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Controller;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HomeController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// handles requests for the root path</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&quot;)</span>	</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">home</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// returns the view name</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;home&quot;</span>;	</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><code>@Controller</code>:   Primary purpose is to identify this class as a component (for component scanning)</p>
<ul>
<li>  You could annotate <code>HomeController</code> as <code>@Service</code>, <code>@Repositoy</code>, and it still works the same  （亲测，确实如此！）</li>
</ul>
<br>



<p>Controller Test:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RunWith(SpringRunner.class)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Web MVC test</span></span><br><span class="line"><span class="meta">@WebMvcTest(HomeController.class)</span>	</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HomeControllerTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Autowire: Inject MockMVC</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> MockMvc mockMvc;	</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testHomePage</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Perform HTTP request GET (client side)</span></span><br><span class="line">        mockMvc.perform(get(<span class="string">&quot;/&quot;</span>))	</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// Expect: Servlet side.  3样东西：HTTP 200 OK, Home view, &quot;Welcome to...&quot;</span></span><br><span class="line">                .andExpect(status().isOk())		</span><br><span class="line">                .andExpect(view().name(<span class="string">&quot;home&quot;</span>))	</span><br><span class="line">                .andExpect(content().string(containsString(<span class="string">&quot;Welcome to...&quot;</span>)));</span><br><span class="line">    &#125;												</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><code>@WebMvcTest</code>:  Arranges the test to run in <u>Spring MVC application context</u> </p>
<ul>
<li>  上面例子中： arranges to register   <code>HomeController</code>  in Spring MVC, so you can throw requests like <code>GET</code></li>
</ul>
<br>



<h2 id="DevTools"><a href="#DevTools" class="headerlink" title="DevTools"></a>DevTools</h2><p>About dev tools:</p>
<ul>
<li>  Auto application restart when code changes</li>
<li>  Auto browser refresh when template changes  &amp;  Auto disable template cache</li>
<li>  Builtin H2 console for H2 database</li>
<li>  When deploying in a production environment, it will be self-disabled</li>
</ul>
<br>



<p>With dev tools, the application is loaded into <strong>2 separate class loaders</strong> in JVM. </p>
<ul>
<li>  One is loaded with files under <code>/src/main</code>    (may change frequently)</li>
<li>  Other is loaded with dependency libraries    (change less often)</li>
</ul>
<p><strong>Cons</strong>:  dependency changes won’t be available in auto restarts</p>
<ul>
<li>  Because the class loader containing dependency libraries isn’t automatically reloaded</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Angular, a MVC Framework</title>
    <url>/2020/Angular/</url>
    <content><![CDATA[<p>In this post, I will discuss some basic aspects of the Angular framework, and improvements Angular has brought to the frontend development.</p>
<span id="more"></span> 



<br>

<h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><br>

<h3 id="AngularJS-amp-Angular"><a href="#AngularJS-amp-Angular" class="headerlink" title="AngularJS &amp; Angular"></a><u>AngularJS &amp; Angular</u></h3><p>AngularJS is the first version of the Angular Framework, and it’s JavaScript-based. On the other hand, Angular refers to all the releases after the first version, and it’s TypeScript-based.</p>
<br>

<h3 id="Directive"><a href="#Directive" class="headerlink" title="Directive"></a><u>Directive</u></h3><blockquote>
<p>  <em>Something similar to the concept of <strong>Directive</strong> is always there since the beginning of browsers and the web.</em></p>
</blockquote>
<br>



<h4 id="The-Shadow-DOM-amp-Built-in-Browser-Directives"><a href="#The-Shadow-DOM-amp-Built-in-Browser-Directives" class="headerlink" title="The Shadow DOM &amp; Built-in Browser Directives"></a>The Shadow DOM &amp; Built-in Browser Directives</h4><p>For instance, a plain input field is an example of a <strong>browser built-in directive</strong>:</p>
<input placeholder="Type Your Search">

<br>



<p>If we turn on <code>Show User Agent Shadow DOM</code> under the Dev Tool Settings, we see the implementation as follows:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">placeholder</span>=<span class="string">&quot;Type Your Search&quot;</span>&gt;</span></span><br><span class="line">## shadow-root</span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">pseudo</span>=<span class="string">&quot;-webkit-input-placeholder&quot;</span> <span class="attr">id</span>=<span class="string">&quot;placeholder&quot;</span> </span></span><br><span class="line"><span class="tag">         <span class="attr">style</span>=<span class="string">&quot;display: block !important; text-overflow: clip;&quot;</span>&gt;</span></span><br><span class="line">        Type Your Search</span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;inner-editor&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>This indicates that the <strong>input component is not a native OS input</strong>. Instead, the browser internally composes HTML tags of other more primitive HTML tags and styles, like <code>div</code>, until it reaches the very native rendering elements of the native OS where it’s running. These elements are said to be part of the <strong>Shadow DOM</strong> of the input component.</p>
<br>



<h4 id="Shadow-DOM"><a href="#Shadow-DOM" class="headerlink" title="Shadow DOM"></a>Shadow DOM</h4><p>These HTML elements are a <strong>hidden document sub-tree</strong> that can exist inside of what it looks like a leaf component, such as an HTML input. The CSS styles that run inside this input are <strong>isolated</strong>: these styles are not visible in the main HTML of the page, they are only visible inside the component.</p>
<p>By using browser built-in features, we can:</p>
<ul>
<li>  Define a public XML-like API to an element of the page</li>
<li>  Define the look and feel of the element using HTML</li>
<li>  Add behavior to that new element</li>
<li>  Add CSS to style it while keeping those styles isolated</li>
</ul>
<p>Therefore, the browser <strong>directive</strong> means: An internal browser implementation mechanism. <strong>The combined specification of a look and feel, an API and a behavior</strong>.</p>
<br>

<h4 id="Angular-Directive"><a href="#Angular-Directive" class="headerlink" title="Angular Directive"></a>Angular Directive</h4><p>What Angular Core is about: </p>
<p>It’s like a missing toolkit for extending the browser with our own HTML elements, with their own API, look and feel and behavior.</p>
<p>It’s designed to <strong>extend HTML</strong> instead of replacing it, by providing a TS implementation of some functionality, that until now was only available as an internal browser composition mechanism.</p>
<p>The goal is to <strong>define our own HTML elements</strong> and use them to compose our application, in a very similar way to what browsers are already doing under the hood.</p>
<br>

<h2 id="The-MVC-Framework"><a href="#The-MVC-Framework" class="headerlink" title="The MVC Framework"></a>The MVC Framework</h2><p>MVC is a software design pattern. This pattern is reflected in server-side frameworks such as <strong>Django, Rails, Spring MVC</strong>, and client-side frameworks such as <strong>Angular</strong>.</p>
<br>

<h3 id="From-Spring-MVC-to-Angular"><a href="#From-Spring-MVC-to-Angular" class="headerlink" title="From Spring MVC to Angular"></a><u>From Spring MVC to Angular</u></h3><p>Form-intensive apps are ideal for being built as single page web apps. The main idea of the architecture below is to build the server as <strong>a set of stateless reusable REST services</strong>, and from an MVC perspective to <strong>take the controller out of the backend and move it into the browser</strong>.</p>
<p>The client is MVC-capable and contains all the presentation logic which is separated in a view layer, a controller layer, and a frontend services layer. After the initial application startup, only JSON data goes between client and server.</p>
<img data-src="http://d2huq83j2o5dyd.cloudfront.net/spring-mvc-angular/SpringMVCAngular2.jpg" alt="AngularJs Spring MVC architecture"  />



<br>

<h3 id="Backend-Spring-MVC"><a href="#Backend-Spring-MVC" class="headerlink" title="Backend: Spring MVC"></a><u>Backend: Spring MVC</u></h3><blockquote>
<p>  For the router layer, the same Spring MVC annotations used to build a JSP/Thymeleaf application can also be used to build a REST API.</p>
</blockquote>
<p>The REST API backend is built with the following layers:</p>
<ul>
<li>  <strong>Router Layer</strong>: defines which service entry points correspond to a given HTTP URL, and how parameters are to be read from the HTTP request. Use <strong><code>@RestController</code></strong>. </li>
<li>  <strong>Service Layer</strong>: contains any business logic such as validations, defines the scope of business transactions</li>
<li>  <strong>Persistence Layer</strong>: maps the database to domain objects</li>
</ul>
<p>Note that in the <strong>router layer</strong>, the controllers do not return a String that defines which view template should be rendered. Instead the <strong><code>@ResponseBody</code></strong> annotation indicates that, controller’s return value should be directly rendered and become the response body. For example:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="meta">@ResponseStatus(HttpStatus.OK)</span></span><br><span class="line"><span class="meta">@RequestMapping(method = RequestMethod.GET)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> UserInfoDTO <span class="title">getUserInfo</span><span class="params">(Principal principal)</span> </span>&#123;</span><br><span class="line">    User user = userService.findUserByUsername(principal.getName());</span><br><span class="line">    <span class="comment">/* ...... */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>By adding the <strong>Jackson JSON library</strong>, the returned value will be directly converted to JSON. It’s also possible to convert to XML or other formats, depending on the value of the <code>Accept</code> HTTP header specified by the client.</p>
<br>

<h3 id="Frontend-Angular"><a href="#Frontend-Angular" class="headerlink" title="Frontend: Angular"></a><u>Frontend: Angular</u></h3><p>The frontend should be built around a view-specific model (which is not the domain model), and should only handle presentation logic, but no business logic. The three layers are below:</p>
<br>



<p><strong>View Layer</strong></p>
<p>The view layer is composed of HTML templates, CSS, and any Angular directives representing the different UI components. </p>
<br>



<p><strong>Frontend Service Layer</strong></p>
<p>A set of Angular services that allow to <strong>interact with the backend</strong> (e.g. rethe AppComponent code does not generate HTML, it only fetches the data from the backend),  and that can be injected into Angular controllers. </p>
<blockquote>
<p>  The JSON object is the data, also known as the <strong>Model</strong>, and we would like to display it on the screen - therefore we need to generate HTML based on this Model through the controller layer.</p>
</blockquote>
<br>



<p><strong>Controller Layer</strong></p>
<p>The controller layer is made of Angular controllers that glue the data retrieved from the backend and the view together. The <strong>controller connects view layer &amp; frontend service layer</strong>.</p>
<p>One of the main responsibilities of the controller is to perform frontend validations. This is only for user convenience: e.g. to immediately inform the user that a field is required.</p>
<p>Any <strong>frontend validations need to be repeated in the backend</strong> at the service layer level due to <strong>security</strong> reasons, as the frontend validations can be easily bypassed.</p>
<br>

<h4 id="Angular-MVC"><a href="#Angular-MVC" class="headerlink" title="Angular MVC"></a>Angular MVC</h4><ul>
<li>  the plain JSON object is the <strong>Model</strong> of our Application</li>
<li>  the template (or the output of its processing) is the <strong>View</strong></li>
<li>  the Angular <code>AppComponent</code> binds the View and the Model together, and it serves as the <strong>Controller</strong></li>
</ul>
<br>



<h2 id="jQuery-amp-Angular-MVC"><a href="#jQuery-amp-Angular-MVC" class="headerlink" title="jQuery &amp; Angular MVC"></a>jQuery &amp; Angular MVC</h2><blockquote>
<p>  Biggest difference between jQuery &amp; Angular:</p>
<p>  <strong>Angular does not generate HTML and then let browser parse the HTML. Instead, Angular is generating DOM data structures directly.</strong></p>
</blockquote>
<br>

<h3 id="jQuery"><a href="#jQuery" class="headerlink" title="jQuery"></a><u>jQuery</u></h3><p><strong>Request for Data (Ajax)</strong></p>
<p><a href="https://blog.angular-university.io/why-angular-angular-vs-jquery-a-beginner-friendly-explanation-on-the-advantages-of-angular-and-mvc/">In a jQuery application</a>, the first thing is to query the REST API backend by  jQuery Ajax request, and return only the data. </p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    $.get( <span class="string">&quot;https://some-url/pojos.json&quot;</span>, </span><br><span class="line">          <span class="function"><span class="keyword">function</span>(<span class="params"> data </span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> pojos = <span class="built_in">Object</span>.values(data);</span><br><span class="line">        <span class="built_in">console</span>.log(pojos);</span><br><span class="line">        ...</span><br><span class="line">    &#125;);      </span><br><span class="line">&#125;); </span><br></pre></td></tr></table></figure>

<br>



<p><strong>Generate the View</strong></p>
<p>After we have the data on frontend, we can use it to create the multiple Views:</p>
<blockquote>
<p>  <strong>Note</strong>: The HTML is more than the data. HTML is a particular representation of the Model, that we can call a <strong>View</strong>, and the same data could have multiple views.</p>
</blockquote>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$.get( <span class="string">&quot;https://some-url/pojos.json&quot;</span>, </span><br><span class="line">    <span class="function"><span class="keyword">function</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> pojos = <span class="built_in">Object</span>.values(data);</span><br><span class="line">    <span class="keyword">var</span> html = <span class="string">&quot;&lt;table class=&#x27;table pojos-list&#x27;&gt;&#x27; + &quot;</span> +</span><br><span class="line">        <span class="string">&quot;&#x27;&lt;thead&gt;&quot;</span> + </span><br><span class="line">        <span class="string">&quot;&lt;th&gt;Description&lt;/th&gt;&quot;</span> + </span><br><span class="line">        <span class="string">&quot;&lt;/thead&gt;&quot;</span> + </span><br><span class="line">        <span class="string">&quot;&lt;tbody&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    pojos.forEach(<span class="function"><span class="keyword">function</span>(<span class="params">pojo</span>) </span>&#123;</span><br><span class="line">        html += <span class="string">&#x27;&lt;tr&gt;&#x27;</span> +  +</span><br><span class="line">            <span class="string">&#x27;&lt;td&gt;&#x27;</span> + pojo.description + <span class="string">&#x27;&lt;/td&gt;&#x27;</span> + <span class="string">&#x27;&lt;/tr&gt;&#x27;</span>; &#125;);</span><br><span class="line">    </span><br><span class="line">    html += <span class="string">&#x27;&lt;/tbody&gt;&lt;/table&gt;&#x27;</span>;</span><br><span class="line">    $(<span class="string">&quot;#pojos&quot;</span>).html(html); &#125;);</span><br></pre></td></tr></table></figure>

<br>



<p>For a jQuery application, it takes the data model, and transform it into the multiple views of the data. Below are some of the characteristics:</p>
<ul>
<li>  Not very readable &amp; maintainable, mixing HTML with JS</li>
<li>  This is a lot of code, it makes for a significant portion of our application</li>
<li>  We are building HTML by string concatenation and then passing it on to the browser. But the browser still has to parse it</li>
</ul>
<br>

<h3 id="Improvement-in-Angular"><a href="#Improvement-in-Angular" class="headerlink" title="Improvement in Angular"></a><u>Improvement in Angular</u></h3><p>Now we rewrite the example above using Angular. Important difference between jQuery and Angular (non-MVC &amp; MVC):</p>
<blockquote>
<p>  In Angular, the <strong>Model</strong> and the <strong>View</strong> are clearly separated and <strong>interact</strong> via the <strong><code>AppComponent</code></strong> class, while in jQuery, all is mixed in the same code.</p>
</blockquote>
<br>



<p><strong>Request for Data</strong></p>
<p>Compared to jQuery, we see that:</p>
<ul>
<li>  The <code>AppComponent</code> fetches the data from the backend, and links the template to generate HTML view</li>
<li>  HTTP request is being made via the <strong>Angular HTTP module</strong></li>
<li>  Data is stored in a variable called <code>pojos</code></li>
</ul>
<figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span>(&#123;</span><br><span class="line">  <span class="attr">selector</span>: <span class="string">&#x27;app-root&#x27;</span>,</span><br><span class="line">  <span class="attr">templateUrl</span>: <span class="string">&#x27;app.component.html&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="class"><span class="keyword">class</span> <span class="title">AppComponent</span> <span class="title">implements</span> <span class="title">OnInit</span> </span>&#123;</span><br><span class="line">  <span class="attr">pojos</span>: <span class="built_in">any</span>[];</span><br><span class="line">  <span class="function"><span class="title">constructor</span>(<span class="params"><span class="keyword">private</span> http:Http</span>)</span> &#123;&#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="title">ngOnInit</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.http.get(<span class="string">&#x27;https://some-url/pojos.json&#x27;</span>)</span><br><span class="line">      .map(<span class="function"><span class="params">res</span> =&gt;</span> <span class="built_in">Object</span>.values(res.json()))</span><br><span class="line">      .subscribe(<span class="function"><span class="params">pojos</span> =&gt;</span> <span class="built_in">this</span>.pojos = pojos);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p><strong>Generate the View</strong></p>
<p>The HTML code is in <code>app.component.html</code>, and it’s separated form the component code.  The code is different from the normal HTML  we see, and these expressions are how Angular <strong>ties the data and the view together</strong>.</p>
<ul>
<li><p>  the <strong><code>ngFor</code> directive</strong> that loops through the list of lessons</p>
</li>
<li><p>the <code>&#123;&#123;pojo.description&#125;&#125;</code> expression, which is how we can <strong>output data to the view</strong></p>
</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">class</span>=<span class="string">&#x27;table pojos-list&#x27;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">thead</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">th</span>&gt;</span>Description<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">thead</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">tbody</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">tr</span> *<span class="attr">ngFor</span>=<span class="string">&quot;let pojo of pojos&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>&#123;&#123;pojo.description&#125;&#125;<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">tbody</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p><strong>Modify <code>app.component</code></strong></p>
<p>Angular <strong>keeps the View in sync with the model</strong> for us at all times via its transparent change detection mechanism.</p>
<p>When we make changes, we simply updated the Model, and Angular has reflected the change automatically in the View for us. </p>
<p>We don’t have to write the code that manually synchronizes the Model and the View. That code is generated for us automatically.</p>
<br>



<p><strong>Angular generates DOM data structures directly</strong></p>
<p>This works much <strong>faster</strong> than building manually HTML and then passing it to the DOM for parsing. </p>
<p>By <strong>building DOM nodes directly</strong>, Angular is bypassing the HTML parsing step altogether. So the browser simply takes the ready to use DOM tree and renders it to the screen.</p>
<p>And more than that, it will do so in an optimal way, by trying to change just the HTML that absolutely needs to be changed:</p>
<blockquote>
<p>  <em>Angular will not replace the whole DOM tree each time, it updates the DOM in an optimal way, depending on what parts of the Model have changed.</em></p>
</blockquote>
<br>



<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><u>Summary</u></h3><p> Advantages of using an MVC framework like <strong>Angular</strong>:</p>
<ul>
<li><p><strong>Separation of Concerns</strong></p>
<ul>
<li>Separate Model and View. Use  <strong><code>app.component.ts</code></strong> to bind the model and view.</li>
</ul>
</li>
<li><p>  <strong>Transparent Model to View Synchronization</strong></p>
</li>
<li><p><strong>Faster UI Performance</strong></p>
<ul>
<li>  The View is modified by generating directly <strong>DOM object trees</strong> in a cross-browser compatible way, therefore effectively bypassing the parsing step.</li>
<li>  The HTML still needs to be parsed, but it’s done only <strong>once per template</strong> by Angular and by the browser each time (<strong>JIT</strong> Just in Time, or <strong>AOT</strong> Ahead of Time).</li>
<li>  <strong>CLI</strong>: advanced development environment (have all these features and benefits working transparently out of the box)</li>
</ul>
</li>
</ul>
<br>

<p><strong>Problems with NOT using MVC:</strong></p>
<ul>
<li>  Choosing to not use an MVC framework means that we will have to keep the Model and the View <strong>in sync manually</strong>, which looks simple at first sight but very quickly we will end up with an unmaintainable program.</li>
</ul>
<br>

<h2 id="Useful-Libraries"><a href="#Useful-Libraries" class="headerlink" title="Useful Libraries"></a>Useful Libraries</h2><p><a href="https://purecss.io/">PureCSS</a>  &amp; <a href="http://yui.github.io/skinbuilder/?mode=pure">SkinBuilder</a>: Easily generate a theme based on a primary color. </p>
<br>



<p><a href="https://lodash.com/">Lodash</a>: functional programming library to manipulate data.</p>
<blockquote>
<p>  Lodash makes JavaScript easier by taking the hassle out of working with arrays, numbers, objects, strings, etc. Lodash’s modular methods are great for:</p>
<ul>
<li>  Iterating arrays, objects, &amp; strings</li>
<li>  Manipulating &amp; testing values</li>
<li>  Creating composite functions</li>
</ul>
</blockquote>
<br>



<p><a href="https://github.com/aditzel/spring-security-csrf-token-interceptor">CSRF Angular</a>: prevent cross-site request forgery attacks.</p>
<blockquote>
<p>  <code>npm install spring-security-csrf-token-interceptor</code></p>
</blockquote>
<br>



<p><a href="https://valor-software.com/ngx-bootstrap/#/documentation#getting-started">Ngx Bootstrap</a>: Bootstrapping Angular components.</p>
<blockquote>
<p>  <code>npm install ngx-bootstrap --save</code></p>
</blockquote>
<br>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Angular</tag>
      </tags>
  </entry>
  <entry>
    <title>Banana Fish ~ バナナフィッシュ</title>
    <url>/Notes/Banana-Fish/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid passcode." data-whm="Unverified decryption.">
  <script id="hbeData" type="hbeData" data-hmacdigest="543b0e8eeff22e5453f45e5912c049d20c4261862fc93a8e2a589344c1bdbc86">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-wave">
      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-wave"><p style="text-align:center; font-size:0.8em; font-weight:100;">Passcode please.</p></span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>User Login with Spring Boot</title>
    <url>/2020/SpringBoot-Login/</url>
    <content><![CDATA[<p>In this post, we will implement the User Login feature in Spring Boot. The dependencies we need are JDBC and MyBatis. After we are done with the backend logic, we will use a frontend template to bootstrap the page view.</p>
<span id="more"></span> 

<br>



<h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><blockquote>
<p>  We will start the configuration based on the setup and codes in the <a href="http://merikanto.org/2020/03/SpringBoot-MyBatis/">previous post</a>.</p>
</blockquote>
<br>

<h3 id="Project-Structure"><a href="#Project-Structure" class="headerlink" title="Project Structure"></a><u>Project Structure</u></h3><p>Before we start, the project structure looks like this (under <code>/src/main/java/merikanto/demo</code>):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">meirkanto.demo</span><br><span class="line"></span><br><span class="line">    ├── common</span><br><span class="line">    │   ├── Constants.java</span><br><span class="line">    │   ├── ResultGenerator.java</span><br><span class="line">    │   └── Result.java</span><br><span class="line">    ├── controller</span><br><span class="line">    │   └── UserController.java</span><br><span class="line">    ├── dao</span><br><span class="line">    │   └── UserDao.java</span><br><span class="line">    ├── entity</span><br><span class="line">    │   └── User.java</span><br><span class="line">    ├── service</span><br><span class="line">    │   ├── impl</span><br><span class="line">    │   │   └── UserServiceImpl.java</span><br><span class="line">    │   └── UserService.java</span><br><span class="line">    └── utils</span><br><span class="line">    │   ├── DateUtil.java</span><br><span class="line">    │   ├── MD5Util.java</span><br><span class="line">    │   ├── NumberUtil.java</span><br><span class="line">    │   └── SystemUtil.java</span><br><span class="line">    └── DemoApplication.java</span><br></pre></td></tr></table></figure>

<br>



<h3 id="Define-DB-Schema"><a href="#Define-DB-Schema" class="headerlink" title="Define DB Schema"></a><u>Define DB Schema</u></h3><p>First thing is to define the database schema. </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> DATABASE IF <span class="keyword">EXISTS</span> demo_springboot;</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE demo_springboot;</span><br><span class="line">USE demo_springboot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">user</span> (</span><br><span class="line">id <span class="type">bigint</span>(<span class="number">11</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">username <span class="type">varchar</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">password_hash <span class="type">varchar</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">token <span class="type">varchar</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">create_time datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (id)</span><br><span class="line">)</span><br><span class="line">ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line"><span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span> (id, username, password_hash, token, create_time)</span><br><span class="line"><span class="keyword">VALUES</span>  (<span class="number">1</span>, <span class="string">&#x27;merikanto&#x27;</span>,<span class="string">&#x27;e10adc3949ba59abbe56e057f20f883e&#x27;</span>,<span class="string">&#x27;6f1d93269e8bfdcd2066a248bfdafee6&#x27;</span>, <span class="string">&#x27;2020-03-25 12:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Backend-Logic"><a href="#Backend-Logic" class="headerlink" title="Backend Logic"></a>Backend Logic</h2><h3 id="DAO-Data-Persistence"><a href="#DAO-Data-Persistence" class="headerlink" title="DAO: Data Persistence"></a><u>DAO: Data Persistence</u></h3><blockquote>
<p>  <em>Note: <code>application.properties</code> and the main application Java file are the same.</em> </p>
</blockquote>
<h4 id="User"><a href="#User" class="headerlink" title="User"></a>User</h4><p>Modify class <code>User</code> under the <code>entity</code> package.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.entity;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonFormat;</span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long id;        <span class="comment">// id is the Primary Key</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String userName;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String userToken;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonFormat(pattern = &quot;yyyy-MM-dd&quot;, timezone = &quot;GMT-5&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> Date createTime;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Long <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(Long id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUserName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserName</span><span class="params">(String userName)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.userName = userName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> password;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPassword</span><span class="params">(String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.password = password;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUserToken</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userToken;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserToken</span><span class="params">(String userToken)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.userToken = userToken;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Date <span class="title">getCreateTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> createTime;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCreateTime</span><span class="params">(Date createTime)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.createTime = createTime;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;User&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;id=&quot;</span> + id +</span><br><span class="line">                <span class="string">&quot;, userName=&#x27;&quot;</span> + userName + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, password=&#x27;&quot;</span> + password + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, userToken=&#x27;&quot;</span> + userToken + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, createTime=&quot;</span> + createTime +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="UserDao"><a href="#UserDao" class="headerlink" title="UserDao"></a>UserDao</h4><p>Modify the class <code>UserDao</code> under the <code>dao</code> package.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.dao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.demo.entity.User;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.annotations.Param;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function">List&lt;User&gt; <span class="title">findUsers</span><span class="params">(Map param)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getTotalUser</span><span class="params">(Map param)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">User <span class="title">getUserByUserNameAndPassword</span><span class="params">(<span class="meta">@Param(&quot;userName&quot;)</span> String userName, <span class="meta">@Param(&quot;passwordHash&quot;)</span> String passwordHash)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">User <span class="title">getUserByToken</span><span class="params">(String userToken)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">User <span class="title">getUserById</span><span class="params">(Long id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">User <span class="title">getUserByUserName</span><span class="params">(String userName)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">addUser</span><span class="params">(User user)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">insertUsersBatch</span><span class="params">(<span class="meta">@Param(&quot;Users&quot;)</span> List&lt;User&gt; Users)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">updateUserPassword</span><span class="params">(<span class="meta">@Param(&quot;userId&quot;)</span> Long userId, <span class="meta">@Param(&quot;newPassword&quot;)</span> String newPassword)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">updateUserToken</span><span class="params">(<span class="meta">@Param(&quot;userId&quot;)</span> Long userId, <span class="meta">@Param(&quot;newToken&quot;)</span> String newToken)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">deleteBatch</span><span class="params">(Object[] ids)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">List&lt;User&gt; <span class="title">getAllUsers</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<h4 id="UserDao-xml"><a href="#UserDao-xml" class="headerlink" title="UserDao.xml"></a>UserDao.xml</h4><p>Modify <code>UserDao.xml</code> under <code>resources/mapper</code>, add more complicated logic:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">mapper</span> <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span> <span class="meta-string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">&quot;merikanto.demo.dao.UserDao&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resultMap</span> <span class="attr">type</span>=<span class="string">&quot;merikanto.demo.entity.User&quot;</span> <span class="attr">id</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span> <span class="attr">property</span>=<span class="string">&quot;id&quot;</span> <span class="attr">column</span>=<span class="string">&quot;id&quot;</span> <span class="attr">jdbcType</span>=<span class="string">&quot;BIGINT&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;userName&quot;</span> <span class="attr">column</span>=<span class="string">&quot;username&quot;</span> <span class="attr">jdbcType</span>=<span class="string">&quot;VARCHAR&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;password&quot;</span> <span class="attr">column</span>=<span class="string">&quot;password_hash&quot;</span> <span class="attr">jdbcType</span>=<span class="string">&quot;VARCHAR&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;userToken&quot;</span> <span class="attr">column</span>=<span class="string">&quot;token&quot;</span> <span class="attr">jdbcType</span>=<span class="string">&quot;VARCHAR&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;createTime&quot;</span> <span class="attr">column</span>=<span class="string">&quot;create_time&quot;</span> <span class="attr">jdbcType</span>=<span class="string">&quot;TIMESTAMP&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">resultMap</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;addUser&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;merikanto.demo.entity.User&quot;</span>&gt;</span></span><br><span class="line">        insert into user(username,password_hash)</span><br><span class="line">        values(#&#123;userName&#125;,#&#123;password&#125;)</span><br><span class="line">    <span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;insertUsersBatch&quot;</span>&gt;</span></span><br><span class="line">        insert into user(username,password_hash) VALUES</span><br><span class="line">        <span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">&quot;Users&quot;</span> <span class="attr">index</span>=<span class="string">&quot;index&quot;</span> <span class="attr">item</span>=<span class="string">&quot;User&quot;</span> <span class="attr">open</span>=<span class="string">&quot;&quot;</span> <span class="attr">separator</span>=<span class="string">&quot;,&quot;</span> <span class="attr">close</span>=<span class="string">&quot;&quot;</span>&gt;</span></span><br><span class="line">            (#&#123;User.userName&#125;, #&#123;User.password&#125;)</span><br><span class="line">        <span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;findUsers&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;Map&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select id,username,create_time from user</span><br><span class="line">        order by id desc</span><br><span class="line">        <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;start!=null and limit!=null&quot;</span>&gt;</span></span><br><span class="line">            limit #&#123;start&#125;,#&#123;limit&#125;</span><br><span class="line">        <span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;getTotalUser&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;Map&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;int&quot;</span>&gt;</span></span><br><span class="line">        select count(*) from user</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;getUserByUserNameAndPassword&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select id,username,token</span><br><span class="line">        from user</span><br><span class="line">        where username = #&#123;userName&#125; and password_hash = #&#123;passwordHash&#125;</span><br><span class="line">        ORDER BY  id DESC limit 1</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;getUserByToken&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select id,username,token</span><br><span class="line">        from user</span><br><span class="line">        where token = #&#123;userToken&#125;</span><br><span class="line">        ORDER BY  id DESC limit 1</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;getUserById&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select username,token</span><br><span class="line">        from user</span><br><span class="line">        where id=#&#123;id&#125;</span><br><span class="line">        ORDER BY  id DESC limit 1</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;getUserByUserName&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select id,username,token</span><br><span class="line">        from user</span><br><span class="line">        where username = #&#123;userName&#125;</span><br><span class="line">        ORDER BY  id DESC limit 1</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;updateUserToken&quot;</span>&gt;</span></span><br><span class="line">        update user set token = #&#123;newToken&#125; where id =#&#123;userId&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;updateUserPassword&quot;</span>&gt;</span></span><br><span class="line">        update user set password_hash = #&#123;newPassword&#125;,user_token =&#x27;&#x27; where id =#&#123;userId&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">delete</span> <span class="attr">id</span>=<span class="string">&quot;deleteBatch&quot;</span>&gt;</span></span><br><span class="line">        delete from user where id in</span><br><span class="line">        <span class="tag">&lt;<span class="name">foreach</span> <span class="attr">item</span>=<span class="string">&quot;id&quot;</span> <span class="attr">collection</span>=<span class="string">&quot;array&quot;</span> <span class="attr">open</span>=<span class="string">&quot;(&quot;</span> <span class="attr">separator</span>=<span class="string">&quot;,&quot;</span> <span class="attr">close</span>=<span class="string">&quot;)&quot;</span>&gt;</span></span><br><span class="line">            #&#123;id&#125;</span><br><span class="line">        <span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">delete</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;getAllUsers&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select id,username,create_time from user</span><br><span class="line">        order by id desc</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Service-Business-Logic"><a href="#Service-Business-Logic" class="headerlink" title="Service: Business Logic"></a><u>Service: Business Logic</u></h3><h4 id="UserService"><a href="#UserService" class="headerlink" title="UserService"></a>UserService</h4><p>Add class <code>UserService </code> under <code>service</code> package.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.demo.entity.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">     <span class="comment">// User Login</span></span><br><span class="line">    <span class="function">User <span class="title">updateTokenAndLogin</span><span class="params">(String userName, String password)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="UserServiceImpl"><a href="#UserServiceImpl" class="headerlink" title="UserServiceImpl"></a>UserServiceImpl</h4><p>Then add class <code>UserServiceImpl</code> under <code>/service/impl</code>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.demo.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.entity.User;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.service.UserService;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.utils.MD5Util;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.utils.NumberUtil;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.utils.SystemUtil;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Service(&quot;UserService&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserDao UserDao;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">updateTokenAndLogin</span><span class="params">(String userName, String password)</span> </span>&#123;</span><br><span class="line">        User User = UserDao.getUserByUserNameAndPassword(userName, MD5Util.MD5Encode(password, <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">        <span class="keyword">if</span> (User != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//登录后即执行修改token的操作</span></span><br><span class="line">            String token = getNewToken(System.currentTimeMillis() + <span class="string">&quot;&quot;</span>, User.getId());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (UserDao.updateUserToken(User.getId(), token) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//返回数据时带上token</span></span><br><span class="line">                User.setUserToken(token);</span><br><span class="line">                <span class="keyword">return</span> User;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get Token Value</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">getNewToken</span><span class="params">(String sessionId, Long userId)</span> </span>&#123;</span><br><span class="line">        String src = sessionId + userId + NumberUtil.genRandomNum(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">return</span> SystemUtil.genToken(src);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<h3 id="Controller-Interaction-with-Frontend"><a href="#Controller-Interaction-with-Frontend" class="headerlink" title="Controller: Interaction with Frontend"></a><u>Controller: Interaction with Frontend</u></h3><h4 id="UserController"><a href="#UserController" class="headerlink" title="UserController"></a>UserController</h4><p>Add class <code>UserController</code> under package <code>controller</code>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.demo.common.Result;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.common.ResultGenerator;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.entity.User;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestBody;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMethod;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/users&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserService UserService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/login&quot;, method = RequestMethod.POST)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Result <span class="title">login</span><span class="params">(<span class="meta">@RequestBody</span> User user)</span> </span>&#123;</span><br><span class="line">        Result result = ResultGenerator.genFailResult(<span class="string">&quot;Oops... Login Failed!&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(user.getUserName()) || StringUtils.isEmpty(user.getPassword())) &#123;</span><br><span class="line">            result.setMessage(<span class="string">&quot;Please fill in the login info!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        User loginUser = UserService.updateTokenAndLogin(user.getUserName(), user.getPassword());</span><br><span class="line">        <span class="keyword">if</span> (loginUser != <span class="keyword">null</span>) &#123;</span><br><span class="line">            result = ResultGenerator.genSuccessResult(loginUser);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>



<h2 id="Utilities"><a href="#Utilities" class="headerlink" title="Utilities"></a>Utilities</h2><h3 id="common"><a href="#common" class="headerlink" title="common"></a><u>common</u></h3><h4 id="Constants"><a href="#Constants" class="headerlink" title="Constants"></a>Constants</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.common;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Constants</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESULT_CODE_SUCCESS = <span class="number">200</span>;  <span class="comment">// Success</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESULT_CODE_BAD_REQUEST = <span class="number">412</span>;  <span class="comment">// Error</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESULT_CODE_NOT_LOGIN = <span class="number">402</span>;  <span class="comment">// Not logged in</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESULT_CODE_PARAM_ERROR = <span class="number">406</span>;  <span class="comment">// parameter error</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESULT_CODE_SERVER_ERROR = <span class="number">500</span>;  <span class="comment">// server error</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>





<h4 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.common;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Result</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> resultCode;</span><br><span class="line">    <span class="keyword">private</span> String message;</span><br><span class="line">    <span class="keyword">private</span> T data;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Result</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Result</span><span class="params">(<span class="keyword">int</span> resultCode, String message)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.resultCode = resultCode;</span><br><span class="line">        <span class="keyword">this</span>.message = message;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getResultCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> resultCode;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setResultCode</span><span class="params">(<span class="keyword">int</span> resultCode)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.resultCode = resultCode;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMessage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> message;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMessage</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.message = message;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">getData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setData</span><span class="params">(T data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.data = data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Result <span class="title">failure</span><span class="params">(String code)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Result(<span class="number">500</span>, <span class="string">&quot;Server Error&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Result&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;resultCode=&quot;</span> + resultCode +</span><br><span class="line">                <span class="string">&quot;, message=&#x27;&quot;</span> + message + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, data=&quot;</span> + data +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>







<h4 id="ResultGenerator"><a href="#ResultGenerator" class="headerlink" title="ResultGenerator"></a>ResultGenerator</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.common;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ResultGenerator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SUCCESS_MESSAGE = <span class="string">&quot;SUCCESS&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_FAIL_MESSAGE = <span class="string">&quot;FAIL&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Result <span class="title">genSuccessResult</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Result result = <span class="keyword">new</span> Result();</span><br><span class="line">        result.setResultCode(Constants.RESULT_CODE_SUCCESS);</span><br><span class="line">        result.setMessage(DEFAULT_SUCCESS_MESSAGE);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Result <span class="title">genSuccessResult</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        Result result = <span class="keyword">new</span> Result();</span><br><span class="line">        result.setResultCode(Constants.RESULT_CODE_SUCCESS);</span><br><span class="line">        result.setMessage(message);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Result <span class="title">genSuccessResult</span><span class="params">(Object data)</span> </span>&#123;</span><br><span class="line">        Result result = <span class="keyword">new</span> Result();</span><br><span class="line">        result.setResultCode(Constants.RESULT_CODE_SUCCESS);</span><br><span class="line">        result.setMessage(DEFAULT_SUCCESS_MESSAGE);</span><br><span class="line">        result.setData(data);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Result <span class="title">genFailResult</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        Result result = <span class="keyword">new</span> Result();</span><br><span class="line">        result.setResultCode(Constants.RESULT_CODE_SERVER_ERROR);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(message)) &#123;</span><br><span class="line">            result.setMessage(DEFAULT_FAIL_MESSAGE);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result.setMessage(message);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Result <span class="title">genNullResult</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        Result result = <span class="keyword">new</span> Result();</span><br><span class="line">        result.setResultCode(Constants.RESULT_CODE_BAD_REQUEST);</span><br><span class="line">        result.setMessage(message);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Result <span class="title">genErrorResult</span><span class="params">(<span class="keyword">int</span> code, String message)</span> </span>&#123;</span><br><span class="line">        Result result = <span class="keyword">new</span> Result();</span><br><span class="line">        result.setResultCode(code);</span><br><span class="line">        result.setMessage(message);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h3 id="utils"><a href="#utils" class="headerlink" title="utils"></a><u>utils</u></h3><h4 id="DateUtil"><a href="#DateUtil" class="headerlink" title="DateUtil"></a>DateUtil</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Format the dates</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DateUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getDateString</span><span class="params">(Date date)</span> </span>&#123;</span><br><span class="line">        SimpleDateFormat formatter = <span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> formatter.format(date);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="MD5Util"><a href="#MD5Util" class="headerlink" title="MD5Util"></a>MD5Util</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.security.MessageDigest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MD5Util</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> String <span class="title">byteArrayToHexString</span><span class="params">(<span class="keyword">byte</span> b[])</span> </span>&#123;</span><br><span class="line">        StringBuffer resultSb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; b.length; i++) &#123;</span><br><span class="line">            resultSb.append(byteToHexString(b[i]));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> resultSb.toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> String <span class="title">byteToHexString</span><span class="params">(<span class="keyword">byte</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = b;</span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            n += <span class="number">256</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> d1 = n / <span class="number">16</span>;</span><br><span class="line">        <span class="keyword">int</span> d2 = n % <span class="number">16</span>;</span><br><span class="line">        <span class="keyword">return</span> hexDigits[d1] + hexDigits[d2];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">MD5Encode</span><span class="params">(String origin, String charsetname)</span> </span>&#123;</span><br><span class="line">        String resultString = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            resultString = <span class="keyword">new</span> String(origin);</span><br><span class="line">            MessageDigest md = MessageDigest.getInstance(<span class="string">&quot;MD5&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (charsetname == <span class="keyword">null</span> || <span class="string">&quot;&quot;</span>.equals(charsetname)) &#123;</span><br><span class="line">                resultString = byteArrayToHexString(md.digest(resultString</span><br><span class="line">                        .getBytes()));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                resultString = byteArrayToHexString(md.digest(resultString</span><br><span class="line">                        .getBytes(charsetname)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultString;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String hexDigits[] = &#123;<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;2&quot;</span>, <span class="string">&quot;3&quot;</span>, <span class="string">&quot;4&quot;</span>, <span class="string">&quot;5&quot;</span>,</span><br><span class="line">            <span class="string">&quot;6&quot;</span>, <span class="string">&quot;7&quot;</span>, <span class="string">&quot;8&quot;</span>, <span class="string">&quot;9&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span>, <span class="string">&quot;f&quot;</span>&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="NumberUtil"><a href="#NumberUtil" class="headerlink" title="NumberUtil"></a>NumberUtil</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NumberUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">NumberUtil</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Generate random numbers of fixed length</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">genRandomNum</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">double</span> random = Math.random();</span><br><span class="line">        <span class="keyword">if</span> (random &lt; <span class="number">0.1</span>) &#123;</span><br><span class="line">            random = random + <span class="number">0.1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">            num = num * <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) ((random * num));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="SystemUtil"><a href="#SystemUtil" class="headerlink" title="SystemUtil"></a>SystemUtil</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.math.BigInteger;</span><br><span class="line"><span class="keyword">import</span> java.security.MessageDigest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SystemUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SystemUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">genToken</span><span class="params">(String src)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == src || <span class="string">&quot;&quot;</span>.equals(src))&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            MessageDigest md = MessageDigest.getInstance(<span class="string">&quot;MD5&quot;</span>);</span><br><span class="line">            md.update(src.getBytes());</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> BigInteger(<span class="number">1</span>, md.digest()).toString(<span class="number">16</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>









<h2 id="View-Rendering"><a href="#View-Rendering" class="headerlink" title="View Rendering"></a>View Rendering</h2><p>We choose <code>AdminLTE</code> for bootstrapping the view. The template can be downloaded online, so we won’t talk about it in detail here. </p>
<p>The <code>public.js</code> file under <code>/resources/static/dist/js</code> is here:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;!-- Regex start--&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// if is null</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">isNull</span>(<span class="params">obj</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (obj == <span class="literal">null</span> || obj == <span class="literal">undefined</span> || obj.trim() == <span class="string">&quot;&quot;</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// check length</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">validLength</span>(<span class="params">obj, length</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (obj.trim().length &lt; length) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// username</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">validUserName</span>(<span class="params">userName</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> pattern = <span class="regexp">/^[a-zA-Z0-9_-]&#123;4,16&#125;$/</span>;</span><br><span class="line">    <span class="keyword">if</span> (pattern.test(userName.trim())) &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">true</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// User password check</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">validPassword</span>(<span class="params">password</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> pattern = <span class="regexp">/^[a-zA-Z0-9]&#123;6,20&#125;$/</span>;</span><br><span class="line">    <span class="keyword">if</span> (pattern.test(password.trim())) &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">true</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;!-- Regex end--&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">login</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> userName = $(<span class="string">&quot;#userName&quot;</span>).val();</span><br><span class="line">    <span class="keyword">var</span> password = $(<span class="string">&quot;#password&quot;</span>).val();</span><br><span class="line">    <span class="keyword">if</span> (isNull(userName)) &#123;</span><br><span class="line">        showErrorInfo(<span class="string">&quot;Username Please!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!validUserName(userName)) &#123;</span><br><span class="line">        showErrorInfo(<span class="string">&quot;Please input the right password!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (isNull(password)) &#123;</span><br><span class="line">        showErrorInfo(<span class="string">&quot;Password Please!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!validPassword(password)) &#123;</span><br><span class="line">        showErrorInfo(<span class="string">&quot;Please input the right password!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> data = &#123;<span class="string">&quot;userName&quot;</span>: userName, <span class="string">&quot;password&quot;</span>: password&#125;</span><br><span class="line">    $.ajax(&#123;</span><br><span class="line">        <span class="attr">type</span>: <span class="string">&quot;POST&quot;</span>,           <span class="comment">//方法类型</span></span><br><span class="line">        <span class="attr">dataType</span>: <span class="string">&quot;json&quot;</span>,       <span class="comment">//预期服务器返回的数据类型</span></span><br><span class="line">        <span class="attr">url</span>: <span class="string">&quot;users/login&quot;</span>,</span><br><span class="line">        <span class="attr">contentType</span>: <span class="string">&quot;application/json; charset=utf-8&quot;</span>,</span><br><span class="line">        <span class="attr">data</span>: <span class="built_in">JSON</span>.stringify(data),</span><br><span class="line">        <span class="attr">success</span>: <span class="function"><span class="keyword">function</span> (<span class="params">result</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (result.resultCode == <span class="number">200</span>) &#123;</span><br><span class="line">                $(<span class="string">&#x27;.alert-danger&#x27;</span>).css(<span class="string">&quot;display&quot;</span>, <span class="string">&quot;none&quot;</span>);</span><br><span class="line">                setCookie(<span class="string">&quot;token&quot;</span>, result.data.userToken);</span><br><span class="line">                <span class="built_in">window</span>.location.href = <span class="string">&quot;/&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ;</span><br><span class="line">            <span class="keyword">if</span> (result.resultCode == <span class="number">500</span>) &#123;</span><br><span class="line">                showErrorInfo(<span class="string">&quot;Please check your username and password.&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">error</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            $(<span class="string">&#x27;.alert-danger&#x27;</span>).css(<span class="string">&quot;display&quot;</span>, <span class="string">&quot;none&quot;</span>);</span><br><span class="line">            showErrorInfo(<span class="string">&quot;Interface error!&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// ================== COOKIES =================== //</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// write cookie</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">setCookie</span>(<span class="params">name, value</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> Days = <span class="number">30</span>;</span><br><span class="line">    <span class="keyword">var</span> exp = <span class="keyword">new</span> <span class="built_in">Date</span>();</span><br><span class="line">    exp.setTime(exp.getTime() + Days * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span> * <span class="number">1000</span>);</span><br><span class="line">    <span class="built_in">document</span>.cookie = name + <span class="string">&quot;=&quot;</span> + <span class="built_in">escape</span>(value) + <span class="string">&quot;;expires=&quot;</span> + exp.toGMTString() + <span class="string">&quot;;path=/&quot;</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// read cookie</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getCookie</span>(<span class="params">name</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> arr, reg = <span class="keyword">new</span> <span class="built_in">RegExp</span>(<span class="string">&quot;(^| )&quot;</span> + name + <span class="string">&quot;=([^;]*)(;|$)&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (arr = <span class="built_in">document</span>.cookie.match(reg))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">unescape</span>(arr[<span class="number">2</span>]);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Delete Cookie</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">delCookie</span>(<span class="params">name</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> exp = <span class="keyword">new</span> <span class="built_in">Date</span>();</span><br><span class="line">    exp.setTime(exp.getTime() - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">var</span> cval = getCookie(name);</span><br><span class="line">    <span class="keyword">if</span> (cval != <span class="literal">null</span>)</span><br><span class="line">        <span class="built_in">document</span>.cookie = name + <span class="string">&quot;=&quot;</span> + cval + <span class="string">&quot;;expires=&quot;</span> + exp.toGMTString();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check cookie</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">checkCookie</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (getCookie(<span class="string">&quot;token&quot;</span>) == <span class="literal">null</span>) &#123;</span><br><span class="line">        swal(<span class="string">&quot;Not logged in&quot;</span>, &#123;</span><br><span class="line">            <span class="attr">icon</span>: <span class="string">&quot;error&quot;</span>,</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="built_in">window</span>.location.href = <span class="string">&quot;login.html&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">checkResultCode</span>(<span class="params">code</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (code == <span class="number">402</span>) &#123;</span><br><span class="line">        <span class="built_in">window</span>.location.href = <span class="string">&quot;login.html&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">showErrorInfo</span>(<span class="params">info</span>) </span>&#123;</span><br><span class="line">    $(<span class="string">&#x27;.alert-danger&#x27;</span>).css(<span class="string">&quot;display&quot;</span>, <span class="string">&quot;block&quot;</span>);</span><br><span class="line">    $(<span class="string">&#x27;.alert-danger&#x27;</span>).html(info);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<p>In <code>localhost:8080</code>, we should be able to see this:</p>
<p><img data-src="/images/posts/200325-1.png"></p>
<p>And after we typed in the username and password, we will see the following notice:</p>
<p><img data-src="/images/posts/200325-2.png"></p>
<br>

<p>And now we’ve successfully finished setting up the user login module. </p>
<br>





]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>CRUD with Spring Boot &amp; MyBatis</title>
    <url>/2020/SpringBoot-MyBatis/</url>
    <content><![CDATA[<p>In this post, we will use Spring Boot and MyBatis to do CRUD operations on MySQL databases. MyBatis is a Java <strong>persistence framework</strong> that couples objects with stored procedures or SQL statements, using annotations or an XML descriptor. </p>
<span id="more"></span> 

<br>



<h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><blockquote>
<p>   We will start the configuration based on the setup and codes in the <a href="http://merikanto.org/2020/03/SpringBoot-JDBC/">previous post</a>.</p>
</blockquote>
<br>

<h3 id="Project-Structure"><a href="#Project-Structure" class="headerlink" title="Project Structure"></a><u>Project Structure</u></h3><p>Before we start, the project structure looks like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── java</span><br><span class="line">│   └── merikanto</span><br><span class="line">│       └── demo</span><br><span class="line">│           ├── controller</span><br><span class="line">│           │   ├── HelloController.java</span><br><span class="line">│           │   ├── JdbcController.java</span><br><span class="line">│           │   └── MyBatisController.java</span><br><span class="line">│           ├── dao</span><br><span class="line">│           │   └── UserDao.java</span><br><span class="line">│           ├── entity</span><br><span class="line">│           │   └── User.java</span><br><span class="line">│           └── DemoApplication.java</span><br><span class="line">└── resources</span><br><span class="line">    ├── application.properties</span><br><span class="line">    └── mapper</span><br><span class="line">        └── UserDao.xml</span><br></pre></td></tr></table></figure>



<p>And MySQL settings are the same as the those mentioned in the previous post. Please also make sure to include  the two classes <code>HelloController</code> and <code>JdbcController</code>.</p>
<br>

<h3 id="Pom-Dependency"><a href="#Pom-Dependency" class="headerlink" title="Pom Dependency"></a><u>Pom Dependency</u></h3><p>Add the following to <code>pom.xml</code>:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.5.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>merikanto<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Demo project for Spring Boot<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!-- 引入 MyBatis 场景启动器，包含其自动配置类及 MyBatis 3 相关依赖 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<br>



<h3 id="application-properties"><a href="#application-properties" class="headerlink" title="application.properties"></a><u>application.properties</u></h3><p>Configure the file <code>application.properties</code> under <code>resources</code>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spring.datasource.url=jdbc:mysql://localhost:3306/demo_springboot?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false</span><br><span class="line">spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver</span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=</span><br><span class="line"></span><br><span class="line">mybatis.mapper-locations=classpath:mapper/*Dao.xml</span><br></pre></td></tr></table></figure>



<br>



<h3 id="Add-MapperScan"><a href="#Add-MapperScan" class="headerlink" title="Add  @MapperScan"></a><u>Add  @MapperScan</u></h3><p>Add <code>@MapperScan</code> to the main class:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.mybatis.spring.annotation.MapperScan;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@MapperScan(&quot;merikanto.demo.dao&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;[+] STARTING Spring Boot...&quot;</span>);</span><br><span class="line">        SpringApplication.run(DemoApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>



<h2 id="CRUD-with-MyBatis"><a href="#CRUD-with-MyBatis" class="headerlink" title="CRUD with MyBatis"></a>CRUD with MyBatis</h2><blockquote>
<p>  In the post about <a href="http://merikanto.org/2020/03/Hibernate-Config/#Test-CRUD">Hibernate configuration</a>, I mentioned what CRUD is about: Create, Read, Update, Delete.</p>
</blockquote>
<p>Now that we’re done with the preparation work, we can move on to setting up MyBatis. </p>
<br>

<h3 id="User-Entity"><a href="#User-Entity" class="headerlink" title="User Entity"></a><u>User Entity</u></h3><p>First we create the <code>User</code> class user the <code>entity</code> package.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.entity;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> password; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPassword</span><span class="params">(String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.password = password; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h3 id="UserDao"><a href="#UserDao" class="headerlink" title="UserDao"></a><u>UserDao</u></h3><p>Then we add <code>UserDao</code> under the package <code>dao</code>, and define the interfaces for CRUD operations:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.dao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.demo.entity.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserDao</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// @return</span></span><br><span class="line">    <span class="function">List&lt;User&gt; <span class="title">findAllUsers</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// @param User</span></span><br><span class="line">    <span class="comment">// @return</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">insertUser</span><span class="params">(User User)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// @param User</span></span><br><span class="line">    <span class="comment">// @return</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">updUser</span><span class="params">(User User)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// @param id</span></span><br><span class="line">    <span class="comment">// @return</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">delUser</span><span class="params">(Integer id)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h3 id="UserDao-xml"><a href="#UserDao-xml" class="headerlink" title="UserDao.xml"></a><u>UserDao.xml</u></h3><p>Add <code>UserDao.xml</code> under <code>/resources/mapper</code>:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">mapper</span> <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span> <span class="meta-string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">&quot;merikanto.demo.dao.UserDao&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resultMap</span> <span class="attr">type</span>=<span class="string">&quot;merikanto.demo.entity.User&quot;</span> <span class="attr">id</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;id&quot;</span> <span class="attr">column</span>=<span class="string">&quot;id&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;name&quot;</span> <span class="attr">column</span>=<span class="string">&quot;name&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">&quot;password&quot;</span> <span class="attr">column</span>=<span class="string">&quot;password&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">resultMap</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;findAllUsers&quot;</span> <span class="attr">resultMap</span>=<span class="string">&quot;UserResult&quot;</span>&gt;</span></span><br><span class="line">        select id,name,password from user</span><br><span class="line">        order by id desc</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;insertUser&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;merikanto.demo.entity.User&quot;</span>&gt;</span></span><br><span class="line">        insert into user(name,password)</span><br><span class="line">        values(#&#123;name&#125;,#&#123;password&#125;)</span><br><span class="line">    <span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;updUser&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;merikanto.demo.entity.User&quot;</span>&gt;</span></span><br><span class="line">        update user</span><br><span class="line">        set</span><br><span class="line">        name=#&#123;name&#125;,password=#&#123;password&#125;</span><br><span class="line">        where id=#&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">delete</span> <span class="attr">id</span>=<span class="string">&quot;delUser&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;int&quot;</span>&gt;</span></span><br><span class="line">        delete from user where id=#&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">delete</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>





<h3 id="MyBatisController-for-CRUD"><a href="#MyBatisController-for-CRUD" class="headerlink" title="MyBatisController for CRUD"></a><u>MyBatisController for CRUD</u></h3><p>Add <code>MyBatisController</code> under <code>controller</code> for CRUD. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.demo.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> merikanto.demo.entity.User;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyBatisController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    UserDao userDao;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// === READ === </span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/users/mybatis/queryAll&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;User&gt; <span class="title">queryAll</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userDao.findAllUsers();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// === CREATE === </span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/users/mybatis/insert&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">insert</span><span class="params">(String name, String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(name) || StringUtils.isEmpty(password)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setName(name);</span><br><span class="line">        user.setPassword(password);</span><br><span class="line">        <span class="keyword">return</span> userDao.insertUser(user) &gt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// === UPDATE === </span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/users/mybatis/update&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">insert</span><span class="params">(Integer id, String name, String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (id == <span class="keyword">null</span> || id &lt; <span class="number">1</span> || StringUtils.isEmpty(name) || StringUtils.isEmpty(password)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setId(id);</span><br><span class="line">        user.setName(name);</span><br><span class="line">        user.setPassword(password);</span><br><span class="line">        <span class="keyword">return</span> userDao.updUser(user) &gt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// === DELETE === </span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/users/mybatis/delete&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">insert</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (id == <span class="keyword">null</span> || id &lt; <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> userDao.delUser(id) &gt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h2 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h2><p>Use the following in the browser to test CRUD:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/users/mybatis/insert?name=merikanto&amp;password=<span class="number">123</span>	<span class="comment"># Create</span></span><br><span class="line"></span><br><span class="line">/users/mybatis/insert?name=mybatis&amp;password=<span class="number">123</span>	<span class="comment"># Create</span></span><br><span class="line"></span><br><span class="line">/users/mybatis/queryAll	<span class="comment"># Read</span></span><br><span class="line"></span><br><span class="line">/users/mybatis/update?<span class="built_in">id</span>=<span class="number">2</span>&amp;name=mybatis&amp;password=<span class="number">456</span>	<span class="comment"># Update</span></span><br><span class="line"></span><br><span class="line">/users/mybatis/delete?<span class="built_in">id</span>=<span class="number">2</span>	<span class="comment"># Delete</span></span><br></pre></td></tr></table></figure>

<br>















]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Database Operations with Spring Boot &amp; JDBC</title>
    <url>/2020/SpringBoot-JDBC/</url>
    <content><![CDATA[<p>In this post, we will go through the configuration to setup Spring Boot with MySQL access and operations. In order to make the connection, we will use <strong>JDBC</strong>. </p>
<span id="more"></span> 


<br>

<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><br>

<p><strong>JDBC</strong> stands for Java DataBase Connectivity, and it is a Java API for implementing SQL queries. The basic JDBC configuration file looks like this:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第一步，注册驱动程序  </span></span><br><span class="line"><span class="comment">//com.MySQL.jdbc.Driver  </span></span><br><span class="line">Class.forName(<span class="string">&quot;数据库驱动的完整类名&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//第二步，获取一个数据库的连接  </span></span><br><span class="line">Connection conn = DriverManager.getConnection(<span class="string">&quot;数据库地址&quot;</span>,<span class="string">&quot;用户名&quot;</span>,<span class="string">&quot;密码&quot;</span>);   </span><br><span class="line"></span><br><span class="line"><span class="comment">//第三步，创建一个会话  </span></span><br><span class="line">Statement stmt=conn.createStatement();   </span><br><span class="line"></span><br><span class="line"><span class="comment">//第四步，执行SQL语句  </span></span><br><span class="line">stmt.executeUpdate(<span class="string">&quot;SQL语句&quot;</span>); </span><br><span class="line"></span><br><span class="line"><span class="comment">//或者查询记录  </span></span><br><span class="line">ResultSet rs = stmt.executeQuery(<span class="string">&quot;查询记录的SQL语句&quot;</span>);  </span><br><span class="line"></span><br><span class="line"><span class="comment">//第五步，对查询的结果进行处理  </span></span><br><span class="line"><span class="keyword">while</span>(rs.next())&#123;  </span><br><span class="line"><span class="comment">//操作  </span></span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">//第六步，关闭连接  </span></span><br><span class="line">rs.close();  </span><br><span class="line">stmt.close();  </span><br><span class="line">conn.close();</span><br></pre></td></tr></table></figure>



<p>So now we will use a demo, and set it up step by step.</p>
<br>

<h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><br>

<blockquote>
<p>  <strong>Note: The configuration below is based on Spring Boot Hello World Demo with <code>web starter</code> only.</strong></p>
</blockquote>
<br>

<h3 id="Initialize-DB-in-MySQL"><a href="#Initialize-DB-in-MySQL" class="headerlink" title="Initialize DB in MySQL"></a><u>Initialize DB in MySQL</u></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> DATABASE demo_springboot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE demo_springboot;</span><br><span class="line"></span><br><span class="line">USE demo_springboot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> <span class="keyword">user</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">user</span> (</span><br><span class="line">    id 	 <span class="type">INT</span>(<span class="number">11</span>)	<span class="keyword">NOT</span> <span class="keyword">NULL</span> 	AUTO_INCREMENT,</span><br><span class="line">    name	 <span class="type">VARCHAR</span>(<span class="number">100</span>)	<span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    password <span class="type">VARCHAR</span>(<span class="number">100</span>)	<span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  	<span class="keyword">PRIMARY</span> KEY (id)</span><br><span class="line">) </span><br><span class="line">ENGINE<span class="operator">=</span>INNODB </span><br><span class="line">AUTO_INCREMENT<span class="operator">=</span><span class="number">1</span> </span><br><span class="line"><span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br></pre></td></tr></table></figure>





<br>



<h3 id="Connect-Spring-Boot-to-MySQL"><a href="#Connect-Spring-Boot-to-MySQL" class="headerlink" title="Connect Spring Boot to MySQL"></a><u>Connect Spring Boot to MySQL</u></h3><p>Add dependencies in <code>pom.xml</code>:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<br>

<p>Add Configurations to <code>resources/application.properties</code>  (<strong>use <code>cj.jdbc</code></strong>):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 数据源基本配置</span></span><br><span class="line">spring.datasource.url=jdbc:mysql://localhost:3306/demo_springboot?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false</span><br><span class="line">spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver</span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=</span><br></pre></td></tr></table></figure>

<br>

<p>Check the following dependencies in <code>pom.xml</code>:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.junit.jupiter<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit-jupiter-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.junit.jupiter<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit-jupiter-engine<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<br>

<p>And the following plugins:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.22.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>

<p>Test Connection (<code>DemoApplicationTests</code> under <code>test</code> folder):</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.sql.DataSource;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoApplicationTests</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> DataSource dataSource;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">datasourceTest</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        <span class="comment">// 获取数据库连接对象</span></span><br><span class="line">        Connection connection = dataSource.getConnection();</span><br><span class="line">        <span class="comment">// 判断连接对象是否为空</span></span><br><span class="line">        System.out.println(connection != <span class="keyword">null</span>);</span><br><span class="line">        connection.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>Run Maven with the test class, and the connection is successful if it returns <code>true</code>.</p>
<br>



<h3 id="MySQL-Operations-via-Spring-Boot"><a href="#MySQL-Operations-via-Spring-Boot" class="headerlink" title="MySQL Operations via Spring Boot"></a><u>MySQL Operations via Spring Boot</u></h3><p>Add <code>JdbcController</code> class to <code>main</code>. Then we will do <code>Create</code> and <code>Read</code> from CRUD.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.jdbc.core.JdbcTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注入 jdbcTemplate</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    JdbcTemplate jdbcTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查询 user 表中的所有记录</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/users/queryAll&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;Map&lt;String, Object&gt;&gt; queryAll() &#123;</span><br><span class="line">        List&lt;Map&lt;String, Object&gt;&gt; list = jdbcTemplate.queryForList(<span class="string">&quot;select * from user&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向 user 表中新增一条记录</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/users/insert&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">insert</span><span class="params">(String name, String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(name) || StringUtils.isEmpty(password)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        jdbcTemplate.execute(<span class="string">&quot;insert into user(`name`,`password`) value (\&quot;&quot;</span> + name + <span class="string">&quot;\&quot;,\&quot;&quot;</span> + password + <span class="string">&quot;\&quot;)&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p>Then we try it in the browser, we shall see that the newly added records are fetched via <code>queryAll</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/users/insert?name=merikanto&amp;password=123</span><br><span class="line"></span><br><span class="line">/users/queryAll</span><br></pre></td></tr></table></figure>

<br>

<p>And that is the basics for Spring Boot’s Database connection.</p>
<br>

<br>



<h3 id="P-S-Hello-Controller"><a href="#P-S-Hello-Controller" class="headerlink" title="P. S.  Hello Controller"></a>P. S.  <u>Hello Controller</u></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(&quot;/&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">index</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello World!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



















]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Configuring &amp; Testing Hibernate</title>
    <url>/2020/Hibernate-Config/</url>
    <content><![CDATA[<p>Hibernate is an Object Relational Mapping (ORM) tool for Java. It provides a framework for mapping an <em>object-oriented domain model</em> to a relational database, such as MySQL. </p>
<br>



<span id="more"></span> 

<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><br>



<blockquote>
<p>  <em><strong>Note: The mapping used here avoids using annotations in the Java class.</strong></em> </p>
<p>  <em><strong>Instead, we will create a mapping file for the class object, under the same package.</strong></em></p>
</blockquote>
<br>



<p>The project structure under <code>src/main/java/merikanto</code> is below :</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HelloHibernate/src/main/java/merikanto</span><br><span class="line">    └── hibernate</span><br><span class="line">        ├── entity</span><br><span class="line">        │ 	├── User.hbm.xml</span><br><span class="line">        │ 	└── User.java</span><br><span class="line">        └── test</span><br><span class="line">        	└── Test.java</span><br></pre></td></tr></table></figure>



<br>

<p>To start with, we first set the configs below in MySQL:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">create</span> database hibernate;</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">SET</span> <span class="keyword">GLOBAL</span> time_zone <span class="operator">=</span> <span class="string">&#x27;-4:00&#x27;</span>;	<span class="comment">-- Necessary, otherwise serverTimeZone error.</span></span><br></pre></td></tr></table></figure>



<p>Then create a Maven project in terminal:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn archetype:generate \</span><br><span class="line">    -DgroupId=merikanto.hibernate \</span><br><span class="line">    -DartifactId=HelloHibernate \</span><br><span class="line">    -DarchetypeArtifactId=maven-archetype-quickstart</span><br></pre></td></tr></table></figure>



<p>Open the project in Intellij, and make sure that the database is connected (Need MySQL connector).</p>
<blockquote>
<p>  <code>Project structure - Libraries - search mysql - connect</code></p>
<p>  <code>View - Tool windows - database - add data source - mysql</code></p>
</blockquote>
<br>



<p>Next, edit <code>pom.xml</code>:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">  <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>merikanto.hibernate<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HelloHibernate<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>HelloHibernate<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://merikanto.github.io<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.hibernate<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hibernate-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.4.11.Final<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.19<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">resources</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/java<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">includes</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">include</span>&gt;</span>**/*.xml<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">includes</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">resources</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>merikanto.hibernate<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HelloHibernate<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">classpathScope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">classpathScope</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--Changing the classpath scope!! --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>Test<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p>Create package <code>entity</code> under <code>merikanto.hibernate</code>,  then create new object (class)  <code>User</code> under <code>entity</code>.</p>
<p>A user has 3 properties: </p>
<ul>
<li>  <code>id</code></li>
<li>  <code>username</code> </li>
<li>  <code>password</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.hibernate.entity;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String username;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(<span class="keyword">int</span> id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUsername</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> username;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsername</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.username = username;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> password;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPassword</span><span class="params">(String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.password = password;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<p>Then create <code>User.hbm.xml</code>, under the same <code>entity</code> package as <code>User</code> class.</p>
<p>This file is for mapping (One object – One mapping file). </p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 映射对应的 package --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">hibernate-mapping</span> <span class="attr">package</span>=<span class="string">&quot;merikanto.hibernate.entity&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 实体类和数据库中的表对应（如果没有这个表则新建） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">class</span> <span class="attr">name</span>=<span class="string">&quot;User&quot;</span> <span class="attr">table</span>=<span class="string">&quot;user_info&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- id 主键 和其他属性对应表中相应的字段（这些都是在 User.java 实体类中定义的） --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span> <span class="attr">name</span>=<span class="string">&quot;id&quot;</span> <span class="attr">column</span>=<span class="string">&quot;user_id&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">column</span>=<span class="string">&quot;user_username&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> <span class="attr">column</span>=<span class="string">&quot;user_password&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">hibernate-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure>



<br>



<p>Under <code>src/main/java</code>, create Hibernate configuration file <code>hibernate.cfg.xml </code>.</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&#x27;1.0&#x27; encoding=&#x27;utf-8&#x27;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">hibernate-configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">session-factory</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- Database connection settings --&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 表示使用 mysql 数据库驱动类 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;connection.driver_class&quot;</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- jdbc 的连接 url 和数据库（使用我们之前新建的 hibernate）--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;connection.url&quot;</span>&gt;</span>jdbc:mysql://localhost:3306/hibernate<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 数据库用户名 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;connection.username&quot;</span>&gt;</span>root<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 密码（我的密码为空） --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;connection.password&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- JDBC connection pool (use the built-in) 这一行注释掉--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;property name=&quot;connection.pool_size&quot;&gt;1&lt;/property&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;dialect&quot;</span>&gt;</span>org.hibernate.dialect.MySQL8Dialect<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- Echo all executed SQL to stdout --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 设置 打印输出 sql 语句 为真 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;show_sql&quot;</span>&gt;</span>true<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 设置格式为 sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;format_sql&quot;</span>&gt;</span>true<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 第一次加载 hibernate 时根据实体类自动建立表结构，以后自动更新表结构 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;hbm2ddl.auto&quot;</span>&gt;</span>update<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!-- 映射文件 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mapping</span> <span class="attr">resource</span>=<span class="string">&quot;merikanto/hibernate/entity/User.hbm.xml&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">session-factory</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">hibernate-configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>And now the configuration is done.</p>
<br>





<h2 id="Test-CRUD"><a href="#Test-CRUD" class="headerlink" title="Test (CRUD)"></a>Test (CRUD)</h2><p>Now we run some tests for hibernate. There will be four tests, focusing on the operations below:</p>
<blockquote>
<ul>
<li>  Create</li>
<li>  Read (search)</li>
<li>  Update</li>
<li>  Delete</li>
</ul>
</blockquote>
<br>



<h3 id="Create"><a href="#Create" class="headerlink" title="Create"></a><u>Create</u></h3><p>First we create package <code>test</code> under <code>merikanto.hibernate</code>, then we create class <code>Test</code> under <code>merikanto.hibernate.test</code>.</p>
<p><em><strong>The first test is  for the <code>Create</code> operation.</strong></em></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.hibernate.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.hibernate.entity.User;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.Session;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.SessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.cfg.Configuration;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 Hibernate 配置信息</span></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration().configure();</span><br><span class="line">        <span class="meta">@SuppressWarnings(&quot;deprecation&quot;)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据 configuration 建立 sessionFactory</span></span><br><span class="line">        SessionFactory sessionFactory = configuration.buildSessionFactory();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 开启 session（相当于开启 JDBC 的 connection）</span></span><br><span class="line">        Session session = sessionFactory.openSession();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并开启事务对象</span></span><br><span class="line">        session.beginTransaction();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 新建对象，并赋值</span></span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setId(<span class="number">1</span>);</span><br><span class="line">        user.setUsername(<span class="string">&quot;admin&quot;</span>);</span><br><span class="line">        user.setPassword(<span class="string">&quot;admin&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保存对象</span></span><br><span class="line">        session.save(user);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交事务</span></span><br><span class="line">        session.getTransaction().commit();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关闭 session 和 sessionFactory</span></span><br><span class="line">        session.close();</span><br><span class="line">        sessionFactory.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<p>Then run it in Terminal:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn compile</span><br><span class="line">mvn exec:java -Dexec.mainClass=&quot;merikanto.hibernate.test.Test&quot;</span><br></pre></td></tr></table></figure>



<br>

<h3 id="Read"><a href="#Read" class="headerlink" title="Read"></a><u>Read</u></h3><p><em><strong>The second test is  for the <code>Read</code> operation.</strong></em></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.hibernate.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.hibernate.entity.User;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.hibernate.Session;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.SessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.MetadataSources;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.registry.StandardServiceRegistry;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.registry.StandardServiceRegistryBuilder;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.query.Query;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        StandardServiceRegistry registry = <span class="keyword">new</span> StandardServiceRegistryBuilder()</span><br><span class="line">                <span class="comment">//如果不写配置文件名就会使用默认配置文件名 hibernate.cfg.xml</span></span><br><span class="line">                .configure(<span class="string">&quot;hibernate.cfg.xml&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 建立 sessionFactory</span></span><br><span class="line">        SessionFactory sessionFactory = <span class="keyword">new</span> MetadataSources(registry).buildMetadata().buildSessionFactory();</span><br><span class="line"></span><br><span class="line">        Session session = sessionFactory.openSession();</span><br><span class="line">        session.beginTransaction();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 利用 StringBuilder 来连接查询语句</span></span><br><span class="line">        StringBuilder hq = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 从 User 里面查找（注意 from 后有空格）</span></span><br><span class="line">        <span class="comment">// 相当于 &quot;select * from user_info;&quot;</span></span><br><span class="line">        hq.append(<span class="string">&quot;from &quot;</span>).append( User.class.getName() );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 利用 session 建立 query</span></span><br><span class="line">        Query query = session.createQuery( hq.toString() );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 序列化 query 的结果为一个 list 集合</span></span><br><span class="line">        List&lt;User&gt; users = query.list();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印每一个 User 信息（这里只打印了名字，你也可以打印其他信息）</span></span><br><span class="line">        <span class="keyword">for</span> (User user : users) &#123;</span><br><span class="line">            System.out.println( user.getUsername() );</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        session.getTransaction().commit();</span><br><span class="line">        session.close();</span><br><span class="line">        sessionFactory.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<p>Then run it in Terminal:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn compile</span><br><span class="line">mvn exec:java -Dexec.mainClass=&quot;merikanto.hibernate.test.Test&quot;</span><br></pre></td></tr></table></figure>



<br>

<h3 id="Update"><a href="#Update" class="headerlink" title="Update"></a><u>Update</u></h3><p><em><strong>The third test is  for the <code>Update</code> operation.</strong></em></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.hibernate.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.hibernate.entity.User;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.hibernate.Session;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.SessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.MetadataSources;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.registry.StandardServiceRegistry;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.registry.StandardServiceRegistryBuilder;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.query.Query;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        StandardServiceRegistry registry = <span class="keyword">new</span> StandardServiceRegistryBuilder()</span><br><span class="line">                <span class="comment">//如果不写配置文件名就会使用默认配置文件名 hibernate.cfg.xml</span></span><br><span class="line">                .configure(<span class="string">&quot;hibernate.cfg.xml&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="comment">// 建立 sessionFactory</span></span><br><span class="line">        SessionFactory sessionFactory = <span class="keyword">new</span> MetadataSources(registry).buildMetadata().buildSessionFactory();</span><br><span class="line"></span><br><span class="line">        Session session = sessionFactory.openSession();</span><br><span class="line">        session.beginTransaction();</span><br><span class="line"></span><br><span class="line">        StringBuilder hq = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对比查找的操作来看，因为我们需要修改指定 name 的用户密码，后面需要再添加查询条件</span></span><br><span class="line">        <span class="comment">// 注意 from、where 的空格，&quot;:name&quot; 表示一个参数</span></span><br><span class="line">        hq.append(<span class="string">&quot;from &quot;</span>).append(User.class.getName()).append(<span class="string">&quot; where user_username=:name&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Query query = session.createQuery(hq.toString());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里就设定参数 name 的值为&quot;user1&quot;</span></span><br><span class="line">        query.setParameter(<span class="string">&quot;name&quot;</span>,<span class="string">&quot;user1&quot;</span> );</span><br><span class="line"></span><br><span class="line">        List&lt;User&gt; users = query.list();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (User user : users) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 修改 user1 的密码</span></span><br><span class="line">            user.setPassword(<span class="string">&quot;123-user&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 注意这里是 update</span></span><br><span class="line">            session.update(user);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        session.getTransaction().commit();</span><br><span class="line">        session.close();</span><br><span class="line">        sessionFactory.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<p>Then run it in Terminal:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn compile</span><br><span class="line">mvn exec:java -Dexec.mainClass=&quot;merikanto.hibernate.test.Test&quot;</span><br></pre></td></tr></table></figure>



<br>



<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a><u>Delete</u></h3><p><em><strong>The fourth test is  for the <code>Delete</code> operation.</strong></em></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> merikanto.test.hibernate.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> merikanto.hibernate.entity.User;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.hibernate.Session;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.SessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.MetadataSources;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.registry.StandardServiceRegistry;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.boot.registry.StandardServiceRegistryBuilder;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.query.Query;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        StandardServiceRegistry registry = <span class="keyword">new</span> StandardServiceRegistryBuilder()</span><br><span class="line">                <span class="comment">//如果不写配置文件名就会使用默认配置文件名 hibernate.cfg.xml</span></span><br><span class="line">                .configure(<span class="string">&quot;hibernate.cfg.xml&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="comment">// 建立 sessionFactory</span></span><br><span class="line">        SessionFactory sessionFactory = <span class="keyword">new</span> MetadataSources(registry).buildMetadata().buildSessionFactory();</span><br><span class="line"></span><br><span class="line">        Session session = sessionFactory.openSession();</span><br><span class="line">        session.beginTransaction();</span><br><span class="line"></span><br><span class="line">        StringBuilder hq = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对比查找时候的操作来看，因为我们需要修改指定 name 的用户密码，后面需要再添加查询条件</span></span><br><span class="line">        <span class="comment">// 注意 from、where 的空格，&quot;:name&quot; 表示一个参数</span></span><br><span class="line">        hq.append(<span class="string">&quot;from &quot;</span>).append(User.class.getName()).append(<span class="string">&quot; where user_username=:name&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Query query = session.createQuery(hq.toString());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里就设定参数 name 的值为&quot;user1&quot;</span></span><br><span class="line">        query.setParameter(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;user1&quot;</span>);</span><br><span class="line"></span><br><span class="line">        List&lt;User&gt; users = query.list();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (User user : users) &#123;</span><br><span class="line">            <span class="comment">// 注意这里是 delete</span></span><br><span class="line">            session.delete(user);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        session.getTransaction().commit();</span><br><span class="line">        session.close();</span><br><span class="line">        sessionFactory.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<p>Then run it in Terminal:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn compile</span><br><span class="line">mvn exec:java -Dexec.mainClass=&quot;merikanto.hibernate.test.Test&quot;</span><br></pre></td></tr></table></figure>



<br>



<p>And we now have implemented the tests.</p>
]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>The Rise of &quot;Worse is Better&quot;</title>
    <url>/Notes/Worse-Is-Better/</url>
    <content><![CDATA[<p>From: <a href="http://naggum.no/worse-is-better.html">Lisp:Good News Bad News How to Win Big</a></p>
<p>This article discussed briefly about the Unix design philosophy.</p>
<span id="more"></span> 

<br>

<hr>
<p>I and just about every designer of Common Lisp and CLOS has had extreme exposure to the MIT/Stanford style of design. The essence of this style can be captured by the phrase <em>the right thing</em>. To such a designer it is important to get all of the following characteristics right:</p>
<ul>
<li>Simplicity – the design must be simple, both in implementation and interface. It is more important for the interface to be simple than the implementation.</li>
<li>Correctness – the design must be correct in all observable aspects. Incorrectness is simply not allowed.</li>
<li>Consistency – the design must not be inconsistent. A design is allowed to be slightly less simple and less complete to avoid inconsistency. Consistency is as important as correctness.</li>
<li>Completeness – the design must cover as many important situations as is practical. All reasonably expected cases must be covered. Simplicity is not allowed to overly reduce completeness.</li>
</ul>
<br>

<p>I believe most people would agree that these are good characteristics. I will call the use of this philosophy of design the <em>MIT approach</em> Common Lisp (with CLOS) and Scheme represent the MIT approach to design and implementation.</p>
<p>The worse-is-better philosophy is only slightly different:</p>
<ul>
<li>Simplicity – the design must be simple, both in implementation and interface. It is more important for the implementation to be simple than the interface. Simplicity is the most important consideration in a design.</li>
<li>Correctness – the design must be correct in all observable aspects. It is slightly better to be simple than correct.</li>
<li>Consistency – the design must not be overly inconsistent. Consistency can be sacrificed for simplicity in some cases, but it is better to drop those parts of the design that deal with less common circumstances than to introduce either implementational complexity or inconsistency.</li>
<li>Completeness – the design must cover as many important situations as is practical. All reasonably expected cases should be covered. Completeness can be sacrificed in favor of any other quality. In fact, completeness must sacrificed whenever implementation simplicity is jeopardized. Consistency can be sacrificed to achieve completeness if simplicity is retained; especially worthless is consistency of interface.</li>
</ul>
<br>

<p>Early Unix and C are examples of the use of this school of design, and I will call the use of this design strategy the <em>New Jersey approach</em> I have intentionally caricatured the worse-is-better philosophy to convince you that it is obviously a bad philosophy and that the New Jersey approach is a bad approach.</p>
<p>However, I believe that worse-is-better, even in its strawman form, has better survival characteristics than the-right-thing, and that the New Jersey approach when used for software is a better approach than the MIT approach.</p>
<p>Let me start out by retelling a story that shows that the MIT/New-Jersey distinction is valid and that proponents of each philosophy actually believe their philosophy is better.</p>
<br>

<p>Two famous people, one from MIT and another from Berkeley (but working on Unix) once met to discuss operating system issues. The person from MIT was knowledgeable about ITS (the MIT AI Lab operating system) and had been reading the Unix sources. He was interested in how Unix solved the PC loser-ing problem. The PC loser-ing problem occurs when a user program invokes a system routine to perform a lengthy operation that might have significant state, such as IO buffers. If an interrupt occurs during the operation, the state of the user program must be saved. Because the invocation of the system routine is usually a single instruction, the PC of the user program does not adequately capture the state of the process. The system routine must either back out or press forward. The right thing is to back out and restore the user program PC to the instruction that invoked the system routine so that resumption of the user program after the interrupt, for example, re-enters the system routine. It is called <em>PC loser-ing</em> because the PC is being coerced into <em>loser mode</em>, where <em>loser</em> is the affectionate name for <em>user</em> at MIT.</p>
<p>The MIT guy did not see any code that handled this case and asked the New Jersey guy how the problem was handled. The New Jersey guy said that the Unix folks were aware of the problem, but the solution was for the system routine to always finish, but sometimes an error code would be returned that signaled that the system routine had failed to complete its action. A correct user program, then, had to check the error code to determine whether to simply try the system routine again. The MIT guy did not like this solution because it was not the right thing.</p>
<p>The New Jersey guy said that the Unix solution was right because the design philosophy of Unix was simplicity and that the right thing was too complex. Besides, programmers could easily insert this extra test and loop. The MIT guy pointed out that the implementation was simple but the interface to the functionality was complex. The New Jersey guy said that the right tradeoff has been selected in Unix – namely, implementation simplicity was more important than interface simplicity.</p>
<p>The MIT guy then muttered that sometimes it takes a tough man to make a tender chicken, but the New Jersey guy didn’t understand (I’m not sure I do either).</p>
<br>

<p>Now I want to argue that worse-is-better is better. C is a programming language designed for writing Unix, and it was designed using the New Jersey approach. C is therefore a language for which it is easy to write a decent compiler, and it requires the programmer to write text that is easy for the compiler to interpret. Some have called C a fancy assembly language. Both early Unix and C compilers had simple structures, are easy to port, require few machine resources to run, and provide about 50%-80% of what you want from an operating system and programming language.</p>
<p>Half the computers that exist at any point are worse than median (smaller or slower). Unix and C work fine on them. The worse-is-better philosophy means that implementation simplicity has highest priority, which means Unix and C are easy to port on such machines. Therefore, one expects that if the 50% functionality Unix and C support is satisfactory, they will start to appear everywhere. And they have, haven’t they?</p>
<p><strong>Unix and C are the ultimate computer viruses.</strong></p>
<p>A further benefit of the worse-is-better philosophy is that the programmer is conditioned to sacrifice some safety, convenience, and hassle to get good performance and modest resource use. Programs written using the New Jersey approach will work well both in small machines and large ones, and the code will be portable because it is written on top of a virus.</p>
<p>It is important to remember that the initial virus has to be basically good. If so, the viral spread is assured as long as it is portable. Once the virus has spread, there will be pressure to improve it, possibly by increasing its functionality closer to 90%, but users have already been conditioned to accept worse than the right thing. Therefore, the worse-is-better software first will gain acceptance, second will condition its users to expect less, and third will be improved to a point that is almost the right thing. In concrete terms, even though Lisp compilers in 1987 were about as good as C compilers, there are many more compiler experts who want to make C compilers better than want to make Lisp compilers better.</p>
<p>The good news is that in 1995 we will have a good operating system and programming language; the bad news is that they will be Unix and C++.</p>
<p>There is a final benefit to worse-is-better. Because a New Jersey language and system are not really powerful enough to build complex monolithic software, large systems must be designed to reuse components. Therefore, a tradition of integration springs up.</p>
<br>

<p>How does the right thing stack up? There are two basic scenarios: the <em>big complex system scenario</em> and the <em>diamond-like jewel</em> scenario.</p>
<p>The <em>big complex system</em> scenario goes like this:</p>
<p>First, the right thing needs to be designed. Then its implementation needs to be designed. Finally it is implemented. Because it is the right thing, it has nearly 100% of desired functionality, and implementation simplicity was never a concern so it takes a long time to implement. It is large and complex. It requires complex tools to use properly. The last 20% takes 80% of the effort, and so the right thing takes a long time to get out, and it only runs satisfactorily on the most sophisticated hardware.</p>
<p>The <em>diamond-like jewel</em> scenario goes like this:</p>
<p>The right thing takes forever to design, but it is quite small at every point along the way. To implement it to run fast is either impossible or beyond the capabilities of most implementors.</p>
<p>The two scenarios correspond to Common Lisp and Scheme.</p>
<p>The first scenario is also the scenario for classic artificial intelligence software.</p>
<p>The right thing is frequently a monolithic piece of software, but for no reason other than that the right thing is often designed monolithically. That is, this characteristic is a happenstance.</p>
<p>The lesson to be learned from this is that it is often undesirable to go for the right thing first. It is better to get half of the right thing available so that it spreads like a virus. Once people are hooked on it, take the time to improve it to 90% of the right thing.</p>
<p>A wrong lesson is to take the parable literally and to conclude that C is the right vehicle for AI software. The 50% solution has to be basically right, and in this case it isn’t.</p>
<p>But, one can conclude only that the Lisp community needs to seriously rethink its position on Lisp design. I will say more about this later.</p>
<br>

<br>

]]></content>
      <categories>
        <category>Resources</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Common Debugging Methods for MySQL</title>
    <url>/2020/MySQL-Debug/</url>
    <content><![CDATA[<p>Two types of common bugs when we configure MySQL with root access.</p>
<span id="more"></span> 

<br>



<table>
<thead>
<tr>
<th>Versions</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Environment</td>
<td>Ubuntu 19.10</td>
</tr>
<tr>
<td>MySQL</td>
<td>8.0.19</td>
</tr>
</tbody></table>
<br>



<h2 id="Problem-root-user-denied-access"><a href="#Problem-root-user-denied-access" class="headerlink" title="Problem: root user denied access"></a>Problem: root user denied access</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> systemctl stop mysql;</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>  Create temporary path.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir -p /var/run/mysqld</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>  Change permissions.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo chown mysql:mysql /var/run/mysqld</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>  Enter MySQL in safe mode.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo mysqld_safe --skip-grant-tables</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>  Get into MySQL.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mysql -uroot</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>  Some people successfully solve the problem by  <code>alter user</code>, but it didn’t work in my case. So here’s the work-around:</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> use mysql;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">user</span>, host <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">drop</span> <span class="keyword">user</span> root<span class="variable">@localhost</span>;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> flush privileges;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">user</span> root<span class="variable">@localhost</span> identified <span class="keyword">by</span> <span class="string">&#x27;&#x27;</span>;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> flush privileges;</span><br></pre></td></tr></table></figure>



<p>And now we should be able to use <code>mysql -uroot</code> to get into MySQL.</p>
<br>





<h2 id="Problem-root-user-lacks-privileges"><a href="#Problem-root-user-lacks-privileges" class="headerlink" title="Problem: root user lacks privileges"></a>Problem: root user lacks privileges</h2><blockquote>
<p>   Grant privileges. First get into the safe mode  via the commands before. After get into MySQL:</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>



<blockquote>
<p>  For security purposes, create another standard user without root access:</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> use mysql;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">user</span> NAME<span class="variable">@localhost</span> identified <span class="keyword">by</span> <span class="string">&#x27;&#x27;</span>;</span><br></pre></td></tr></table></figure>



<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> flush privileges;</span><br></pre></td></tr></table></figure>



<p>And the problem shall be solved.</p>
<br>























]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Core Java Overview</title>
    <url>/2020/Core-Java/</url>
    <content><![CDATA[<p>Today we will walk through some syntax &amp; features in core Java. Note that the version we use here is Java 8.</p>
<span id="more"></span>

<br>

<hr>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a><u>Notes</u></h3><p><strong>OpenJDK</strong>: open source version of Java</p>
<br>

<p><strong>JVM</strong>: </p>
<ul>
<li><p>  OS process that provides the Java runtime environment</p>
</li>
<li><p>  <strong>Interpreter</strong> for the bytecode form (with JIT compilation to give a huge performance boost)</p>
</li>
<li><p>  Other languages can also run in JVM, as long as they have valid class files</p>
</li>
<li><p>  Makes use of runtime information self-manageable</p>
</li>
</ul>
<blockquote>
<p>  <strong>Research</strong>: Programs’ runtime behavior has a large amount of interesting &amp; useful patterns that cannot be deduced at compile time.</p>
<p>  JVM was the <strong>1st platform</strong> to utilize this research, collects info to make better decisions about how to execute the code. </p>
</blockquote>
<br>

<p><strong>JIT</strong>: </p>
<ul>
<li>  HotSpot VM improved by detecting <strong>hot methods</strong> (methods used most often), then JVM compiles the hot methods directly to machine code.</li>
<li>  Old days, Javac produces heavily optimized machine code. But then it’s better to just optimize JIT itself</li>
</ul>
<br>

<p><strong>Class file</strong> is the smallest unit of functionality the platform will deal with. </p>
<br>

<p><strong>Javac</strong>:</p>
<ul>
<li><p>  Produces bytecode, while compilers produce machine code</p>
</li>
<li><p>  Javac creates the intermediate representation (bytecode)</p>
</li>
<li><p><strong>Compilation</strong>: JIT (it actually produces machine code)</p>
  <br></li>
</ul>
<p><strong>Bytecode</strong>: </p>
<ul>
<li>  The instruction code (opcode) is just a single byte, only 256 possibilities</li>
<li>  Byte ordering: <strong>big-endian</strong></li>
</ul>
 <br>

<h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a><u>Comparison</u></h3><h4 id="Java-amp-C"><a href="#Java-amp-C" class="headerlink" title="Java &amp; C"></a>Java &amp; C</h4><ul>
<li>  Java is object-oriented; C is not</li>
<li>  Java is portable as class files; C need to be recompiled</li>
<li>  Java has no pointers &amp; pointer arithmetic, </li>
<li>  Java provides <strong>automatic memory management</strong> via garbage collection</li>
<li>  Java has no ability to lay out memory at low level (no structs)</li>
<li>  Java has no pre-processor</li>
</ul>
<br>

<h4 id="Java-amp-C-1"><a href="#Java-amp-C-1" class="headerlink" title="Java &amp; C++"></a>Java &amp; C++</h4><ul>
<li>  Java is always pass by value (object references are values)</li>
<li>  Java does not support full multiple inheritance</li>
<li>  Java has no <strong>operator overloading</strong></li>
</ul>
<br>

<h4 id="Java-amp-JS"><a href="#Java-amp-JS" class="headerlink" title="Java &amp; JS"></a>Java &amp; JS</h4><ul>
<li>  Java uses class-based objects; JS is prototype-based</li>
<li>  Java has namespaces; JS does not</li>
<li>  Java is multi-threaded; JS is not</li>
</ul>
<br>

<h2 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h2><div class="note warning"><p><strong>Note</strong>: <code>strictfp</code> &amp; <code>assert</code> keywords are almost never used.</p>
</div>



<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a><u>Overview</u></h3><p><strong>Classes</strong> are collections of methods &amp; fields.</p>
<p><strong>Reference types:</strong> </p>
<ul>
<li>  Fields</li>
<li>  Methods</li>
<li>  Constructors</li>
</ul>
<br>

<p><strong>Structure</strong>:</p>
<ul>
<li><p>  Primitives</p>
</li>
<li><p>  Operators</p>
</li>
<li><p>  Expressions</p>
</li>
<li><p>  Statements</p>
</li>
<li><p>  Methods</p>
</li>
<li><p>  Classes</p>
</li>
<li><p>  Packages</p>
</li>
<li><p>Programs / Applications</p>
  <br></li>
</ul>
<h3 id="Lexical-Structure"><a href="#Lexical-Structure" class="headerlink" title="Lexical Structure"></a><u>Lexical Structure</u></h3><p>Java programs are written using Unicode. </p>
<br>

<p><code>const</code> &amp; <code>goto</code> are reserved keywords, but aren’t actually used in the language.</p>
<br>

<p><strong>Literals</strong></p>
<ul>
<li>  <strong>Definition</strong>: Literals are values that appear directly in Java source code.</li>
<li>  <strong>Include</strong>: ints,　floats,　chars with single &amp; double quotes,　reserved words (true / false / null)</li>
<li>  Each primitive type has a literal syntax for including type values <strong>literally</strong> in the code</li>
</ul>
<br>

<h3 id="Primitives"><a href="#Primitives" class="headerlink" title="Primitives"></a><u>Primitives</u></h3><p><strong>Eight types:</strong></p>
<ul>
<li>  1 boolean type</li>
<li>  1 character type</li>
<li>  2 floating-point type</li>
<li>  4 integer type</li>
</ul>
<table>
<thead>
<tr>
<th>Type</th>
<th>Size</th>
<th>Comments</th>
</tr>
</thead>
<tbody><tr>
<td>boolean</td>
<td>1 bit</td>
<td>true / false</td>
</tr>
<tr>
<td>char</td>
<td>16 bits</td>
<td>Unicode</td>
</tr>
<tr>
<td>byte</td>
<td>8 bits</td>
<td>signed int</td>
</tr>
<tr>
<td>short</td>
<td>16 bits</td>
<td>signed int</td>
</tr>
<tr>
<td>int</td>
<td>32 bits</td>
<td>signed int</td>
</tr>
<tr>
<td>long</td>
<td>64 bits</td>
<td>signed int</td>
</tr>
<tr>
<td>float</td>
<td>32 bits</td>
<td></td>
</tr>
<tr>
<td>double</td>
<td>64 bits</td>
<td></td>
</tr>
</tbody></table>
<br>

<p><strong><code>boolean</code></strong>: A <code>boolean</code> is neither an integral nor an object type. It cannot be widened / narrowed.</p>
<br>

<p><strong><code>char</code></strong>:</p>
<ul>
<li>  Java 8 uses Unicode 6.2</li>
<li>Recent release of Unicode includes chars whose encoding / codepoints do not fit in 16 bits (use 21 bits instead)<ul>
<li>  Use <code>int</code> to hold codepoint of a supplementary char, or encode in surrogate pair of 2 char values</li>
</ul>
</li>
<li>  <strong>String literals</strong>: <code>String</code> type is class (a reference type)</li>
</ul>
<br>

<p><strong>Ints (4)</strong>:</p>
<ul>
<li>  All int types represent <strong>signed</strong> numbers</li>
<li>  Ints can be expressed in hex, binary, or octal notation (use underscore for binary literal)</li>
<li>  <strong>Integer arithmetic in Java never produces overflow / underflow</strong> (numbers just wrap around)</li>
</ul>
<br>

<p><strong>Floats (2)</strong>:</p>
<ul>
<li>  Floating-point literals are <code>double</code> by default</li>
<li>  <strong>Cannot</strong> be expressed in hex, binary, octal</li>
<li>  <code>float</code> &amp; <code>double</code> values are only approximation of the represented numbers</li>
<li><strong>4 special values</strong>: Positive &amp; negative infinity, zero, NaN (not a number)<ul>
<li>  Differentiate between positive &amp; negative zero</li>
</ul>
</li>
<li>  Arithmetic <strong>Never throws exceptions</strong>, even when performing illegal operations (NaN)</li>
</ul>
<br>

<h4 id="Type-Conversion"><a href="#Type-Conversion" class="headerlink" title="Type Conversion"></a>Type Conversion</h4><ul>
<li><p>  Only <code>boolean</code> cannot be converted</p>
</li>
<li><p>  <strong>Widening</strong>: Value converted to a wider type</p>
</li>
<li><p><strong>Narrowing</strong>: Value converted to a narrower type</p>
<ul>
<li>  Not always safe, may lose data</li>
</ul>
</li>
<li><p><strong>cast</strong>: Force type conversion (often used to convert floats to ints)</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">13</span>;</span><br><span class="line"><span class="keyword">byte</span> b = (<span class="keyword">byte</span>) i;   <span class="comment">// (byte) is a cast</span></span><br><span class="line">i = (<span class="keyword">int</span>) <span class="number">13.1</span>;      <span class="comment">// (int) another cast</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<h3 id="Expressions-amp-Operators"><a href="#Expressions-amp-Operators" class="headerlink" title="Expressions &amp; Operators"></a><u>Expressions &amp; Operators</u></h3><h4 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h4><ul>
<li><strong>Precedence</strong>: <ul>
<li>  Operators with higher precedence are performed first</li>
<li>  Default precedence is compatible with rules in C</li>
</ul>
</li>
<li><strong>Associativity</strong>: <ul>
<li>  Most are left-to-right associative</li>
<li>  A <strong>reference</strong> is an object / array</li>
</ul>
</li>
</ul>
<br>

<p>Comparison, equality, Boolean operators always return <strong><code>boolean</code></strong> values.</p>
<br>

<p><strong>Post-increment</strong>: <code>a++</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">a[i++]++;</span><br><span class="line"></span><br><span class="line">a[i++] = a[i++] + <span class="number">1</span>;</span><br><span class="line"><span class="comment">// Adds 1 to an array element, and stores new value in another element</span></span><br></pre></td></tr></table></figure>



<p><strong>Pre-increment</strong>: <strong><code>++a</code></strong> first increments <code>a</code>, then returns the incremented value.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> b = ++a + ++a * ++a;	<span class="comment">// Equals: b = 3 + 4 * 5 = 23</span></span><br></pre></td></tr></table></figure>

<br>

<p>Java has built-in string conversion for all primitive types ( use <code>toString()</code> )</p>
<br>

<p><strong><code>==</code></strong>:  </p>
<ul>
<li>  For reference types, it only compares the content (if refers to the same object)</li>
<li>  If <code>==</code> is used to compare different types of numeric / character values, the narrower type will be first converted to the wider type</li>
</ul>
<br>

<p><strong>Boolean operator</strong></p>
<ul>
<li>  <code>A &amp;&amp; B</code>: To increase efficiency, only evaluate B,  if A is <code>true</code></li>
<li>  <code>A || B</code>: If A is <code>true</code>, then skip B. (since it will always be true)</li>
<li><code>A &amp; B</code>,　<code>A | B</code>: <ul>
<li>  Always evaluate both A &amp; B</li>
<li>  Used as a bitwise operator with integer operands</li>
</ul>
</li>
<li>  <code>A ^ B</code>: Must always evaluate both</li>
</ul>
<br>

<p><strong>Bitwise &amp; Shift Operators</strong></p>
<ul>
<li>  <code>&lt;&lt;</code>: left shift</li>
<li>  <code>&gt;&gt;</code>: signed right shift</li>
<li>  <code>&gt;&gt;&gt;</code>: unsigned right shift</li>
</ul>
<br>

<p><strong>Other operators</strong></p>
<ul>
<li>  <code>instanceof</code></li>
<li>  <code>.</code>　: object member access</li>
<li>  <code>[]</code>　: array element access</li>
<li>  <code>()</code>　: method invocation / type conversion / casting</li>
<li>  <code>-&gt;</code>　: lambda expression</li>
<li><code>new</code>　: object creation<ul>
<li>  Objects are created with <code>new</code></li>
<li>  A <strong>constructor</strong> is a <u>special block of code that initializes a newly created object</u></li>
</ul>
</li>
</ul>
<br>

<h3 id="Statements"><a href="#Statements" class="headerlink" title="Statements"></a><u>Statements</u></h3><p>Many statements defined by Java are <strong>flow-control</strong> statements.</p>
<br>

<p><strong>Compound statement</strong>: Statements grouped together with <code>&#123; &#125;</code></p>
<br>

<p><strong>Labeled statement</strong>: pre-pend an identifier, used by <code>break</code> &amp; <code>continue</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">loop1: <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">    loop2: <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; ++j)</span><br><span class="line">        <span class="keyword">break</span> loop1;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>Local var declaration statement</strong>:</p>
<ul>
<li>  Since Java is a <strong>statically typed</strong> language, only values of that type can be stored in the variable</li>
<li>  Local vars can be used only within the method / block in which they’re defined (<strong>lexical scope</strong>)</li>
</ul>
<br>

<p><strong><code>Boolean</code></strong>: wrapper type (the wrapper object is auto unboxed)</p>
<p><strong><code>boolean</code></strong>: primitive type</p>
<br>

<p><strong><code>else</code></strong></p>
<p>Without <code>&#123; &#125;</code>, <code>else</code> is associated with the nearest <code>if</code>.</p>
<br>

<p><strong><code>switch</code></strong></p>
<p>Use <strong><code>break</code></strong> after each case. Each case must be a <strong>constant</strong> or a <strong>constant expression</strong> that the compiler can evaluate.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span>(n) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">        <span class="comment">// code block</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">        <span class="comment">// code block</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">// code block</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong><code>do-while</code></strong></p>
<ul>
<li>  loop expression is tested at the boom of the loop </li>
<li>  Execute <strong>at least once</strong></li>
</ul>
<br>

<p><strong><code>for</code></strong></p>
<ul>
<li><p>Three things at the top : <strong>initialize</strong>, <strong>test</strong>, and <strong>update steps</strong></p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (init; test; update)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Equal to the while below:</span></span><br><span class="line">init;</span><br><span class="line"><span class="keyword">while</span> (test) &#123;</span><br><span class="line">    statement;</span><br><span class="line">    update;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
<li><p>Use comma to separate multiple init. / update:</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; <span class="number">10</span>; ++i, -j)</span><br></pre></td></tr></table></figure>

</li>
<li><p>Can be used for iterating through a linked list:</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> ( node n = head; n != <span class="keyword">null</span>; n = n.next() )</span><br><span class="line">    process(n);</span><br></pre></td></tr></table></figure>

</li>
<li><p>Infinite loop:</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(;;)    <span class="comment">// All three expressions are optional</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<ul>
<li><p><strong>foreach</strong> loop: Iterate <strong>collections</strong></p>
<ul>
<li>  Hides loop counter (iterator) </li>
<li>  Cannot get the array index</li>
</ul>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (element: collection)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<p><strong><code>break</code></strong></p>
<ul>
<li>  Exit innermost loop</li>
<li>  Use <strong><a href="#u-Statements-u">label</a></strong> to choose exit</li>
</ul>
<br>

<p><strong><code>continue</code></strong></p>
<ul>
<li>  <code>continue</code> quits the current iteration, and starts the next one</li>
<li>  Only used within <code>while</code> / <code>for</code> loops</li>
</ul>
<br>

<p><strong><code>synchronized</code></strong></p>
<ul>
<li><p>Prevent multiple threads from modifying an object simultaneously (might corrupt the object’s state)</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (expression) &#123;</span><br><span class="line">    <span class="comment">// code block</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>  Before executing the code block, the Java interpreter first obtain an <strong>exclusive lock</strong> on the object specified by <code>expression</code>. The lock is held until finish running the code block. While a thread holds the lock, other threads cannot obtain the lock.</p>
</li>
<li><p>  <code>synchronized</code> as a <strong>method modifier</strong>: The entire method is locked </p>
</li>
</ul>
<br>

<p><strong><code>throw</code></strong></p>
<ul>
<li><p>  An <strong>exception</strong>: A <strong>signal</strong> that indicates exceptional condition / error has occurred</p>
</li>
<li><p><code>throw</code> signals the exceptional condition, <code>catch</code> handles that exception. When there’s a <code>throw</code>, the interpreter stops normal program execution, and starts looking for an exception handler that can catch / handle the exception</p>
<blockquote>
<p>  <em>顺序：</em> </p>
<ul>
<li>  <em>先看 method 里有没有 exception handler</em></li>
<li>  <em>再看 code 里有没有处理 exception</em></li>
<li>  <em>如果都没有就 print error message &amp; stack trace</em></li>
</ul>
</blockquote>
  <br></li>
<li><p>  <strong>An exception is represented by an object</strong></p>
</li>
</ul>
<br>

<p><strong><code>try / catch / finally</code></strong></p>
<ul>
<li>  Every <code>try</code> must be followed by a <code>catch</code> / <code>finally</code> (to do the exception handling and cleanup)</li>
<li>  <code>finally</code>: close files / shut down network connections</li>
<li>  Exit try before <code>finally</code>: <code>System.exit()</code></li>
</ul>
<br>

<p><strong><code>assert</code></strong></p>
<ul>
<li><p>  Rarely used, inflexible for testing applications</p>
</li>
<li><p>Never attempt to catch <code>AssertionError</code> from your own code (might have unexpected results in future versions)</p>
</li>
</ul>
<br>

<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a><u>Methods</u></h3><p>A <strong>method invocation</strong> is an expression that’s evaluated by the Java interpreter.</p>
<br>

<h4 id="Method-Signature"><a href="#Method-Signature" class="headerlink" title="Method Signature"></a>Method Signature</h4><p>A method signature contains:</p>
<ul>
<li>  Method name</li>
<li>  Parameters (number, order, type, name)</li>
<li>  Returned value type</li>
<li>  Checked exceptions to <code>throw</code></li>
<li>  Method modifiers</li>
</ul>
<p>Method signature can also include <strong>type variable declarations</strong> (generic methods).</p>
<br>

<p><strong>Abstract methods</strong> only have specification, but no implementation (no method body).</p>
<br>

<p>A method signature is the method <strong>specification</strong>, and defines the API for the method.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">modifiers type <span class="title">name</span> <span class="params">(paramlist)</span> [<span class="keyword">throws</span> exception]</span></span><br></pre></td></tr></table></figure>

<p>The signature is followed by the method body ( = method implementation = bunch of Java statements).</p>
<ul>
<li><p>  <code>modifiers</code>: public / protected / private,　final,　native, 　static,　synchronized / volatile,　abstract,　strictfp</p>
</li>
<li><p>  <code>type</code>: specifies the return type</p>
</li>
<li><p>  <strong>Constructor</strong>: initialize newly created objects (constructor’s signature does not include the <code>type</code> specification)</p>
</li>
<li><p><code>name</code>: follows the specification of its modifier &amp; type (method names &amp; variable names are Java identifiers)</p>
<ul>
<li>  <strong>Method overloading</strong>: Define more than one method with the same name (each method has a different param list)</li>
</ul>
</li>
<li><p>  Param list: empty is <code>( )</code>. Java does not regard <code>void</code> as a type</p>
</li>
<li><p><code>throw</code>:</p>
<ul>
<li><p><strong>Checked exceptions</strong>: </p>
<ul>
<li>  Category of exception classes that must be <u>listed in the <code>throw</code> clause</u> of methods that can throw them</li>
<li>  Must use <code>throw</code> clause to declare the exception in the method signature</li>
<li>  Java compiler <strong>checks</strong> to make sure they’re declared in the method signature, hence the name “checked”</li>
</ul>
</li>
<li><p><strong>Unchecked exceptions</strong>: </p>
<ul>
<li><p>  Failures that cannot be predicted, due to runtime conditions. (e.g. <code>OutOfMemoryError</code>, <code>NullPointerException</code>)</p>
</li>
<li>  <div class="note danger"><p><strong>Murphy’s law</strong>: Anything that can go wrong, will go wrong.</p>
</div></li>
</ul>
</li>
<li><p><strong>Exceptions are throwable objects</strong>. 2 categories:</p>
<ul>
<li>  <strong>Error</strong> (Any exception object that is an <code>Error</code> is <strong>unchecked</strong>)</li>
<li>  <strong>Exception</strong> (<strong>checked</strong>)</li>
<li>  特例： <code>RuntimeException</code> is unchecked</li>
</ul>
</li>
</ul>
</li>
</ul>
<br>

<h4 id="Method-Modifiers"><a href="#Method-Modifiers" class="headerlink" title="Method Modifiers"></a>Method Modifiers</h4><p><strong>abstract</strong></p>
<ul>
<li><p>  An <strong>abstract method</strong> is a <u>specification without an implementation</u></p>
</li>
<li><p>A class that includes an abstract method must also be <code>abstract</code>. Such class cannot be instantiated</p>
  <div class="note primary"><p>Need implementation of specification, to instantiate the class.</p>
</div></li>
</ul>
<br>

<p><strong>final</strong></p>
<ul>
<li>  A <code>final</code> method may not be overridden or hidden by a subclass</li>
<li>  All <code>private</code> methods are implicitly <code>final</code></li>
</ul>
<br>

<p><strong>native</strong></p>
<ul>
<li>  Indicates method implementation is written in “native” languages such as C</li>
<li>  Provided externally to the Java program, <strong>platform-dependent</strong></li>
<li>  All native &amp; abstract methods have no body</li>
<li>  Used to interface Java code to existing C / C++ libraries</li>
</ul>
<br>

<p><strong>static</strong></p>
<p>A method with <code>static</code> is a <strong>class method</strong> associated with the <strong>class itself</strong>, but not associated with the instance of the class</p>
<br>

<p><strong>strictfp</strong></p>
<ul>
<li>  <code>fp</code>: floating point</li>
<li>  Only perform fp arithmetic using 32 / 64 bit floating-point formats, even this is less accurate</li>
</ul>
<br>

<p><strong>synchronized</strong></p>
<ul>
<li><p>Makes a method thread safe, prevents 2 thread from executing the method at the same time</p>
<blockquote>
<p>  <em>Before a thread invokes a <code>synchronized</code> method, it must obtain a lock on the method’s class, or on relevant instance of the class.</em></p>
</blockquote>
</li>
<li><p>  <code>synchronized</code> modifier is an <strong>implementation detail</strong> (because methods can make themselves thread safe in other ways)</p>
</li>
</ul>
<br>

<div class="note success"><p><strong>Annotations</strong>: intermediary between <u>method modifier</u> &amp; supplementary <u>type information</u>.</p>
</div>



<br>

<h3 id="Class-amp-Objects"><a href="#Class-amp-Objects" class="headerlink" title="Class &amp; Objects"></a><u>Class &amp; Objects</u></h3><p>A <strong>class</strong> is a named <u>collection of fields</u> that hold data values &amp; methods</p>
<ul>
<li><p>  One of the 5 reference types</p>
</li>
<li><p>  流程: define a class, instantiate it, and use the resulting <strong>object</strong></p>
</li>
<li><p><strong>Classes define new data types.</strong></p>
  <div class="note warning"><p>Important to distinguish between <strong>data type</strong> &amp; the <strong>value</strong> data type represents.</p>
</div></li>
<li><p>  <strong>A class is data type</strong>, and class value is called the <strong>object</strong>. Each class defines a type of objects.</p>
</li>
</ul>
<br>

<p><strong>Define a class</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">double</span> x, y;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Constructor, initialize the field</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Point</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.x = x;</span><br><span class="line">        <span class="keyword">this</span>.y = y;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">distance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Math.sqrt(x*x + y*y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<p><strong>Create an object</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// New object p, of the class Point</span></span><br><span class="line">Point p = <span class="keyword">new</span> Point(<span class="number">2.0</span>, -<span class="number">3.5</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>  <strong>Dynamic loading</strong> mechanism:  Java allows programs to load classes &amp; create instances of classes dynamically</li>
<li>  Objects can also be created by <strong>deserializing</strong> them</li>
</ul>
<br>

<p><strong>Object literals</strong></p>
<ul>
<li><p>  <strong>String literal</strong>: strings are objects; the data type to represent text is the <code>String</code> class</p>
</li>
<li><p><strong>Type literal</strong>: a <code>Class</code> class. Instances of <code>Class</code> class represent a Java data type</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Include a Class object literally in the code</span></span><br><span class="line">Class&lt;?&gt; typeIntArray = <span class="keyword">int</span>[].class;</span><br></pre></td></tr></table></figure></li>
<li><p>  <strong>Null reference</strong>: reference to nothing / absence of a reference . <code>Null</code> is a member of <strong>every</strong> reference type.</p>
</li>
</ul>
<br>

<h3 id="Lambda-Expressions"><a href="#Lambda-Expressions" class="headerlink" title="Lambda Expressions"></a><u>Lambda Expressions</u></h3><p>A <strong>lambda expression</strong> is a function that does not have a name.</p>
<ul>
<li><p>  Can be treated as a <strong>value</strong></p>
</li>
<li><p>  Java does not allow code to run on its own outside of class: Lambda is an anonymous method that is defined on some class</p>
</li>
<li><p>Syntax: <code>(paramlist) -&gt; (statements)</code></p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Runnable r = () -&gt; System.out.println(<span class="string">&quot;hello&quot;</span>);</span><br></pre></td></tr></table></figure></li>
<li><p>When lambda is used as a value, it is automatically converted to a new object of the correct type .</p>
  <div class="note info"><p><strong>Auto conversion</strong> &amp; <strong>Type inference</strong> is essential to Java’s lambda expressions.</p>
</div></li>
</ul>
<br>

<h3 id="Arrays"><a href="#Arrays" class="headerlink" title="Arrays"></a><u>Arrays</u></h3><p>Array type are <strong>reference</strong> types, and instances of arrays are <strong>objects</strong>.</p>
<ul>
<li>  Arrays inherit the methods of <code>java.lang.Object</code></li>
<li>  Arrays implement the <code>Cloneable</code> interface, and override the <code>clone()</code> method to ensure arrays can be cloned</li>
<li>  Arrays also implement <code>Serializable</code>, so it can be serialized, if its elements are serialized</li>
<li>  All arrays have a  <code>public final int</code>  field called <code>length</code></li>
</ul>
<br>

<p><strong>Type conversion</strong></p>
<ul>
<li>  Since arrays <strong>extend <code>Object</code></strong> and <strong>implement <code>Clonable</code> &amp; <code>Serializable</code></strong> interfaces, an array type can be widened to any of these 3 types.</li>
<li>  Ability to widen array type (<strong>array covariance</strong>): Array’s compile-time type is not same as runtime type</li>
<li>  Compilers need runtime checks, to ensure <u>runtime value type</u> match <u>runtime array element type</u></li>
</ul>
<br>

<p><strong>Init. Arrays</strong></p>
<ul>
<li><p>  Array types don’t have constructors </p>
</li>
<li><p>  Init. value: 0 / <code>false</code> / <code>null</code></p>
</li>
<li><p>Use anonymous array literals (apply to <u>multi-dimensional array</u> as well):</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String response = Question( <span class="string">&quot;Exit?&quot;</span>, <span class="keyword">new</span> String[] &#123;<span class="string">&quot;Yes&quot;</span>, <span class="string">&quot;No&quot;</span>&#125; );</span><br></pre></td></tr></table></figure></li>
<li><p>As part of variable declaration: (Array literals are created &amp; initialized at runtime)</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] response = &#123;<span class="string">&quot;Yes&quot;</span>, <span class="string">&quot;No&quot;</span>&#125;;</span><br></pre></td></tr></table></figure>

  <div class="note success"><p>Java does all array initialization at runtime: </p>
<p>Expressions in an array initializer may be computed at runtime, and need not be compile-time constants.</p>
</div></li>
</ul>
<br>

<p><strong>Copy Arrays</strong></p>
<ul>
<li><p>  Since all array types implement <code>Cloneable</code>, hence any array can be copied by the <code>clone()</code> method</p>
</li>
<li><p>A <strong>cast</strong> is required to convert return value to the appropriate array type</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"><span class="keyword">int</span>[] b = (<span class="keyword">int</span>[]) a.clone();</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Two ways to copy arrays</strong></p>
<ul>
<li><p><code>clone()</code> : shallow copy</p>
<blockquote>
<p>  <em>If array element type is a reference type, then only the references are copied. Any array can be cloned even if element type is not <code>Clonable</code>.</em></p>
</blockquote>
</li>
<li><p><code>System.arraycopy()</code></p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// arraycopy(source, s[i], destination, d[j], #-of-elements)</span></span><br><span class="line">System.arraycopy(a, <span class="number">1</span>, a, <span class="number">0</span>, n);</span><br><span class="line"><span class="comment">// Shift elements in [1, n] one index down</span></span><br></pre></td></tr></table></figure>

<p>  ​    Works even for overlapping copies within the same array. </p>
</li>
</ul>
</li>
</ul>
<br>

<p><strong>Array Utilities</strong></p>
<ul>
<li>  <code>java.util.Arrays</code> contains a number of static utility methods</li>
<li>  Most of the methods are heavily overloaded, with versions for <u>arrays of primitive types</u> &amp; <u>arrays of objects</u></li>
<li>  <code>sort()</code> &amp; <code>binarySearch()</code> for sort, search arrays</li>
<li>  <code>Arrays.toString()</code>, convert array content to string output</li>
</ul>
<br>

<p><strong>Multi-dimensional Arrays</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[][] a = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>][<span class="number">10</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// The statement above equals to:</span></span><br><span class="line"><span class="keyword">int</span>[][] a = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>][];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; ++i)	<span class="comment">// Loop 10 times</span></span><br><span class="line">    a[i] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br></pre></td></tr></table></figure>

<p><strong>Line 1</strong> does three things:</p>
<ul>
<li>  Declare the variable <code>a</code></li>
<li>  Creates a 10-element array, to hold 10 arrays of <code>int</code></li>
<li>  Creates 10 more arrays with a loop</li>
</ul>
<p>When using the <code>new</code> keyword, only need to specify the <strong>leftmost</strong> dimension of the array.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1-D array</span></span><br><span class="line"><span class="keyword">float</span>[][][] a = <span class="keyword">new</span> <span class="keyword">float</span>[<span class="number">10</span>][][];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2-D array</span></span><br><span class="line"><span class="keyword">float</span>[][][] a = <span class="keyword">new</span> <span class="keyword">float</span>[<span class="number">10</span>][<span class="number">10</span>][];</span><br></pre></td></tr></table></figure>



<br>

<h3 id="Reference-Types"><a href="#Reference-Types" class="headerlink" title="Reference Types"></a><u>Reference Types</u></h3><p><a href="https://www.oreilly.com/library/view/java-8-pocket/9781491901083/ch04.html">Five reference types</a></p>
<ul>
<li>  <strong>Annotation</strong>: Associate metadata with program elements</li>
<li>  <strong>Array</strong></li>
<li>  <strong>Enumeration</strong>: Reference for a set of objects that represents a related set of choices</li>
<li>  <strong>Class</strong>: Provide inheritance, polymorphism, and encapsulation</li>
<li>  <strong>Interface</strong>: Provide  public API and is <strong>implemented</strong> by Java classes</li>
</ul>
<br>

<p><strong>Object</strong>: value / instance of any reference type.</p>
<br>

<p><strong>Reference &amp; Primitive Types</strong></p>
<ul>
<li><p>  User cannot define new primitive types, but reference types are user-defined</p>
</li>
<li><p>  Primitive types represent <strong>single values</strong>; Reference types are <strong>aggregate</strong> types that hold zero / more primitive values or objects</p>
</li>
<li><p>  Primitive types only require <strong>1 - 8 bytes</strong> of memory. For reference types, only the <strong>reference to that memory</strong> is stored</p>
</li>
<li><p>Imagine a <strong>reference</strong> as a <strong>pointer</strong> or a <strong>memory address</strong> (Java cannot manipulate references)</p>
  <div class="note primary"><p>Memory for storing a object is <u>dynamically allocated on the <strong>heap</strong></u>, and it’s auto <u>garbage-collected</u> when the object is no longer needed .</p>
</div></li>
</ul>
<br>

<p><strong>Pass arguments to methods</strong></p>
<ul>
<li>  <strong>Primitive</strong>: The method is given a copy of the argument used to invoke the method</li>
<li>  <strong>Reference</strong>: Method pass a private copy of a reference to the object</li>
</ul>
<br>

<p><strong>Compare Objects</strong></p>
<p>Reference types, 2 kinds of equality:</p>
<ul>
<li>Equality of reference<ul>
<li>  <code>.equals()</code>:  判断内容是否一致</li>
</ul>
</li>
<li>Equality of object<ul>
<li>  <code>==</code>　: Whether 2 references refer to the same object </li>
</ul>
</li>
</ul>
<p>Arrays always inherit the default <code>equals()</code> method the compares references, rather than array content.</p>
<br>

<p><strong>Boxing &amp; Unboxing</strong></p>
<ul>
<li><p>Treat primitive values as objects: <strong>wrapper class</strong> for each of the 8 primitive types (<strong>Immutable, final classes</strong>)</p>
<blockquote>
<p>  <code>Boolean</code>, <code>Byte</code>, <code>Short</code>, <code>Character</code>, <code>Integer</code>, <code>Long</code>, <code>Float</code>, <code>Double</code></p>
</blockquote>
</li>
<li><p>  Use wrapper class when you want to store primitive values in <strong>collections</strong></p>
</li>
<li><p>  <strong>Boxing</strong> convert primitives to wrapper objects, and <strong>Unboxing</strong> converts wrapper class back to primitives</p>
</li>
<li><p><strong>Autoboxing</strong>: Java performs boxing &amp; unboxing automatically</p>
<ul>
<li>  Autoboxing makes dealing with collections much easier.</li>
</ul>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; n = <span class="keyword">new</span> ArrayList&lt;&gt;();   <span class="comment">// Box into integer</span></span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<h3 id="Packages-amp-Namespaces"><a href="#Packages-amp-Namespaces" class="headerlink" title="Packages &amp; Namespaces"></a><u>Packages &amp; Namespaces</u></h3><p>A <strong>package</strong> is a named collection of classes , interfaces &amp; other reference types.</p>
<br>

<p><code>javax</code>: Extension to the Java Platform.</p>
<br>

<p>Each class has a <strong>simple name</strong> &amp; <strong>fully qualified name</strong>.</p>
<p>E.g. class <code>String</code> &amp; <code>java.lang.String</code></p>
<br>

<p>Use <strong>globally unique package name</strong> to partition the Java namespace, and prevent name collisions between classes</p>
<br>

<h4 id="Static-Imports"><a href="#Static-Imports" class="headerlink" title="Static Imports"></a>Static Imports</h4><p>On-demand import does not apply to <strong>subpackages</strong>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// On-demand import </span></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br></pre></td></tr></table></figure>

<br>

<p>Import <strong>static members</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.Math.*;</span><br></pre></td></tr></table></figure>

<p><strong>Important use:</strong> Import the name of constants into your code.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Enumerated type</span></span><br><span class="line"><span class="keyword">package</span> hello;</span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Names</span> </span>&#123;ALICE, BOB, CHARLIE&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// import in another file</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> hello.Names.*;</span><br></pre></td></tr></table></figure>

<div class="note success"><p>Using <u>static member <code>import</code> declarations for constants</u> is generally better than implementing an interface that defines the constants.</p>
</div>

<br>

<p>It is legal to import <strong>static methods with the same name</strong> from more than 2 different types, as long as the <strong>method signatures</strong> are different.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Legal Import</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.util.Arryas.sort;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.util.Collections.sort;</span><br></pre></td></tr></table></figure>



<br>

<h3 id="File-Structure"><a href="#File-Structure" class="headerlink" title="File Structure"></a><u>File Structure</u></h3><div class="note primary"><p>All Java statements must appear within <strong>methods</strong>;</p>
<p>All methods must appear within <strong>type definition</strong>.</p>
</div>



<p>A Java file consists of:</p>
<ul>
<li>  <code>package</code> directive (optional)</li>
<li>  <code>import</code> / <code>import static</code> directives</li>
<li>  Type definitions</li>
</ul>
<br>

<p><strong>Restriction for Java files</strong>:</p>
<ul>
<li>  Each file contain at most one top-level <code>public</code> class</li>
<li>  A public class is designed for use by other classes in other packages</li>
<li>  File name &amp; class name  must be the same</li>
</ul>
<br>

<p>Tell the interpreter to look in locations <strong>other than the current directory</strong>: </p>
<p>Specify <code>java -classpath</code> in Terminal</p>
<br>



<h3 id="Run-Programs"><a href="#Run-Programs" class="headerlink" title="Run Programs"></a><u>Run Programs</u></h3><p>The <code>main()</code> method is the <strong>main entry point</strong> for your program. This method is passed an array of strings, and returns no value.</p>
<p>When <code>main()</code> returns, the Java interpreter exits.</p>
<br>

<br>]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Deploying and Scaling Microservices in Kubernetes</title>
    <url>/2019/Kubernetes-Microservices/</url>
    <content><![CDATA[<p>Kubernetes is an open-source container orchestration tool for managing containerized applications. In this post, we will  build, deploy, and manage an end-to-end microservices application in Kubernetes. The sample web application you’ll use is a “todo list” application written in Node.js that uses MongoDB as a database. </p>
<p>You’ll build a container image for this app from a Dockerfile, push the image to Docker Hub, and then deploy it to your cluster. Then you’ll scale the app to meet increased demand.</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Build-Image-with-Dockerfile"><a href="#Build-Image-with-Dockerfile" class="headerlink" title="Build Image with Dockerfile"></a>Build Image with Dockerfile</h2><p>We will begin by containerizing the web application by packaging it into a Docker image.</p>
<p>Start by changing to your home directory, then use Git to clone this post’s sample web application from its official repository on GitHub.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">~</span></span><br><span class="line"><span class="string">git</span> <span class="string">clone</span> <span class="string">https://github.com/janakiramm/todo-app.git</span></span><br></pre></td></tr></table></figure>
<p>Build the container image from the Dockerfile. Use the -t switch to tag the image with the registry username, image name, and an optional tag.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">build</span> <span class="string">-t</span> <span class="string">merikanto/todo</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>
<p>Verify that the image is created by running the docker images command.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">images</span></span><br></pre></td></tr></table></figure>
<p>Next, push your image to the public registry on Docker Hub. To do this, log in to your Docker Hub account:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">login</span></span><br></pre></td></tr></table></figure>
<p>Once you provide your credentials, tag your image using your Docker Hub username:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">tag</span> <span class="string">merikanto/todo-app</span></span><br></pre></td></tr></table></figure>
<p>Then push your image to Docker Hub:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">push</span></span><br></pre></td></tr></table></figure>
<p>You can verify that the new image is available by searching Docker Hub in your web browser.</p>
<p>With the Docker image pushed to the registry, let’s package the application for Kubernetes.</p>
<br>

<hr>
<h2 id="Deploy-MongoDB-Pod-in-K8S"><a href="#Deploy-MongoDB-Pod-in-K8S" class="headerlink" title="Deploy MongoDB Pod in K8S"></a>Deploy MongoDB Pod in K8S</h2><p>The application uses MongoDB to store to-do lists created through the web application.  To run MongoDB in Kubernetes, we need to package it as a Pod. When we launch this Pod, it will run a single instance of MongoDB.</p>
<p>Create a new YAML file called db-pod.yaml:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">db-pod.yaml</span></span><br></pre></td></tr></table></figure>
<p>Add the following code which defines a Pod with one container based on MongoDB. We expose port 27017, the standard port used by MongoDB. Notice that the definition contains the labels name and app. We’ll use those labels to identify and configure specific Pods.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># db-pod.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">db</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mongo</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">todoapp</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">mongo</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">mongo</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongo</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">27017</span></span><br><span class="line"></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongo-storage</span></span><br><span class="line">            <span class="attr">mountPath:</span> <span class="string">/data/db</span></span><br><span class="line"></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongo-storage</span></span><br><span class="line">            <span class="attr">hostPath:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/data/db</span></span><br></pre></td></tr></table></figure>

<p>The data is stored in the volume called mongo-storage which is mapped to the /data/db location of the node. For more information on Volumes, refer to the official Kubernetes volumes documentation.</p>
<p>Run the following command to create a Pod.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">db-pod.yml</span></span><br></pre></td></tr></table></figure>
<p>You’ll see this output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">pod</span> <span class="string">&quot;db&quot;</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>Now verify the creation of the Pod.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>Let’s make this Pod accessible to the internal consumers of the cluster.</p>
<p>Create a new file called <code>db-service.yaml</code> that contains this code which defines the Service for MongoDB:</p>
<p>The Service discovers all the Pods in the same Namespace that match the Label with name: db. The selector section of the YAML file explicitly defines this association.</p>
<p>We specify that the Service is visible within the cluster through the declaration type: <code>ClusterIP</code>.</p>
<p>Save the file and exit the editor. Then use kubectl to submit it to the cluster.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">db-service.yml</span></span><br></pre></td></tr></table></figure>
<p>You’ll see this output indicating the Service was created successfully:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">service</span> <span class="string">&quot;db&quot;</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>Let’s get the port on which the Pod is available.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">services</span></span><br></pre></td></tr></table></figure>
<p>You’ll see this output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Output</span></span><br><span class="line"><span class="string">NAME</span>         <span class="string">TYPE</span>        <span class="string">CLUSTER-IP</span>       <span class="string">EXTERNAL-IP</span>   <span class="string">PORT(S)</span>     <span class="string">AGE</span></span><br><span class="line"><span class="string">db</span>           <span class="string">ClusterIP</span>   <span class="number">10.109</span><span class="number">.114</span><span class="number">.243</span>   <span class="string">&lt;none&gt;</span>        <span class="number">27017</span><span class="string">/TCP</span>   <span class="string">14s</span></span><br><span class="line"><span class="string">kubernetes</span>   <span class="string">ClusterIP</span>   <span class="number">10.96</span><span class="number">.0</span><span class="number">.1</span>        <span class="string">&lt;none&gt;</span>        <span class="number">443</span><span class="string">/TCP</span>     <span class="string">47m</span></span><br></pre></td></tr></table></figure>
<p>From this output, you can see that the Service is available on port 27017. The web application can reach MongoDB through this service. When it uses the hostname db, the DNS service running within Kubernetes will resolve the address to the ClusterIP associated with the Service. This mechanism allows Pods to discover and communicate with each other.</p>
<p>With the database Pod and Service in place, let’s create a Pod for the web application.</p>
<br>

<hr>
<h2 id="Deploy-Web-App-as-a-Pod"><a href="#Deploy-Web-App-as-a-Pod" class="headerlink" title="Deploy Web App as a Pod"></a>Deploy Web App as a Pod</h2><p>Let’s package the Docker image you created in the first step of this post as a Pod and deploy it to the cluster. This will act as the front-end web application layer accessible to end users.</p>
<p>Create a new YAML file called web-pod.yaml:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">web-pod.yaml</span></span><br></pre></td></tr></table></figure>
<p>Add the following code which defines a Pod with one container based on the merikanto/todo-app Docker image. It is exposed on port 3000 over the TCP protocol.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># web-pod.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">todoapp</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">merikanto/todo-app</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure>
<p>Notice that the definition contains the labels name and app. A Service will use these labels to route inbound traffic to the appropriate ports.</p>
<p>Run the following command to create the Pod:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">web-pod.yaml</span></span><br></pre></td></tr></table></figure>
<p>Let’s verify the creation of the Pod:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>Notice that we have both the MongoDB database and web app running as Pods.</p>
<p>Now we will make the web Pod accessible to the public Internet.</p>
<p>Services expose a set of Pods either internally or externally. Let’s define a Service that makes the web Pod publicly available. We’ll expose it through a NodePort, a scheme that makes the Pod accessible through an arbitrary port opened on each Node of the cluster.</p>
<p>Create a new file called web-service.yaml that contains this code which defines the Service for the app:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">todoapp</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">     <span class="attr">port:</span> <span class="number">3000</span></span><br><span class="line">     <span class="attr">targetPort:</span> <span class="number">3000</span></span><br><span class="line">     <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>
<p>The Service discovers all the Pods in the same Namespace that match the Label with the name web. The selector section of the YAML file explicitly defines this association.</p>
<p>We specify that the Service is of type NodePort through the type: NodePort declaration.</p>
<p>Use kubectl to submit this to the cluster.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">web-service.yml</span></span><br></pre></td></tr></table></figure>
<p>You’ll see this output indicating the Service was created successfully:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">service</span> <span class="string">&quot;web&quot;</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>Let’s get the port on which the Pod is available.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">services</span></span><br></pre></td></tr></table></figure>
<p>From this output, we see that the Service is available on port 30770. Let’s try to connect to one of the Worker Nodes.</p>
<p>Obtain the public IP address for one of the Worker Nodes associated with your Kubernetes Cluster by using the DigitalOcean console.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">DigitalOcean</span> <span class="string">console</span> <span class="string">showing</span> <span class="string">worker</span> <span class="string">nodes</span></span><br></pre></td></tr></table></figure>

<p>Once you’ve obtained the IP address, use the curl command to make an HTTP request to one of the nodes on port 30770:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">curl</span> <span class="string">http://your_worker_ip_address:30770</span></span><br></pre></td></tr></table></figure>
<p>You’ll see output similar to this:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Containers Todo Example<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&#x27;stylesheet&#x27;</span> <span class="attr">href</span>=<span class="string">&#x27;/stylesheets/screen.css&#x27;</span> /&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--[if lt IE 9]&gt;</span></span><br><span class="line"><span class="comment">    &lt;script src=&quot;http://html5shiv.googlecode.com/svn/trunk/html5.js&quot;&gt;&lt;/script&gt;</span></span><br><span class="line"><span class="comment">    &lt;![endif]--&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;layout&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">id</span>=<span class="string">&quot;page-title&quot;</span>&gt;</span>Containers Todo Example<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;list&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;/create&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span> <span class="attr">accept-charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-new&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">&quot;input&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;content&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;layout-footer&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;/javascripts/ga.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>You’ve defined the web Pod and a Service. Now let’s look at scaling it with Replica Sets.</p>
<br>

<hr>
<h2 id="Scale-the-Web-Application"><a href="#Scale-the-Web-Application" class="headerlink" title="Scale the Web Application"></a>Scale the Web Application</h2><p>A Replica Set ensures that a minimum number of Pods are running in the cluster at all times. When a Pod is packaged as a Replica Set, Kubernetes will always run the minimum number of Pods defined in the specification.</p>
<p>Let’s delete the current Pod and recreate two Pods through the Replica Set. If we leave the Pod running it will not be a part of the Replica Set. Thus, it’s a good idea to launch Pods through a Replica Set, even when the count is just one.</p>
<p>First, delete the existing Pod.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">delete</span> <span class="string">pod</span> <span class="string">web</span></span><br></pre></td></tr></table></figure>

<p>Now create a new Replica Set declaration. The definition of the Replica Set is identical to a Pod. The key difference is that it contains the replica element which defines the number of Pods that need to run. Like a Pod, it also contains Labels as metadata that help in Service discovery.</p>
<p>Create the file web-rs.yaml and add this code to the file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">todoapp</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">merikanto/todo-app</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure>
<p>Save and close the file.</p>
<p>Now create the Replica Set:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">web-rs.yaml</span></span><br></pre></td></tr></table></figure>

<p>Then check the number of Pods:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>

<p>When we access the Service through the NodePort, the request will be sent to one of the Pods managed by the Replica Set.</p>
<p>Let’s test the functionality of a Replica Set by deleting one of the Pods and seeing what happens:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">delete</span> <span class="string">pod</span> <span class="string">web-wh6nf</span></span><br></pre></td></tr></table></figure>

<p>Look at the Pods again:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>

<p>As soon as the Pod is deleted, Kubernetes has created another one to ensure the desired count is maintained.</p>
<p>We can scale the Replica Set to run additional web Pods.</p>
<p>Run the following command to scale the web application to 10 Pods.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">scale</span> <span class="string">rs/web</span> <span class="string">--replicas=10</span></span><br></pre></td></tr></table></figure>
<p>Check the Pod count:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>You’ll see this output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Output</span><br><span class="line">NAME        READY     STATUS              RESTARTS   AGE</span><br><span class="line">db          1/1       Running             0          22m</span><br><span class="line">web-4nh4g   1/1       Running             0          21s</span><br><span class="line">web-7vbb5   1/1       Running             0          21s</span><br><span class="line">web-8zd55   1/1       Running             0          21s</span><br><span class="line">web-f8hvq   0/1       ContainerCreating   0          21s</span><br><span class="line">web-ffrt6   1/1       Running             0          21s</span><br><span class="line">web-k6zv7   0/1       ContainerCreating   0          21s</span><br><span class="line">web-n5l5h   1/1       Running             0          3m</span><br><span class="line">web-qmdxn   1/1       Running             0          21s</span><br><span class="line">web-vc45m   1/1       Running             0          21s</span><br><span class="line">web-ws59m   1/1       Running             0          2m</span><br></pre></td></tr></table></figure>

<p>Kubernetes has initiated the process of scaling the web Pod. When the request comes to the Service via the NodePort, it gets routed to one of the Pods in the Replica Set.</p>
<p>When the traffic and load subsides, we can revert to the original configuration of two Pods.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">scale</span> <span class="string">rs/web</span> <span class="string">--replicas=2</span></span><br></pre></td></tr></table></figure>

<p>This command terminates all the Pods except two.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>

<p>To verify the availability of the Replica Set, try deleting one of the Pods and check the count.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl delete pod web-ws59m</span><br><span class="line"></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure>

<p>As soon as the Pod count changes, Kubernetes adjusts it to match the count defined in the YAML file. When one of the web Pods in the Replica Set is deleted, another Pod is immediately created to maintain the desired count. This ensures high availability of the application by ensuring that the minimum number of Pods are running all the time.</p>
<p>You can delete all the objects created during this post with the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">delete</span> <span class="string">-f</span> <span class="string">db-pod.yaml</span> <span class="string">-f</span> <span class="string">db-service.yaml</span> <span class="string">-f</span> <span class="string">web-rs.yaml</span> <span class="string">-f</span> <span class="string">web-service.yaml</span></span><br></pre></td></tr></table></figure>

<br>

<br>


]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 19.10 Config</title>
    <url>/2019/Ubuntu-Config/</url>
    <content><![CDATA[<p>今天大半天全都用来调试 Ubuntu 了。之前因为系统从 18.04 直接升级到 19.10，很多地方不稳定，还有无尽的 dependency issues， 今天索性把所有东西重装一遍。</p>
<p>​    </p>
<span id="more"></span> 






<p>Ubuntu 19.10 的界面虽然作了更新，但系统自带的几款主题仍然巨丑无比。于是把之前一直心水不已的 Kali 主题移植过来，瞬间爱了～ </p>
<p><img data-src="/images/posts/200320-1.png"></p>
<p>图里分别是 Files， Terminal， 和 Gedit。Gedit 自带的皮肤仍然是配色非常迷，因此自己参照版式，写了一个配色方案。近似于 One Dark，但配色更符合个人口味。</p>
<p>Terminal 修改系统配置文件，加了个颜文字，哈哈～  </p>
<br>



<p>剩下的就是各种配置了。之前的系统打包复制了一些东西（<code>dump</code>），但有的还是重新再来一遍 （旧系统的配置已经乱七八糟）。</p>
<p>于是进行了如下配置：</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Objective</th>
<th>Commands /  Notes</th>
</tr>
</thead>
<tbody><tr>
<td><strong>MySQL</strong></td>
<td>解除 sudo</td>
<td><code>mysql -uroot</code></td>
</tr>
<tr>
<td><strong>Docker</strong></td>
<td>解除 sudo</td>
<td><code>docker run hello-world</code></td>
</tr>
<tr>
<td><strong>JDK</strong></td>
<td>版本依赖</td>
<td><code>sudo update-alternatives --config java</code></td>
</tr>
<tr>
<td><strong>Jenkins (8)</strong></td>
<td>Debug</td>
<td>血与泪的教训。。。关于第三方 Plugins 的安装</td>
</tr>
<tr>
<td><strong>Tomcat</strong></td>
<td>Debug</td>
<td>系统路径的配置，Catalina Debug</td>
</tr>
<tr>
<td><strong>Anyconnect</strong></td>
<td>Debug</td>
<td>旧版本无法启动</td>
</tr>
<tr>
<td><strong>Pinyin</strong></td>
<td>Debug</td>
<td>换掉 iBus 自带的拼音，用 Intelligent Pinyin</td>
</tr>
</tbody></table>
<br>



<p>其它就不一一列举了。以后有新的配置，会进行更新。</p>
<br>













]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Intro to InfluxDB</title>
    <url>/2019/InfluxDB/</url>
    <content><![CDATA[<p>The growth of time based data creates the need for time series databases, for which you can of course use a traditional relational database management system (RDBMS) like Oracle, SQL Server or MySQL, but somewhere down the line you will begin to see some limitations regarding time series data. </p>
<p>Possibilities for native time series databases are limited, but <strong>InfluxDB</strong> from InfluxData does just that. It is a big data store, designed to handle the high write and read requests for time series projects.  <strong>InfluxDB is a fairly new product and is a part of InfluxData’s TICK stack</strong>. </p>
<span id="more"></span>  

<p>It is written in the <strong>Go</strong> programming language developed at Google and as mentioned is specifically designed for time series data mainly thanks to the high availability and I/O speeds. Furthermore the installation of the system is quick and practically painless in contrast to other big data storage solutions, yet there is possibility for complex solutions thanks to the built in scalability for distributed systems.</p>
<blockquote>
<p>  Reference:</p>
<p>  <a href="https://www.influxdata.com/modern-time-series-platform/">Official Blog</a></p>
<p>  <a href="https://blog.justinwflory.com/2017/08/influxdb-time-series-database/">Time-series database stack</a></p>
<p>  <a href="https://blog.timescale.com/blog/what-the-heck-is-time-series-data-and-why-do-i-need-a-time-series-database-dcf3b1b18563/">Time-Series Data</a></p>
</blockquote>
<br>

<hr>
<h2 id="Time-Series-Data"><a href="#Time-Series-Data" class="headerlink" title="Time Series Data"></a>Time Series Data</h2><p>As InfluxDB is a time series database it’s important to see what differentiates time series data from other data types. In other words; “What is time series data?”.</p>
<p>In essence, time series data is a collection of datapoints that meet the following requirements:</p>
<ul>
<li>all datapoints are composed out of variable measurements within a certain time interval</li>
<li>the said time interval needs to be continuous, so measurements should be made at all times within this time interval</li>
<li>the time between one measurement and the following should be equal to the previous and the next ones</li>
<li>only one value can be measured for each datapoint for one specific time unit</li>
</ul>
<p>Some examples of time series data can be the closing amounts of the stock markets, the periodically measured temperatures and/or CPU loads of your computer or a measurement of your heart rate during a sport session.</p>
<p>The most used visualisations of time series are line diagrams, as you can see in the example  image, which shows heart rate data.</p>
<img data-src="/images/posts/191125-1.jpeg" style="zoom:80%;" />

<p>Time series are often used in statistics or pattern recognition for example in applied sciences or engineering.</p>
<p>One last important feature of time series data is the fact that there is a natural order in the data based on time, which separates this type of data with cross-sectional analysis where no natural ordening exists.</p>
<br>

<hr>
<h2 id="Time-Series-DB"><a href="#Time-Series-DB" class="headerlink" title="Time Series DB"></a>Time Series DB</h2><p>Now we have insights on what time series data is, we need to see where the time series databases fit in. Of course, the quickest answer on what a time series database exactly is, is; “A database in which you can store and manage time series data”, but what exactly are the benefits of these native time series databases over the relational databases that we came accustomed to? </p>
<p>First of all time series databases are exceptionally good in handling expiring data, what means that obsolete or irrelevant data — from previous time periodes — can easily be filtered and removed.</p>
<p>If removing the data is no option, there is always the possibility of downsampling the data. In this case you can join multiple datapoints for a certain time interval into one datapoint, effectively lowering the granularity of the data set. </p>
<p>The main point of the time series databases is of course the ability to do efficient time related queries on the data and this in a rapid fashion.</p>
<br>

<hr>
<h2 id="InfluxData-TICK-Stack"><a href="#InfluxData-TICK-Stack" class="headerlink" title="InfluxData TICK Stack"></a>InfluxData TICK Stack</h2><p>As mentioned before, InfluxDB is the database store in the platform that InfluxData calls the TICK stack. As with InfluxDB, all other programs are developed in Go programming language and are open source. The name is simply composed out of the initial letters of each program:</p>
<img data-src="/images/posts/191125-2.jpeg" style="zoom:60%;" />

<br>

<h3 id="Telegraf"><a href="#Telegraf" class="headerlink" title="Telegraf"></a><u>Telegraf</u></h3><p>Telegraf is the data collector of the TICK stack and can be used to collect metrics and values on the host system or on external systems via HTTPS API. Telegraf will then write the data to InfluxDB in the correct format.</p>
<img data-src="/images/posts/191125-3.jpeg" style="zoom:80%;" />

<p>In extent of the example given earlier you can easily have Telegraf collect data on CPU usage for all processes on a host computer.</p>
<br>

<h3 id="Chronograf"><a href="#Chronograf" class="headerlink" title="Chronograf"></a><u>Chronograf</u></h3><p>Chronograf is a simple to install and use application for ad-hoc visualisation of your time series data stored on InfluxDB. It boasts possibilities to create templates for easy and quick use and possess pre-configured dashboard for use with most used datasets. Here’s an example of time series data visualisation:</p>
<img data-src="/images/posts/191125-4.jpeg" style="zoom:100%;" />

<br>

<h3 id="Kapacitor"><a href="#Kapacitor" class="headerlink" title="Kapacitor"></a><u>Kapacitor</u></h3><p>Kapacitor is InfluxData’s native data processing engine for InfluxDB, it gives the user the possibility to process the collected time series data, either through batch processing or stream processing. The processing engine enables the user to add own logic to create alerts with dynamic thresholds, compare metrics with patterns or compute statistical anomalies. Kapacitor’s domain specific language called TICKscript:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">stream</span><br><span class="line">    <span class="comment">// Select just the cpu measurement from our example database</span></span><br><span class="line">    .from().measurement(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    .alert()</span><br><span class="line">        .crit(lambda: <span class="string">&quot;usage_idle&quot;</span> &lt; <span class="number">70</span>)</span><br><span class="line">        <span class="comment">// Whenever we get an alert, write it to a file</span></span><br><span class="line">        .log(<span class="string">&#x27;/tmp/alerts.log&#x27;</span>)</span><br></pre></td></tr></table></figure>



<br>

<hr>
<h2 id="Look-Deeper-into-InfluxDB"><a href="#Look-Deeper-into-InfluxDB" class="headerlink" title="Look Deeper into InfluxDB"></a>Look Deeper into InfluxDB</h2><p>As InfluxDB is designed as a native time series database it is mainly focused on quickly storing large amounts of incoming data and providing rapid query results on these datasets. </p>
<p>Focusing on the Create and Read portions of the CRUD acronym and in lesser extent the Update and Delete makes that InfluxDB is not really a CRUD system, more CR(ud) in essence.</p>
<p>The system, however, is ideal for monitoring metrics, IoT (Internet of Things) sensor data and real-time analysis, which data is abundantly available through in day by day tasks, as highlighted in the introduction.</p>
<p>Features of InfluxDB as described by InfluxData are;</p>
<ul>
<li><p>High performance of the system which allows for high write and read speeds along with native data compression</p>
</li>
<li><p>Thanks to the programming in Go, the code has no external dependancies and is compiled in one file</p>
</li>
<li><p>Clustering is built in making use of third party software for distributed computing unnecessary to provide a high level of reliability and availability of the data</p>
</li>
</ul>
<p>In order to achieve the high speeds in both input as retrieval of data, InfluxData recommends the use of SSD’s over conventional mechanical hard disks for the machines that run InfluxDB.</p>
<br>

<hr>
<h2 id="InfluxQL"><a href="#InfluxQL" class="headerlink" title="InfluxQL"></a>InfluxQL</h2><p>For people like me, who worked with relational databases accompanied with SQL, starting to use InfluxDB will be very familiar since the query language of InfluxDB is based on the SQL syntax.  They call it Influx Query Language or InfluxQL in short and will allow SQL users to put their knowledge to work on InfluxDB. Most of the well known syntax like GROUP BY, MERGE, JOIN are present, as are frequently used mathematical functions — as MIN, MAX, MODE, MEDIAN and PERCENTILE — which make it possible to run routine analytical computations on the collected datasets.</p>
<p>As opposed SQL Databases you will notice that there is no pre-defined schema in InfluxDB which makes adding data with deviating formats easy. Notable is that since we are working with time series data, the primary key in InfluxDB will always be time, which is set by the system.</p>
<br>

<hr>
<h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><p>In the following part I will highlight some of the basic concepts of influxDB. Often I will compare the basic concepts to the traditional relational database management systems because this helped me in understanding these concepts through my experience with RDBMS’s. I hope this will help others as well. </p>
<img data-src="/images/posts/191125-6.jpeg" style="zoom:55%;" />

<br>

<h3 id="Timestamp"><a href="#Timestamp" class="headerlink" title="Timestamp"></a><u>Timestamp</u></h3><p>It should be clear by now that InfluxDB is designed for time series data. Therefore it may not come as a surprise that time is literally of the essence. Time is stored in the form of timestamps in, what can be compared to a column, conveniently called time. </p>
<p>The time is stored in the RFC3339 UTC format, which is yyyy-mm-ddThh:mm:ssZ.</p>
<img data-src="/images/posts/191125-7.jpeg" style="zoom:55%;" />

<br>

<h3 id="Fields"><a href="#Fields" class="headerlink" title="Fields"></a><u>Fields</u></h3><blockquote>
<p>  <strong>Field Keys, Field Values and Field Sets</strong></p>
</blockquote>
<p>Next there is the a group called the fields, a first type, called field keys, can be compared with the column names in RDBMS. These are of the type string and contain metadata, the information of what is measured.</p>
<p><strong>Field values</strong> in turn, hold the actual measured values and can be any number of type — string, float, integer or boolean — and since we are covering a time series database, will always associated with time.</p>
<p>It is worth noting that without fields you cannot enter a new line in InfluxDB and that fields are not indexed, which will greatly influence the query speed.</p>
<p>The combination of a field key with a field value is called a field set. For the example data the eighty field sets are:</p>
<img data-src="/images/posts/191125-8.jpeg" style="zoom:55%;" />

<br>

<h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a><u>Tags</u></h3><blockquote>
<p>   <strong>Tag Keys,Tag Values and Tag Sets</strong></p>
</blockquote>
<p>Tags are set up similarly to fields, with the difference that both tag keys and tag values are of the type string and hold metadata. Therefore tags are used to add extra information regarding the measurements. </p>
<p>Though they are optional, it can be very useful to add these to the dataset as — contrary to fields — these tags are indexed which makes them an excellent choice to filter the data on. </p>
<p>As with the fields, the combination of a tag key-value is defined as a tag set. The tag sets for the example data are; </p>
<img data-src="/images/posts/191125-9.jpeg" style="zoom:55%;" />

<br>

<h3 id="Measurement"><a href="#Measurement" class="headerlink" title="Measurement"></a><u>Measurement</u></h3><p>A measurement is used as container to hold the timestamps, fields and tags. It gives the user a way to describe the data in the set. Conceptually, this can be compared to the table name in a relational database system and since the measurement contains a description of sorts, the type for this is string.</p>
<br>

<h3 id="Retention-policy"><a href="#Retention-policy" class="headerlink" title="Retention policy"></a><u>Retention policy</u></h3><p>With retention policy the user defines the period that datapoints are being stored in InfluxDB, which is called DURATION but also the number of versions that should be kept on the cluster, as REPLICATION.</p>
<br>

<h3 id="Series"><a href="#Series" class="headerlink" title="Series"></a><u>Series</u></h3><p>Now we know about tag sets, measurements and retention policies we can talk about series. These are collections of datapoints that have the same;</p>
<ul>
<li>retention policy</li>
<li>measurement</li>
<li>tag set</li>
</ul>
<p>Each series will get an arbitrary series name, here are the four series of the example data;</p>
<img data-src="/images/posts/191125-10.jpeg" style="zoom:55%;" />

<br>

<h3 id="Point"><a href="#Point" class="headerlink" title="Point"></a><u>Point</u></h3><p>The basis of our data sets are the points, this is one or more field sets and/or tag sets in the same series with the same timestamp. In RDBMS terms, this can be compared to a single row of data. For example;</p>
<img data-src="/images/posts/191125-11.jpeg" style="zoom:55%;" />

<br>

<h3 id="Database"><a href="#Database" class="headerlink" title="Database"></a><u>Database</u></h3><p>The database is the main container that holds all information regarding to users, queries and of course the time series data itself. As mentioned earlier, the database in InfluxDB is schemaless, which makes addition of new measurements, with different fields and tags easy.</p>
<br>

<br>


<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Doing CI/CD with Kubernetes</title>
    <url>/2019/Kubernetes-CICD/</url>
    <content><![CDATA[<p>If you are getting started with containers, you will likely want to know how to automate building, testing, and deployment. By taking a Cloud Native approach to these processes, you can leverage the right infrastructure APIs to package and deploy applications in an automated way.</p>
<p>Two building blocks for doing automation include <strong>container images</strong> and <strong>container orchestrators</strong>. </p>
<span id="more"></span> 

<p>Over the last year or so, Kubernetes has become the default choice for container orchestration. In this first article of the CI/CD with Kubernetes series, you will:</p>
<ul>
<li>Build container images with Docker, Buildah, and Kaniko.</li>
<li>Set up a Kubernetes cluster with Terraform, and create Deployments and Services.</li>
<li>Extend the functionality of a Kubernetes cluster with Custom Resources.</li>
</ul>
<p>By the end of this post, you will have container images built with Docker, Buildah, and Kaniko, and a Kubernetes cluster with Deployments, Services, and Custom Resources.</p>
<blockquote>
<p>   Please note: The kubernetes cluster is set on the DigitalOcean platform using kubeadm and Terraform.</p>
</blockquote>
<br>

<hr>
<h2 id="Image-Build-with-Docker-amp-Buildah"><a href="#Image-Build-with-Docker-amp-Buildah" class="headerlink" title="Image Build with Docker &amp; Buildah"></a>Image Build with Docker &amp; Buildah</h2><p>A container image is a self-contained entity with its own application code, runtime, and dependencies that you can use to create and run containers. You can use different tools to create container images, and in this step you will build containers with two of them: Docker and Buildah.</p>
<br>

<h3 id="Build-with-Dockerfiles"><a href="#Build-with-Dockerfiles" class="headerlink" title="Build with Dockerfiles"></a><u>Build with Dockerfiles</u></h3><p>Docker builds your container images automatically by reading instructions from a Dockerfile, a text file that includes the commands required to assemble a container image. Using the docker image build command, you can create an automated build that will execute the command-line instructions provided in the Dockerfile. When building the image, you will also pass the build context with the Dockerfile, which contains the set of files required to create an environment and run an application in the container image.</p>
<p>Typically, you will create a project folder for your Dockerfile and build context. Create a folder called demo to begin:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">demo</span></span><br><span class="line"><span class="string">cd</span> <span class="string">demo</span></span><br></pre></td></tr></table></figure>
<p>Next, create a Dockerfile inside the demo folder:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">Dockerfile</span></span><br></pre></td></tr></table></figure>
<p>Add the following content to the file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/demo/Dockerfile</span></span><br><span class="line"><span class="string">FROM</span> <span class="string">ubuntu:16.04</span></span><br><span class="line"></span><br><span class="line"><span class="string">LABEL</span> <span class="string">MAINTAINER</span> <span class="string">neependra@cloudyuga.guru</span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">apt-get</span> <span class="string">update</span> <span class="string">\</span></span><br><span class="line">    <span class="string">&amp;&amp;</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">-y</span> <span class="string">nginx</span> <span class="string">\</span></span><br><span class="line">    <span class="string">&amp;&amp;</span> <span class="string">apt-get</span> <span class="string">clean</span> <span class="string">\</span></span><br><span class="line">    <span class="string">&amp;&amp;</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/var/lib/apt/lists/*</span> <span class="string">/tmp/*</span> <span class="string">/var/tmp/*</span> <span class="string">\</span></span><br><span class="line">    <span class="string">&amp;&amp;</span> <span class="string">echo</span> <span class="string">&quot;daemon off;&quot;</span> <span class="string">&gt;&gt;</span> <span class="string">/etc/nginx/nginx.conf</span></span><br><span class="line"></span><br><span class="line"><span class="string">EXPOSE</span> <span class="number">80</span></span><br><span class="line"><span class="string">CMD</span> [<span class="string">&quot;nginx&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>This Dockerfile consists of a set of instructions that will build an image to run Nginx. During the build process ubuntu:16.04 will function as the base image, and the nginx package will be installed. Using the CMD instruction, you’ve also configured nginx to be the default command when the container starts.</p>
<p>Next, you’ll build the container image with the docker image build command, using the current directory (.) as the build context. Passing the -t option to this command names the image <code>merikanto/nginx:latest</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">docker</span> <span class="string">image</span> <span class="string">build</span> <span class="string">-t</span> <span class="string">merikanto/nginx:latest</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>
<p>Your image is now built. You can list your Docker images using the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">image</span> <span class="string">ls</span></span><br></pre></td></tr></table></figure>

<p>You can now use the <code>merikanto/nginx:latest</code> image to create containers.</p>
<br>

<h3 id="Build-with-Project-Atomic-Buildah"><a href="#Build-with-Project-Atomic-Buildah" class="headerlink" title="Build with Project Atomic-Buildah"></a><u>Build with Project Atomic-Buildah</u></h3><p>Buildah is a CLI tool, developed by Project Atomic, for quickly building Open Container Initiative (OCI)-compliant images. OCI provides specifications for container runtimes and images in an effort to standardize industry best practices.</p>
<p>Buildah can create an image either from a working container or from a Dockerfile. It can build images completely in user space without the Docker daemon, and can perform image operations like build, list, push, and tag. In this step, you’ll compile Buildah from source and then use it to create a container image.</p>
<p>To install Buildah you will need the required dependencies, including tools that will enable you to manage packages and package security, among other things. Run the following commands to install these packages:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span></span><br><span class="line"></span><br><span class="line">sudo apt-get install software-properties-common</span><br><span class="line"></span><br><span class="line">sudo add-apt-repository ppa:alexlarsson/flatpak</span><br><span class="line"></span><br><span class="line">sudo add-apt-repository ppa:gophers/archive</span><br><span class="line"></span><br><span class="line">sudo apt-add-repository ppa:projectatomic/ppa</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">sudo apt-get install bats btrfs-tools git libapparmor-dev \</span><br><span class="line">libdevmapper-dev libglib2.0-dev libgpgme11-dev libostree-dev \</span><br><span class="line">libseccomp-dev libselinux1-dev skopeo-containers go-md2man</span><br></pre></td></tr></table></figure>
<p>Because you will compile the buildah source code to create its package, you’ll also need to install Go:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo curl -O https://storage.googleapis.com/golang/go1.8.linux-amd64.tar.gz</span><br><span class="line">sudo tar -xvf go1.8.linux-amd64.tar.gz</span><br><span class="line">sudo mv go /usr/<span class="built_in">local</span></span><br><span class="line">sudo <span class="built_in">echo</span> <span class="string">&#x27;export PATH=$PATH:/usr/local/go/bin&#x27;</span> &gt;&gt; ~/.profile</span><br><span class="line"><span class="built_in">source</span> ~/.profile</span><br><span class="line">go version </span><br></pre></td></tr></table></figure>
<p>You will see the following output, indicating a successful installation:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">go version go1.8 linux/amd64</span><br></pre></td></tr></table></figure>
<p>You can now get the buildah source code to create its package, along with the runc binary. runc is the implementation of the OCI container runtime, which you will use to run your Buildah containers.</p>
<p>Run the following commands to install runc and buildah:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mkdir ~/buildah</span><br><span class="line"><span class="built_in">cd</span> ~/buildah</span><br><span class="line"><span class="built_in">export</span> GOPATH=`<span class="built_in">pwd</span>`</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/containers/buildah ./src/github.com/containers/buildah</span><br><span class="line"><span class="built_in">cd</span> ./src/github.com/containers/buildah</span><br><span class="line">make runc all TAGS=<span class="string">&quot;apparmor seccomp&quot;</span></span><br><span class="line">sudo cp ~/buildah/src/github.com/opencontainers/runc/runc /usr/bin/.</span><br><span class="line">sudo apt install buildah </span><br></pre></td></tr></table></figure>
<p>Next, create the /etc/containers/registries.conf file to configure your container registries:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/containers/registries.conf</span></span><br></pre></td></tr></table></figure>
<p>Add the following content to the file to specify your registries:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/containers/registries.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This is a system-wide configuration file used to</span></span><br><span class="line"><span class="comment"># keep track of registries for various container backends.</span></span><br><span class="line"><span class="comment"># It adheres to TOML format and does not support recursive</span></span><br><span class="line"><span class="comment"># lists of registries.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The default location for this configuration file is /etc/containers/registries.conf.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The only valid categories are: &#x27;registries.search&#x27;, &#x27;registries.insecure&#x27;,</span></span><br><span class="line"><span class="comment"># and &#x27;registries.block&#x27;.</span></span><br><span class="line"></span><br><span class="line">[registries.search]</span><br><span class="line">registries = [<span class="string">&#x27;docker.io&#x27;</span>, <span class="string">&#x27;registry.fedoraproject.org&#x27;</span>, <span class="string">&#x27;quay.io&#x27;</span>, <span class="string">&#x27;registry.access.redhat.com&#x27;</span>, <span class="string">&#x27;registry.centos.org&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you need to access insecure registries, add the registry&#x27;s fully-qualified name.</span></span><br><span class="line"><span class="comment"># An insecure registry is one that does not have a valid SSL certificate or only does HTTP.</span></span><br><span class="line">[registries.insecure]</span><br><span class="line">registries = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you need to block pull access from a registry, uncomment the section below</span></span><br><span class="line"><span class="comment"># and add the registries fully-qualified name.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Docker only</span></span><br><span class="line">[registries.block]</span><br><span class="line">registries = []</span><br></pre></td></tr></table></figure>
<p>The registries.conf configuration file specifies which registries should be consulted when completing image names that do not include a registry or domain portion.</p>
<p>Now run the following command to build an image, using the <a href="https://github.com/do-community/rsvpapp-webinar1">https://github.com/do-community/rsvpapp-webinar1</a> repository as the build context. This repository also contains the relevant Dockerfile:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">buildah</span> <span class="string">build-using-dockerfile</span> <span class="string">-t</span> <span class="string">rsvpapp:buildah</span> <span class="string">github.com/do-community/rsvpapp-webinar1</span> </span><br></pre></td></tr></table></figure>
<p>This command creates an image named rsvpapp:buildah from the Dockerfille available in the <a href="https://github.com/do-community/rsvpapp-webinar1">https://github.com/do-community/rsvpapp-webinar1</a> repository.</p>
<p>To list the images, use the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">buildah</span> <span class="string">images</span></span><br></pre></td></tr></table></figure>
<p>One of these images is <code>localhost/rsvpapp:buildah</code>, which you just created. The other, <code>docker.io/teamcloudyuga/python:alpine</code>, is the base image from the Dockerfile.</p>
<p>Once you have built the image, you can push it to Docker Hub. This will allow you to store it for future use. You will first need to login to your Docker Hub account from the command line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">login</span> <span class="string">-u</span> <span class="string">merikanto</span> <span class="string">-p</span> <span class="string">your-dockerhub-password</span></span><br></pre></td></tr></table></figure>
<p>Once the login is successful, you will get a file, ~/.docker/config.json, that will contain your Docker Hub credentials. You can then use that file with buildah to push images to Docker Hub.</p>
<p>For example, if you wanted to push the image you just created, you could run the following command, citing the authfile and the image to push:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">buildah</span> <span class="string">push</span> <span class="string">--authfile</span> <span class="string">~/.docker/config.json</span> <span class="string">\</span></span><br><span class="line"><span class="string">rsvpapp:buildah</span> <span class="string">docker://merikanto/rsvpapp:buildah</span></span><br></pre></td></tr></table></figure>
<p>You can also push the resulting image to the local Docker daemon using the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">buildah</span> <span class="string">push</span> <span class="string">rsvpapp:buildah</span> <span class="string">docker-daemon:rsvpapp:buildah</span></span><br></pre></td></tr></table></figure>
<p>Finally, take a look at the Docker images you have created:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">docker</span> <span class="string">image</span> <span class="string">ls</span></span><br></pre></td></tr></table></figure>
<p>As expected, you should now see a new image, rsvpapp:buildah, that has been exported using buildah.</p>
<p>You now have experience building container images with two different tools, Docker and Buildah. Let’s move on to discussing how to set up a cluster of containers with Kubernetes.</p>
<br>

<hr>
<h2 id="Set-Up-a-K8S-Cluster"><a href="#Set-Up-a-K8S-Cluster" class="headerlink" title="Set Up a K8S Cluster"></a>Set Up a K8S Cluster</h2><blockquote>
<p>  We will set up a K8S cluster on Digital Ocean with kubeadm&amp; Terraform.</p>
</blockquote>
<p>There are different ways to set up Kubernetes on DigitalOcean. To learn more about how to set up Kubernetes with kubeadm, for example, you can look at How To Create a Kubernetes Cluster Using Kubeadm on Ubuntu 18.04.</p>
<p>Since this post discusses taking a Cloud Native approach to application development, we’ll apply this methodology when setting up our cluster. Specifically, we will automate our cluster creation using kubeadm and Terraform, a tool that simplifies creating and changing infrastructure.</p>
<p>Using your personal access token, you will connect to DigitalOcean with Terraform to provision 3 servers. You will run the kubeadm commands inside of these VMs to create a 3-node Kubernetes cluster containing one master node and two workers.</p>
<p>On your Ubuntu server, create a pair of SSH keys, which will allow password-less logins to your VMs:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh-keygen</span> <span class="string">-t</span> <span class="string">rsa</span></span><br></pre></td></tr></table></figure>
<p>You will see the following output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (~/.ssh/id_rsa): </span><br></pre></td></tr></table></figure>
<p>Press ENTER to save the key pair in the ~/.ssh directory in your home directory, or enter another destination.</p>
<p>Next, you will see the following prompt:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">Enter</span> <span class="string">passphrase</span> <span class="string">(empty</span> <span class="string">for</span> <span class="literal">no</span> <span class="string">passphrase):</span> </span><br></pre></td></tr></table></figure>
<p>In this case, press ENTER without a password to enable password-less logins to your nodes. Get your public key by running the following command, which will display it in your terminal:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">~/.ssh/id_rsa.pub</span></span><br></pre></td></tr></table></figure>
<p>Add this key to your DigitalOcean account by following these directions.</p>
<p>Next, install Terraform:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install unzip</span><br><span class="line">wget https://releases.hashicorp.com/terraform/0.11.7/terraform_0.11.7_linux_amd64.zip</span><br><span class="line">unzip terraform_0.11.7_linux_amd64.zip</span><br><span class="line">sudo mv terraform /usr/bin/.</span><br><span class="line">terraform version</span><br></pre></td></tr></table></figure>
<p>You will see output confirming your Terraform installation:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">Terraform v0.11.7</span><br></pre></td></tr></table></figure>
<p>Next, run the following commands to install kubectl, a CLI tool that will communicate with your Kubernetes cluster, and to create a ~/.kube directory in your user’s home directory:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get install apt-transport-https</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">sudo touch /etc/apt/sources.list.d/kubernetes.list </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&quot;</span> | sudo tee -a /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install kubectl</span><br><span class="line">mkdir -p ~/.kube</span><br></pre></td></tr></table></figure>
<p>Creating the ~/.kube directory will enable you to copy the configuration file to this location. You’ll do that once you run the Kubernetes setup script later in this section. By default, the kubectl CLI looks for the configuration file in the ~/.kube directory to access the cluster.</p>
<p>Next, clone the sample project repository for this post, which contains the Terraform scripts for setting up the infrastructure:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">git</span> <span class="string">clone</span> <span class="string">https://github.com/do-community/k8s-cicd-webinars.git</span></span><br></pre></td></tr></table></figure>
<p>Go to the Terrafrom script directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/</span></span><br></pre></td></tr></table></figure>
<p>Get a fingerprint of your SSH public key:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh-keygen</span> <span class="string">-E</span> <span class="string">md5</span> <span class="string">-lf</span> <span class="string">~/.ssh/id_rsa.pub</span> <span class="string">|</span> <span class="string">awk</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>You will see output like the following, with the highlighted portion representing your key:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">MD5:dd:d1:b7:0f:6d:30:c0:be:ed:ae:c7:b9:b8:4a:df:5e</span></span><br></pre></td></tr></table></figure>
<p>Keep in mind that your key will differ from what’s shown here.</p>
<p>Save the fingerprint to an environmental variable so Terraform can use it:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">export</span> <span class="string">FINGERPRINT=dd:d1:b7:0f:6d:30:c0:be:ed:ae:c7:b9:b8:4a:df:5e</span></span><br></pre></td></tr></table></figure>
<p>Next, export your DO personal access token:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">export</span> <span class="string">TOKEN=your-do-access-token</span></span><br></pre></td></tr></table></figure>
<p>Now take a look at the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/ project directory:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ls</span><br><span class="line">Output</span><br><span class="line">cluster.tf  destroy.sh  files outputs.tf  provider.tf  script.sh</span><br></pre></td></tr></table></figure>
<p>This folder contains the necessary scripts and configuration files for deploying your Kubernetes cluster with Terraform.</p>
<p>Execute the script.sh script to trigger the Kubernetes cluster setup:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">./script.sh</span></span><br></pre></td></tr></table></figure>
<p>When the script execution is complete, kubectl will be configured to use the Kubernetes cluster you’ve created.</p>
<p>List the cluster nodes using kubectl get nodes:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">nodes</span></span><br></pre></td></tr></table></figure>
<p>You now have one master and two worker nodes in the Ready state.</p>
<p>With a Kubernetes cluster set up, you can now explore another option for building container images: Kaniko from Google.</p>
<br>

<hr>
<h2 id="Build-Container-Images-with-Kaniko"><a href="#Build-Container-Images-with-Kaniko" class="headerlink" title="Build Container Images with Kaniko"></a>Build Container Images with Kaniko</h2><p>Earlier in this post, you built container images with Dockerfiles and Buildah. But what if you could build container images directly on Kubernetes? There are ways to run the docker image build command inside of Kubernetes, but this isn’t native Kubernetes tooling. You would have to depend on the Docker daemon to build images, and it would need to run on one of the Pods in the cluster.</p>
<p>A tool called Kaniko allows you to build container images with a Dockerfile on an existing Kubernetes cluster. In this step, you will build a container image with a Dockerfile using Kaniko. You will then push this image to Docker Hub.</p>
<p>In order to push your image to Docker Hub, you will need to pass your Docker Hub credentials to Kaniko. In the previous step, you logged into Docker Hub and created a ~/.docker/config.json file with your login credentials. Let’s use this configuration file to create a Kubernetes ConfigMap object to store the credentials inside the Kubernetes cluster. The ConfigMap object is used to store configuration parameters, decoupling them from your application.</p>
<p>To create a ConfigMap called docker-config using the ~/.docker/config.json file, run the following command:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo kubectl create configmap docker-config --from-file=<span class="variable">$HOME</span>/.docker/config.json</span><br></pre></td></tr></table></figure>
<p>Next, you can create a Pod definition file called pod-kaniko.yml in the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/ directory (though it can go anywhere).</p>
<p>First, make sure that you are in the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/ directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/</span></span><br></pre></td></tr></table></figure>
<p>Create the <code>pod-kaniko.yml</code> file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">pod-kaniko.yml</span></span><br></pre></td></tr></table></figure>
<p>Add the following content to the file to specify what will happen when you deploy your Pod. Be sure to replace merikanto in the Pod’s args field with your own Docker Hub username:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/pod-kaniko.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">gcr.io/kaniko-project/executor:latest</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--dockerfile=./Dockerfile&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--context=/tmp/rsvpapp/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--destination=docker.io/merikanto/rsvpapp:kaniko&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--force&quot;</span> ]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker-config</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/root/.docker/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">demo</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/tmp/rsvpapp</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">python</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">demo</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>]</span><br><span class="line">      <span class="attr">args:</span> [<span class="string">&quot;-c&quot;</span>, <span class="string">&quot;git clone https://github.com/do-community/rsvpapp-webinar1.git /tmp/rsvpapp&quot;</span>] </span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">demo</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/tmp/rsvpapp</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker-config</span></span><br><span class="line">      <span class="attr">configMap:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">docker-config</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">demo</span></span><br><span class="line">      <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>This configuration file describes what will happen when your Pod is deployed. First, the Init container will clone the Git repository with the Dockerfile, <a href="https://github.com/do-community/rsvpapp-webinar1.git">https://github.com/do-community/rsvpapp-webinar1.git</a>, into a shared volume called demo. Init containers run before application containers and can be used to run utilties or other tasks that are not desirable to run from your application containers. Your application container, kaniko, will then build the image using the Dockerfile and push the resulting image to Docker Hub, using the credentials you passed to the ConfigMap volume docker-config.</p>
<p>To deploy the kaniko pod, run the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="string">pod-kaniko.yml</span> </span><br></pre></td></tr></table></figure>
<p>You will see the following confirmation:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">pod/kaniko</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>Get the list of pods:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>You will see the following list:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">NAME</span>      <span class="string">READY</span>     <span class="string">STATUS</span>     <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">kaniko</span>    <span class="number">0</span><span class="string">/1</span>       <span class="string">Init:0/1</span>   <span class="number">0</span>          <span class="string">47s</span></span><br></pre></td></tr></table></figure>
<p>Wait a few seconds, and then run kubectl get pods again for a status update:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>You will see the following:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">NAME</span>      <span class="string">READY</span>     <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">kaniko</span>    <span class="number">1</span><span class="string">/1</span>       <span class="string">Running</span>   <span class="number">0</span>          <span class="string">1m</span></span><br></pre></td></tr></table></figure>
<p>Finally, run kubectl get pods once more for a final status update:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>This sequence of output tells you that the Init container ran, cloning the GitHub repository inside of the demo volume. After that, the Kaniko build process ran and eventually finished.</p>
<p>Check the logs of the pod:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">logs</span> <span class="string">kaniko</span></span><br></pre></td></tr></table></figure>
<p>From the logs, you can see that the kaniko container built the image from the Dockerfile and pushed it to your Docker Hub account.</p>
<p>You can now pull the Docker image. Be sure again to replace merikanto with your Docker Hub username:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">pull</span> <span class="string">merikanto/rsvpapp:kaniko</span></span><br></pre></td></tr></table></figure>
<p>You have now successfully built a Kubernetes cluster and created new images from within the cluster. Let’s move on to discussing Deployments and Services.</p>
<br>

<hr>
<h2 id="K8S-Deployments-amp-Services"><a href="#K8S-Deployments-amp-Services" class="headerlink" title="K8S Deployments &amp; Services"></a>K8S Deployments &amp; Services</h2><p>Kubernetes Deployments allow you to run your applications. Deployments specify the desired state for your Pods, ensuring consistency across your rollouts. In this step, you will create an Nginx deployment file called deployment.yml in the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/ directory to create an Nginx Deployment.</p>
<p>First, open the file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">deployment.yml</span></span><br></pre></td></tr></table></figure>
<p>Add the following configuration to the file to define your Nginx Deployment:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terraform/deployment.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>This file defines a Deployment named nginx-deployment that creates three pods, each running an nginx container on port 80.</p>
<p>To deploy the Deployment, run the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="string">deployment.yml</span></span><br></pre></td></tr></table></figure>
<p>You will see a confirmation that the Deployment was created:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">deployment.apps/nginx-deployment</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>List your Deployments:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">deployments</span></span><br></pre></td></tr></table></figure>
<p>You can see that the nginx-deployment Deployment has been created and the desired and current count of the Pods are same: 3.</p>
<p>To list the Pods that the Deployment created, run the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>You can see from this output that the desired number of Pods are running.</p>
<p>To expose an application deployment internally and externally, you will need to create a Kubernetes object called a Service. Each Service specifies a ServiceType, which defines how the service is exposed. In this example, we will use a NodePort ServiceType, which exposes the Service on a static port on each node.</p>
<p>To do this, create a file, service.yml, in the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom/ directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">service.yml</span></span><br></pre></td></tr></table></figure>
<p>Add the following content to define your Service:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom/service.yml</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30111</span></span><br></pre></td></tr></table></figure>
<p>These settings define the Service, nginx-service, and specify that it will target port 80 on your Pod. nodePort defines the port where the application will accept external traffic.</p>
<p>To deploy the Service run the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="string">service.yml</span></span><br></pre></td></tr></table></figure>
<p>You will see a confirmation:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">service/nginx-service</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>List the Services:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">service</span></span><br></pre></td></tr></table></figure>
<p>You will see the following list:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">kubernetes      ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        5h</span><br><span class="line">nginx-service   NodePort    10.100.98.213   &lt;none&gt;        80:30111/TCP   7s</span><br></pre></td></tr></table></figure>
<p>Your Service, nginx-service, is exposed on port 30111 and you can now access it on any of the node’s public IPs. For example, navigating to <a href="http://node_1_ip:30111/">http://node_1_ip:30111</a> or <a href="http://node_2_ip:30111/">http://node_2_ip:30111</a> should take you to Nginx’s standard welcome page.</p>
<p>Once you have tested the Deployment, you can clean up both the Deployment and Service:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl delete deployment nginx-deployment</span><br><span class="line">kubectl delete service nginx-service</span><br></pre></td></tr></table></figure>
<p>These commands will delete the Deployment and Service you have created.</p>
<p>Now that you have worked with Deployments and Services, let’s move on to creating Custom Resources.</p>
<br>

<hr>
<h2 id="Create-Custom-Resources-in-K8S"><a href="#Create-Custom-Resources-in-K8S" class="headerlink" title="Create Custom Resources in K8S"></a>Create Custom Resources in K8S</h2><p>Kubernetes offers limited but production-ready functionalities and features. It is possible to extend Kubernetes’ offerings, however, using its Custom Resources feature. In Kubernetes, a resource is an endpoint in the Kubernetes API that stores a collection of API objects. A Pod resource contains a collection of Pod objects, for instance. With Custom Resources, you can add custom offerings for networking, storage, and more. These additions can be created or removed at any point.</p>
<p>In addition to creating custom objects, you can also employ sub-controllers of the Kubernetes Controller component in the control plane to make sure that the current state of your objects is equal to the desired state. The Kubernetes Controller has sub-controllers for specified objects. For example, ReplicaSet is a sub-controller that makes sure the desired Pod count remains consistent. When you combine a Custom Resource with a Controller, you get a true declarative API that allows you to specify the desired state of your resources.</p>
<p>In this step, you will create a Custom Resource and related objects.</p>
<p>To create a Custom Resource, first make a file called crd.yml in the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom/ directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">crd.yml</span></span><br></pre></td></tr></table></figure>
<p>Add the following Custom Resource Definition (CRD):</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom/crd.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">webinars.digitalocean.com</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">digitalocean.com</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">webinars</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">webinar</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Webinar</span></span><br><span class="line">    <span class="attr">shortNames:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">wb</span></span><br></pre></td></tr></table></figure>
<p>To deploy the CRD defined in crd.yml, run the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">crd.yml</span> </span><br></pre></td></tr></table></figure>
<p>You will see a confirmation that the resource has been created:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/webinars.digitalocean.com created</span><br></pre></td></tr></table></figure>
<p>The crd.yml file has created a new RESTful resource path: /apis/digtialocean.com/v1/namespaces/*/webinars. </p>
<p>You can now refer to your objects using webinars, webinar, Webinar, and wb, as you listed them in the names section of the CustomResourceDefinition. You can check the RESTful resource with the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">proxy</span> <span class="string">&amp;</span> <span class="string">curl</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8001/apis/digitalocean.com</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: If you followed the <a href="/2018/Initial-Server-Setup/">initial server setup post</a>, then you will need to allow traffic to port 8001 in order for this test to work. Enable traffic to this port with the following command:</p>
<p><code>sudo ufw allow 8001</code></p>
</blockquote>
<p>You will see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">HTTP/1.1</span> <span class="number">200</span> <span class="string">OK</span></span><br><span class="line"><span class="attr">Content-Length:</span> <span class="number">238</span></span><br><span class="line"><span class="attr">Content-Type:</span> <span class="string">application/json</span></span><br><span class="line"><span class="attr">Date:</span> <span class="string">Fri,</span> <span class="number">03</span> <span class="string">Aug</span> <span class="number">2018 06:10:12 </span><span class="string">GMT</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;apiVersion&quot;:</span> <span class="string">&quot;v1&quot;</span>, </span><br><span class="line">    <span class="attr">&quot;kind&quot;:</span> <span class="string">&quot;APIGroup&quot;</span>, </span><br><span class="line">    <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;digitalocean.com&quot;</span>, </span><br><span class="line">    <span class="attr">&quot;preferredVersion&quot;:</span> &#123;</span><br><span class="line">        <span class="attr">&quot;groupVersion&quot;:</span> <span class="string">&quot;digitalocean.com/v1&quot;</span>, </span><br><span class="line">        <span class="attr">&quot;version&quot;:</span> <span class="string">&quot;v1&quot;</span></span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="attr">&quot;serverAddressByClientCIDRs&quot;:</span> <span class="literal">null</span>, </span><br><span class="line">    <span class="attr">&quot;versions&quot;:</span> [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;groupVersion&quot;:</span> <span class="string">&quot;digitalocean.com/v1&quot;</span>, </span><br><span class="line">            <span class="attr">&quot;version&quot;:</span> <span class="string">&quot;v1&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Next, create the object for using new Custom Resources by opening a file called webinar.yml:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">webinar.yml</span></span><br></pre></td></tr></table></figure>
<p>Add the following content to create the object:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom/webinar.yml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">&quot;digitalocean.com/v1&quot;</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Webinar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">webinar1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">webinar</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>
<p>Run the following command to push these changes to the cluster:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="string">webinar.yml</span> </span><br></pre></td></tr></table></figure>
<p>You will see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">webinar.digitalocean.com/webinar1</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>
<p>You can now manage your webinar objects using kubectl. For example:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">webinar</span></span><br></pre></td></tr></table></figure>
<p>You now have an object called webinar1. If there had been a Controller, it would have intercepted the object creation and performed any defined operations.</p>
<br>
### <u>Deleting a Custom Resource Definition</u>
To delete all of the objects for your Custom Resource, use the following command:
    
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">delete</span> <span class="string">webinar</span> <span class="string">--all</span></span><br></pre></td></tr></table></figure>
<p>You will see:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">webinar.digitalocean.com</span> <span class="string">&quot;webinar1&quot;</span> <span class="string">deleted</span></span><br></pre></td></tr></table></figure>
<p>Remove the Custom Resource itself:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">delete</span> <span class="string">crd</span> <span class="string">webinars.digitalocean.com</span></span><br></pre></td></tr></table></figure>
<p>You will see a confirmation that it has been deleted:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">customresourcedefinition.apiextensions.k8s.io</span> <span class="string">&quot;webinars.digitalocean.com&quot;</span> <span class="string">deleted</span></span><br></pre></td></tr></table></figure>
<p>After deletion you will not have access to the API endpoint that you tested earlier with the curl command.</p>
<p>This sequence is an introduction to how you can extend Kubernetes functionalities without modifying your Kubernetes code.</p>
<br>
## Delete the K8S Cluster
To destroy the Kubernetes cluster itself, you can use the destroy.sh script from the ~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom folder. Make sure that you are in this directory:

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">~/k8s-cicd-webinars/webinar1/2-kubernetes/1-Terrafrom</span></span><br></pre></td></tr></table></figure>
<p>Run the script:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">./destroy.sh</span></span><br></pre></td></tr></table></figure>
<p>By running this script, you’ll allow Terraform to communicate with the DigitalOcean API and delete the servers in your cluster.</p>
<p><br><br></p>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>腐り姫～euthanasia～</title>
    <url>/Notes/Euthanasia/</url>
    <content><![CDATA[<blockquote>
<p>坏掉了。这个世界，都坏掉了。。。</p>
</blockquote>
<p>今天推荐一款暗黑 Galgame —— 腐り姫。游戏最初发售于 2002 年。《腐姬》是许多颇具影响力的 Galgame的先祖，后来者诸如 TYPE-MOON 社的《Fate/stay night》，以及06年发行的《ひぐらしのなく顷に》（寒蝉鸣泣之时），多多少少都受了《腐姬》的影响。</p>
<span id="more"></span> 




<br>


<br>

]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>SaltStack Terminology and Concepts</title>
    <url>/2019/Saltstack-Intro/</url>
    <content><![CDATA[<p>Salt, or SaltStack, is a <strong>remote execution tool and configuration management system</strong>. The <strong>remote execution capabilities</strong> allow administrators to run commands on various machines in parallel with a flexible targeting system. The <strong>configuration management functionality</strong> establishes a client-server model to quickly, easily, and securely bring infrastructure components in line with a given policy.</p>
<p>Here, we will discuss some of the basic concepts and terminology needed to begin effectively learning to use Salt.</p>
<span id="more"></span> 

<blockquote>
<p>  <strong>Reference:</strong></p>
<p>  <a href="https://www.digitalocean.com/community/tutorial_series/managing-development-environments-with-saltstack">Managing Development Environments with SaltStack</a></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-saltstack-terminology-and-concepts">SaltStack Terminology and Concepts</a></p>
</blockquote>
<br>

<hr>
<h2 id="Salt-Machine-Roles"><a href="#Salt-Machine-Roles" class="headerlink" title="Salt Machine Roles"></a>Salt Machine Roles</h2><p>Salt’s control structure is fairly simple as configuration management systems go. In a typical setup, there are only two distinct classes of machines.</p>
<br>

<h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>The Salt master is the machine that controls the infrastructure and dictates policies for the servers it manages. It operates both as a repository for configuration data and as the control center that initiates remote commands and ensures the state of your other machines. A daemon called salt-master is installed on the master to provide this functionality.</p>
<p>While it is possible to control infrastructure using a masterless configuration, most setups benefit from the advanced features available in the Salt master. In fact, for larger infrastructure management, Salt has the ability to delegate certain components and tasks typically associated with the master to dedicated servers. It can also operate in a tiered master configuration where commands can be relayed through lower master machines.</p>
<br>

<h3 id="Minions"><a href="#Minions" class="headerlink" title="Minions"></a>Minions</h3><p>The servers that Salt manages are called minions. A daemon called salt-minion is installed on each of the managed machines and configured to communicate with the master. The minion is responsible for executing the instructions sent by the master, reporting on the success of jobs, and providing data about the underlying host.</p>
<br>

<hr>
<h2 id="How-Salt-Components-Communicate"><a href="#How-Salt-Components-Communicate" class="headerlink" title="How Salt Components Communicate"></a>How Salt Components Communicate</h2><p>Salt masters and minions, by default, communicate using the <strong>ZeroMQ messaging library</strong>. This provides extremely high performance network communication between parties, allowing Salt to send messages and data at rapid speeds. Because ZeroMQ is a library and not an independent service, this functionality is available in the salt-master and salt-minion daemons natively.</p>
<p>When using ZeroMQ, Salt maintains a public key system for authenticating masters and minions. Upon first boot, a minion generates a key pair and sends its credentials to the master server it is configured to contact. The master can then accept this key after verifying the identity of the minion. The two parties can then communicate quickly and securely using ZeroMQ encrypted with the keys.</p>
<p>If for some reason it is impossible to install the salt-minion daemon on a node, Salt can also issue commands over SSH. This transport option is provided for convenience, but it degrades performance quite considerably and can lead to complications with other Salt commands in some instances. It is highly recommended that you use the salt-minion daemon where possible for performance, security, and simplicity.</p>
<br>

<hr>
<h2 id="Salt-Terminology"><a href="#Salt-Terminology" class="headerlink" title="Salt Terminology"></a>Salt Terminology</h2><p>Before diving into Salt, it is a good idea to familiarize yourself with some of the terminology that will be used. Salt has many powerful features, but it can be difficult to match names with their functionality at first. Let’s take a look at some of the more general terms you are likely to see.</p>
<br>

<h3 id="Remote-Execution-Execution-Modules-and-Functions"><a href="#Remote-Execution-Execution-Modules-and-Functions" class="headerlink" title="Remote Execution: Execution Modules and Functions"></a>Remote Execution: Execution Modules and Functions</h3><p>Salt attempts to provide a distinction between its remote execution and configuration management functions. The remote execution capabilities are provided by execution modules. Execution modules are sets of related functions that perform work on minions.</p>
<p>While Salt includes functions that allow you to run arbitrary shell commands on minions, the idea behind execution modules is to provide a concise mechanism for executing commands without having to “shell out” and provide detailed instructions about how to complete the process. The use of modules allows Salt to abstract the underlying differences between systems. You can get similar information from minions running Linux or BSD, even though the actual mechanisms to gather that data would be different.</p>
<p>Salt comes with a decent selection of builtin execution modules to provide out-of-the-box functionality. Administrators can also write their own modules or include community-written modules to extend the library of commands that can be executed on minion machines.</p>
<br>

<h3 id="Configuration-Management-States-Formulas-and-Templates"><a href="#Configuration-Management-States-Formulas-and-Templates" class="headerlink" title="Configuration Management: States, Formulas, and Templates"></a>Configuration Management: States, Formulas, and Templates</h3><p>The configuration management functionality of Salt can be accessed by creating repositories of configuration files. The files contained within these repositories can be of a few different types.</p>
<br>

<h4 id="States-and-Formulas"><a href="#States-and-Formulas" class="headerlink" title="States and Formulas"></a>States and Formulas</h4><p>The configuration management portion of Salt is primarily implemented using the state system.</p>
<p>The state system uses state modules, which are distinct from the execution modules described above. Fortunately, state and execution modules tend to mirror each other quite closely. The state system is aptly named, as it allows an administrator to describe the state that a system should be placed in. As with execution modules, most state modules represent functionality shortcuts and provide easy syntax for many common actions. This helps maintain readability and removes the necessity of including complex logic in the configuration management files themselves.</p>
<p>Salt formulas are sets of state module calls, arranged with the aim of producing a certain result. These are the configuration management files that describe how a system should look once the formula has been applied. By default, these are written in the YAML data serialization format, which provides a very good middle ground between high-readability and machine-friendliness.</p>
<p>The Salt administrator can apply formulas by mapping minions to specific sets of formulas. Formulas can also be applied in an ad hoc manner as needed. Minions will execute the state modules found within to bring its system in line with the provided policy.</p>
<p>A good collection of Salt formulas created by the SaltStack organization and community can by found in this GitHub account.</p>
<br>

<h4 id="Templates"><a href="#Templates" class="headerlink" title="Templates"></a>Templates</h4><p>Templating allows Salt formulas and other files to be written in a more flexible manner. Templates can use the information available about the minions to construct customized versions of formula or configuration files. By default, Salt uses the Jinja template format, which provides substitution functionality and simple logical constructs for decision making.</p>
<p>Renderers are the components that runs the template to produce valid state or configuration files. Renderers are defined by the templating format that constitutes the input and the data serialization format that will be produced as an output. Considering the defaults described above, the default renderer processes Jinja templates in order to produce YAML files.</p>
<br>

<h4 id="Querying-about-and-Assigning-Information-to-Minions"><a href="#Querying-about-and-Assigning-Information-to-Minions" class="headerlink" title="Querying about and Assigning Information to Minions"></a>Querying about and Assigning Information to Minions</h4><p>In order to manage vast numbers of systems, Salt requires some information about each of the host systems. The templates described above can use data associated with each system to tailor the behavior of each minion. There are a few different systems in place to query about or assign this information to hosts.</p>
<br>

<h4 id="Grains"><a href="#Grains" class="headerlink" title="Grains"></a>Grains</h4><p>Salt grains are pieces of information, gathered by and maintained by a minion, primarily concerning its underlying host system. These are typically collected by the salt-minion daemon and passed back to the master upon request. This functionality can be leveraged for many different purposes.</p>
<p>For instance, grain data can be used for targeting a specific subset of nodes from the pool of minions for remote execution or configuration management. If you want to see the uptime of your Ubuntu servers, grains allow you to target only these machines.</p>
<p>Grains can also be used as arguments for configuration changes or commands. For example, you can use grains to get the IPv4 address associated with the eth0 interface for a change to a configuration file or as an argument to a command.</p>
<p>Administrators can also assign grains to minions. For instance, it is fairly common to use grains to assign a “role” to a server. This can then be used to target a subset of nodes similar to the operating system example above.</p>
<br>

<h4 id="Pillars"><a href="#Pillars" class="headerlink" title="Pillars"></a>Pillars</h4><p>While it is possible to assign grains to minions, the vast majority of configuration variables will be assigned through the pillars system. In Salt, a pillar represents a key-value store that a minion can use to retrieve arbitrary assigned data. This functions as a dictionary data structure which can be nested or tiered for organizational purposes.</p>
<p>Pillars offer a few important advantages over the grain system for assigning values. Most importantly, pillar data is only available to the minions assigned to it. Other minions will not have access to the values stored within. This makes it ideal for storing sensitive data specific to a node or a subset of nodes. For instance, secret keys or database connection strings are often provided in a pillar configuration.</p>
<p>Pillar data is often leveraged in the configuration management context as a way to inject variable data into a configuration template. Salt offers a selection of template formats for replacing the variable portions of a configuration file with the items specific to the node that will be applying it. Grains are also often used in this way for referencing host data.</p>
<br>

<h4 id="Mine"><a href="#Mine" class="headerlink" title="Mine"></a>Mine</h4><p>Salt mine is an area on the master server where the results from regularly executed commands on minions can be stored. The purpose of this system is to collect the results of arbitrary commands run on minion machines. This global store can then be queried by other components and minions throughout your infrastructure.</p>
<p>The Salt mine only stores the most recent result for each command run, meaning that it will not help you if you need access to historic data. The main purpose of the mine is to provide up-to-date information from minion machines as a flexible supplement to the grain data that is already available. Minions can query data about their counterparts using the mine system. The interval in which the minion refreshes the data in the mine can be configured on a per-minion basis.</p>
<br>

<h3 id="Additional-Functionality"><a href="#Additional-Functionality" class="headerlink" title="Additional Functionality"></a>Additional Functionality</h3><p>Salt provides a few other systems that do not fit nicely into the above categories.</p>
<br>

<h4 id="Reactors"><a href="#Reactors" class="headerlink" title="Reactors"></a>Reactors</h4><p>The Salt reactor system provides a mechanism for triggering actions in response to generated events. In Salt, changes occurring throughout your infrastructure will cause the salt-minion or salt-master daemons to generate events on a ZeroMQ message bus. The reactor system watches this bus and compares events against its configured reactors in order to respond appropriately.</p>
<p>The main goal of the reactor system is to provide a flexible system for creating automated situational responses. For instance, if you have developed an auto-scaling strategy, your system will automatically create nodes to dynamically meet your resource demands. Each new node would trigger an event. A reactor could be set up to listen to these events and configure the new node, incorporating it into the existing infrastructure.</p>
<br>

<h4 id="Runners"><a href="#Runners" class="headerlink" title="Runners"></a>Runners</h4><p>Salt runners are modules that execute on the master server instead of minions. Some runners are general purpose utilities used to check the status of various parts of the system or to do maintenance. Some are powerful applications that provide the ability to orchestrate your infrastructure on a broader scale.</p>
<br>

<h4 id="Returners"><a href="#Returners" class="headerlink" title="Returners"></a>Returners</h4><p>Salt returners are used to specify alternative locations where the results of an action run on a minion will be sent. By default, minions return their data to the master. A returner allows the administrator to re-route the return data to a different destination. Typically, this means that the results are returned to the destination specified by the returner and to the process that initiated the minion command.</p>
<p>Most often, returners will pass the results off to a database system or a metrics or logging service. This provides a flexible method for getting arbitrary data into these systems. Returners can also be used to collect Salt-specific data like job caches and event data.</p>
<br>

<hr>
<h2 id="Salt-Commands"><a href="#Salt-Commands" class="headerlink" title="Salt Commands"></a>Salt Commands</h2><p>Salt provides a number of commands to take advantage of the components outlined above. There is some significant crossover in terms of functionality between these tools, but we’ve attempted to highlight their primary functions below.</p>
<ul>
<li><code>salt-master</code>: This is the master daemon process. You can start the master service with this command directly, or more typically, through an init script or service file.</li>
<li><code>salt-minion</code>: Likewise, this is minion daemon process, used to communicate with the master and execute commands. Most users will also start this from init scripts or service files.</li>
<li><code>salt-key</code>: This tool is used to manage minion public keys. This tool is used to view current keys and to make decisions about public keys sent by prospective minions. It can also generate keys to place on minions out-of-band.</li>
<li><code>salt</code>: This command is used to target minions in order to run ad-hoc execution modules. This is the main tool used for remote execution.</li>
<li><code>salt-ssh</code>: This command allows you to use SSH as an alternative to ZeroMQ for the transport mechanism.</li>
<li><code>salt-run</code>: This command is used to run runner modules on the master server.</li>
<li><code>salt-call</code>: This command is used to run execution modules directly on a minion you are logged into. This is often used to debug problematic commands by bypassing the master.</li>
<li><code>salt-cloud</code>: This command is used to control and provision cloud resources from many different providers. New minions can easily be spun up and bootstrapped.</li>
</ul>
<p>There are some other commands as well, like salt-api, salt-cp, and salt-syndic, which aren’t used quite so often.</p>
<br>


<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible - A Reference Guide</title>
    <url>/2019/Ansible-Reference/</url>
    <content><![CDATA[<p>Ansible is a modern configuration management tool that facilitates the task of setting up and maintaining remote servers.</p>
<p><a href="https://www.digitalocean.com/community/tags/ansible?type=tutorials">This cheat sheet-style guide</a> provides a quick reference to commands and practices commonly used when working with Ansible. For an overview of Ansible and how to install and configure it, please check our guide on how to install and configure Ansible on Ubuntu 18.04.</p>
<span id="more"></span> 

<br>

<ul>
<li>This guide is in cheat sheet format with self-contained command-line snippets.</li>
<li>Jump to any section that is relevant to the task you are trying to complete.</li>
<li>When you see highlighted text in this guide’s commands, keep in mind that this text should refer to hosts, usernames and IP addresses from your own inventory.<br></li>
</ul>
<hr>
<h2 id="Ansible-Glossary"><a href="#Ansible-Glossary" class="headerlink" title="Ansible Glossary"></a>Ansible Glossary</h2><p>The following Ansible-specific terms are largely used throughout this guide:</p>
<ul>
<li>Control Machine / Node: a system where Ansible is installed and configured to connect and execute commands on nodes.</li>
<li>Node: a server controlled by Ansible.</li>
<li>Inventory File: a file that contains information about the servers Ansible controls, typically located at /etc/ansible/hosts.</li>
<li>Playbook: a file containing a series of tasks to be executed on a remote server.</li>
<li>Role: a collection of playbooks and other files that are relevant to a goal such as installing a web server.</li>
</ul>
<p>Play: a full Ansible run. A play can have several playbooks and roles, included from a single playbook that acts as entry point.<br>If you’d like to practice the commands used in this guide with a working Ansible playbook, you can use this playbook from our guide on Automating Initial Server Setup with Ansible on Ubuntu 18.04. You’ll need at least one remote server to use as node.</p>
<br>

<hr>
<h2 id="Test-Connectivity-to-Nodes"><a href="#Test-Connectivity-to-Nodes" class="headerlink" title="Test Connectivity to Nodes"></a>Test Connectivity to Nodes</h2><p>To test that Ansible is able to connect and run commands and playbooks on your nodes, you can use the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">ping</span></span><br></pre></td></tr></table></figure>
<p>The ping module will test if you have valid credentials for connecting to the nodes defined in your inventory file, in addition to testing if Ansible is able to run Python scripts on the remote server. A pong reply back means Ansible is ready to run commands and playbooks on that node.</p>
<br>

<hr>
<h2 id="Connect-as-a-Different-User"><a href="#Connect-as-a-Different-User" class="headerlink" title="Connect as a Different User"></a>Connect as a Different User</h2><p>By default, Ansible tries to connect to the nodes as your current system user, using its corresponding SSH keypair. To connect as a different user, append the command with the -u flag and the name of the intended user:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">ping</span> <span class="string">-u</span> <span class="string">merikanto</span></span><br></pre></td></tr></table></figure>
<p>The same is valid for ansible-playbook:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">-u</span> <span class="string">merikanto</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Use-a-Custom-SSH-Key"><a href="#Use-a-Custom-SSH-Key" class="headerlink" title="Use a Custom SSH Key"></a>Use a Custom SSH Key</h2><p>If you’re using a custom SSH key to connect to the remote servers, you can provide it at execution time with the –private-key option:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">ping</span> <span class="string">--private-key=~/.ssh/custom_id</span></span><br></pre></td></tr></table></figure>
<p>This option is also valid for ansible-playbook:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--private-key=~/.ssh/custom_id</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Use-Password-Based-Auth"><a href="#Use-Password-Based-Auth" class="headerlink" title="Use Password-Based Auth"></a>Use Password-Based Auth</h2><p>If you need to use password-based authentication in order to connect to the nodes, you need to append the option –ask-pass to your Ansible command.</p>
<p>This will make Ansible prompt you for the password of the user on the remote server that you’re attempting to connect as:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">ping</span> <span class="string">--ask-pass</span></span><br></pre></td></tr></table></figure>
<p>This option is also valid for ansible-playbook:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--ask-pass</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Provide-the-sudo-Password"><a href="#Provide-the-sudo-Password" class="headerlink" title="Provide the sudo Password"></a>Provide the sudo Password</h2><p>If the remote user needs to provide a password in order to run sudo commands, you can include the option –ask-become-pass to your Ansible command. This will prompt you to provide the remote user sudo password:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">ping</span> <span class="string">--ask-become-pass</span></span><br></pre></td></tr></table></figure>
<p>This option is also valid for ansible-playbook:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--ask-become-pass</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Custom-Inventory-File"><a href="#Custom-Inventory-File" class="headerlink" title="Custom Inventory File"></a>Custom Inventory File</h2><p>The default inventory file is typically located at /etc/ansible/hosts, but you can also use the -i option to point to custom inventory files when running Ansible commands and playbooks. This is useful for setting up per-project inventories that can be included in version control systems such as Git:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">ping</span> <span class="string">-i</span> <span class="string">my_custom_inventory</span></span><br></pre></td></tr></table></figure>
<p>The same option is valid for ansible-playbook:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">-i</span> <span class="string">my_custom_inventory</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Dynamic-Inventory-File"><a href="#Dynamic-Inventory-File" class="headerlink" title="Dynamic Inventory File"></a>Dynamic Inventory File</h2><p>Ansible supports inventory scripts for building dynamic inventory files. This is useful if your inventory fluctuates, with servers being created and destroyed often.</p>
<p>You can find a number of open source inventory scripts on the official Ansible GitHub repository. After downloading the desired script to your Ansible control machine and setting up any required information — such as API credentials — you can use the executable as custom inventory with any Ansible command that supports this option.</p>
<p>The following command uses Ansible’s DigitalOcean inventory script with a ping command to check connectivity to all current active servers:</p>
<pre><code>ansible all -m ping -i digital_ocean.py
</code></pre>
<p>For more details on how to use dynamic inventory files, please refer to the official Ansible documentation.</p>
<br>

<h2 id="Running-ad-hoc-Commands"><a href="#Running-ad-hoc-Commands" class="headerlink" title="Running ad-hoc Commands"></a>Running <code>ad-hoc</code> Commands</h2><p>To execute any command on a node, use the -a option followed by the command you want to run, in quotes.</p>
<p>This will execute uname -a on all the nodes in your inventory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">all</span> <span class="string">-a</span> <span class="string">&quot;uname -a&quot;</span></span><br></pre></td></tr></table></figure>
<p>It is also possible to run Ansible modules with the option -m. The following command would install the package vim on server1 from your inventory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">server1</span> <span class="string">-m</span> <span class="string">apt</span> <span class="string">-a</span> <span class="string">&quot;name=vim&quot;</span></span><br></pre></td></tr></table></figure>
<p>Before making changes to your nodes, you can conduct a dry run to predict how the servers would be affected by your command. This can be done by including the –check option:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">server1</span> <span class="string">-m</span> <span class="string">apt</span> <span class="string">-a</span> <span class="string">&quot;name=vim&quot;</span> <span class="string">--check</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Run-Playbooks"><a href="#Run-Playbooks" class="headerlink" title="Run Playbooks"></a>Run Playbooks</h2><p>To run a playbook and execute all the tasks defined within it, use the ansible-playbook command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span></span><br></pre></td></tr></table></figure>
<p>To overwrite the default hosts option in the playbook and limit execution to a certain group or host, include the option -l in your command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">-l</span> <span class="string">server1</span> <span class="string">myplaybook.yml</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Get-Info-about-a-Play"><a href="#Get-Info-about-a-Play" class="headerlink" title="Get Info about a Play"></a>Get Info about a Play</h2><p>The option –list-tasks is used to list all tasks that would be executed by a play without making any changes to the remote servers:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--list-tasks</span></span><br></pre></td></tr></table></figure>
<p>Similarly, it is possible to list all hosts that would be affected by a play, without running any tasks on the remote servers:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--list-hosts</span></span><br></pre></td></tr></table></figure>
<p>You can use tags to limit the execution of a play. To list all tags available in a play, use the option –list-tags:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--list-tags</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Control-Playbook-Execution"><a href="#Control-Playbook-Execution" class="headerlink" title="Control Playbook Execution"></a>Control Playbook Execution</h2><p>You can use the option –start-at-task to define a new entry point for your playbook. Ansible will then skip anything that comes before the specified task, executing the remaining of the play from that point on. This option requires a valid task name as argument:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--start-at-task=&quot;Set</span> <span class="string">Up</span> <span class="string">Nginx&quot;</span></span><br></pre></td></tr></table></figure>
<p>To only execute tasks associated with specific tags, you can use the option –tags. For instance, if you’d like to only execute tasks tagged as nginx or mysql, you can use:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--tags=mysql,nginx</span></span><br></pre></td></tr></table></figure>
<p>If you want to skip all tasks that are under specific tags, use –skip-tags. The following command would execute myplaybook.yml, skipping all tasks tagged as mysql:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--skip-tags=mysql</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Ansible-Vault-for-Sensitive-Data"><a href="#Ansible-Vault-for-Sensitive-Data" class="headerlink" title="Ansible Vault for Sensitive Data"></a>Ansible Vault for Sensitive Data</h2><p>If your Ansible playbooks deal with sensitive data like passwords, API keys, and credentials, it is important to keep that data safe by using an encryption mechanism. Ansible provides ansible-vault to encrypt files and variables.</p>
<p>Even though it is possible to encrypt any Ansible data file as well as binary files, it is more common to use ansible-vault to encrypt variable files containing sensitive data. After encrypting a file with this tool, you’ll only be able to execute, edit or view its contents by providing the relevant password defined when you first encrypted the file.</p>
<br>

<h3 id="Create-Encrypted-File"><a href="#Create-Encrypted-File" class="headerlink" title="Create Encrypted File"></a><u>Create Encrypted File</u></h3><p>You can create a new encrypted Ansible file with:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">create</span> <span class="string">credentials.yml</span></span><br></pre></td></tr></table></figure>
<p>This command will perform the following actions:</p>
<ul>
<li>First, it will prompt you to enter a new password. You’ll need to provide this password whenever you access the file contents, whether it’s for editing, viewing, or just running playbooks or commands using those values.</li>
<li>Next, it will open your default command-line editor so you can populate the file with the desired contents.</li>
<li>Finally, when you’re done editing, ansible-vault will save the file as encrypted data.</li>
</ul>
<br>

<h3 id="Encrypt-Existing-Ansible-File"><a href="#Encrypt-Existing-Ansible-File" class="headerlink" title="Encrypt Existing Ansible File"></a><u>Encrypt Existing Ansible File</u></h3><p>To encrypt an existing Ansible file, you can use the following syntax:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">encrypt</span> <span class="string">credentials.yml</span></span><br></pre></td></tr></table></figure>
<p>This will prompt you for a password that you’ll need to enter whenever you access the file credentials.yml.</p>
<br>

<h3 id="View-Contents-of-Encrypted-File"><a href="#View-Contents-of-Encrypted-File" class="headerlink" title="View Contents of Encrypted File"></a><u>View Contents of Encrypted File</u></h3><p>If you want to view the contents of a file that was previously encrypted with ansible-vault and you don’t need to change its contents, you can use:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">view</span> <span class="string">credentials.yml</span></span><br></pre></td></tr></table></figure>
<p>This will prompt you to provide the password you selected when you first encrypted the file with ansible-vault.</p>
<br>

<h3 id="Edit-an-Encrypted-File"><a href="#Edit-an-Encrypted-File" class="headerlink" title="Edit an Encrypted File"></a><u>Edit an Encrypted File</u></h3><p>To edit the contents of a file that was previously encrypted with Ansible Vault, run:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">edit</span> <span class="string">credentials.yml</span></span><br></pre></td></tr></table></figure>
<p>This will prompt you to provide the password you chose when first encrypting the file credentials.yml with ansible-vault. After password validation, your default command-line editor will open with the unencrypted contents of the file, allowing you to make your changes. When finished, you can save and close the file as you would normally, and the updated contents will be saved as encrypted data.</p>
<br>

<h3 id="Decrypt-Encrypted-Files"><a href="#Decrypt-Encrypted-Files" class="headerlink" title="Decrypt Encrypted Files"></a><u>Decrypt Encrypted Files</u></h3><p>If you wish to permanently revert a file that was previously encrypted with ansible-vault to its unencrypted version, you can do so with this syntax:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">decrypt</span> <span class="string">credentials.yml</span></span><br></pre></td></tr></table></figure>
<p>This will prompt you to provide the same password used when first encrypting the file credentials.yml with ansible-vault. After password validation, the file contents will be saved to the disk as unencrypted data.</p>
<br>

<h3 id="Use-Multiple-Vault-Passwords"><a href="#Use-Multiple-Vault-Passwords" class="headerlink" title="Use Multiple Vault Passwords"></a><u>Use Multiple Vault Passwords</u></h3><p>Ansible supports multiple vault passwords grouped by different vault IDs. This is useful if you want to have dedicated vault passwords for different environments, such as development, testing, and production environments.</p>
<p>To create a new encrypted file using a custom vault ID, include the –vault-id option along with a label and the location where ansible-vault can find the password for that vault. The label can be any identifier, and the location can either be prompt, meaning that the command should prompt you to enter a password, or a valid path to a password file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">create</span> <span class="string">--vault-id</span> <span class="string">dev@prompt</span> <span class="string">credentials_dev.yml</span></span><br></pre></td></tr></table></figure>
<p>This will create a new vault ID named dev that uses prompt as password source. By combining this method with group variable files, you’ll be able to have separate ansible vaults for each application environment:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">create</span> <span class="string">--vault-id</span> <span class="string">prod@prompt</span> <span class="string">credentials_prod.yml</span></span><br></pre></td></tr></table></figure>
<p>We used dev and prod as vault IDs to demonstrate how you can create separate vaults per environment, but you can create as many vaults as you want, and you can use any identifier of your choice as vault ID.</p>
<p>Now to view, edit, or decrypt these files, you’ll need to provide the same vault ID and password source along with the ansible-vault command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">edit</span> <span class="string">credentials_dev.yml</span> <span class="string">--vault-id</span> <span class="string">dev@prompt</span> </span><br></pre></td></tr></table></figure>

<br>

<h3 id="Use-a-Password-File"><a href="#Use-a-Password-File" class="headerlink" title="Use a Password File"></a><u>Use a Password File</u></h3><p>If you need to automate the process of provisioning servers with Ansible using a third-party tool, you’ll need a way to provide the vault password without being prompted for it. You can do that by using a password file with ansible-vault.</p>
<p>A password file can be a plain text file or an executable script. If the file is an executable script, the output produced by this script will be used as the vault password. Otherwise, the raw contents of the file will be used as vault password.</p>
<p>To use a password file with ansible-vault, you need to provide the path to a password file when running any of the vault commands:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-vault</span> <span class="string">create</span> <span class="string">--vault-id</span> <span class="string">dev@path/to/passfile</span> <span class="string">credentials_dev.yml</span></span><br></pre></td></tr></table></figure>
<p>Ansible doesn’t make a distinction between content that was encrypted using prompt or a password file as password source, as long as the input password is the same. In practical terms, this means it is OK to encrypt a file using prompt and then later use a password file to store the same password used with the prompt method. The opposite is also true: you can encrypt content using a password file and later use the prompt method, providing the same password when prompted by Ansible.</p>
<p>For extended flexibility and security, instead of having your vault password stored in a plain text file, you can use a Python script to obtain the password from other sources. The official Ansible repository contains a few examples of vault scripts that you can use for reference when creating a custom script that suits the particular needs of your project.</p>
<br>

<hr>
<h2 id="Playbook-with-Encrypted-Data-via-Ansible-Vault"><a href="#Playbook-with-Encrypted-Data-via-Ansible-Vault" class="headerlink" title="Playbook with Encrypted Data via Ansible Vault"></a>Playbook with Encrypted Data via Ansible Vault</h2><p>Whenever you run a playbook that uses data previously encrypted via ansible-vault, you’ll need to provide the vault password to your playbook command.</p>
<p>If you used default options and the prompt password source when encrypting the data used in this playbook, you can use the option –ask-vault-pass to make Ansible prompt you for the password:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--ask-vault-pass</span></span><br></pre></td></tr></table></figure>
<p>If you used a password file instead of prompting for the password, you should use the option –vault-password-file instead:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--vault-password-file</span> <span class="string">my_vault_password.py</span></span><br></pre></td></tr></table></figure>
<p>If you’re using data encrypted under a vault ID, you’ll need to provide the same vault ID and password source you used when first encrypting the data:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--vault-id</span> <span class="string">dev@prompt</span></span><br></pre></td></tr></table></figure>
<p>If using a password file with your vault ID, you should provide the label followed by the full path to the password file as password source:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">--vault-id</span> <span class="string">dev@vault_password.py</span></span><br></pre></td></tr></table></figure>
<p>If your play uses multiple vaults, you should provide a –vault-id parameter for each of them, in no particular order:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible-playbook myplaybook.yml --vault-id dev@vault_password.py \</span><br><span class="line">--vault-id <span class="built_in">test</span>@prompt --vault-id ci@prompt</span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Debugging"><a href="#Debugging" class="headerlink" title="Debugging"></a>Debugging</h2><p>If you run into errors while executing Ansible commands and playbooks, it’s a good idea to increase output verbosity in order to get more information about the problem. You can do that by including the -v option to the command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">-v</span></span><br></pre></td></tr></table></figure>
<p>If you need more detail, you can use -vvv and this will increase verbosity of the output. If you’re unable to connect to the remote nodes via Ansible, use -vvvv to get connection debugging information:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">myplaybook.yml</span> <span class="string">-vvvv</span></span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This post covers some of the most common Ansible commands you may use when provisioning servers, such as how to execute remote commands on your nodes and how to run playbooks using a variety of custom settings.</p>
<p>There are other command variations and flags that you may find useful for your Ansible workflow. To get an overview of all available options, you can use the help command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span>  <span class="string">--help</span></span><br></pre></td></tr></table></figure>
<p>If you want a more comprehensive view of Ansible and all its available commands and features, please refer to the official Ansible documentation.</p>
<br>

<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Use Ansible to Install &amp; Set Up Docker</title>
    <url>/2019/Ansible-Docker/</url>
    <content><![CDATA[<p>With the popularization of containerized applications and microservices, server automation now plays an essential role in systems administration. It is also a way to establish standard procedures for new servers and reduce human error.</p>
<p>This post explains how to use Ansible to automate the steps to set up docker. Docker is an application that simplifies the process of managing containers, resource-isolated processes that behave in a similar way to virtual machines, but are more portable, more resource-friendly, and depend more heavily on the host operating system.</p>
<span id="more"></span> 

<p>While you can complete this setup manually, using a configuration management tool like Ansible to automate the process will save you time and establish standard procedures that can be repeated through tens to hundreds of nodes. Ansible offers a simple architecture that doesn’t require special software to be installed on nodes, and it provides a robust set of features and built-in modules which facilitate writing automation scripts.</p>
<br>

<hr>
<h2 id="Condition-Check"><a href="#Condition-Check" class="headerlink" title="Condition Check"></a>Condition Check</h2><p>In order to execute the automated setup provided by the playbook discussed in this guide, you’ll need:</p>
<ul>
<li><p>Ansible installed either on your local machine or on a remote server that you have set up as an Ansible Control Node. You can follow Step 1 of the post How to Install and Configure Ansible on Ubuntu 18.04 to get this set up.</p>
<ul>
<li>If you plan to use a remote server as your Ansible Control Node, it should have a non-root user with sudo privileges and a basic firewall configured prior to installing Ansible. Follow our Initial Server Setup Guide for Ubuntu 18.04 to set this up.</li>
</ul>
</li>
<li><p>Access to one or more Ubuntu 18.04 servers which will be used as your Ansible hosts. Each should have a non-root user with sudo privileges and a basic firewall configured. Follow our guide on Automating Initial Server Setup with Ansible on Ubuntu 18.04 to set this up automatically. Alternatively, you can set this up manually by following our Initial Server Setup Guide for Ubuntu 18.04 on each of your Ansible hosts.</p>
<br></li>
</ul>
<h3 id="Testing-Connectivity-to-Nodes"><a href="#Testing-Connectivity-to-Nodes" class="headerlink" title="Testing Connectivity to Nodes"></a>Testing Connectivity to Nodes</h3><p>To make sure Ansible is able to execute commands on your nodes, run the following command from your Ansible Control Node:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible</span> <span class="string">-m</span> <span class="string">ping</span> <span class="string">all</span></span><br></pre></td></tr></table></figure>
<p>This command will use Ansible’s built-in ping module to run a connectivity test on all nodes from your default inventory file, connecting as the current system user. The ping module will test whether:</p>
<ul>
<li><p>your Ansible hosts are accessible;</p>
</li>
<li><p>your Ansible Control Node has valid SSH credentials;</p>
</li>
<li><p>your hosts are able to run Ansible modules using Python.<br>If you installed and configured Ansible correctly, you will get output similar to this:</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">server1</span> <span class="string">|</span> <span class="string">SUCCESS</span> <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;changed&quot;:</span> <span class="literal">false</span>, </span><br><span class="line">    <span class="attr">&quot;ping&quot;:</span> <span class="string">&quot;pong&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">server2</span> <span class="string">|</span> <span class="string">SUCCESS</span> <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;changed&quot;:</span> <span class="literal">false</span>, </span><br><span class="line">    <span class="attr">&quot;ping&quot;:</span> <span class="string">&quot;pong&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">server3</span> <span class="string">|</span> <span class="string">SUCCESS</span> <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;changed&quot;:</span> <span class="literal">false</span>, </span><br><span class="line">    <span class="attr">&quot;ping&quot;:</span> <span class="string">&quot;pong&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Once you get a pong reply back from a host, it means you’re ready to run Ansible commands and playbooks on that server.</p>
<blockquote>
<p>Note: If you are unable to get a successful response back from your servers, check our Ansible Cheat Sheet Guide for more information on how to run Ansible commands with custom connection options.</p>
</blockquote>
<br>

<hr>
<h2 id="Ansible-Playbook"><a href="#Ansible-Playbook" class="headerlink" title="Ansible Playbook"></a>Ansible Playbook</h2><p>This Ansible playbook provides an alternative to manually running through the procedure outlined in our guide on How To Install and Use Docker on Ubuntu 18.04.</p>
<p>Running this playbook will perform the following actions on your Ansible hosts:</p>
<ul>
<li>Install aptitude, which is preferred by Ansible as an alternative to the apt package manager.</li>
<li>Install the required system packages.</li>
<li>Install the Docker GPG APT key.</li>
<li>Add the official Docker repository to the apt sources.</li>
<li>Install Docker.</li>
<li>Install the Python Docker module via pip.</li>
<li>Pull the default image specified by default_container_image from Docker Hub.</li>
<li>Create the number of containers defined by create_containers field, each using the image defined by default_container_image, and execute the command defined in default_container_command in each new container.</li>
</ul>
<p>Once the playbook has finished running, you will have a number of containers created based on the options you defined within your configuration variables.</p>
<br>

<hr>
<h2 id="Playbook-Guide"><a href="#Playbook-Guide" class="headerlink" title="Playbook Guide"></a>Playbook Guide</h2><p>To get started, we’ll download the contents of the playbook to your Ansible Control Node. For your convenience, the contents of the playbook are also included in the next section of this guide.</p>
<p>Use curl to download this playbook from the command line:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">curl -L https://raw.githubusercontent.com/do-community/ansible-playbooks \</span><br><span class="line">/master/docker/ubuntu1804.yml -o docker_ubuntu.yml</span><br></pre></td></tr></table></figure>
<p>This will download the contents of the playbook to a file named docker_ubuntu.yml in your current working directory. You can examine the contents of the playbook by opening the file with your command-line editor of choice:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">docker_ubuntu.yml</span></span><br></pre></td></tr></table></figure>
<p>Once you’ve opened the playbook file, you should notice a section named vars with variables that require your attention:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker_ubuntu.yml</span></span><br><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="attr">vars:</span></span><br><span class="line">  <span class="attr">create_containers:</span> <span class="number">4</span></span><br><span class="line">  <span class="attr">default_container_name:</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">default_container_image:</span> <span class="string">ubuntu</span></span><br><span class="line">  <span class="attr">default_container_command:</span> <span class="string">sleep</span> <span class="string">1d</span></span><br><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>
<p>Here’s what these variables mean:</p>
<ul>
<li><code>create_containers</code>: The number of containers to create.</li>
<li><code>default_container_name</code>: Default container name.</li>
<li><code>default_container_image</code>: Default Docker image to be used when creating containers.</li>
<li><code>default_container_command</code>: Default command to run on new containers.</li>
</ul>
<p>Once you’re done updating the variables inside docker_ubuntu.yml, save and close the file. If you used vim, do so by pressing CTRL + X, Y, then ENTER.</p>
<p>You’re now ready to run this playbook on one or more servers. Most playbooks are configured to be executed on all servers from your inventory, by default. We can use the -l flag to make sure that only a subset of servers, or a single server, is affected by the playbook. To execute the playbook only on server1, you can use the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">docker_ubuntu.yml</span> <span class="string">-l</span> <span class="string">server1</span></span><br></pre></td></tr></table></figure>
<p>You will get output similar to this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">...</span><br><span class="line">TASK [Add Docker GPG apt Key] ********************************************************************************************************************</span><br><span class="line">changed: [server1]</span><br><span class="line"></span><br><span class="line">TASK [Add Docker Repository] *********************************************************************************************************************</span><br><span class="line">changed: [server1]</span><br><span class="line"></span><br><span class="line">TASK [Update apt and install docker-ce] **********************************************************************************************************</span><br><span class="line">changed: [server1]</span><br><span class="line"></span><br><span class="line">TASK [Install Docker Module <span class="keyword">for</span> Python] **********************************************************************************************************</span><br><span class="line">changed: [server1]</span><br><span class="line"></span><br><span class="line">TASK [Pull default Docker image] *****************************************************************************************************************</span><br><span class="line">changed: [server1]</span><br><span class="line"></span><br><span class="line">TASK [Create default containers] *****************************************************************************************************************</span><br><span class="line">changed: [server1] =&gt; (item=1)</span><br><span class="line">changed: [server1] =&gt; (item=2)</span><br><span class="line">changed: [server1] =&gt; (item=3)</span><br><span class="line">changed: [server1] =&gt; (item=4)</span><br><span class="line"></span><br><span class="line">PLAY RECAP ***************************************************************************************************************************************</span><br><span class="line">server1                  : ok=9    changed=8    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br></pre></td></tr></table></figure>


<blockquote>
<p>Note: For more information on how to run Ansible playbooks, check our Ansible Cheat Sheet Guide.</p>
</blockquote>
<p>When the playbook is finished running, log in via SSH to the server provisioned by Ansible and run docker ps -a to check if the containers were successfully created:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">docker</span> <span class="string">ps</span> <span class="string">-a</span></span><br></pre></td></tr></table></figure>
<p>Now the containers defined in the playbook were created successfully. Since this was the last task in the playbook, it also confirms that the playbook was fully executed on this server.</p>
<br>

<hr>
<h2 id="Playbook-Contents"><a href="#Playbook-Contents" class="headerlink" title="Playbook Contents"></a>Playbook Contents</h2><p>You can find the Docker playbook featured in this post in the ansible-playbooks repository within the DigitalOcean Community GitHub organization. To copy or download the script contents directly, click the Raw button towards the top of the script, or click here to view the raw contents directly.</p>
<p>The full contents are also included here for your convenience:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker_ubuntu.yml</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">vars:</span></span><br><span class="line">    <span class="attr">create_containers:</span> <span class="number">4</span></span><br><span class="line">    <span class="attr">default_container_name:</span> <span class="string">docker</span></span><br><span class="line">    <span class="attr">default_container_image:</span> <span class="string">ubuntu</span></span><br><span class="line">    <span class="attr">default_container_command:</span> <span class="string">sleep</span> <span class="string">1d</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">aptitude</span> <span class="string">using</span> <span class="string">apt</span></span><br><span class="line">      <span class="attr">apt:</span> <span class="string">name=aptitude</span> <span class="string">state=latest</span> <span class="string">update_cache=yes</span> <span class="string">force_apt_get=yes</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">required</span> <span class="string">system</span> <span class="string">packages</span></span><br><span class="line">      <span class="attr">apt:</span> <span class="string">name=&#123;&#123;</span> <span class="string">item</span> <span class="string">&#125;&#125;</span> <span class="string">state=latest</span> <span class="string">update_cache=yes</span></span><br><span class="line">      <span class="attr">loop:</span> [ <span class="string">&#x27;apt-transport-https&#x27;</span>, <span class="string">&#x27;ca-certificates&#x27;</span>, <span class="string">&#x27;curl&#x27;</span>, <span class="string">&#x27;software-properties-common&#x27;</span>, <span class="string">&#x27;python3-pip&#x27;</span>, <span class="string">&#x27;virtualenv&#x27;</span>, <span class="string">&#x27;python3-setuptools&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Add</span> <span class="string">Docker</span> <span class="string">GPG</span> <span class="string">apt</span> <span class="string">Key</span></span><br><span class="line">      <span class="attr">apt_key:</span></span><br><span class="line">        <span class="attr">url:</span> <span class="string">https://download.docker.com/linux/ubuntu/gpg</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Add</span> <span class="string">Docker</span> <span class="string">Repository</span></span><br><span class="line">      <span class="attr">apt_repository:</span></span><br><span class="line">        <span class="attr">repo:</span> <span class="string">deb</span> <span class="string">https://download.docker.com/linux/ubuntu</span> <span class="string">bionic</span> <span class="string">stable</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Update</span> <span class="string">apt</span> <span class="string">and</span> <span class="string">install</span> <span class="string">docker-ce</span></span><br><span class="line">      <span class="attr">apt:</span> <span class="string">update_cache=yes</span> <span class="string">name=docker-ce</span> <span class="string">state=latest</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Docker</span> <span class="string">Module</span> <span class="string">for</span> <span class="string">Python</span></span><br><span class="line">      <span class="attr">pip:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pull image specified by variable default_image from the Docker Hub</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Pull</span> <span class="string">default</span> <span class="string">Docker</span> <span class="string">image</span></span><br><span class="line">      <span class="attr">docker_image:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; default_container_image &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">source:</span> <span class="string">pull</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Creates the number of containers defined by the variable create_containers, using default values</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">default</span> <span class="string">containers</span></span><br><span class="line">      <span class="attr">docker_container:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; default_container_name &#125;&#125;</span><span class="template-variable">&#123;&#123; item &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; default_container_image &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">command:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; default_container_command &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">      <span class="attr">with_sequence:</span> <span class="string">count=&#123;&#123;</span> <span class="string">create_containers</span> <span class="string">&#125;&#125;</span></span><br></pre></td></tr></table></figure>

<p>Feel free to modify this playbook to best suit your individual needs within your own workflow. For example, you could use the docker_image module to push images to Docker Hub or the docker_container module to set up container networks.</p>
<br>

<hr>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Automating your infrastructure setup can not only save you time, but it also helps to ensure that your servers will follow a standard configuration that can be customized to your needs. With the distributed nature of modern applications and the need for consistency between different staging environments, automation like this has become a central component in many teams’ development processes.</p>
<p>In this post, we demonstrated how to use Ansible to automate the process of installing and setting up Docker on a remote server. Because each individual typically has different needs when working with containers, we encourage you to check out the official Ansible documentation for more information and use cases of the <code>docker_container</code> Ansible module.</p>
<br>

<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Use Celery &amp; RabbitMQ to Queue Tasks</title>
    <url>/2019/Celery-RabbitMQ/</url>
    <content><![CDATA[<p>Asynchronous, or non-blocking, processing is a method of separating the execution of certain tasks from the main flow of a program. This provides you with several advantages, including allowing your user-facing code to run without interruption.</p>
<p>Message passing is a method which program components can use to communicate and exchange information. It can be implemented synchronously or asynchronously and can allow discrete processes to communicate without problems. </p>
<span id="more"></span> 

<p>Message passing is often implemented as an alternative to traditional databases for this type of usage because message queues often implement additional features, provide increased performance, and can reside completely in-memory.</p>
<p><strong>Celery</strong> is a task queue that is built on an asynchronous message passing system. It can be used as a bucket where programming tasks can be dumped. The program that passed the task can continue to execute and function responsively, and then later on, it can poll celery to see if the computation is complete and retrieve the data.</p>
<blockquote>
<p>  <em>Celery allows you to string background tasks together, group tasks, and combine functions in interesting ways. While celery is written in Python, its protocol can be implemented in any language. It can even function with other languages through webhooks. This makes it incredibly flexible for moving tasks into the background, regardless of your chosen language.</em></p>
</blockquote>
<p>By implementing a job queue into your program’s environment, you can easily offload tasks and continue to handle interactions from your users. This is a simple way to increase the responsiveness of your applications and not get locked up while performing long-running computations.</p>
<p>In this post, we will install and implement a celery job queue using RabbitMQ as the messaging system.</p>
<br>

<blockquote>
<p>  <strong>Reference:</strong></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-manage-rabbitmq">Configure RabbitMQ</a></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/how-to-use-rabbitmq-and-python-s-puka-to-deliver-messages-to-multiple-consumers">Use RabbitMQ and Python’s Puka to Deliver Messages to Multiple Consumers</a></p>
</blockquote>
<br>

<hr>
<h2 id="Install-the-Components"><a href="#Install-the-Components" class="headerlink" title="Install the Components"></a>Install the Components</h2><h3 id="Install-Celery"><a href="#Install-Celery" class="headerlink" title="Install Celery"></a><u>Install Celery</u></h3><p>Celery is written in Python, and as such, it is easy to install in the same way that we handle regular Python packages.</p>
<p>We will follow the recommended procedures for handling Python packages by creating a virtual environment to install our messaging system. This helps us keep our environment stable and not effect the larger system.</p>
<p>Install the Python virtual environment package from Ubuntu’s default repositories:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">update</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">python-virtualenv</span></span><br></pre></td></tr></table></figure>
<p>We will create a messaging directory where we will implement our system:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">~/messaging</span></span><br><span class="line"><span class="string">cd</span> <span class="string">~/messaging</span></span><br></pre></td></tr></table></figure>
<p>We can now create a virtual environment where we can install celery by using the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">virtualenv</span> <span class="string">--no-site-packages</span> <span class="string">venv</span></span><br></pre></td></tr></table></figure>
<p>With the virtual environment configured, we can activate it by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">source</span> <span class="string">venv/bin/activate</span></span><br></pre></td></tr></table></figure>
<p>Your prompt will change to reflect that you are now operating in the virtual environment we made above. This will ensure that our Python packages are installed locally instead of globally.</p>
<p>If at any time we need to deactivate the environment (not now), you can type:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">deactivate</span></span><br></pre></td></tr></table></figure>
<p>Now that we have activated the environment, we can install celery with pip:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">pip3</span> <span class="string">install</span> <span class="string">celery</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="Install-RabbitMQ"><a href="#Install-RabbitMQ" class="headerlink" title="Install RabbitMQ"></a><u>Install RabbitMQ</u></h3><p>Celery requires a messaging agent in order to handle requests from an external source. This agent is referred to as a “broker”.</p>
<p>There are quite a few options for brokers available to choose from, including relational databases, NoSQL databases, key-value stores, and actual messaging systems.</p>
<p>We will be configuring celery to use the RabbitMQ messaging system, as it provides robust, stable performance and interacts well with celery. It is a great solution because it includes features that mesh well with our intended use.</p>
<p>We can install RabbitMQ through Ubuntu’s repositories:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">rabbitmq-server</span></span><br></pre></td></tr></table></figure>
<p>The RabbitMQ service is started automatically on our server upon installation.</p>
<br>

<h2 id="Create-a-Celery-Instance"><a href="#Create-a-Celery-Instance" class="headerlink" title="Create a Celery Instance"></a>Create a Celery Instance</h2><hr>
<p>In order to use celery’s task queuing capabilities, our first step after installation must be to create a celery instance. This is a simple process of importing the package, creating an “app”, and then setting up the tasks that celery will be able to execute in the background.</p>
<p>Let’s create a Python script inside our messaging directory called tasks.py where we can define tasks that our workers can perform.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">~/messaging/tasks.py</span></span><br></pre></td></tr></table></figure>
<p>The first thing we should do is import the Celery function from the celery package:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br></pre></td></tr></table></figure>
<p>After that, we can create a celery application instance that connects to the default RabbitMQ service:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br><span class="line"></span><br><span class="line">app = Celery(<span class="string">&#x27;tasks&#x27;</span>, backend=<span class="string">&#x27;amqp&#x27;</span>, broker=<span class="string">&#x27;amqp://&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>The first argument to the Celery function is the name that will be prepended to tasks to identify them.</p>
<p>The backend parameter is an optional parameter that is necessary if you wish to query the status of a background task, or retrieve its results.</p>
<p>If your tasks are simply functions that do some work and then quit, without returning a useful value to use in your program, you can leave this parameter out. If only some of your tasks require this functionality, enable it here and we can disable it on a case-by-case basis further on.</p>
<p>The broker parameter specifies the URL needed to connect to our broker. In our case, this is the RabbitMQ service that is running on our server. RabbitMQ operates using a protocol called “amqp”. If RabbitMQ is operating under its default configuration, celery can connect with no other information other than the amqp:// scheme.</p>
<br>

<h3 id="Build-Celery-Tasks"><a href="#Build-Celery-Tasks" class="headerlink" title="Build Celery Tasks"></a><u>Build Celery Tasks</u></h3><p>Still in this file, we now need to add our tasks.</p>
<p>Each celery task must be introduced with the decorator @app.task. This allows celery to identify functions that it can add its queuing functions to. After each decorator, we simply create a function that our workers can run.</p>
<p>Our first task will be a simple function that prints out a string to console.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br><span class="line"></span><br><span class="line">app = Celery(<span class="string">&#x27;tasks&#x27;</span>, backend=<span class="string">&#x27;amqp&#x27;</span>, broker=<span class="string">&#x27;amqp://&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.task</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_hello</span>():</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;hello there&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Because this function does not return any useful information (it instead prints it to the console), we can tell celery to not use the backend to store state information about this task. This is less complicated under the hood and requires fewer resources.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br><span class="line"></span><br><span class="line">app = Celery(<span class="string">&#x27;tasks&#x27;</span>, backend=<span class="string">&#x27;amqp&#x27;</span>, broker=<span class="string">&#x27;amqp://&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.task(<span class="params">ignore_result=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_hello</span>():</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;hello there&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Next, we will add another function that will generate prime numbers (taken from RosettaCode). This can be a long-running process, so it is a good example for how we can deal with asynchronous worker processes when we are waiting for a result.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br><span class="line"></span><br><span class="line">app = Celery(<span class="string">&#x27;tasks&#x27;</span>, backend=<span class="string">&#x27;amqp&#x27;</span>, broker=<span class="string">&#x27;amqp://&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.task(<span class="params">ignore_result=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_hello</span>():</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;hello there&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.task</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_prime</span>(<span class="params">x</span>):</span></span><br><span class="line">    multiples = []</span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">2</span>, x+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> multiples:</span><br><span class="line">            results.append(i)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(i*i, x+<span class="number">1</span>, i):</span><br><span class="line">                multiples.append(j)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<p>Because we care about what the return value of this function is, and because we want to know when it has completed (so that we may use the results, etc), we do not add the ignore_result parameter to this second task.</p>
<p>Save and close the file.</p>
<br>

<hr>
<h2 id="Start-Celery-Worker-Processes"><a href="#Start-Celery-Worker-Processes" class="headerlink" title="Start Celery Worker Processes"></a>Start Celery Worker Processes</h2><p>We can now start a worker processes that will be able to accept connections from applications. It will use the file we just created to learn about the tasks it can perform.</p>
<p>Starting a worker instance is as easy as calling out the application name with the celery command. We will include a “&amp;” character at the end of our string to put our worker process in the background:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">celery</span> <span class="string">worker</span> <span class="string">-A</span> <span class="string">tasks</span> <span class="string">&amp;</span></span><br></pre></td></tr></table></figure>
<p>This will start up an application, and then detach it from the terminal, allowing you to continue to use it for other tasks.</p>
<p>If you want to start multiple workers, you can do so by naming each one with the -n argument:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">celery</span> <span class="string">worker</span> <span class="string">-A</span> <span class="string">tasks</span> <span class="string">-n</span> <span class="string">one.%h</span> <span class="string">&amp;</span></span><br><span class="line"><span class="string">celery</span> <span class="string">worker</span> <span class="string">-A</span> <span class="string">tasks</span> <span class="string">-n</span> <span class="string">two.%h</span> <span class="string">&amp;</span></span><br></pre></td></tr></table></figure>
<p>The %h will be replaced by the hostname when the worker is named.</p>
<p>To stop workers, you can use the kill command. We can query for the process id and then eliminate the workers based on this information.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ps auxww | grep <span class="string">&#x27;celery worker&#x27;</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class="built_in">kill</span></span><br></pre></td></tr></table></figure>
<p>This will allow the worker to complete its current task before exiting.</p>
<p>If you wish to shut down all workers without waiting for them to complete their tasks, you can execute:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ps auxww | grep <span class="string">&#x27;celery worker&#x27;</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class="built_in">kill</span> -9</span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Use-Queue-to-Handle-Work"><a href="#Use-Queue-to-Handle-Work" class="headerlink" title="Use Queue to Handle Work"></a>Use Queue to Handle Work</h2><p>We can use the worker process(es) we spawned to complete work in the background for our programs.</p>
<p>Instead of creating an entire program to demonstrate how this works, we will explore the different options in a Python interpreter:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">python3</span></span><br></pre></td></tr></table></figure>
<p>At the prompt, we can import our functions into the environment:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tasks <span class="keyword">import</span> print_hello</span><br><span class="line"><span class="keyword">from</span> tasks <span class="keyword">import</span> gen_prime</span><br></pre></td></tr></table></figure>
<p>If you test these functions, they appear to not have any special functionality. The first function prints a line as expected:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print_hello()</span><br><span class="line"></span><br><span class="line">hello there</span><br></pre></td></tr></table></figure>
<p>The second function returns a list of prime numbers:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">primes = gen_prime(<span class="number">1000</span>)</span><br><span class="line"><span class="built_in">print</span>(primes)</span><br></pre></td></tr></table></figure>
<p>If we give the second function a larger range of numbers to check, the execution hangs while it calculates:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">primes = gen_prime(<span class="number">50000</span>)</span><br></pre></td></tr></table></figure>
<p>Stop the execution by typing “CTRL-C”. This process is clearly not computing in the background.</p>
<p>To access the background worker, we need to use the .delay method. Celery wraps our functions with additional capabilities. This method is used to pass the function to a worker to execute. It should return immediately:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">primes = gen_prime.delay(<span class="number">50000</span>)</span><br></pre></td></tr></table></figure>
<p>This task is now being executed by the workers we started earlier. Because we configured a backend parameter for our application, we can check the status of the computation and get access to the result.</p>
<p>To check whether the task is complete, we can use the .ready method:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">primes.ready()</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>A value of “False” means that the task is still running and a result is not available yet. When we get a value of “True”, we can do something with the answer.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">primes.ready()</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>We can get the value by using the .get method.</p>
<p>If we have already verified that the value is computed with the .ready method, then we can use that method like this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> primes.get()</span><br><span class="line"></span><br><span class="line">[<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">23</span>, <span class="number">29</span>, <span class="number">31</span>, <span class="number">37</span>, <span class="number">41</span>, <span class="number">43</span>, <span class="number">47</span>, <span class="number">53</span>, </span><br><span class="line"> <span class="number">59</span>, <span class="number">61</span>, <span class="number">67</span>, <span class="number">71</span>, <span class="number">73</span>, <span class="number">79</span>, <span class="number">83</span>, <span class="number">89</span>, <span class="number">97</span>, <span class="number">101</span>, <span class="number">103</span>, <span class="number">107</span>, <span class="number">109</span>, <span class="number">113</span>, </span><br><span class="line"> <span class="number">127</span>, <span class="number">131</span>, <span class="number">137</span>, <span class="number">139</span>, <span class="number">149</span>, <span class="number">151</span>, <span class="number">157</span>, <span class="number">163</span>, <span class="number">167</span>, <span class="number">173</span>, <span class="number">179</span>, <span class="number">181</span>, </span><br><span class="line"> <span class="number">191</span>, <span class="number">193</span>, <span class="number">197</span>, <span class="number">199</span>, <span class="number">211</span>, <span class="number">223</span>, <span class="number">227</span>, <span class="number">229</span>, <span class="number">233</span>, <span class="number">239</span>, <span class="number">241</span>, <span class="number">251</span>, </span><br><span class="line"> <span class="number">257</span>, <span class="number">263</span>, <span class="number">269</span>, <span class="number">271</span>, <span class="number">277</span>, <span class="number">281</span>, <span class="number">283</span>, <span class="number">293</span>, <span class="number">307</span>, <span class="number">311</span>, <span class="number">313</span>, <span class="number">317</span>, </span><br><span class="line"> <span class="number">331</span>, <span class="number">337</span>, <span class="number">347</span>, <span class="number">349</span>, <span class="number">353</span>, <span class="number">359</span>, <span class="number">367</span>, <span class="number">373</span>, <span class="number">379</span>, <span class="number">383</span>, <span class="number">389</span>, <span class="number">397</span>, </span><br><span class="line"> <span class="number">401</span>, <span class="number">409</span>, <span class="number">419</span>, <span class="number">421</span>, <span class="number">431</span>, <span class="number">433</span>, <span class="number">439</span>, <span class="number">443</span>, <span class="number">449</span>, <span class="number">457</span>, <span class="number">461</span>, <span class="number">463</span>, </span><br><span class="line"> <span class="number">467</span>, <span class="number">479</span>, <span class="number">487</span>, <span class="number">491</span>, <span class="number">499</span>, <span class="number">503</span>, <span class="number">509</span>, <span class="number">521</span>, <span class="number">523</span>, ...</span><br></pre></td></tr></table></figure>

<p>If, however, you have not used the .ready method prior to calling .get, you most likely want to add a “timeout” option so that your program isn’t forced to wait for the result, which would defeat the purpose of our implementation:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> primes.get(timeout=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>This will raise an exception if it times out, which you can handle in your program.</p>
<br>

<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Migrate a Docker Compose Workflow to Kubernetes</title>
    <url>/2019/Kubernetes-Docker-Compose/</url>
    <content><![CDATA[<p>When building modern, stateless applications, containerizing your application’s components is the first step in deploying and scaling on distributed platforms. If you have used Docker Compose in development, you will have modernized and containerized your application by:</p>
<ul>
<li>Extracting necessary configuration information from your code.</li>
<li>Offloading your application’s state.</li>
<li>Packaging your application for repeated use.</li>
</ul>
<span id="more"></span> 

<p>You will also have written service definitions that specify how your container images should run.</p>
<p>To run your services on a distributed platform like Kubernetes, you will need to translate your Compose service definitions to Kubernetes objects. This will allow you to scale your application with resiliency. One tool that can speed up the translation process to Kubernetes is kompose, a conversion tool that helps developers move Compose workflows to container orchestrators like Kubernetes or OpenShift.</p>
<p>In this post, we will translate Compose services to Kubernetes objects using <code>kompose</code>. You will use the object definitions that kompose provides as a starting point and make adjustments to ensure that your setup will use Secrets, Services, and PersistentVolumeClaims in the way that Kubernetes expects. By the end of the post, you will have a single-instance Node.js application with a MongoDB database running on a Kubernetes cluster. This setup will mirror the functionality of the code described in Containerizing a Node.js Application with Docker Compose and will be a good starting point to build out a production-ready solution that will scale with your needs.</p>
<br>

<p>The files we will create are a good starting point to build from as you move toward production. As you develop your application, you can work on implementing the following:</p>
<ul>
<li><p>Centralized logging and monitoring. </p>
</li>
<li><p>Ingress Resources to route traffic to your cluster. This is a good alternative to a LoadBalancer in cases where you are running multiple Services, which each require their own LoadBalancer, or where you would like to implement application-level routing strategies (A/B &amp; canary tests, for example). </p>
</li>
<li><p>Backup strategies for your Kubernetes objects. </p>
</li>
</ul>
<br>

<hr>
<h2 id="Install-kompose"><a href="#Install-kompose" class="headerlink" title="Install kompose"></a>Install kompose</h2><p>To begin using kompose, navigate to the project’s GitHub Releases page, and copy the link to the current release (version 1.18.0 as of this writing). Paste this link into the following curl command to download the latest version of kompose:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">curl -L https://github.com/kubernetes/kompose/releases/download \</span><br><span class="line">/v1.18.0/kompose-linux-amd64 -o kompose</span><br></pre></td></tr></table></figure>
<p>For details about installing on non-Linux systems, please refer to the installation instructions.</p>
<p>Make the binary executable:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">chmod</span> <span class="string">+x</span> <span class="string">kompose</span></span><br></pre></td></tr></table></figure>
<p>Move it to your PATH:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">mv</span> <span class="string">./kompose</span> <span class="string">/usr/local/bin/kompose</span></span><br></pre></td></tr></table></figure>
<p>To verify that it has been installed properly, you can do a version check:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kompose</span> <span class="string">version</span></span><br></pre></td></tr></table></figure>
<p>If the installation was successful, you will see output like the following:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">1.18</span><span class="number">.0</span> <span class="string">(06a2e56)</span></span><br></pre></td></tr></table></figure>
<p>With kompose installed and ready to use, you can now clone the Node.js project code that you will be translating to Kubernetes.</p>
<br>

<hr>
<h2 id="Clone-amp-Package-the-Application"><a href="#Clone-amp-Package-the-Application" class="headerlink" title="Clone &amp; Package the Application"></a>Clone &amp; Package the Application</h2><p>To use our application with Kubernetes, we will need to clone the project code and package the application so that the kubelet service can pull the image.</p>
<p>Our first step will be to clone the <code>node-mongo-docker-de</code>v repository from GitHub. This repository includes the code from the setup described in Containerizing a Node.js Application for Development With Docker Compose, which uses a demo Node.js application to demonstrate how to set up a development environment using Docker Compose. You can find more information about the application itself in the series From Containers to Kubernetes with Node.js.</p>
<p>Clone the repository into a directory called node_project:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">git</span> <span class="string">clone</span> <span class="string">https://github.com/do-community/node-mongo-docker-dev.git</span> <span class="string">node_project</span></span><br></pre></td></tr></table></figure>
<p>Navigate to the node_project directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">node_project</span></span><br></pre></td></tr></table></figure>
<p>The node_project directory contains files and directories for a shark information application that works with user input. It has been modernized to work with containers: sensitive and specific configuration information has been removed from the application code and refactored to be injected at runtime, and the application’s state has been offloaded to a MongoDB database.</p>
<p>For more information about designing modern, stateless applications, please see Architecting Applications for Kubernetes and Modernizing Applications for Kubernetes.</p>
<p>The project directory includes a Dockerfile with instructions for building the application image. Let’s build the image now so that you can push it to your Docker Hub account and use it in your Kubernetes setup.</p>
<p>Using the docker build command, build the image with the -t flag, which allows you to tag it with a memorable name. In this case, tag the image with your Docker Hub username and name it node-kubernetes or a name of your own choosing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">build</span> <span class="string">-t</span> <span class="string">merikanto/node-kubernetes</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>
<p>The . in the command specifies that the build context is the current directory.</p>
<p>It will take a minute or two to build the image. Once it is complete, check your images:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">images</span></span><br></pre></td></tr></table></figure>
<p>Next, log in to the Docker Hub account you created in the prerequisites:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">login</span> <span class="string">-u</span> <span class="string">merikanto</span> </span><br></pre></td></tr></table></figure>
<p>When prompted, enter your Docker Hub account password. Logging in this way will create a <code>~/.docker/config.json</code> file in your user’s home directory with your Docker Hub credentials.</p>
<p>Push the application image to Docker Hub with the docker push command. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">push</span> <span class="string">merikanto/node-kubernetes</span></span><br></pre></td></tr></table></figure>
<p>You now have an application image that you can pull to run your application with Kubernetes. The next step will be to translate your application service definitions to Kubernetes objects.</p>
<br>

<h2 id="Translate-Compose-Services-to-K8S-Objects-with-kompose"><a href="#Translate-Compose-Services-to-K8S-Objects-with-kompose" class="headerlink" title="Translate Compose Services to K8S Objects with kompose"></a>Translate Compose Services to K8S Objects with kompose</h2><p>Our Docker Compose file, here called <code>docker-compose.yaml</code>, lays out the definitions that will run our services with Compose. A service in Compose is a running container, and service definitions contain information about how each container image will run. In this step, we will translate these definitions to Kubernetes objects by using kompose to create yaml files. These files will contain specs for the Kubernetes objects that describe their desired state.</p>
<p>We will use these files to create different types of objects: Services, which will ensure that the Pods running our containers remain accessible; Deployments, which will contain information about the desired state of our Pods; a PersistentVolumeClaim to provision storage for our database data; a ConfigMap for environment variables injected at runtime; and a Secret for our application’s database user and password. Some of these definitions will be in the files kompose will create for us, and others we will need to create ourselves.</p>
<p>First, we will need to modify some of the definitions in our docker-compose.yaml file to work with Kubernetes. We will include a reference to our newly-built application image in our nodejs service definition and remove the bind mounts, volumes, and additional commands that we used to run the application container in development with Compose. Additionally, we’ll redefine both containers’ restart policies to be in line with the behavior Kubernetes expects.</p>
<p>Open the file with vim or your favorite editor:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">docker-compose.yaml</span></span><br></pre></td></tr></table></figure>
<p>The current definition for the nodejs application service looks like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">nodejs:</span></span><br><span class="line">    <span class="attr">build:</span></span><br><span class="line">      <span class="attr">context:</span> <span class="string">.</span></span><br><span class="line">      <span class="attr">dockerfile:</span> <span class="string">Dockerfile</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nodejs</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">nodejs</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br><span class="line">    <span class="attr">env_file:</span> <span class="string">.env</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_USERNAME=$MONGO_USERNAME</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_PASSWORD=$MONGO_PASSWORD</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_HOSTNAME=db</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_PORT=$MONGO_PORT</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_DB=$MONGO_DB</span> </span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;80:8080&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">.:/home/node/app</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node_modules:/home/node/app/node_modules</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">app-network</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">./wait-for.sh</span> <span class="string">db:27017</span> <span class="string">--</span> <span class="string">/home/node/app/node_modules/.bin/nodemon</span> <span class="string">app.js</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>Make the following edits to your service definition:</p>
<ul>
<li>Use your node-kubernetes image instead of the local Dockerfile.</li>
<li>Change the container restart policy from unless-stopped to always.</li>
<li>Remove the volumes list and the command instruction.</li>
</ul>
<p>The finished service definition will now look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">nodejs:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">merikanto/node-kubernetes</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">nodejs</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">env_file:</span> <span class="string">.env</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_USERNAME=$MONGO_USERNAME</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_PASSWORD=$MONGO_PASSWORD</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_HOSTNAME=db</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_PORT=$MONGO_PORT</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_DB=$MONGO_DB</span> </span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;80:8080&quot;</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">app-network</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>Next, scroll down to the db service definition. Here, make the following edits:</p>
<ul>
<li>Change the restart policy for the service to always.</li>
<li>Remove the .env file. Instead of using values from the .env file, we will pass the values for our MONGO_INITDB_ROOT_USERNAME and MONGO_INITDB_ROOT_PASSWORD to the database container using the Secret we will create in Step 4.</li>
</ul>
<p>The db service definition will now look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mongo:4.1.8-xenial</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">db</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_INITDB_ROOT_USERNAME=$MONGO_USERNAME</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MONGO_INITDB_ROOT_PASSWORD=$MONGO_PASSWORD</span></span><br><span class="line">    <span class="attr">volumes:</span>  </span><br><span class="line">      <span class="bullet">-</span> <span class="string">dbdata:/data/db</span>   </span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">app-network</span></span><br><span class="line"><span class="string">...</span>  </span><br></pre></td></tr></table></figure>
<p>Finally, at the bottom of the file, remove the node_modules volumes from the top-level volumes key. The key will now look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">dbdata:</span></span><br></pre></td></tr></table></figure>
<p>Save and close the file when you are finished editing.</p>
<p>Before translating our service definitions, we will need to write the .env file that kompose will use to create the ConfigMap with our non-sensitive information. Please see Step 2 of Containerizing a Node.js Application for Development With Docker Compose for a longer explanation of this file.</p>
<p>In that post, we added .env to our .gitignore file to ensure that it would not copy to version control. This means that it did not copy over when we cloned the node-mongo-docker-dev repository in Step 2 of this post. We will therefore need to recreate it now.</p>
<p>Create the file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">.env</span></span><br></pre></td></tr></table></figure>
<p>kompose will use this file to create a ConfigMap for our application. However, instead of assigning all of the variables from the nodejs service definition in our Compose file, we will add only the MONGO_DB database name and the MONGO_PORT. We will assign the database username and password separately when we manually create a Secret object in Step 4.</p>
<p>Add the following port and database name information to the .env file. Feel free to rename your database if you would like:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">MONGO_PORT=27017</span></span><br><span class="line"><span class="string">MONGO_DB=sharkinfo</span></span><br></pre></td></tr></table></figure>
<p>Save and close the file when you are finished editing.</p>
<p>You are now ready to create the files with your object specs. kompose offers multiple options for translating your resources. You can:</p>
<ul>
<li>Create yaml files based on the service definitions in your docker-compose.yaml file with kompose convert.</li>
<li>Create Kubernetes objects directly with kompose up.</li>
<li>Create a Helm chart with kompose convert -c.</li>
</ul>
<p>For now, we will convert our service definitions to yaml files and then add to and revise the files kompose creates.</p>
<p>Convert your service definitions to yaml files with the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kompose</span> <span class="string">convert</span></span><br></pre></td></tr></table></figure>
<p>You can also name specific or multiple Compose files using the -f flag.</p>
<p>After you run this command, kompose will output information about the files it has created:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">INFO Kubernetes file <span class="string">&quot;nodejs-service.yaml&quot;</span> created </span><br><span class="line">INFO Kubernetes file <span class="string">&quot;db-deployment.yaml&quot;</span> created </span><br><span class="line">INFO Kubernetes file <span class="string">&quot;dbdata-persistentvolumeclaim.yaml&quot;</span> created </span><br><span class="line">INFO Kubernetes file <span class="string">&quot;nodejs-deployment.yaml&quot;</span> created </span><br><span class="line">INFO Kubernetes file <span class="string">&quot;nodejs-env-configmap.yaml&quot;</span> created </span><br></pre></td></tr></table></figure>
<p>These include yaml files with specs for the Node application Service, Deployment, and ConfigMap, as well as for the dbdata PersistentVolumeClaim and MongoDB database Deployment.</p>
<p>These files are a good starting point, but in order for our application’s functionality to match the setup described in Containerizing a Node.js Application for Development With Docker Compose we will need to make a few additions and changes to the files kompose has generated.</p>
<br>

<hr>
<h2 id="Create-Kubernetes-Secrets"><a href="#Create-Kubernetes-Secrets" class="headerlink" title="Create Kubernetes Secrets"></a>Create Kubernetes Secrets</h2><p>In order for our application to function in the way we expect, we will need to make a few modifications to the files that kompose has created. The first of these changes will be generating a Secret for our database user and password and adding it to our application and database Deployments. Kubernetes offers two ways of working with environment variables: ConfigMaps and Secrets. kompose has already created a ConfigMap with the non-confidential information we included in our .env file, so we will now create a Secret with our confidential information: our database username and password.</p>
<p>The first step in manually creating a Secret will be to convert your username and password to base64, an encoding scheme that allows you to uniformly transmit data, including binary data.</p>
<p>Convert your database username:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -n <span class="string">&#x27;your_database_username&#x27;</span> | base64</span><br></pre></td></tr></table></figure>
<p>Note down the value you see in the output.</p>
<p>Next, convert your password:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -n <span class="string">&#x27;your_database_password&#x27;</span> | base64</span><br></pre></td></tr></table></figure>
<p>Take note of the value in the output here as well.</p>
<p>Open a file for the Secret:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">secret.yaml</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: Kubernetes objects are typically defined using YAML, which strictly forbids tabs and requires two spaces for indentation. If you would like to check the formatting of any of your yaml files, you can use a linter or test the validity of your syntax using kubectl create with the –dry-run and –validate flags:</p>
<p><code>kubectl create -f your_yaml_file.yaml --dry-run --validate=true</code></p>
<p>In general, it is a good idea to validate your syntax before creating resources with kubectl.</p>
</blockquote>
<p>Add the following code to the file to create a Secret that will define your MONGO_USERNAME and MONGO_PASSWORD using the encoded values you just created. Be sure to replace the dummy values here with your encoded username and password:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/secret.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongo-secret</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">MONGO_USERNAME:</span> <span class="string">your_encoded_username</span></span><br><span class="line">  <span class="attr">MONGO_PASSWORD:</span> <span class="string">your_encoded_password</span></span><br></pre></td></tr></table></figure>
<p>We have named the Secret object mongo-secret, but you are free to name it anything you would like.</p>
<p>Save and close this file when you are finished editing. As you did with your .env file, be sure to add secret.yaml to your .gitignore file to keep it out of version control.</p>
<p>With secret.yaml written, our next step will be to ensure that our application and database Pods both use the values we added to the file. Let’s start by adding references to the Secret to our application Deployment.</p>
<p>Open the file called nodejs-deployment.yaml:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">nodejs-deployment.yaml</span></span><br></pre></td></tr></table></figure>
<p>The file’s container specifications include the following environment variables defined under the env key:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/nodejs-deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>    </span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_DB</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_DB</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-env</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_HOSTNAME</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">db</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_PASSWORD</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_PORT</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_PORT</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-env</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_USERNAME</span></span><br></pre></td></tr></table></figure>
<p>We will need to add references to our Secret to the MONGO_USERNAME and MONGO_PASSWORD variables listed here, so that our application will have access to those values. Instead of including a configMapKeyRef key to point to our nodejs-env ConfigMap, as is the case with the values for MONGO_DB and MONGO_PORT, we’ll include a secretKeyRef key to point to the values in our mongo-secret secret.</p>
<p>Add the following Secret references to the MONGO_USERNAME and MONGO_PASSWORD variables:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/nodejs-deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_DB</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_DB</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-env</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_HOSTNAME</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">db</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_PASSWORD</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">mongo-secret</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_PASSWORD</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_PORT</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_PORT</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-env</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_USERNAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">mongo-secret</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_USERNAME</span></span><br></pre></td></tr></table></figure>
<p>Save and close the file when you are finished editing.</p>
<p>Next, we’ll add the same values to the db-deployment.yaml file.</p>
<p>Open the file for editing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">db-deployment.yaml</span></span><br></pre></td></tr></table></figure>
<p>In this file, we will add references to our Secret for following variable keys: MONGO_INITDB_ROOT_USERNAME and MONGO_INITDB_ROOT_PASSWORD. The mongo image makes these variables available so that you can modify the initialization of your database instance. MONGO_INITDB_ROOT_USERNAME and MONGO_INITDB_ROOT_PASSWORD together create a root user in the admin authentication database and ensure that authentication is enabled when the database container starts.</p>
<p>Using the values we set in our Secret ensures that we will have an application user with root privileges on the database instance, with access to all of the administrative and operational privileges of that role. When working in production, you will want to create a dedicated application user with appropriately scoped privileges.</p>
<p>Under the MONGO_INITDB_ROOT_USERNAME and MONGO_INITDB_ROOT_PASSWORD variables, add references to the Secret values:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/db-deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_INITDB_ROOT_PASSWORD</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">mongo-secret</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_PASSWORD</span>        </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGO_INITDB_ROOT_USERNAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">mongo-secret</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">MONGO_USERNAME</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">mongo:4.1.8-xenial</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>Save and close the file when you are finished editing.</p>
<p>With your Secret in place, you can move on to creating your database Service and ensuring that your application container only attempts to connect to the database once it is fully set up and initialized.</p>
<br>

<hr>
<h2 id="Create-DB-Service-amp-App-Init-Container"><a href="#Create-DB-Service-amp-App-Init-Container" class="headerlink" title="Create DB Service &amp; App Init Container"></a>Create DB Service &amp; App Init Container</h2><p>Now that we have our Secret, we can move on to creating our database Service and an Init Container that will poll this Service to ensure that our application only attempts to connect to the database once the database startup tasks, including creating the <code>MONGO_INITDB</code> user and password, are complete.</p>
<p>For a discussion of how to implement this functionality in Compose, please see Step 4 of Containerizing a Node.js Application for Development with Docker Compose.</p>
<p>Open a file to define the specs for the database Service:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">db-service.yaml</span>  </span><br></pre></td></tr></table></figure>
<p>Add the following code to the file to define the Service:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/db-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span> </span><br><span class="line">    <span class="attr">kompose.cmd:</span> <span class="string">kompose</span> <span class="string">convert</span></span><br><span class="line">    <span class="attr">kompose.version:</span> <span class="number">1.18</span><span class="number">.0</span> <span class="string">(06a2e56)</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">io.kompose.service:</span> <span class="string">db</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">db</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">27017</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">27017</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">io.kompose.service:</span> <span class="string">db</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>The selector that we have included here will match this Service object with our database Pods, which have been defined with the label io.kompose.service: db by kompose in the db-deployment.yaml file. We’ve also named this service db.</p>
<p>Save and close the file when you are finished editing.</p>
<p>Next, let’s add an Init Container field to the containers array in nodejs-deployment.yaml. This will create an Init Container that we can use to delay our application container from starting until the db Service has been created with a Pod that is reachable. This is one of the possible uses for Init Containers; to learn more about other use cases, please see the official documentation.</p>
<p>Open the nodejs-deployment.yaml file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">nodejs-deployment.yaml</span></span><br></pre></td></tr></table></figure>
<p>Within the Pod spec and alongside the containers array, we are going to add an initContainers field with a container that will poll the db Service.</p>
<p>Add the following code below the ports and resources fields and above the restartPolicy in the nodejs containers array:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/nodejs-deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="string">...</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nodejs</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">        <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-db</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nc -z db:27017; do echo waiting for db; sleep 2; done;&#x27;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="string">...</span>               </span><br></pre></td></tr></table></figure>
<p>This Init Container uses the BusyBox image, a lightweight image that includes many UNIX utilities. In this case, we’ll use the netcat utility to poll whether or not the Pod associated with the db Service is accepting TCP connections on port 27017.</p>
<p>This container command replicates the functionality of the wait-for script that we removed from our docker-compose.yaml file in Step 3. For a longer discussion of how and why our application used the wait-for script when working with Compose, please see Step 4 of Containerizing a Node.js Application for Development with Docker Compose.</p>
<p>Init Containers run to completion; in our case, this means that our Node application container will not start until the database container is running and accepting connections on port 27017. The db Service definition allows us to guarantee this functionality regardless of the exact location of the database container, which is mutable.</p>
<p>Save and close the file when you are finished editing.</p>
<p>With your database Service created and your Init Container in place to control the startup order of your containers, you can move on to checking the storage requirements in your PersistentVolumeClaim and exposing your application service using a LoadBalancer.</p>
<br>

<hr>
<h2 id="Expose-the-Application-Frontend"><a href="#Expose-the-Application-Frontend" class="headerlink" title="Expose the Application Frontend"></a>Expose the Application Frontend</h2><p>Before running our application, we will make two final changes to ensure that our database storage will be provisioned properly and that we can expose our application frontend using a LoadBalancer.</p>
<p>First, let’s modify the storage resource defined in the <code>PersistentVolumeClaim</code> that kompose created for us. This Claim allows us to dynamically provision storage to manage our application’s state.</p>
<p>To work with PersistentVolumeClaims, you must have a StorageClass created and configured to provision storage resources. In our case, because we are working with DigitalOcean Kubernetes, our default StorageClass provisioner is set to dobs.csi.digitalocean.com (DigitalOcean Block Storage).</p>
<p>We can check this by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">storageclass</span></span><br></pre></td></tr></table></figure>
<p>If you are working with a DigitalOcean cluster, you will see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">NAME</span>                         <span class="string">PROVISIONER</span>                 <span class="string">AGE</span></span><br><span class="line"><span class="string">do-block-storage</span> <span class="string">(default)</span>   <span class="string">dobs.csi.digitalocean.com</span>   <span class="string">76m</span></span><br></pre></td></tr></table></figure>
<p>If you are not working with a DigitalOcean cluster, you will need to create a StorageClass and configure a provisioner of your choice. For details about how to do this, please see the official documentation.</p>
<p>When kompose created dbdata-persistentvolumeclaim.yaml, it set the storage resource to a size that does not meet the minimum size requirements of our provisioner. We will therefore need to modify our PersistentVolumeClaim to use the minimum viable DigitalOcean Block Storage unit: 1GB. Please feel free to modify this to meet your storage requirements.</p>
<p>Open dbdata-persistentvolumeclaim.yaml:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">dbdata-persistentvolumeclaim.yaml</span></span><br></pre></td></tr></table></figure>
<p>Replace the storage value with 1Gi:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/dbdata-persistentvolumeclaim.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">io.kompose.service:</span> <span class="string">dbdata</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dbdata</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>Also note the accessMode: ReadWriteOnce means that the volume provisioned as a result of this Claim will be read-write only by a single node. Please see the documentation for more information about different access modes.</p>
<p>Save and close the file when you are finished.</p>
<p>Next, open nodejs-service.yaml:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">nodejs-service.yaml</span></span><br></pre></td></tr></table></figure>
<p>We are going to expose this Service externally using a DigitalOcean Load Balancer. If you are not using a DigitalOcean cluster, please consult the relevant documentation from your cloud provider for information about their load balancers. Alternatively, you can follow the official Kubernetes documentation on setting up a highly available cluster with kubeadm, but in this case you will not be able to use PersistentVolumeClaims to provision storage.</p>
<p>Within the Service spec, specify LoadBalancer as the Service type:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ~/node_project/nodejs-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>When we create the nodejs Service, a load balancer will be automatically created, providing us with an external IP where we can access our application.</p>
<p>Save and close the file when you are finished editing.</p>
<p>With all of our files in place, we are ready to start and test the application.</p>
<br>

<hr>
<h2 id="Start-amp-Access-the-Application"><a href="#Start-amp-Access-the-Application" class="headerlink" title="Start &amp; Access the Application"></a>Start &amp; Access the Application</h2><p>It’s time to create our Kubernetes objects and test that our application is working as expected.</p>
<p>To create the objects we’ve defined, we’ll use kubectl create with the -f flag, which will allow us to specify the files that kompose created for us, along with the files we wrote. Run the following command to create the Node application and MongoDB database Services and Deployments, along with your Secret, ConfigMap, and PersistentVolumeClaim:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl create -f nodejs-service.yaml,nodejs-deployment.yaml, \</span><br><span class="line">nodejs-env-configmap.yaml,db-service.yaml,db-deployment.yaml, \</span><br><span class="line">dbdata-persistentvolumeclaim.yaml,secret.yaml</span><br></pre></td></tr></table></figure>
<p>You will see the following output indicating that the objects have been created:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">service/nodejs created</span><br><span class="line">deployment.extensions/nodejs created</span><br><span class="line">configmap/nodejs-env created</span><br><span class="line">service/db created</span><br><span class="line">deployment.extensions/db created</span><br><span class="line">persistentvolumeclaim/dbdata created</span><br><span class="line">secret/mongo-secret created</span><br></pre></td></tr></table></figure>
<p>To check that your Pods are running, type:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
<p>You don’t need to specify a Namespace here, since we have created our objects in the default Namespace. If you are working with multiple Namespaces, be sure to include the -n flag when running this command, along with the name of your Namespace.</p>
<p>You will see the following output while your db container is starting and your application Init Container is running:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME                      READY   STATUS              RESTARTS   AGE</span><br><span class="line">db-679d658576-kfpsl       0/1     ContainerCreating   0          10s</span><br><span class="line">nodejs-6b9585dc8b-pnsws   0/1     Init:0/1            0          10s</span><br></pre></td></tr></table></figure>
<p>Once that container has run and your application and database containers have started, you will see this output:</p>
<pre><code>Output
NAME                      READY   STATUS    RESTARTS   AGE
db-679d658576-kfpsl       1/1     Running   0          54s
nodejs-6b9585dc8b-pnsws   1/1     Running   0          54s
</code></pre>
<p>The Running STATUS indicates that your Pods are bound to nodes and that the containers associated with those Pods are running. READY indicates how many containers in a Pod are running. For more information, please consult the documentation on Pod lifecycles.</p>
<blockquote>
<p>Note:</p>
<p>If you see unexpected phases in the STATUS column, remember that you can troubleshoot your Pods with the following commands:</p>
<p><code>kubectl describe pods your_pod</code><br><code>kubectl logs your_pod</code></p>
</blockquote>
<p>With your containers running, you can now access the application. To get the IP for the LoadBalancer, type:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">svc</span></span><br></pre></td></tr></table></figure>
<p>You will see the following output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)        AGE</span><br><span class="line">db           ClusterIP      10.245.189.250   &lt;none&gt;           27017/TCP      93s</span><br><span class="line">kubernetes   ClusterIP      10.245.0.1       &lt;none&gt;           443/TCP        25m12s</span><br><span class="line">nodejs       LoadBalancer   10.245.15.56     your_lb_ip       80:30729/TCP   93s</span><br></pre></td></tr></table></figure>
<p>The EXTERNAL_IP associated with the nodejs service is the IP address where you can access the application. If you see a <pending> status in the EXTERNAL_IP column, this means that your load balancer is still being created.</p>
<p>Once you see an IP in that column, navigate to it in your browser: <a href="http://your_lb_ip/">http://your_lb_ip</a>.</p>
<p>You should see the following landing page:</p>
<p><img data-src="https://assets.digitalocean.com/articles/docker_node_image/landing_page.png" alt="Application Landing Page"></p>
<p>Click on the Get Shark Info button. You will see a page with an entry form where you can enter a shark name and a description of that shark’s general character:</p>
<p><img data-src="https://assets.digitalocean.com/articles/node_mongo/shark_form.png" alt="Shark Info Form"></p>
<p>In the form, add a shark of your choosing. To demonstrate, we will add Megalodon Shark to the Shark Name field, and Ancient to the Shark Character field:</p>
<p><img data-src="https://assets.digitalocean.com/articles/node_mongo/shark_filled.png" alt="Filled Shark Form"></p>
<p>Click on the Submit button. You will see a page with this shark information displayed back to you:</p>
<p><img data-src="https://assets.digitalocean.com/articles/node_mongo/shark_added.png" alt="Shark Output"></p>
<p>You now have a single instance setup of a Node.js application with a MongoDB database running on a Kubernetes cluster.</p>
<br>

<br>


]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Configure Prometheus on Ubuntu</title>
    <url>/2019/Prometheus/</url>
    <content><![CDATA[<p>Prometheus is a powerful, open-source monitoring system that collects metrics from your services and stores them in a time-series database. It offers a multi-dimensional data model, a flexible query language, and diverse visualization possibilities through tools like Grafana.</p>
<p>By default, Prometheus only exports metrics about itself (e.g. the number of requests it’s received, its memory consumption, etc.). But, you can greatly expand Prometheus by installing exporters, optional programs that generate additional metrics.</p>
<span id="more"></span> 

<p>Exporters — both the official ones that the Prometheus team maintains as well as the community-contributed ones — provide information about everything from infrastructure, databases, and web servers to messaging systems, APIs, and more.</p>
<p>Some of the most popular choices include:</p>
<ul>
<li><p><code>node_exporter</code> - This produces metrics about infrastructure, including the current CPU, memory and disk usage, as well as I/O and network statistics, such as the number of bytes read from a disk or a server’s average load.</p>
</li>
<li><p><code>blackbox_exporter</code> - This generates metrics derived from probing protocols like HTTP and HTTPS to determine endpoint availability, response time, and more.</p>
</li>
<li><p><code>mysqld_exporter</code> - This gathers metrics related to a MySQL server, such as the number of executed queries, average query response time, and cluster replication status.</p>
</li>
<li><p><code>rabbitmq_exporter</code> - This outputs metrics about the RabbitMQ messaging system, including the number of messages published, the number of messages ready to be delivered, and the size of all the messages in the queue.</p>
</li>
<li><p><code>nginx-vts-exporter</code> - This provides metrics about an Nginx web server using the Nginx VTS module, including the number of open connections, the number of sent responses (grouped by response codes), and the total size of sent or received requests in bytes.</p>
</li>
</ul>
<p>You can find a more complete list of both official and community-contributed exporters on Prometheus’ website.</p>
<p>In this post, we will install, configure, and secure Prometheus and Node Exporter to generate metrics that will make it easier to monitor your server’s performance.</p>
<br>

<blockquote>
<p>Reference:</p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04">Configure Prometheus on Ubuntu</a></p>
<p><a href="https://www.digitalocean.com/community/tutorial_series/how-to-query-prometheus">How To Query Prometheus</a></p>
</blockquote>
<br>

<hr>
<h2 id="Create-Service-Users"><a href="#Create-Service-Users" class="headerlink" title="Create Service Users"></a>Create Service Users</h2><p>For security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. We’ll use these accounts throughout the post to isolate the ownership on Prometheus’ core files and directories.</p>
<p>Create these two users, and use the –no-create-home and –shell /bin/false options so that these users can’t log into the server.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo useradd --no-create-home --shell /bin/<span class="literal">false</span> prometheus</span><br><span class="line">sudo useradd --no-create-home --shell /bin/<span class="literal">false</span> node_exporter</span><br></pre></td></tr></table></figure>
<p>Before we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in /etc for Prometheus’ configuration files and a directory in /var/lib for its data.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo mkdir /etc/prometheus</span><br><span class="line">sudo mkdir /var/lib/prometheus</span><br></pre></td></tr></table></figure>
<p>Now, set the user and group ownership on the new directories to the prometheus user.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo chown prometheus:prometheus /etc/prometheus</span><br><span class="line">sudo chown prometheus:prometheus /var/lib/prometheus</span><br></pre></td></tr></table></figure>
<p>With our users and directories in place, we can now download Prometheus and then create the minimal configuration file to run Prometheus for the first time.</p>
<br>

<hr>
<h2 id="Downloading-Prometheus"><a href="#Downloading-Prometheus" class="headerlink" title="Downloading Prometheus"></a>Downloading Prometheus</h2><p>First, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries along with their checksums on the Prometheus download page.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"></span><br><span class="line">curl -LO https://github.com/prometheus/prometheus/releases \ </span><br><span class="line">/download/v2.0.0/prometheus-2.0.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>
<p>Next, use the sha256sum command to generate a checksum of the downloaded file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sha256sum</span> <span class="string">prometheus-2.0.0.linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>Compare the output from this command with the checksum on the Prometheus download page to ensure that your file is both genuine and not corrupted.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">e12917b25b32980daee0e9cf879d9ec197e2893924bd1574604eb0f550034d46  </span><br><span class="line">prometheus-2.0.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>
<p>If the checksums don’t match, remove the downloaded file and repeat the preceding steps to re-download the file.</p>
<p>Now, unpack the downloaded archive.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">tar</span> <span class="string">xvf</span> <span class="string">prometheus-2.0.0.linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>This will create a directory called prometheus-2.0.0.linux-amd64 containing two binary files (prometheus and promtool), consoles and console_libraries directories containing the web interface files, a license, a notice, and several example files.</p>
<p>Copy the two binaries to the /usr/local/bin directory.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo cp prometheus-2.0.0.linux-amd64/prometheus /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">sudo cp prometheus-2.0.0.linux-amd64/promtool /usr/<span class="built_in">local</span>/bin/</span><br></pre></td></tr></table></figure>
<p>Set the user and group ownership on the binaries to the prometheus user created in Step 1.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo chown prometheus:prometheus /usr/<span class="built_in">local</span>/bin/prometheus</span><br><span class="line">sudo chown prometheus:prometheus /usr/<span class="built_in">local</span>/bin/promtool</span><br></pre></td></tr></table></figure>
<p>Copy the consoles and console_libraries directories to /etc/prometheus.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo cp -r prometheus-2.0.0.linux-amd64/consoles /etc/prometheus</span><br><span class="line">sudo cp -r prometheus-2.0.0.linux-amd64/console_libraries /etc/prometheus</span><br></pre></td></tr></table></figure>
<p>Set the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo chown -R prometheus:prometheus /etc/prometheus/consoles</span><br><span class="line">sudo chown -R prometheus:prometheus /etc/prometheus/console_libraries</span><br></pre></td></tr></table></figure>
<p>Lastly, remove the leftover files from your home directory as they are no longer needed.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">rm</span> <span class="string">-rf</span> <span class="string">prometheus-2.0.0.linux-amd64.tar.gz</span> <span class="string">prometheus-2.0.0.linux-amd64</span></span><br></pre></td></tr></table></figure>
<p>Now that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.</p>
<br>

<hr>
<h2 id="Config-Prometheus"><a href="#Config-Prometheus" class="headerlink" title="Config Prometheus"></a>Config Prometheus</h2><p>In the /etc/prometheus directory, use vim or your favorite text editor to create a configuration file named prometheus.yml. For now, this file will contain just enough information to run Prometheus for the first time.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/prometheus/prometheus.yml</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Warning: Prometheus’ configuration file uses the YAML format, which strictly forbids tabs and requires two spaces for indentation. Prometheus will fail to start if the configuration file is incorrectly formatted.</p>
</blockquote>
<p>In the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span></span><br></pre></td></tr></table></figure>

<p>This scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.</p>
<p>Now, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span></span><br><span class="line">    <span class="attr">scrape_interval:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>Prometheus uses the job_name to label exporters in queries and on graphs, so be sure to pick something descriptive here.</p>
<p>And, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.</p>
<p>Lastly, Prometheus uses the static_configs and targets directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.</p>
<p>Your configuration file should now look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span></span><br><span class="line">    <span class="attr">scrape_interval:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>Save the file and exit your text editor.</p>
<p>Now, set the user and group ownership on the configuration file to the prometheus user created in Step 1.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">chown</span> <span class="string">prometheus:prometheus</span> <span class="string">/etc/prometheus/prometheus.yml</span></span><br></pre></td></tr></table></figure>
<p>With the configuration complete, we’re ready to test Prometheus by running it for the first time.</p>
<br>

<hr>
<h2 id="Running-Prometheus"><a href="#Running-Prometheus" class="headerlink" title="Running Prometheus"></a>Running Prometheus</h2><p>Start up Prometheus as the prometheus user, providing the path to both the configuration file and the data directory.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo -u prometheus /usr/<span class="built_in">local</span>/bin/prometheus \</span><br><span class="line">    --config.file /etc/prometheus/prometheus.yml \</span><br><span class="line">    --storage.tsdb.path /var/lib/prometheus/ \</span><br><span class="line">    --web.console.templates=/etc/prometheus/consoles \</span><br><span class="line">    --web.console.libraries=/etc/prometheus/console_libraries</span><br></pre></td></tr></table></figure>
<p>The output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port 9090.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">level=info ts=2017-11-17T18:37:27.474530094Z <span class="built_in">caller</span>=main.go:215 msg=<span class="string">&quot;Starting Prometheus&quot;</span> version=<span class="string">&quot;(version=2.0.0, branch=HEAD, re</span></span><br><span class="line"><span class="string">vision=0a74f98628a0463dddc90528220c94de5032d1a0)&quot;</span></span><br><span class="line">level=info ts=2017-11-17T18:37:27.474758404Z <span class="built_in">caller</span>=main.go:216 build_context=<span class="string">&quot;(go=go1.9.2, user=root@615b82cb36b6, date=20171108-</span></span><br><span class="line"><span class="string">07:11:59)&quot;</span></span><br><span class="line">level=info ts=2017-11-17T18:37:27.474883982Z <span class="built_in">caller</span>=main.go:217 host_details=<span class="string">&quot;(Linux 4.4.0-98-generic #121-Ubuntu SMP Tue Oct 10 1</span></span><br><span class="line"><span class="string">4:24:03 UTC 2017 x86_64 prometheus-update (none))&quot;</span></span><br><span class="line">level=info ts=2017-11-17T18:37:27.483661837Z <span class="built_in">caller</span>=web.go:380 component=web msg=<span class="string">&quot;Start listening for connections&quot;</span> address=0.0.0.0</span><br><span class="line">:9090</span><br><span class="line">level=info ts=2017-11-17T18:37:27.489730138Z <span class="built_in">caller</span>=main.go:314 msg=<span class="string">&quot;Starting TSDB&quot;</span></span><br><span class="line">level=info ts=2017-11-17T18:37:27.516050288Z <span class="built_in">caller</span>=targetmanager.go:71 component=<span class="string">&quot;target manager&quot;</span> msg=<span class="string">&quot;Starting target manager...</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line">level=info ts=2017-11-17T18:37:27.537629169Z <span class="built_in">caller</span>=main.go:326 msg=<span class="string">&quot;TSDB started&quot;</span></span><br><span class="line">level=info ts=2017-11-17T18:37:27.537896721Z <span class="built_in">caller</span>=main.go:394 msg=<span class="string">&quot;Loading configuration file&quot;</span> filename=/etc/prometheus/promethe</span><br><span class="line">us.yml</span><br><span class="line">level=info ts=2017-11-17T18:37:27.53890004Z <span class="built_in">caller</span>=main.go:371 msg=<span class="string">&quot;Server is ready to receive requests.&quot;</span></span><br></pre></td></tr></table></figure>

<p>If you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.</p>
<p>Now, halt Prometheus by pressing CTRL+C, and then open a new systemd service file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/systemd/system/prometheus.service</span></span><br></pre></td></tr></table></figure>
<p>The service file tells systemd to run Prometheus as the prometheus user, with the configuration file located in the <code>/etc/prometheus/prometheus.yml</code> directory and to store its data in the <code>/var/lib/prometheus</code> directory. (The details of systemd service files are beyond the scope of this post, but you can learn more at Understanding Systemd Units and Unit Files.)</p>
<p>Copy the following content into the file:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Prometheus</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=prometheus</span><br><span class="line">Group=prometheus</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/prometheus \</span><br><span class="line">    --config.file /etc/prometheus/prometheus.yml \</span><br><span class="line">    --storage.tsdb.path /var/lib/prometheus/ \</span><br><span class="line">    --web.console.templates=/etc/prometheus/consoles \</span><br><span class="line">    --web.console.libraries=/etc/prometheus/console_libraries</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<p>Finally, save the file and close your text editor.</p>
<p>To use the newly created service, reload systemd.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">daemon-reload</span></span><br></pre></td></tr></table></figure>
<p>You can now start Prometheus using the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">prometheus</span></span><br></pre></td></tr></table></figure>
<p>To make sure Prometheus is running, check the service’s status.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">prometheus</span></span><br></pre></td></tr></table></figure>
<p>The output tells you Prometheus’ status, main process identifier (PID), memory use, and more.</p>
<p>If the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continue. Lastly, enable the service to start on boot.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">prometheus</span></span><br></pre></td></tr></table></figure>
<p>Now that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.</p>
<br>

<hr>
<h2 id="Download-Node-Exporter"><a href="#Download-Node-Exporter" class="headerlink" title="Download Node Exporter"></a>Download Node Exporter</h2><p>To expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage.</p>
<p>First, download the current stable version of Node Exporter into your home directory. You can find the latest binaries along with their checksums on Prometheus’ download page.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"></span><br><span class="line">curl -LO https://github.com/prometheus/node_exporter/releases/download/v0.15.1/node_exporter-0.15.1.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>
<p>Use the sha256sum command to generate a checksum of the downloaded file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sha256sum</span> <span class="string">node_exporter-0.15.1.linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>Verify the downloaded file’s integrity by comparing its checksum with the one on the download page.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">7ffb3773abb71dd2b2119c5f6a7a0dbca0cff34b24b2ced9e01d9897df61a127</span>  <span class="string">node_exporter-0.15.1.linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>If the checksums don’t match, remove the downloaded file and repeat the preceding steps.</p>
<p>Now, unpack the downloaded archive.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">tar</span> <span class="string">xvf</span> <span class="string">node_exporter-0.15.1.linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>This will create a directory called node_exporter-0.15.1.linux-amd64 containing a binary file named node_exporter, a license, and a notice.</p>
<p>Copy the binary to the /usr/local/bin directory and set the user and group ownership to the node_exporter user that you created in Step 1.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo cp node_exporter-0.15.1.linux-amd64/node_exporter /usr/<span class="built_in">local</span>/bin</span><br><span class="line">sudo chown node_exporter:node_exporter /usr/<span class="built_in">local</span>/bin/node_exporter</span><br></pre></td></tr></table></figure>
<p>Lastly, remove the leftover files from your home directory as they are no longer needed.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">rm</span> <span class="string">-rf</span> <span class="string">node_exporter-0.15.1.linux-amd64.tar.gz</span> <span class="string">node_exporter-0.15.1.linux-amd64</span></span><br></pre></td></tr></table></figure>
<p>Now that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.</p>
<br>

<hr>
<h2 id="Running-Node-Exporter"><a href="#Running-Node-Exporter" class="headerlink" title="Running Node Exporter"></a>Running Node Exporter</h2><p>The steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/systemd/system/node_exporter.service</span></span><br></pre></td></tr></table></figure>
<p>This service file tells your system to run Node Exporter as the node_exporter user with the default set of collectors enabled.</p>
<p>Copy the following content into the service file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">Unit</span>]</span><br><span class="line"><span class="string">Description=Node</span> <span class="string">Exporter</span></span><br><span class="line"><span class="string">Wants=network-online.target</span></span><br><span class="line"><span class="string">After=network-online.target</span></span><br><span class="line"></span><br><span class="line">[<span class="string">Service</span>]</span><br><span class="line"><span class="string">User=node_exporter</span></span><br><span class="line"><span class="string">Group=node_exporter</span></span><br><span class="line"><span class="string">Type=simple</span></span><br><span class="line"><span class="string">ExecStart=/usr/local/bin/node_exporter</span></span><br><span class="line"></span><br><span class="line">[<span class="string">Install</span>]</span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br></pre></td></tr></table></figure>
<p>Collectors define which metrics Node Exporter will generate. You can see Node Exporter’s complete list of collectors — including which are enabled by default and which are deprecated — in the Node Exporter README file.</p>
<p>If you ever need to override the default list of collectors, you can use the –collectors.enabled flag, like:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Node</span> <span class="string">Exporter</span> <span class="string">service</span> <span class="string">file</span> <span class="string">part</span> <span class="bullet">-</span> <span class="string">/etc/systemd/system/node_exporter.service</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">ExecStart=/usr/local/bin/node_exporter</span> <span class="string">--collectors.enabled</span> <span class="string">meminfo,loadavg,filesystem</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>The preceding example would tell Node Exporter to generate metrics using only the meminfo, loadavg, and filesystem collectors. You can limit the collectors to however few or many you need, but note that there are no blank spaces before or after the commas.</p>
<p>Save the file and close your text editor.</p>
<p>Finally, reload systemd to use the newly created service.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">daemon-reload</span></span><br></pre></td></tr></table></figure>
<p>You can now run Node Exporter using the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">node_exporter</span></span><br></pre></td></tr></table></figure>
<p>Verify that Node Exporter’s running correctly with the status command.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">node_exporter</span></span><br></pre></td></tr></table></figure>
<p>Like before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more.</p>
<p>If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing. Lastly, enable Node Exporter to start on boot.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">node_exporter</span></span><br></pre></td></tr></table></figure>
<p>With Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.</p>
<br>

<hr>
<h2 id="Use-Prometheus-to-Scrape-Node-Exporter"><a href="#Use-Prometheus-to-Scrape-Node-Exporter" class="headerlink" title="Use Prometheus to Scrape Node Exporter"></a>Use Prometheus to Scrape Node Exporter</h2><p>Because Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself.</p>
<p>Open the configuration file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/prometheus/prometheus.yml</span></span><br></pre></td></tr></table></figure>
<p>At the end of the scrape_configs block, add a new entry called node_exporter.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;node_exporter&#x27;</span></span><br><span class="line">    <span class="attr">scrape_interval:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9100&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>Because this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100.</p>
<p>Your whole configuration file should look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span></span><br><span class="line">    <span class="attr">scrape_interval:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;node_exporter&#x27;</span></span><br><span class="line">    <span class="attr">scrape_interval:</span> <span class="string">5s</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9100&#x27;</span>]       </span><br></pre></td></tr></table></figure>
<p>Save the file and exit your text editor when you’re ready to continue.</p>
<p>Finally, restart Prometheus to put the changes into effect.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">prometheus</span></span><br></pre></td></tr></table></figure>
<p>Once again, verify that everything is running correctly with the status command.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">prometheus</span></span><br></pre></td></tr></table></figure>
<p>If the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.</p>
<p>We now have Prometheus and Node Exporter installed, configured, and running. As a final precaution before connecting to the web interface, we’ll enhance our installation’s security with basic HTTP authentication to ensure that unauthorized users can’t access our metrics.</p>
<br>

<hr>
<h2 id="Secure-Prometheus"><a href="#Secure-Prometheus" class="headerlink" title="Secure Prometheus"></a>Secure Prometheus</h2><p>Prometheus does not include built-in authentication or any other general purpose security mechanism. On the one hand, this means you’re getting a highly flexible system with fewer configuration restraints; on the other hand, it means it’s up to you to ensure that your metrics and overall setup are sufficiently secure.</p>
<p>For simplicity’s sake, we’ll use Nginx to add basic HTTP authentication to our installation, which both Prometheus and its preferred data visualization tool, Grafana, fully support.</p>
<p>Start by installing apache2-utils, which will give you access to the htpasswd utility for generating password files.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install apache2-utils</span><br></pre></td></tr></table></figure>
<p>Now, create a password file by telling <code>htpasswd</code> where you want to store the file and which username you’d like to use for authentication.</p>
<blockquote>
<p>Note: <code>htpasswd</code> will prompt you to enter and re-confirm the password you’d like to associate with this user. Also, make note of both the username and password you enter here, as you’ll need them to log into Prometheus in Step 9.</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">htpasswd</span> <span class="string">-c</span> <span class="string">/etc/nginx/.htpasswd</span> <span class="string">merikanto</span></span><br></pre></td></tr></table></figure>
<p>The result of this command is a newly-created file called .htpasswd, located in the /etc/nginx directory, containing the username and a hashed version of the password you entered.</p>
<p>Next, configure Nginx to use the newly-created passwords.</p>
<p>First, make a Prometheus-specific copy of the default Nginx configuration file so that you can revert back to the defaults later if you run into a problem.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">cp</span> <span class="string">/etc/nginx/sites-available/default</span> <span class="string">/etc/nginx/sites-available/prometheus</span></span><br></pre></td></tr></table></figure>
<p>Then, open the new configuration file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/sites-available/prometheus</span></span><br></pre></td></tr></table></figure>
<p>Locate the location / block under the server block. It should look like:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/nginx/sites-available/default</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="string">location</span> <span class="string">/</span> &#123;</span><br><span class="line">        <span class="string">try_files</span> <span class="string">$uri</span> <span class="string">$uri/</span> <span class="string">=404;</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>As we will be forwarding all traffic to Prometheus, replace the try_files directive with the following content:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/nginx/sites-available/prometheus</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="string">location</span> <span class="string">/</span> &#123;</span><br><span class="line">        <span class="string">auth_basic</span> <span class="string">&quot;Prometheus server authentication&quot;</span><span class="string">;</span></span><br><span class="line">        <span class="string">auth_basic_user_file</span> <span class="string">/etc/nginx/.htpasswd;</span></span><br><span class="line">        <span class="string">proxy_pass</span> <span class="string">http://localhost:9090;</span></span><br><span class="line">        <span class="string">proxy_http_version</span> <span class="number">1.1</span><span class="string">;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">Upgrade</span> <span class="string">$http_upgrade;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">Connection</span> <span class="string">&#x27;upgrade&#x27;</span><span class="string">;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">Host</span> <span class="string">$host;</span></span><br><span class="line">        <span class="string">proxy_cache_bypass</span> <span class="string">$http_upgrade;</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>These settings ensure that users will have to authenticate at the start of each new session. Additionally, the reverse proxy will direct all requests handled by this block to Prometheus.</p>
<p>When you’re finished making changes, save the file and close your text editor.</p>
<p>Now, deactivate the default Nginx configuration file by removing the link to it in the /etc/nginx/sites-enabled directory, and activate the new configuration file by creating a link to it.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo rm /etc/nginx/sites-enabled/default</span><br><span class="line">sudo ln -s /etc/nginx/sites-available/prometheus /etc/nginx/sites-enabled/</span><br></pre></td></tr></table></figure>
<p>Before restarting Nginx, check the configuration for errors using the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">nginx</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>
<p>The output should indicate that the syntax is ok and the test is successful. If you receive an error message, follow the on-screen instructions to fix the problem before proceeding to the next step.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output of Nginx configuration tests</span></span><br><span class="line">nginx: the configuration file /etc/nginx/nginx.conf syntax is ok</span><br><span class="line">nginx: configuration file /etc/nginx/nginx.conf <span class="built_in">test</span> is successful</span><br></pre></td></tr></table></figure>
<p>Then, reload Nginx to incorporate all of the changes.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>
<p>Verify that Nginx is up and running.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>
<p>If your output doesn’t indicate that the service’s status is active, follow the on-screen messages and re-trace the preceding steps to resolve the issue before continuing.</p>
<p>At this point, we have a fully-functional and secured Prometheus server, so we can log into the web interface to begin looking at metrics.</p>
<br>

<hr>
<h2 id="Test-Prometheus"><a href="#Test-Prometheus" class="headerlink" title="Test Prometheus"></a>Test Prometheus</h2><p>Prometheus provides a basic web interface for monitoring the status of itself and its exporters, executing queries, and generating graphs. But, due to the interface’s simplicity, the Prometheus team recommends installing and using Grafana for anything more complicated than testing and debugging.</p>
<p>In this post, we’ll use the built-in web interface to ensure that Prometheus and Node Exporter are up and running, and we’ll also take a look at simple queries and graphs.</p>
<p>To begin, point your web browser to <a href="http://your_server_ip/">http://your_server_ip</a>.</p>
<p>In the HTTP authentication dialogue box, enter the username and password you chose in Step 8.</p>
<p><img data-src="/images/posts/190814-1.png" alt="01"></p>
<p>Once logged in, you’ll see the Expression Browser, where you can execute and visualize custom queries.</p>
<p><img data-src="/images/posts/190814-2.png" alt="02"></p>
<p>Before executing any expressions, verify the status of both Prometheus and Node Explorer by clicking first on the Status menu at the top of the screen and then on the Targets menu option. As we have configured Prometheus to scrape both itself and Node Exporter, you should see both targets listed in the UP state.</p>
<p><img data-src="/images/posts/190814-3.png" alt="03"></p>
<p>If either exporter is missing or displays an error message, check the service’s status with the following commands:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo systemctl status prometheus</span><br><span class="line">sudo systemctl status node_exporter</span><br></pre></td></tr></table></figure>
<p>The output for both services should report a status of Active: active (running). If a service either isn’t active at all or is active but still not working correctly, follow the on-screen instructions and re-trace the previous steps before continuing.</p>
<p>Next, to make sure that the exporters are working correctly, we’ll execute a few expressions against Node Exporter.</p>
<p>First, click on the Graph menu at the top of the screen to return to the Expression Browser.</p>
<p><img data-src="/images/posts/190814-4.png" alt="04"></p>
<p>In the Expression field, type node_memory_MemAvailable and press the Execute button to update the Console tab with the amount of memory your server has.</p>
<p><img data-src="/images/posts/190814-5.png" alt="05"></p>
<p>By default, Node Exporter reports this amount in bytes. To convert to megabytes, we’ll use math operators to divide by 1024 twice.</p>
<p>In the Expression field, enter node_memory_MemAvailable/1024/1024 and then press the Execute button.</p>
<p><img data-src="/images/posts/190814-6.png" alt="06"><br>The Console tab will now display the results in megabytes.</p>
<p>If you want to verify the results, execute the free command from your terminal. (The -h flag tells free to report back in a human-readable format, giving us the amount in megabytes.)</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">free</span> <span class="string">-h</span></span><br></pre></td></tr></table></figure>
<p>This output contains details about memory usage, including available memory displayed in the available column.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           488M        144M         17M        3.7M        326M        324M</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<p>In addition to basic operators, the Prometheus query language also provides many functions for aggregating results.</p>
<p>In the Expression field, type avg_over_time(node_memory_MemAvailable[5m])/1024/1024 and click on the Execute button. The result will be the average available memory over the last 5 minutes in megabytes.</p>
<p><img data-src="/images/posts/190814-7.png" alt="07"></p>
<p>Now, click on the Graph tab to display the executed expression as a graph instead of as text.</p>
<p><img data-src="/images/posts/190814-8.png" alt="08"></p>
<p>Finally, while still on this tab, hover your mouse over the graph for additional details about any specific point along the graph’s X and Y axes.</p>
<p>If you’d like to learn more about creating expressions in Prometheus’ built-in web interface, see the Querying Prometheus portion of the official documentation.</p>
<br>

<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Monitor Remote Servers with Zabbix</title>
    <url>/2019/Zabbix/</url>
    <content><![CDATA[<p><u>Zabbix is open-source monitoring software for networks and applications</u>. It offers real-time monitoring of thousands of metrics collected from servers, virtual machines, network devices, and web applications. These metrics can help you determine the current health of your IT infrastructure and detect problems with hardware or software components before customers complain. Useful information is stored in a database so you can analyze data over time and improve the quality of provided services, or plan upgrades of your equipment.</p>
<span id="more"></span> 

<p>Zabbix uses several options for collecting metrics, including <strong>agentless monitoring of user services</strong> and <strong>client-server architecture</strong>. To collect server metrics, it uses a small agent on the monitored client to gather data and send it to the Zabbix server. Zabbix supports encrypted communication between the server and connected clients, so your data is protected while it travels over insecure networks.</p>
<p>The Zabbix server stores its data in a relational database powered by MySQL, PostgreSQL, or Oracle. You can also store historical data in nosql databases like Elasticsearch and TimescaleDB. Zabbix provides a web interface so you can view data and configure system settings.</p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-zabbix-to-securely-monitor-remote-servers-on-ubuntu-18-04">In this post</a>, we will configure two machines. One will be configured as the server, and the other as a client that we monitor. The server will use a MySQL database to record monitoring data and use Apache to serve the web interface.</p>
<p>To  be more specific, we need:</p>
<ul>
<li><p>Two Ubuntu servers set up by following the <a href="/2018/Initial-Server-Setup/">Initial Server Setup Steps</a>. On one server, we will install Zabbix server. It will monitor your second server; this second server will be referred to as the second Ubuntu server.</p>
</li>
<li><p>The server that will run the Zabbix server needs Apache, MySQL, and PHP installed. </p>
</li>
</ul>
<p>Additionally, because the Zabbix Server is used to access valuable information about your infrastructure that you would not want unauthorized users to access, it’s important that you keep your server secure by installing a <u>TLS/SSL certificate</u>. This is optional but strongly encouraged. </p>
<br>

<blockquote>
<p>  More: <a href="https://www.digitalocean.com/community/tutorials/how-to-gather-infrastructure-metrics-with-metricbeat-on-ubuntu-18-04">How To Gather Infrastructure Metrics with Metricbeat on Ubuntu</a></p>
</blockquote>
<br>

<hr>
<h2 id="Install-Zabbix-Server"><a href="#Install-Zabbix-Server" class="headerlink" title="Install Zabbix Server"></a>Install Zabbix Server</h2><p>First, you need to install Zabbix on the server where you installed MySQL, Apache, and PHP. Log into this machine as your non-root user:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">merikanto@zabbix_server_ip_address</span></span><br></pre></td></tr></table></figure>
<p>Zabbix is available in Ubuntu’s package manager, but it’s outdated, so use the official Zabbix repository to install the latest stable version. Download and install the repository configuration package:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wget https://repo.zabbix.com/zabbix/4.2/ubuntu/pool/main/z/zabbix-release \</span><br><span class="line">/zabbix-release_4.2-1+bionic_all.deb</span><br><span class="line"></span><br><span class="line">sudo dpkg -i zabbix-release_4.2-1+bionic_all.deb</span><br></pre></td></tr></table></figure>
<p>Update the package index so the new repository is included:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>
<p>Then install the Zabbix server and web frontend with MySQL database support:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">zabbix-server-mysql</span> <span class="string">zabbix-frontend-php</span></span><br></pre></td></tr></table></figure>
<p>Also, install the Zabbix agent, which will let you collect data about the Zabbix server status itself.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">zabbix-agent</span></span><br></pre></td></tr></table></figure>
<p>Before you can use Zabbix, you have to set up a database to hold the data that the Zabbix server will collect from its agents. You can do this in the next step.</p>
<br>

<hr>
<h2 id="Config-MySQL-for-Zabbix"><a href="#Config-MySQL-for-Zabbix" class="headerlink" title="Config MySQL for Zabbix"></a>Config MySQL for Zabbix</h2><p>You need to create a new MySQL database and populate it with some basic information in order to make it suitable for Zabbix. You’ll also create a specific user for this database so Zabbix isn’t logging into MySQL with the root account.</p>
<p>Log into MySQL as the root user using the root password that you set up during the MySQL server installation:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mysql</span> <span class="string">-uroot</span> <span class="string">-p</span></span><br></pre></td></tr></table></figure>
<p>Create the Zabbix database with UTF-8 character support:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database zabbix <span class="type">character</span> <span class="keyword">set</span> utf8 <span class="keyword">collate</span> utf8_bin;</span><br></pre></td></tr></table></figure>
<p>Then create a user that the Zabbix server will use, give it access to the new database, and set the password for the user:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> zabbix.<span class="operator">*</span> <span class="keyword">to</span> zabbix<span class="variable">@localhost</span> identified <span class="keyword">by</span> <span class="string">&#x27;your_zabbix_mysql_password&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>Then apply these new permissions:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<p>Next you have to import the initial schema and data. The Zabbix installation provided you with a file that sets this up.</p>
<p>Run the following command to set up the schema and import the data into the zabbix database. Use zcat since the data in the file is compressed.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">zcat</span> <span class="string">/usr/share/doc/zabbix-server-mysql/create.sql.gz</span> <span class="string">|</span> <span class="string">mysql</span> <span class="string">-uzabbix</span> <span class="string">-p</span> <span class="string">zabbix</span></span><br></pre></td></tr></table></figure>
<p>Enter the password for the zabbix MySQL user that you configured when prompted.</p>
<p>This command will not output any errors if it was successful. If you see the error ERROR 1045 (28000): Access denied for userzabbix@’localhost’ (using password: YES) then make sure you used the password for the zabbix user and not the root user.</p>
<p>In order for the Zabbix server to use this database, you need to set the database password in the Zabbix server configuration file. Open the configuration file in your preferred text editor. This post will use vim:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/zabbix/zabbix_server.conf</span></span><br></pre></td></tr></table></figure>
<p>Look for the following section of the file:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">### Option: DBPassword                           </span></span><br><span class="line"><span class="comment">#       Database password. Ignored for SQLite.   </span></span><br><span class="line"><span class="comment">#       Comment this line if no password is used.</span></span><br><span class="line"><span class="comment">#                                                </span></span><br><span class="line"><span class="comment"># Mandatory: no                                  </span></span><br><span class="line"><span class="comment"># Default:                                       </span></span><br><span class="line"><span class="comment"># DBPassword=</span></span><br></pre></td></tr></table></figure>
<p>These comments in the file explain how to connect to the database. You need to set the DBPassword value in the file to the password for your database user. Add this line below those comments to configure the database:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">DBPassword=your_zabbix_mysql_password</span></span><br></pre></td></tr></table></figure>

<p>That takes care of the Zabbix server configuration. Next, you will make some modifications to your PHP setup in order for the Zabbix web interface to work properly.</p>
<br>

<hr>
<h2 id="Config-PHP-for-Zabbix"><a href="#Config-PHP-for-Zabbix" class="headerlink" title="Config PHP for Zabbix"></a>Config PHP for Zabbix</h2><p>The Zabbix web interface is written in PHP and requires some special PHP server settings. The Zabbix installation process created an Apache configuration file that contains these settings. It is located in the directory /etc/zabbix and is loaded automatically by Apache. You need to make a small change to this file, so open it up with the following:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/zabbix/apache.conf</span></span><br></pre></td></tr></table></figure>
<p>The file contains PHP settings that meet the necessary requirements for the Zabbix web interface. However, the timezone setting is commented out by default. To make sure that Zabbix uses the correct time, you need to set the appropriate timezone.</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">IfModule</span> <span class="attr">mod_php7.c</span>&gt;</span></span><br><span class="line">    php_value max_execution_time 300</span><br><span class="line">    php_value memory_limit 128M</span><br><span class="line">    php_value post_max_size 16M</span><br><span class="line">    php_value upload_max_filesize 2M</span><br><span class="line">    php_value max_input_time 300</span><br><span class="line">    php_value always_populate_raw_post_data -1</span><br><span class="line">    # php_value date.timezone Europe/Riga</span><br><span class="line"><span class="tag">&lt;/<span class="name">IfModule</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Uncomment the timezone line, highlighted in the preceding code block, and change it to your timezone. You can use this list of supported time zones to find the right one for you. Then save and close the file.</p>
<p>Now restart Apache to apply these new settings.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">apache2</span></span><br></pre></td></tr></table></figure>
<p>You can now start the Zabbix server.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">zabbix-server</span></span><br></pre></td></tr></table></figure>
<p>Then check whether the Zabbix server is running properly:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">zabbix-server</span></span><br></pre></td></tr></table></figure>
<p>Finally, enable the server to start at boot time:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">zabbix-server</span></span><br></pre></td></tr></table></figure>
<p>The server is set up and connected to the database. Next, set up the web frontend.</p>
<br>

<h2 id="Config-Settings-for-Zabbix-Web-UI"><a href="#Config-Settings-for-Zabbix-Web-UI" class="headerlink" title="Config Settings for Zabbix Web UI"></a>Config Settings for Zabbix Web UI</h2><hr>
<p>The web interface lets you see reports and add hosts that you want to monitor, but it needs some initial setup before you can use it. Launch your browser and go to the address <a href="http://zabbix_server_name/zabbix/">http://zabbix_server_name/zabbix/</a>. On the first screen, you will see a welcome message. Click Next step to continue.</p>
<p>On the next screen, you will see the table that lists all of the prerequisites to run Zabbix.</p>
<p><img data-src="/images/posts/190721-1.png" alt="01"></p>
<p>All of the values in this table must be OK, so verify that they are. Be sure to scroll down and look at all of the prerequisites. Once you’ve verified that everything is ready to go, click Next step to proceed.</p>
<p>The next screen asks for database connection information.</p>
<p><img data-src="/images/posts/190721-2.png" alt="02"></p>
<p>You told the Zabbix server about your database, but the Zabbix web interface also needs access to the database to manage hosts and read data. Therefore enter the MySQL credentials you configured in Step 2 and click Next step to proceed.</p>
<p>On the next screen, you can leave the options at their default values.</p>
<p><img data-src="/images/posts/190721-3.png" alt="03"></p>
<p>The Name is optional; it is used in the web interface to distinguish one server from another in case you have several monitoring servers. Click Next step to proceed.</p>
<p>The next screen will show the pre-installation summary so you can confirm everything is correct.</p>
<p><img data-src="/images/posts/190721-4.png" alt="04"></p>
<p>Click Next step to proceed to the final screen.</p>
<p>The web interface setup is complete! This process creates the configuration file /usr/share/zabbix/conf/zabbix.conf.php which you could back up and use in the future. Click Finish to proceed to the login screen. The default user is Admin and the password is zabbix.</p>
<p>Before you log in, set up the Zabbix agent on your second Ubuntu server.</p>
<br>

<hr>
<h2 id="Install-amp-Config-Zabbix-Agent"><a href="#Install-amp-Config-Zabbix-Agent" class="headerlink" title="Install &amp; Config Zabbix Agent"></a>Install &amp; Config Zabbix Agent</h2><p>Now you need to configure the agent software that will send monitoring data to the Zabbix server.</p>
<p>Log in to the second Ubuntu server:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">merikanto@second_ubuntu_server_ip_address</span></span><br></pre></td></tr></table></figure>
<p>Then, just like on the Zabbix server, run the following commands to install the repository configuration package:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">wget</span> <span class="string">https://repo.zabbix.com/zabbix/4.2/ubuntu/pool</span> <span class="string">\</span></span><br><span class="line"><span class="string">/main/z/zabbix-release/zabbix-release_4.2-1+bionic_all.deb</span></span><br><span class="line"></span><br><span class="line"><span class="string">sudo</span> <span class="string">dpkg</span> <span class="string">-i</span> <span class="string">zabbix-release_4.2-1+bionic_all.deb</span></span><br></pre></td></tr></table></figure>
<p>Next, update the package index:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>
<p>Then install the Zabbix agent:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">zabbix-agent</span></span><br></pre></td></tr></table></figure>
<p>While Zabbix supports certificate-based encryption, setting up a certificate authority is beyond the scope of this post, but you can use pre-shared keys (PSK) to secure the connection between the server and agent.</p>
<p>First, generate a PSK:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo sh -c <span class="string">&quot;openssl rand -hex 32 &gt; /etc/zabbix/zabbix_agentd.psk&quot;</span></span><br></pre></td></tr></table></figure>
<p>Show the key so you can copy it somewhere. You will need it to configure the host.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">/etc/zabbix/zabbix_agentd.psk</span></span><br></pre></td></tr></table></figure>
<p>The key will look something like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">12eb854dea38ac9ee7d1ded2d74cee6262b0a56710f6946f7913d674ab82cdd4</span></span><br></pre></td></tr></table></figure>
<p>Now edit the Zabbix agent settings to set up its secure connection to the Zabbix server. Open the agent configuration file in your text editor:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/zabbix/zabbix_agentd.conf</span></span><br></pre></td></tr></table></figure>
<p>Each setting within this file is documented via informative comments throughout the file, but you only need to edit some of them.</p>
<p>First you have to edit the IP address of the Zabbix server. Find the following section:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">### Option: Server</span></span><br><span class="line"><span class="comment">#       List of comma delimited IP addresses (or hostnames) of Zabbix servers.</span></span><br><span class="line"><span class="comment">#       Incoming connections will be accepted only from the hosts listed here.</span></span><br><span class="line"><span class="comment">#       If IPv6 support is enabled then &#x27;127.0.0.1&#x27;, &#x27;::127.0.0.1&#x27;, &#x27;::ffff:127.0.0.1&#x27; are treated equally.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Mandatory: no</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment"># Server=</span></span><br><span class="line"></span><br><span class="line">Server=127.0.0.1</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Change the default value to the IP of your Zabbix server:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Server=zabbix_server_ip_address</span></span><br></pre></td></tr></table></figure>
<p>Next, find the section that configures the secure connection to the Zabbix server and enable pre-shared key support. Find the TLSConnect section, which looks like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">### Option: TLSConnect</span></span><br><span class="line"><span class="comment">#       How the agent should connect to server or proxy. Used for active checks.</span></span><br><span class="line"><span class="comment">#       Only one value can be specified:</span></span><br><span class="line"><span class="comment">#               unencrypted - connect without encryption</span></span><br><span class="line"><span class="comment">#               psk         - connect using TLS and a pre-shared key</span></span><br><span class="line"><span class="comment">#               cert        - connect using TLS and a certificate</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Mandatory: yes, if TLS certificate or PSK parameters are defined (even for &#x27;unencrypted&#x27; connection)</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment"># TLSConnect=unencrypted</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Then add this line to configure pre-shared key support:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TLSConnect=psk</span></span><br></pre></td></tr></table></figure>
<p>Next, locate the TLSAccept section, which looks like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">### Option: TLSAccept</span></span><br><span class="line"><span class="comment">#       What incoming connections to accept.</span></span><br><span class="line"><span class="comment">#       Multiple values can be specified, separated by comma:</span></span><br><span class="line"><span class="comment">#               unencrypted - accept connections without encryption</span></span><br><span class="line"><span class="comment">#               psk         - accept connections secured with TLS and a pre-shared key</span></span><br><span class="line"><span class="comment">#               cert        - accept connections secured with TLS and a certificate</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Mandatory: yes, if TLS certificate or PSK parameters are defined (even for &#x27;unencrypted&#x27; connection)</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment"># TLSAccept=unencrypted</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Configure incoming connections to support pre-shared keys by adding this line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TLSAccept=psk</span></span><br></pre></td></tr></table></figure>
<p>Next, find the TLSPSKIdentity section, which looks like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">### Option: TLSPSKIdentity</span></span><br><span class="line"><span class="comment">#       Unique, case sensitive string used to identify the pre-shared key.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Mandatory: no</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment"># TLSPSKIdentity=</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Choose a unique name to identify your pre-shared key by adding this line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TLSPSKIdentity=PSK</span> <span class="number">001</span></span><br></pre></td></tr></table></figure>
<p>You’ll use this as the PSK ID when you add your host through the Zabbix web interface.</p>
<p>Then set the option that points to your previously created pre-shared key. Locate the TLSPSKFile option:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">### Option: TLSPSKFile</span></span><br><span class="line"><span class="comment">#       Full pathname of a file containing the pre-shared key.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Mandatory: no</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment"># TLSPSKFile=</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Add this line to point the Zabbix agent to your PSK file you created:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TLSPSKFile=/etc/zabbix/zabbix_agentd.psk</span></span><br></pre></td></tr></table></figure>
<p>Save and close the file. Now you can restart the Zabbix agent and set it to start at boot time:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">zabbix-agent</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">zabbix-agent</span></span><br></pre></td></tr></table></figure>
<p>For good measure, check that the Zabbix agent is running properly:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">zabbix-agent</span></span><br></pre></td></tr></table></figure>
<p>The agent will listen on port 10050 for connections from the server. Configure UFW to allow connections to this port:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ufw</span> <span class="string">allow</span> <span class="number">10050</span><span class="string">/tcp</span></span><br></pre></td></tr></table></figure>
<p>You can learn more about UFW in How To Set Up a Firewall with UFW on Ubuntu 18.04.</p>
<p>Your agent is now ready to send data to the Zabbix server. But in order to use it, you have to link to it from the server’s web console. In the next step, you will complete the configuration.</p>
<br>

<hr>
<h2 id="Add-New-Host-to-Zabbix-Server"><a href="#Add-New-Host-to-Zabbix-Server" class="headerlink" title="Add New Host to Zabbix Server"></a>Add New Host to Zabbix Server</h2><p>Installing an agent on a server you want to monitor is only half of the process. Each host you want to monitor needs to be registered on the Zabbix server, which you can do through the web interface.</p>
<p>Log in to the Zabbix Server web interface by navigating to the address <a href="http://zabbix_server_name/zabbix/">http://zabbix_server_name/zabbix/</a>.</p>
<p><img data-src="/images/posts/190721-5.png" alt="05"></p>
<p>When you have logged in, click on Configuration, and then Hosts in the top navigation bar. Then click the Create host button in the top right corner of the screen. This will open the host configuration page.</p>
<p><img data-src="/images/posts/190721-6.png" alt="06"></p>
<p>Adjust the Host name and IP address to reflect the host name and IP address of your second Ubuntu server, then add the host to a group. You can select an existing group, for example Linux servers, or create your own group. The host can be in multiple groups. To do this, enter the name of an existing or new group in the Groups field and select the desired value from the proposed list.</p>
<p>Once you’ve added the group, click the Templates tab.</p>
<p><img data-src="/images/posts/190721-7.png" alt="07"></p>
<p>Type Template OS Linux in the Search field and then click Add to add this template to the host.</p>
<p>Next, navigate to the Encryption tab. Select PSK for both Connections to host and Connections from host. Then set PSK identity to PSK 001, which is the value of the TLSPSKIdentity setting of the Zabbix agent you configured previously. Then set PSK value to the key you generated for the Zabbix agent. It’s the one stored in the file /etc/zabbix/zabbix_agentd.psk on the agent machine.</p>
<p><img data-src="/images/posts/190721-8.png" alt="08"></p>
<p>Finally, click the Add button at the bottom of the form to create the host.</p>
<p>You will see your new host in the list. Wait for a minute and reload the page to see green labels indicating that everything is working fine and the connection is encrypted.</p>
<p><img data-src="/images/posts/190721-9.png" alt="09"></p>
<p>If you have additional servers you need to monitor, log in to each host, install the Zabbix agent, generate a PSK, configure the agent, and add the host to the web interface following the same steps you followed to add your first host.</p>
<p>The Zabbix server is now monitoring your second Ubuntu server. Now, set up email notifications to be notified about problems.</p>
<br>

<hr>
<h2 id="Config-Email-Notifications"><a href="#Config-Email-Notifications" class="headerlink" title="Config Email Notifications"></a>Config Email Notifications</h2><p>Zabbix automatically supports several types of notifications: email, Jabber, SMS, etc. You can also use alternative notification methods, such as Telegram or Slack. You can see the full list of integrations here.</p>
<p>The simplest communication method is email, and this post will configure notifications for this media type.</p>
<p>Click on Administration, and then Media types in the top navigation bar. You will see the list of all media types. Click on Email.</p>
<p>Adjust the SMTP options according to the settings provided by your email service. This post uses Gmail’s SMTP capabilities to set up email notifications; if you would like more information about setting this up, see How To Use Google’s SMTP Server.</p>
<blockquote>
<p><strong>Note:</strong> </p>
<p>If you use 2-Step Verification with Gmail, you need to generate an App Password for Zabbix. You don’t need to remember it, you’ll only have to enter an App password once during setup. You will find instructions on how to generate this password in the Google Help Center.</p>
</blockquote>
<p>You can also choose the message format—html or plain text. Finally, click the Update button at the bottom of the form to update the email parameters.</p>
<p><img data-src="/images/posts/190721-10.png" alt="10"></p>
<p>Now, create a new user. Click on Administration, and then Users in the top navigation bar. You will see the list of users. Then click the Create user button in the top right corner of the screen. This will open the user configuration page.</p>
<p><img data-src="/images/posts/190721-11.png" alt="11"></p>
<p>Enter the new username in the Alias field and set up a new password. Next, add the user to the administrator’s group. Type Zabbix administrators in the Groups field and select it from the proposed list.</p>
<p>Once you’ve added the group, click the Media tab and click on the Add underlined link. You will see a pop-up window.</p>
<p><img data-src="/images/posts/190721-12.png" alt="12"></p>
<p>Enter your email address in the Send to field. You can leave the rest of the options at the default values. Click the Add button at the bottom to submit.</p>
<p>Now navigate to the Permissions tab. Select Zabbix Super Admin from the User type drop-down menu.</p>
<p>Finally, click the Add button at the bottom of the form to create the user.</p>
<p>Now you need to enable notifications. Click on the Configuration tab, and then Actions in the top navigation bar. You will see a pre-configured action, which is responsible for sending notifications to all Zabbix administrators. You can review and change the settings by clicking on its name. For the purposes of this post, use the default parameters. To enable the action, click on the red Disabled link in the Status column.</p>
<p>Now you are ready to receive alerts. In the next step, you will generate one to test your notification setup.</p>
<br>

<hr>
<h2 id="Generate-a-Test-Alert"><a href="#Generate-a-Test-Alert" class="headerlink" title="Generate a Test Alert"></a>Generate a Test Alert</h2><p>In this step, you will generate a test alert to ensure everything is connected. By default, Zabbix keeps track of the amount of free disk space on your server. It automatically detects all disk mounts and adds the corresponding checks. This discovery is executed every hour, so you need to wait a while for the notification to be triggered.</p>
<p>Create a temporary file that’s large enough to trigger Zabbix’s file system usage alert. To do this, log in to your second Ubuntu server if you’re not already connected.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">merikanto@second_ubuntu_server_ip_address</span></span><br></pre></td></tr></table></figure>
<p>Next, determine how much free space you have on the server. You can use the df command to find out:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">df</span> <span class="string">-h</span></span><br></pre></td></tr></table></figure>
<p>The command df will report the disk space usage of your file system, and the -h will make the output human-readable. You’ll see output like the following:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/vda1        25G  1.2G   23G   5% /</span><br></pre></td></tr></table></figure>
<p>In this case, the free space is 23GB. Your free space may differ.</p>
<p>Use the fallocate command, which allows you to pre-allocate or de-allocate space to a file, to create a file that takes up more than 80% of the available disk space. This will be enough to trigger the alert:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">fallocate</span> <span class="string">-l</span> <span class="string">20G</span> <span class="string">/tmp/temp.img</span></span><br></pre></td></tr></table></figure>
<p>After around an hour, Zabbix will trigger an alert about the amount of free disk space and will run the action you configured, sending the notification message. You can check your inbox for the message from the Zabbix server. You will see a message like:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Problem started at 10:37:54 on 2019.04.05</span><br><span class="line">Problem name: Free disk space is less than 20% on volume /</span><br><span class="line">Host: Second Ubuntu server</span><br><span class="line">Severity: Warning</span><br><span class="line"></span><br><span class="line">Original problem ID: 34</span><br></pre></td></tr></table></figure>
<p>You can also navigate to the Monitoring tab, and then Dashboard to see the notification and its details.</p>
<p><img data-src="/images/posts/190721-13.png" alt="13"></p>
<p>Now that you know the alerts are working, delete the temporary file you created so you can reclaim your disk space:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">rm</span> <span class="string">-f</span> <span class="string">/tmp/temp.img</span></span><br></pre></td></tr></table></figure>
<p>After a minute Zabbix will send the recovery message and the alert will disappear from main dashboard.</p>
<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Centralize Log with rsyslog &amp; Logstash</title>
    <url>/2019/Centralize-Logs/</url>
    <content><![CDATA[<p>Making sense of the millions of log lines your organization generates can be a <a href="https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-rsyslog-logstash-and-elasticsearch-on-ubuntu-14-04">daunting challenge</a>. On one hand, these log lines provide a view into application performance, server performance metrics, and security. On the other hand, log management and analysis can be very time consuming, which may hinder adoption of these increasingly necessary services.</p>
<p>Open-source software, such as <strong>rsyslog</strong>, <strong>Elasticsearch</strong>, and <strong>Logstash</strong> provide the tools to transmit, transform, and store log data. In this post, we will see how to <u>create a centralized rsyslog server to store log files from multiple systems</u>, and then <u>use Logstash to send them to an Elasticsearch server</u>.</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>We will see how to centralize logs generated or received by syslog, <u>specifically the variant known as <strong>rsyslog</strong></u>. Syslog, and syslog-based tools like rsyslog, collect important information from the kernel and many of the programs that run to keep UNIX-like servers running. </p>
<p>As syslog is a standard, and not just a program, many software projects support sending data to syslog. By centralizing this data, you can more easily audit security, monitor application behavior, and keep track of other vital server information.</p>
<p>From a centralized, or aggregating rsyslog server, you can then forward the data to Logstash, which can further parse and enrich your log data before sending it on to Elasticsearch. We will setup:</p>
<ul>
<li>A single, client (or forwarding) rsyslog server</li>
<li>A single, server (or collecting) rsyslog server, to receive logs from the rsyslog client</li>
<li>A Logstash instance to receive the messages from the rsyslog collecting server</li>
<li>An Elasticsearch server to receive the data from Logstash</li>
</ul>
<br>

<p>We will also use Digital Ocean’s services. Create the following Droplets with private networking enabled:</p>
<ul>
<li>  Ubuntu Droplet named rsyslog-client</li>
<li>  Ubuntu  Droplet (1 GB or greater) named rsyslog-server where centralized logs will be stored and Logstash will be installed</li>
<li>  Ubuntu Droplet with Elasticsearch installed </li>
</ul>
<p>And don’t forget to set up the <a href="/2018/Initial-Server-Setup/">initial Ubuntu Server</a>. </p>
<br>

<hr>
<h2 id="Determine-Private-IP"><a href="#Determine-Private-IP" class="headerlink" title="Determine Private IP"></a>Determine Private IP</h2><p>In this section, you will determine which private IP addresses are assigned to each Droplet. This information will be needed through the post.</p>
<p>On each Droplet, find its IP addresses with the <code>ifconfig</code> command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ifconfig</span> <span class="string">-a</span></span><br></pre></td></tr></table></figure>
<p>The -a option is used to show all interfaces. The primary Ethernet interface is usually called eth0. In this case, however, we want the IP from eth1, the private IP address. These private IP addresses are not routable over the Internet and are used to communicate in private LANs — in this case, between servers in the same data center over secondary interfaces.</p>
<p>The output will look similar to:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output from ifconfig -a</span></span><br><span class="line"></span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 04:01:06:a7:6f:01  </span><br><span class="line">          inet addr:123.456.78.90  Bcast:123.456.78.255  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::601:6ff:fea7:6f01/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:168 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:137 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:18903 (18.9 KB)  TX bytes:15024 (15.0 KB)</span><br><span class="line"></span><br><span class="line">eth1      Link encap:Ethernet  HWaddr 04:01:06:a7:6f:02  </span><br><span class="line">          inet addr:10.128.2.25  Bcast:10.128.255.255  Mask:255.255.0.0</span><br><span class="line">          inet6 addr: fe80::601:6ff:fea7:6f02/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:6 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:5 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:468 (468.0 B)  TX bytes:398 (398.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          inet6 addr: ::1/128 Scope:Host</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:16436  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure>

<p>The section to note here is eth1 and within that inet addr. In this case, the private network address is 10.128.2.25. This address is only accessible from other servers, within the same region, that have private networking enabled.</p>
<p>Be sure to repeat this step for all 3 Droplets. Save these private IP addresses somewhere secure. They will be used throughout this post.</p>
<br>

<hr>
<h2 id="Set-BindIP-for-Elasticsearch"><a href="#Set-BindIP-for-Elasticsearch" class="headerlink" title="Set BindIP for Elasticsearch"></a>Set BindIP for Elasticsearch</h2><p>The <a href="/2019/ELK/">post on ELK</a> shows you how to set the bind address to localhost so that other servers can’t access the service. However, we need to change this so Logstash can send it data over its private network address.</p>
<p>We will bind Elasticsearch to its private IP address. Elasticsearch will only listen to requests to this IP address.</p>
<p>On the Elasticsearch server, edit the configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/elasticsearch/elasticsearch.yml</span></span><br></pre></td></tr></table></figure>
<p>Find the line that contains network.bind_host. If it is commented out, uncomment it by removing the # character at the beginning of the line. Change the value to the private IP address for the Elasticsearch server so it looks like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">network.bind_host:</span> <span class="string">private_ip_address</span></span><br></pre></td></tr></table></figure>
<p>Finally, restart Elasticsearch to enable the change.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">elasticsearch</span> <span class="string">restart</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Warning: It is very important that you only allow servers you trust to connect to Elasticsearch. Using iptables is highly recommended. For this post, you only want to trust the private IP address of the rsyslog-server Droplet, which has Logstash running on it.</p>
</blockquote>
<br>

<hr>
<h2 id="Centralized-Server-to-Receive-Data"><a href="#Centralized-Server-to-Receive-Data" class="headerlink" title="Centralized Server to Receive Data"></a>Centralized Server to Receive Data</h2><p>In this section, we will configure the rsyslog-server Droplet to be the centralized server able to receive data from other syslog servers on port 514.</p>
<p>To configure the rsyslog-server to receive data from other syslog servers, edit <code>/etc/rsyslog.conf</code> on the rsyslog-server Droplet:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/rsyslog.conf</span></span><br></pre></td></tr></table></figure>
<p>Find these lines already commented out in your rsyslog.conf:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># provides UDP syslog reception</span></span><br><span class="line"><span class="comment">#$ModLoad imudp</span></span><br><span class="line"><span class="comment">#$UDPServerRun 514</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># provides TCP syslog reception</span></span><br><span class="line"><span class="comment">#$ModLoad imtcp</span></span><br><span class="line"><span class="comment">#$InputTCPServerRun 514</span></span><br></pre></td></tr></table></figure>
<p>The first lines of each section (<code>$ModLoad imudp</code> and <code>$ModLoad imtcp</code>) load the imudp and imtcp modules, respectively. The imudp stands for input module udp, and imtcp stands for input module tcp. These modules listen for incoming data from other syslog servers.</p>
<p>The second lines of each section (``$UDPSerververRun 514<code>and</code>$TCPServerRun 514`) indicate that rsyslog should start the respective UDP and TCP servers for these protocols listening on port 514 (which is the syslog default port).</p>
<p>To enable these modules and servers, uncomment the lines so the file now contains:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># provides UDP syslog reception</span></span><br><span class="line"><span class="variable">$ModLoad</span> imudp</span><br><span class="line"><span class="variable">$UDPServerRun</span> 514</span><br><span class="line"></span><br><span class="line"><span class="comment"># provides TCP syslog reception</span></span><br><span class="line"><span class="variable">$ModLoad</span> imtcp</span><br><span class="line"><span class="variable">$InputTCPServerRun</span> 514</span><br></pre></td></tr></table></figure>
<p>Save and close the rsyslog configuration file.</p>
<p>Restart rsyslog by running:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">rsyslog</span> <span class="string">restart</span></span><br></pre></td></tr></table></figure>
<p>Your centralized rsyslog server is now configured to listen for messages from remote syslog (including rsyslog) instances.</p>
<blockquote>
<p>   <strong>Tip</strong>: To validate your rsyslog configuration file, you can run the <code>sudo rsyslogd -N1</code> command.</p>
</blockquote>
<br>

<h2 id="Send-Data-Remotely-with-rsyslog"><a href="#Send-Data-Remotely-with-rsyslog" class="headerlink" title="Send Data Remotely with rsyslog"></a>Send Data Remotely with rsyslog</h2><p>In this section, we will configure the rsyslog-client to send log data to the ryslog-server Droplet we configured in the last step.</p>
<p>In a default rsyslog setup on Ubuntu, you’ll find two files in <code>/etc/rsyslog.d</code>:</p>
<ul>
<li><code>20-ufw.conf</code></li>
<li><code>50-default.conf</code></li>
</ul>
<p>On the rsyslog-client, edit the default configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/rsyslog.d/50-default.conf</span></span><br></pre></td></tr></table></figure>

<p>Add the following line at the top of the file before the log by facility section, replacing private_ip_of_ryslog_server with the private IP of your centralized server:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">*.*                    @private_ip_of_ryslog_server:514</span><br></pre></td></tr></table></figure>


<p>The first part of the line (.) means we want to send all messages. While it is outside the scope of this post, you can configure rsyslog to send only certain messages. The remainder of the line explains how to send the data and where to send the data. In our case, the @ symbol before the IP address tells rsyslog to use UDP to send the messages. Change this to @@ to use TCP. This is followed by the private IP address of rsyslog-server with rsyslog and Logstash installed on it. The number after the colon is the port number to use.</p>
<p>Restart rsyslog to enable the changes:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">rsyslog</span> <span class="string">restart</span></span><br></pre></td></tr></table></figure>
<p>Congratulations! You are now sending your syslog messages to a centralized server!</p>
<blockquote>
<p>  <strong>Tip</strong>: To validate your rsyslog configuration file, you can run the <code>sudo rsyslogd -N</code>1 command.</p>
</blockquote>
<br>

<hr>
<h2 id="Format-Log-Data-to-JSON"><a href="#Format-Log-Data-to-JSON" class="headerlink" title="Format Log Data to JSON"></a>Format Log Data to JSON</h2><p>Elasticsearch requires that all documents it receives be in JSON format, and rsyslog provides a way to accomplish this by way of a template.</p>
<p>In this step, we will configure our centralized rsyslog server to use a JSON template to format the log data before sending it to Logstash, which will then send it to Elasticsearch on a different server.</p>
<p>Back on the rsyslog-server server, create a new configuration file to format the messages into JSON format before sending to Logstash:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/rsyslog.d/01-json-template.conf</span></span><br></pre></td></tr></table></figure>
<p>Copy the following contents to the file exactly as shown:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">template(name=<span class="string">&quot;json-template&quot;</span></span><br><span class="line">  <span class="built_in">type</span>=<span class="string">&quot;list&quot;</span>) &#123;</span><br><span class="line">    constant(value=<span class="string">&quot;&#123;&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;@timestamp\&quot;:\&quot;&quot;</span>)     property(name=<span class="string">&quot;timereported&quot;</span> dateFormat=<span class="string">&quot;rfc3339&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;@version\&quot;:\&quot;1&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;message\&quot;:\&quot;&quot;</span>)     property(name=<span class="string">&quot;msg&quot;</span> format=<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;sysloghost\&quot;:\&quot;&quot;</span>)  property(name=<span class="string">&quot;hostname&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;severity\&quot;:\&quot;&quot;</span>)    property(name=<span class="string">&quot;syslogseverity-text&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;facility\&quot;:\&quot;&quot;</span>)    property(name=<span class="string">&quot;syslogfacility-text&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;programname\&quot;:\&quot;&quot;</span>) property(name=<span class="string">&quot;programname&quot;</span>)</span><br><span class="line">      constant(value=<span class="string">&quot;\&quot;,\&quot;procid\&quot;:\&quot;&quot;</span>)      property(name=<span class="string">&quot;procid&quot;</span>)</span><br><span class="line">    constant(value=<span class="string">&quot;\&quot;&#125;\n&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Other than the first and the last, notice that the lines produced by this template have a comma at the beginning of them. This is to maintain the JSON structure and help keep the file readable by lining everything up neatly. This template formats your messages in the way that Elasticsearch and Logstash expect to receive them. This is what they will look like:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Example JSON message</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;@timestamp&quot;</span> <span class="string">:</span> <span class="string">&quot;2015-11-18T18:45:00Z&quot;</span>,</span><br><span class="line">  <span class="string">&quot;@version&quot;</span> <span class="string">:</span> <span class="string">&quot;1&quot;</span>,</span><br><span class="line">  <span class="string">&quot;message&quot;</span> <span class="string">:</span> <span class="string">&quot;Your syslog message here&quot;</span>,</span><br><span class="line">  <span class="string">&quot;sysloghost&quot;</span> <span class="string">:</span> <span class="string">&quot;hostname.example.com&quot;</span>,</span><br><span class="line">  <span class="string">&quot;severity&quot;</span> <span class="string">:</span> <span class="string">&quot;info&quot;</span>,</span><br><span class="line">  <span class="string">&quot;facility&quot;</span> <span class="string">:</span> <span class="string">&quot;daemon&quot;</span>,</span><br><span class="line">  <span class="string">&quot;programname&quot;</span> <span class="string">:</span> <span class="string">&quot;my_program&quot;</span>,</span><br><span class="line">  <span class="string">&quot;procid&quot;</span> <span class="string">:</span> <span class="string">&quot;1234&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>Tip</strong>: The rsyslog.com docs show the variables available from rsyslog if you would like to custom the log data. However, you must send it in JSON format to Logstash and then to Elasticsearch.</p>
</blockquote>
<p>The data being sent is not using this format yet. The next step shows out to configure the server to use this template file.</p>
<br>

<h2 id="Centralized-Server-amp-Logstash"><a href="#Centralized-Server-amp-Logstash" class="headerlink" title="Centralized Server &amp; Logstash"></a>Centralized Server &amp; Logstash</h2><hr>
<p>Now that we have the template file that defines the proper JSON format, let’s configure the centralized rsyslog server to send the data to Logstash, which is on the same Droplet for this post.</p>
<p>At startup, rsyslog will look through the files in <code>/etc/rsyslog.d</code> and create its configuration from them. Let’s add our own configuration file to extended the configuration.</p>
<p>On the rsyslog-server, create <code>/etc/rsyslog.d/60-output.conf</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/rsyslog.d/60-output.conf</span></span><br></pre></td></tr></table></figure>
<p>Copy the following lines to this file:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This line sends all lines to defined IP address at port 10514,</span></span><br><span class="line"><span class="comment"># using the &quot;json-template&quot; format template</span></span><br><span class="line"></span><br><span class="line">*.*                         @private_ip_logstash:10514;json-template</span><br></pre></td></tr></table></figure>

<p>The <code>*.*</code> at the beginning means to process the remainder of the line for all log messages. The @ symbols means to use UDP (Use @@ to instead use TCP). The IP address or hostname after the @ is where to forward the messages. In our case, we are using the private IP address for rsyslog-server since the rsyslog centralized server and the Logstash server are installed on the same Droplet. This must match the private IP address you configure Logstash to listen on in the next step.</p>
<p>The port number is next. This post uses port 10514. Note that the Logstash server must listen on the same port using the same protocol. The last part is our template file that shows how to format the data before passing it along.</p>
<p>Do not restart rsyslog yet. First, we have to configure Logstash to receive the messages.</p>
<br>

<hr>
<h2 id="Receive-JSON-Messages-in-Logstash"><a href="#Receive-JSON-Messages-in-Logstash" class="headerlink" title="Receive JSON Messages in Logstash"></a>Receive JSON Messages in Logstash</h2><p>In this step you will install Logstash, configure it to receive JSON messages from rsyslog, and configure it to send the JSON messages on to Elasticsearch.</p>
<p>Logstash requires Java 7 or later. Next, install the security key for the Logstash repository:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">wget</span> <span class="string">-qO</span> <span class="bullet">-</span> <span class="string">https://packages.elastic.co/GPG-KEY-elasticsearch</span> <span class="string">|</span> <span class="string">sudo</span> <span class="string">apt-key</span> <span class="string">add</span> <span class="bullet">-</span></span><br></pre></td></tr></table></figure>
<p>Add the repository definition to your /etc/apt/sources.list file:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb http://packages.elastic.co/logstash/2.3/debian stable main&quot;</span> \</span><br><span class="line">| sudo tee -a /etc/apt/sources.list</span><br></pre></td></tr></table></figure>
<p>Note: Use the echo method described above to add the Logstash repository. Do not use add-apt-repository as it will add a deb-src entry as well, but Elastic does not provide a source package. This will result in an error when you attempt to run apt-get update.</p>
<p>Update your package lists to include the Logstash repository:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>
<p>Finally, install Logstash:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">logstash</span></span><br></pre></td></tr></table></figure>
<p>Now that Logstash is installed, let’s configure it to listen for messages from rsyslog.</p>
<p>The default installation of Logstash looks for configuration files in <code>/etc/logstash/conf.d</code>. Edit the main configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/logstash/conf.d/logstash.conf</span></span><br></pre></td></tr></table></figure>
<p>Then, add these lines to <code>/etc/logstash/conf.d/logstash.conf</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This input block will listen on port 10514 for logs to come in.</span></span><br><span class="line"><span class="comment"># host should be an IP on the Logstash server.</span></span><br><span class="line"><span class="comment"># codec =&gt; &quot;json&quot; indicates that we expect the lines we&#x27;re receiving to be in JSON format</span></span><br><span class="line"><span class="comment"># type =&gt; &quot;rsyslog&quot; is an optional identifier to help identify messaging streams in the pipeline.</span></span><br><span class="line"></span><br><span class="line"><span class="string">input</span> &#123;</span><br><span class="line">  <span class="string">udp</span> &#123;</span><br><span class="line">    <span class="string">host</span> <span class="string">=&gt;</span> <span class="string">&quot;logstash_private_ip&quot;</span></span><br><span class="line">    <span class="string">port</span> <span class="string">=&gt;</span> <span class="number">10514</span></span><br><span class="line">    <span class="string">codec</span> <span class="string">=&gt;</span> <span class="string">&quot;json&quot;</span></span><br><span class="line">    <span class="string">type</span> <span class="string">=&gt;</span> <span class="string">&quot;rsyslog&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is an empty filter block.  You can later add other filters here to further process</span></span><br><span class="line"><span class="comment"># your log lines</span></span><br><span class="line"></span><br><span class="line"><span class="string">filter</span> &#123; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># This output block will send all events of type &quot;rsyslog&quot; to Elasticsearch at the configured</span></span><br><span class="line"><span class="comment"># host and port into daily indices of the pattern, &quot;rsyslog-YYYY.MM.DD&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">output</span> &#123;</span><br><span class="line">  <span class="string">if</span> [<span class="string">type</span>] <span class="string">==</span> <span class="string">&quot;rsyslog&quot;</span> &#123;</span><br><span class="line">    <span class="string">elasticsearch</span> &#123;</span><br><span class="line">      <span class="string">hosts</span> <span class="string">=&gt;</span> [ <span class="string">&quot;elasticsearch_private_ip:9200&quot;</span> ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The syslog protocol is UDP by definition, so this configuration mirrors that standard.</p>
<p>In the input block, set the Logstash host address by replacing <code>logstashprivateip</code> with the private IP address of rsyslog-server, which also has Logstash installed on it.</p>
<p>The input block configure Logstash to listen on port 10514 so it won’t compete with syslog instances on the same machine. A port less than 1024 would require Logstash to be run as root, which is not a good security practice.</p>
<p>Be sure to replace <code>elasticsearchprivateip</code> with the private IP address of your Elasticsearch Droplet. The output block shows a simple conditional configuration. Its object is to only allow matching events through. In this case, that is only events with a “type” of “rsyslog”.</p>
<p>Test your Logstash configuration changes:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">logstash</span> <span class="string">configtest</span></span><br></pre></td></tr></table></figure>
<p>It should display Configuration OK if there are no syntax errors. Otherwise, try and read the error output to see what’s wrong with your Logstash configuration.</p>
<p>When all these steps are completed, you can start your Logstash instance by running:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">logstash</span> <span class="string">start</span></span><br></pre></td></tr></table></figure>
<p>Also restart rsyslog on the same server since it has a Logstash instance to forward to now:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">rsyslog</span> <span class="string">restart</span></span><br></pre></td></tr></table></figure>
<p>To verify that Logstash is listening on port 10514:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">netstat</span> <span class="string">-na</span> <span class="string">|</span> <span class="string">grep</span> <span class="number">10514</span></span><br></pre></td></tr></table></figure>
<p>You should see something like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">udp6</span>       <span class="number">0</span>      <span class="number">0</span> <span class="number">10.128</span><span class="number">.33</span><span class="number">.68</span><span class="string">:10514</span>     <span class="string">:::*</span>  </span><br></pre></td></tr></table></figure>
<p>You will see the private IP address of rsyslog-server and the 10514 port number we are using to listen for rsyslog data.</p>
<blockquote>
<p>Tip: To troubleshoot Logstash, stop the service with sudo service logstash stop and run it in the foreground with verbose messages:</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">/opt/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf --verbose</span><br></pre></td></tr></table></figure>

<p>It will contain usual information such as verifying with IP address and UDP port Logstash is using:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Starting UDP listener &#123;:address=&gt;<span class="string">&quot;10.128.33.68:10514&quot;</span>, :level=&gt;:info&#125;</span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Verify-Elasticsearch-Input"><a href="#Verify-Elasticsearch-Input" class="headerlink" title="Verify Elasticsearch Input"></a>Verify Elasticsearch Input</h2><p>Earlier, we configured Elasticsearch to listen on its private IP address. It should now be receiving messages from Logstash. In this step, we will verify that Elasticsearch is receiving the log data.</p>
<p>The rsyslog-client and rsyslog-server Droplets should be sending all their log data to Logstash, which is then passed along to Elasticsearch. Let’s generate a security message to verify that Elasticsearch is indeed receiving these messages.</p>
<p>On rsyslog-client, execute the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">tail</span> <span class="string">/var/log/auth.log</span></span><br></pre></td></tr></table></figure>
<p>You will see the security log on the local system at the end of the output. It will look similar to:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">May  2 16:43:15 rsyslog-client sudo:    merikanto : TTY=pts/0 ; PWD=/etc/rsyslog.d ; USER=root ; COMMAND=/usr/bin/tail /var/<span class="built_in">log</span>/auth.log</span><br><span class="line">May  2 16:43:15 rsyslog-client sudo: pam_unix(sudo:session): session opened <span class="keyword">for</span> user root by merikanto(uid=0)</span><br></pre></td></tr></table></figure>

<p>With a simple query, you can check Elasticsearch:</p>
<p>Run the following command on the Elasticsearch server or any system that is allowed to access it. Replace elasticsearch_ip with the private IP address of the Elasticsearch server. This IP address must also be the one you configured Elasticsearch to listen on earlier in this post.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">curl -XGET <span class="string">&#x27;http://elasticsearch_ip:9200/_all/_search?q=*&amp;pretty&#x27;</span></span><br></pre></td></tr></table></figure>
<p>In the output you will see something similar to the following:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">      <span class="string">&quot;_index&quot;</span> <span class="string">:</span> <span class="string">&quot;logstash-2016.05.04&quot;</span>,</span><br><span class="line">      <span class="string">&quot;_type&quot;</span> <span class="string">:</span> <span class="string">&quot;rsyslog&quot;</span>,</span><br><span class="line">      <span class="string">&quot;_id&quot;</span> <span class="string">:</span> <span class="string">&quot;AVR8fpR-e6FP4Elp89Ww&quot;</span>,</span><br><span class="line">      <span class="string">&quot;_score&quot;</span> <span class="string">:</span> <span class="number">1.0</span>,</span><br><span class="line">      <span class="string">&quot;_source&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;@timestamp&quot;</span><span class="string">:&quot;2016-05-04T15:59:10.000Z&quot;</span>,<span class="string">&quot;@version&quot;</span><span class="string">:&quot;1&quot;</span>,<span class="string">&quot;message&quot;</span><span class="string">:&quot;</span>    <span class="attr">merikanto :</span> <span class="string">TTY=pts/0</span> <span class="string">;</span> <span class="string">PWD=/home/merikanto</span> <span class="string">;</span> <span class="string">USER=root</span> <span class="string">;</span> <span class="string">COMMAND=/usr/bin/tail</span> <span class="string">/var/log/auth.log&quot;</span>,<span class="string">&quot;sysloghost&quot;</span><span class="string">:&quot;rsyslog-client&quot;</span>,<span class="string">&quot;severity&quot;</span><span class="string">:&quot;notice&quot;</span>,<span class="string">&quot;facility&quot;</span><span class="string">:&quot;authpriv&quot;</span>,<span class="string">&quot;programname&quot;</span><span class="string">:&quot;sudo&quot;</span>,<span class="string">&quot;procid&quot;</span><span class="string">:&quot;-&quot;</span>,<span class="string">&quot;type&quot;</span><span class="string">:&quot;rsyslog&quot;</span>,<span class="string">&quot;host&quot;</span><span class="string">:&quot;10.128.33.68&quot;</span>&#125;</span><br><span class="line">    &#125;<span class="string">,</span></span><br></pre></td></tr></table></figure>

<p>Notice that the name of the Droplet that generated the rsyslog message is in the log (rsyslog-client).</p>
<p>With this simple verification step, our centralized rsyslog setup is complete and fully operational.</p>
<br>


<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>再見理想</title>
    <url>/Notes/Beyond/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid passcode." data-whm="Unverified decryption.">
  <script id="hbeData" type="hbeData" data-hmacdigest="3bb3ea9dab0b455806c2575c3e0f9e72ad8cab2df5eae2f965be911e1247d900">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-wave">
      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-wave"><p style="text-align:center; font-size:0.8em; font-weight:100;">Passcode please.</p></span>
      </label>
      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">
        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>
      </svg>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>EFK with Kubernetes</title>
    <url>/2019/Kubernetes-EFK/</url>
    <content><![CDATA[<p>When running multiple services and applications on a Kubernetes cluster, a centralized, cluster-level logging stack can help you quickly sort through and analyze the heavy volume of log data produced by your Pods. One popular centralized logging solution is the <strong>Elasticsearch, Fluentd, and Kibana (EFK)</strong> stack.</p>
<span id="more"></span> 

<p>Elasticsearch is a real-time, distributed, and scalable search engine which allows for full-text and structured search, as well as analytics. It is commonly used to index and search through large volumes of log data, but can also be used to search many different kinds of documents.</p>
<p>Elasticsearch is commonly deployed alongside Kibana, a powerful data visualization frontend and dashboard for Elasticsearch. Kibana allows you to explore your Elasticsearch log data through a web interface, and build dashboards and queries to quickly answer questions and gain insight into your Kubernetes applications.</p>
<p>In this post we’ll use Fluentd to collect, transform, and ship log data to the Elasticsearch backend. Fluentd is a popular open-source data collector that we’ll set up on our Kubernetes nodes to tail container log files, filter and transform the log data, and deliver it to the Elasticsearch cluster, where it will be indexed and stored.</p>
<p>We’ll begin by configuring and launching a scalable Elasticsearch cluster, and then create the Kibana Kubernetes Service and Deployment. To conclude, we’ll set up Fluentd as a DaemonSet so it runs on every Kubernetes worker node.</p>
<br>

<hr>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this post, we will see how to set up and configure Elasticsearch, Fluentd, and Kibana on a Kubernetes cluster. We’ve used a minimal logging architecture that consists of a single logging agent Pod running on each Kubernetes worker node.</p>
<p>Before deploying this logging stack into your production Kubernetes cluster, it’s best to tune the resource requirements and limits as indicated throughout this post. You may also want to set up X-Pack to enable built-in monitoring and security features.</p>
<p>The logging architecture we’ve used here consists of 3 Elasticsearch Pods, a single Kibana Pod (not load-balanced), and a set of Fluentd Pods rolled out as a DaemonSet. You may wish to scale this setup depending on your production use case. To learn more about scaling your Elasticsearch and Kibana stack, consult Scaling Elasticsearch.</p>
<p>Kubernetes also allows for more complex logging agent architectures that may better suit your use case. To learn more, consult Logging Architecture from the Kubernetes docs.</p>
<br>

<hr>
<h2 id="Create-a-Namespace"><a href="#Create-a-Namespace" class="headerlink" title="Create a Namespace"></a>Create a Namespace</h2><p>Before we roll out an Elasticsearch cluster, we’ll first create a Namespace into which we’ll install all of our logging instrumentation. Kubernetes lets you separate objects running in your cluster using a “virtual cluster” abstraction called Namespaces. In this post, we’ll create a kube-logging namespace into which we’ll install the EFK stack components. This Namespace will also allow us to quickly clean up and remove the logging stack without any loss of function to the Kubernetes cluster.</p>
<p>To begin, first investigate the existing Namespaces in your cluster using kubectl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">namespaces</span></span><br></pre></td></tr></table></figure>

<p>You should see the following three initial Namespaces, which come preinstalled with your Kubernetes cluster:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME          STATUS    AGE</span><br><span class="line">default       Active    5m</span><br><span class="line">kube-system   Active    5m</span><br><span class="line">kube-public   Active    5m</span><br></pre></td></tr></table></figure>

<p>The default Namespace houses objects that are created without specifying a Namespace. The kube-system Namespace contains objects created and used by the Kubernetes system, like kube-dns, kube-proxy, and kubernetes-dashboard. It’s good practice to keep this Namespace clean and not pollute it with your application and instrumentation workloads.</p>
<p>The kube-public Namespace is another automatically created Namespace that can be used to store objects you’d like to be readable and accessible throughout the whole cluster, even to unauthenticated users.</p>
<p>To create the kube-logging Namespace, first open and edit a file called kube-logging.yaml using your favorite editor, such as vim:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">kube-logging.yaml</span></span><br></pre></td></tr></table></figure>

<p>Inside your editor, paste the following Namespace object YAML:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">kube-logging</span></span><br></pre></td></tr></table></figure>

<p>Then, save and close the file.</p>
<p>Here, we specify the Kubernetes object’s kind as a Namespace object. To learn more about Namespace objects, consult the Namespaces Walkthrough in the official Kubernetes documentation. We also specify the Kubernetes API version used to create the object (v1), and give it a name, kube-logging.</p>
<p>Once you’ve created the kube-logging.yaml Namespace object file, create the Namespace using kubectl create with the -f filename flag:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">kube-logging.yaml</span></span><br></pre></td></tr></table></figure>

<p>You should see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">namespace/kube-logging</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>

<p>You can then confirm that the Namespace was successfully created:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">namespaces</span></span><br></pre></td></tr></table></figure>

<p>At this point, you should see the new kube-logging Namespace:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME           STATUS    AGE</span><br><span class="line">default        Active    23m</span><br><span class="line">kube-logging   Active    1m</span><br><span class="line">kube-public    Active    23m</span><br><span class="line">kube-system    Active    23m</span><br></pre></td></tr></table></figure>

<p>We can now deploy an Elasticsearch cluster into this isolated logging Namespace.</p>
<br>

<hr>
<h2 id="Create-Elasticsearch-StatefulSet"><a href="#Create-Elasticsearch-StatefulSet" class="headerlink" title="Create Elasticsearch StatefulSet"></a>Create Elasticsearch StatefulSet</h2><p>Now that we’ve created a Namespace to house our logging stack, we can begin rolling out its various components. We’ll first begin by deploying a 3-node Elasticsearch cluster.</p>
<p>In this post, we use 3 Elasticsearch Pods to avoid the “split-brain” issue that occurs in highly-available, multi-node clusters. At a high-level, “split-brain” is what arises when one or more nodes can’t communicate with the others, and several “split” masters get elected. With 3 nodes, if one gets disconnected from the cluster temporarily, the other two nodes can elect a new master and the cluster can continue functioning while the last node attempts to rejoin. To learn more, consult A new era for cluster coordination in Elasticsearch and Voting configurations.</p>
<br>

<h3 id="Create-Headless-Service"><a href="#Create-Headless-Service" class="headerlink" title="Create Headless Service"></a><u>Create Headless Service</u></h3><p>To start, we’ll create a headless Kubernetes service called elasticsearch that will define a DNS domain for the 3 Pods. A headless service does not perform load balancing or have a static IP; to learn more about headless services, consult the official Kubernetes documentation.</p>
<p>Open a file called elasticsearch_svc.yaml using your favorite editor:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">elasticsearch_svc.yaml</span></span><br></pre></td></tr></table></figure>

<p>Paste in the following Kubernetes service YAML:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9200</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">rest</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9300</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">inter-node</span></span><br></pre></td></tr></table></figure>

<p>We define a Service called elasticsearch in the kube-logging Namespace, and give it the app: elasticsearch label. We then set the .spec.selector to app: elasticsearch so that the Service selects Pods with the app: elasticsearch label. When we associate our Elasticsearch StatefulSet with this Service, the Service will return DNS A records that point to Elasticsearch Pods with the app: elasticsearch label.</p>
<p>We then set clusterIP: None, which renders the service headless. Finally, we define ports 9200 and 9300 which are used to interact with the REST API, and for inter-node communication, respectively.</p>
<p>Create the service using kubectl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">elasticsearch_svc.yaml</span></span><br></pre></td></tr></table></figure>

<p>You should see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">service/elasticsearch</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>

<p>Finally, double-check that the service was successfully created using kubectl get:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl get services --namespace=kube-logging</span><br></pre></td></tr></table></figure>

<p>You should see the following:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">elasticsearch   ClusterIP   None         &lt;none&gt;        9200/TCP,9300/TCP   26s</span><br></pre></td></tr></table></figure>

<p>Now that we’ve set up our headless service and a stable .elasticsearch.kube-logging.svc.cluster.local domain for our Pods, we can go ahead and create the StatefulSet.</p>
<br>

<h3 id="Create-the-StatefulSet"><a href="#Create-the-StatefulSet" class="headerlink" title="Create the StatefulSet"></a><u>Create the StatefulSet</u></h3><p>A Kubernetes StatefulSet allows you to assign a stable identity to Pods and grant them stable, persistent storage. Elasticsearch requires stable storage to persist data across Pod rescheduling and restarts. To learn more about the StatefulSet workload, consult the Statefulsets page from the Kubernetes docs.</p>
<p>Open a file called elasticsearch_statefulset.yaml in your favorite editor:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">elasticsearch_statefulset.yaml</span></span><br></pre></td></tr></table></figure>

<p>We will move through the StatefulSet object definition section by section, pasting blocks into this file.</p>
<p>Begin by pasting in the following block:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">es-cluster</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure>

<p>In this block, we define a StatefulSet called es-cluster in the kube-logging namespace. We then associate it with our previously created elasticsearch Service using the serviceName field. This ensures that each Pod in the StatefulSet will be accessible using the following DNS address: es-cluster-[0,1,2].elasticsearch.kube-logging.svc.cluster.local, where [0,1,2] corresponds to the Pod’s assigned integer ordinal.</p>
<p>We specify 3 replicas (Pods) and set the matchLabels selector to app: elasticseach, which we then mirror in the .spec.template.metadata section. The .spec.selector.matchLabels and .spec.template.metadata.labels fields must match.</p>
<p>We can now move on to the object spec. Paste in the following block of YAML immediately below the preceding block:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.2.0</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9200</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">rest</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9300</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">inter-node</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster.name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">k8s-logs</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node.name</span></span><br><span class="line">            <span class="attr">valueFrom:</span></span><br><span class="line">              <span class="attr">fieldRef:</span></span><br><span class="line">                <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">discovery.seed_hosts</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster.initial_master_nodes</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;es-cluster-0,es-cluster-1,es-cluster-2&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ES_JAVA_OPTS</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;-Xms512m -Xmx512m&quot;</span></span><br></pre></td></tr></table></figure>

<p>Here we define the Pods in the StatefulSet. We name the containers elasticsearch and choose the docker.elastic.co/elasticsearch/elasticsearch:7.2.0 Docker image. At this point, you may modify this image tag to correspond to your own internal Elasticsearch image, or a different version. Note that for the purposes of this post, only Elasticsearch 7.2.0 has been tested.</p>
<p>We then use the resources field to specify that the container needs at least 0.1 vCPU guaranteed to it, and can burst up to 1 vCPU (which limits the Pod’s resource usage when performing an initial large ingest or dealing with a load spike). You should modify these values depending on your anticipated load and available resources. To learn more about resource requests and limits, consult the official Kubernetes Documentation.</p>
<p>We then open and name ports 9200 and 9300 for REST API and inter-node communication, respectively. We specify a volumeMount called data that will mount the PersistentVolume named data to the container at the path /usr/share/elasticsearch/data. We will define the VolumeClaims for this StatefulSet in a later YAML block.</p>
<p>Finally, we set some environment variables in the container:</p>
<ul>
<li><code>cluster.name</code>: The Elasticsearch cluster’s name, which in this post is k8s-logs.</li>
<li><code>node.name</code>: The node’s name, which we set to the .metadata.name field using valueFrom. This will resolve to es-cluster-[0,1,2], depending on the node’s assigned ordinal.</li>
<li><code>discovery.seed_hosts</code>: This field sets a list of master-eligible nodes in the cluster that will seed the node discovery process. In this post, thanks to the headless service we configured earlier, our Pods have domains of the form es-cluster-[0,1,2].elasticsearch.kube-logging.svc.cluster.local, so we set this variable accordingly. Using local namespace Kubernetes DNS resolution, we can shorten this to es-cluster-[0,1,2].elasticsearch. To learn more about Elasticsearch discovery, consult the official Elasticsearch documentation.</li>
<li><code>cluster.initial_master_nodes</code>: This field also specifies a list of master-eligible nodes that will participate in the master election process. Note that for this field you should identify nodes by their node.name, and not their hostnames.</li>
<li><code>ES_JAVA_OPTS</code>: Here we set this to -Xms512m -Xmx512m which tells the JVM to use a minimum and maximum heap size of 512 MB. You should tune these parameters depending on your cluster’s resource availability and needs. To learn more, consult Setting the heap size.</li>
</ul>
<p>The next block we’ll paste in looks as follows:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fix-permissions</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;</span>]</span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">increase-vm-max-map</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;sysctl&quot;</span>, <span class="string">&quot;-w&quot;</span>, <span class="string">&quot;vm.max_map_count=262144&quot;</span>]</span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">increase-fd-ulimit</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;ulimit -n 65536&quot;</span>]</span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>In this block, we define several Init Containers that run before the main elasticsearch app container. These Init Containers each run to completion in the order they are defined. To learn more about Init Containers, consult the official Kubernetes Documentation.</p>
<p>The first, named fix-permissions, runs a chown command to change the owner and group of the Elasticsearch data directory to 1000:1000, the Elasticsearch user’s UID. By default Kubernetes mounts the data directory as root, which renders it inaccessible to Elasticsearch. To learn more about this step, consult Elasticsearch’s “Notes for production use and defaults.”</p>
<p>The second, named increase-vm-max-map, runs a command to increase the operating system’s limits on mmap counts, which by default may be too low, resulting in out of memory errors. To learn more about this step, consult the official Elasticsearch documentation.</p>
<p>The next Init Container to run is increase-fd-ulimit, which runs the ulimit command to increase the maximum number of open file descriptors. To learn more about this step, consult the “Notes for Production Use and Defaults” from the official Elasticsearch documentation.</p>
<blockquote>
<p>Note: </p>
<p><em>The Elasticsearch Notes for Production Use also mentions disabling swapping for performance reasons. Depending on your Kubernetes installation or provider, swapping may already be disabled. To check this, exec into a running container and run <code>cat /proc/swaps</code> to list active swap devices. If you see nothing there, swap is disabled.</em></p>
</blockquote>
<p>Now that we’ve defined our main app container and the Init Containers that run before it to tune the container OS, we can add the final piece to our StatefulSet object definition file: the volumeClaimTemplates.</p>
<p>Paste in the following volumeClaimTemplate block:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteOnce&quot;</span> ]</span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">do-block-storage</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">100Gi</span></span><br></pre></td></tr></table></figure>

<p>In this block, we define the StatefulSet’s volumeClaimTemplates. Kubernetes will use this to create PersistentVolumes for the Pods. In the block above, we name it data (which is the name we refer to in the volumeMounts defined previously), and give it the same app: elasticsearch label as our StatefulSet.</p>
<p>We then specify its access mode as ReadWriteOnce, which means that it can only be mounted as read-write by a single node. We define the storage class as do-block-storage in this post since we use a DigitalOcean Kubernetes cluster for demonstration purposes. You should change this value depending on where you are running your Kubernetes cluster. To learn more, consult the Persistent Volume documentation.</p>
<p>Finally, we specify that we’d like each PersistentVolume to be 100GiB in size. You should adjust this value depending on your production needs.</p>
<p>The complete StatefulSet spec should look something like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">es-cluster</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.2.0</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9200</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">rest</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9300</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">inter-node</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster.name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">k8s-logs</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node.name</span></span><br><span class="line">            <span class="attr">valueFrom:</span></span><br><span class="line">              <span class="attr">fieldRef:</span></span><br><span class="line">                <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">discovery.seed_hosts</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster.initial_master_nodes</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;es-cluster-0,es-cluster-1,es-cluster-2&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ES_JAVA_OPTS</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;-Xms512m -Xmx512m&quot;</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fix-permissions</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;</span>]</span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">increase-vm-max-map</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;sysctl&quot;</span>, <span class="string">&quot;-w&quot;</span>, <span class="string">&quot;vm.max_map_count=262144&quot;</span>]</span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">increase-fd-ulimit</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;ulimit -n 65536&quot;</span>]</span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteOnce&quot;</span> ]</span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">do-block-storage</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">100Gi</span></span><br></pre></td></tr></table></figure>

<p>Once you’re satisfied with your Elasticsearch configuration, save and close the file.</p>
<p>Now, deploy the StatefulSet using kubectl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">elasticsearch_statefulset.yaml</span></span><br></pre></td></tr></table></figure>

<p>You should see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">statefulset.apps/es-cluster</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>

<p>You can monitor the StatefulSet as it is rolled out using kubectl rollout status:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl rollout status sts/es-cluster --namespace=kube-logging</span><br></pre></td></tr></table></figure>

<p>You should see the following output as the cluster is rolled out:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">Waiting <span class="keyword">for</span> 3 pods to be ready...</span><br><span class="line">Waiting <span class="keyword">for</span> 2 pods to be ready...</span><br><span class="line">Waiting <span class="keyword">for</span> 1 pods to be ready...</span><br><span class="line">partitioned roll out complete: 3 new pods have been updated...</span><br></pre></td></tr></table></figure>

<p>Once all the Pods have been deployed, you can check that your Elasticsearch cluster is functioning correctly by performing a request against the REST API.</p>
<p>To do so, first forward the local port 9200 to the port 9200 on one of the Elasticsearch nodes (es-cluster-0) using kubectl port-forward:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl port-forward es-cluster-0 9200:9200 --namespace=kube-logging</span><br></pre></td></tr></table></figure>

<p>Then, in a separate terminal window, perform a curl request against the REST API:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">curl http://localhost:9200/_cluster/state?pretty</span><br></pre></td></tr></table></figure>

<p>You shoulds see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;cluster_name&quot;</span> <span class="string">:</span> <span class="string">&quot;k8s-logs&quot;</span>,</span><br><span class="line">  <span class="string">&quot;compressed_size_in_bytes&quot;</span> <span class="string">:</span> <span class="number">348</span>,</span><br><span class="line">  <span class="string">&quot;cluster_uuid&quot;</span> <span class="string">:</span> <span class="string">&quot;QD06dK7CQgids-GQZooNVw&quot;</span>,</span><br><span class="line">  <span class="string">&quot;version&quot;</span> <span class="string">:</span> <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;state_uuid&quot;</span> <span class="string">:</span> <span class="string">&quot;mjNIWXAzQVuxNNOQ7xR-qg&quot;</span>,</span><br><span class="line">  <span class="string">&quot;master_node&quot;</span> <span class="string">:</span> <span class="string">&quot;IdM5B7cUQWqFgIHXBp0JDg&quot;</span>,</span><br><span class="line">  <span class="string">&quot;blocks&quot;</span> <span class="string">:</span> &#123; &#125;,</span><br><span class="line">  <span class="string">&quot;nodes&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">    <span class="string">&quot;u7DoTpMmSCixOoictzHItA&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">      <span class="string">&quot;name&quot;</span> <span class="string">:</span> <span class="string">&quot;es-cluster-1&quot;</span>,</span><br><span class="line">      <span class="string">&quot;ephemeral_id&quot;</span> <span class="string">:</span> <span class="string">&quot;ZlBflnXKRMC4RvEACHIVdg&quot;</span>,</span><br><span class="line">      <span class="string">&quot;transport_address&quot;</span> <span class="string">:</span> <span class="string">&quot;10.244.8.2:9300&quot;</span>,</span><br><span class="line">      <span class="string">&quot;attributes&quot;</span> <span class="string">:</span> &#123; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;IdM5B7cUQWqFgIHXBp0JDg&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">      <span class="string">&quot;name&quot;</span> <span class="string">:</span> <span class="string">&quot;es-cluster-0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;ephemeral_id&quot;</span> <span class="string">:</span> <span class="string">&quot;JTk1FDdFQuWbSFAtBxdxAQ&quot;</span>,</span><br><span class="line">      <span class="string">&quot;transport_address&quot;</span> <span class="string">:</span> <span class="string">&quot;10.244.44.3:9300&quot;</span>,</span><br><span class="line">      <span class="string">&quot;attributes&quot;</span> <span class="string">:</span> &#123; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;R8E7xcSUSbGbgrhAdyAKmQ&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">      <span class="string">&quot;name&quot;</span> <span class="string">:</span> <span class="string">&quot;es-cluster-2&quot;</span>,</span><br><span class="line">      <span class="string">&quot;ephemeral_id&quot;</span> <span class="string">:</span> <span class="string">&quot;9wv6ke71Qqy9vk2LgJTqaA&quot;</span>,</span><br><span class="line">      <span class="string">&quot;transport_address&quot;</span> <span class="string">:</span> <span class="string">&quot;10.244.40.4:9300&quot;</span>,</span><br><span class="line">      <span class="string">&quot;attributes&quot;</span> <span class="string">:</span> &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>This indicates that our Elasticsearch cluster k8s-logs has successfully been created with 3 nodes: es-cluster-0, es-cluster-1, and es-cluster-2. The current master node is es-cluster-0.</p>
<p>Now that your Elasticsearch cluster is up and running, you can move on to setting up a Kibana frontend for it.</p>
<br>

<hr>
<h2 id="Create-Kibana-Deployment-amp-Service"><a href="#Create-Kibana-Deployment-amp-Service" class="headerlink" title="Create Kibana Deployment &amp; Service"></a>Create Kibana Deployment &amp; Service</h2><p>To launch Kibana on Kubernetes, we’ll create a Service called kibana, and a Deployment consisting of one Pod replica. You can scale the number of replicas depending on your production needs, and optionally specify a LoadBalancer type for the Service to load balance requests across the Deployment pods.</p>
<p>This time, we’ll create the Service and Deployment in the same file. Open up a file called kibana.yaml in your favorite editor:</p>
<pre><code>vim kibana.yaml
</code></pre>
<p>Paste in the following service spec:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">5601</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">docker.elastic.co/kibana/kibana:7.2.0</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_URL</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">http://elasticsearch:9200</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5601</span></span><br></pre></td></tr></table></figure>

<p>Then, save and close the file.</p>
<p>In this spec we’ve defined a service called kibana in the kube-logging namespace, and gave it the app: kibana label.</p>
<p>We’ve also specified that it should be accessible on port 5601 and use the app: kibana label to select the Service’s target Pods.</p>
<p>In the Deployment spec, we define a Deployment called kibana and specify that we’d like 1 Pod replica.</p>
<p>We use the docker.elastic.co/kibana/kibana:7.2.0 image. At this point you may substitute your own private or public Kibana image to use.</p>
<p>We specify that we’d like at the very least 0.1 vCPU guaranteed to the Pod, bursting up to a limit of 1 vCPU. You may change these parameters depending on your anticipated load and available resources.</p>
<p>Next, we use the ELASTICSEARCH_URL environment variable to set the endpoint and port for the Elasticsearch cluster. Using Kubernetes DNS, this endpoint corresponds to its Service name elasticsearch. This domain will resolve to a list of IP addresses for the 3 Elasticsearch Pods. To learn more about Kubernetes DNS, consult DNS for Services and Pods.</p>
<p>Finally, we set Kibana’s container port to 5601, to which the kibana Service will forward requests.</p>
<p>Once you’re satisfied with your Kibana configuration, you can roll out the Service and Deployment using kubectl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">kibana.yaml</span></span><br></pre></td></tr></table></figure>

<p>You should see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">service/kibana</span> <span class="string">created</span></span><br><span class="line"><span class="string">deployment.apps/kibana</span> <span class="string">created</span></span><br></pre></td></tr></table></figure>

<p>You can check that the rollout succeeded by running the following command:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl rollout status deployment/kibana --namespace=kube-logging</span><br></pre></td></tr></table></figure>

<p>You should see the following output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="string">deployment</span> <span class="string">&quot;kibana&quot;</span> <span class="string">successfully</span> <span class="string">rolled</span> <span class="string">out</span></span><br></pre></td></tr></table></figure>

<p>To access the Kibana interface, we’ll once again forward a local port to the Kubernetes node running Kibana. Grab the Kibana Pod details using kubectl get:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span> <span class="string">--namespace=kube-logging</span></span><br></pre></td></tr></table></figure>

<p>And the output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">es-cluster-0              1/1       Running   0          55m</span><br><span class="line">es-cluster-1              1/1       Running   0          54m</span><br><span class="line">es-cluster-2              1/1       Running   0          54m</span><br><span class="line">kibana-6c9fb4b5b7-plbg2   1/1       Running   0          4m27s</span><br></pre></td></tr></table></figure>

<p>Here we observe that our Kibana Pod is called <code>kibana-6c9fb4b5b7-plbg2</code>.</p>
<p>Forward the local port 5601 to port 5601 on this Pod:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl port-forward kibana-6c9fb4b5b7-plbg2 5601:5601 --namespace=kube-logging</span><br></pre></td></tr></table></figure>
<p>You should see the following output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">Forwarding from 127.0.0.1:5601 -&gt; 5601</span><br><span class="line">Forwarding from [::1]:5601 -&gt; 5601</span><br></pre></td></tr></table></figure>


<p>Now, in your web browser, visit the following URL:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">http://localhost:5601</span><br></pre></td></tr></table></figure>

<p>If you see the Kibana welcome page, you’ve successfully deployed Kibana into your Kubernetes cluster. You can now move on to rolling out the final component of the EFK stack: the log collector, Fluentd.</p>
<br>

<hr>
<h2 id="Create-Fluentd-DaemonSet"><a href="#Create-Fluentd-DaemonSet" class="headerlink" title="Create Fluentd DaemonSet"></a>Create Fluentd DaemonSet</h2><p>In this post, we’ll set up Fluentd as a DaemonSet, which is a Kubernetes workload type that runs a copy of a given Pod on each Node in the Kubernetes cluster. Using this DaemonSet controller, we’ll roll out a Fluentd logging agent Pod on every node in our cluster. To learn more about this logging architecture, consult “Using a node logging agent” from the official Kubernetes docs.</p>
<p>In Kubernetes, containerized applications that log to stdout and stderr have their log streams captured and redirected to JSON files on the nodes. The Fluentd Pod will tail these log files, filter log events, transform the log data, and ship it off to the Elasticsearch logging backend we deployed in Step 2.</p>
<p>In addition to container logs, the Fluentd agent will tail Kubernetes system component logs like kubelet, kube-proxy, and Docker logs. To see a full list of sources tailed by the Fluentd logging agent, consult the kubernetes.conf file used to configure the logging agent. To learn more about logging in Kubernetes clusters, consult “Logging at the node level” from the official Kubernetes documentation.</p>
<p>Begin by opening a file called fluentd.yaml in your favorite text editor:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">fluentd.yaml</span></span><br></pre></td></tr></table></figure>

<p>Once again, we’ll paste in the Kubernetes object definitions block by block, providing context as we go along. In this post, we use the Fluentd DaemonSet spec provided by the Fluentd maintainers. Another helpful resource provided by the Fluentd maintainers is Kuberentes Fluentd.</p>
<p>First, paste in the following ServiceAccount definition:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">fluentd.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">fluentd</span></span><br></pre></td></tr></table></figure>

<p>Here, we create a Service Account called fluentd that the Fluentd Pods will use to access the Kubernetes API. We create it in the kube-logging Namespace and once again give it the label app: fluentd. To learn more about Service Accounts in Kubernetes, consult Configure Service Accounts for Pods in the official Kubernetes docs.</p>
<p>Next, paste in the following ClusterRole block:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">namespaces</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br></pre></td></tr></table></figure>

<p>Here we define a ClusterRole called fluentd to which we grant the get, list, and watch permissions on the pods and namespaces objects. ClusterRoles allow you to grant access to cluster-scoped Kubernetes resources like Nodes. To learn more about Role-Based Access Control and Cluster Roles, consult Using RBAC Authorization from the official Kubernetes documentation.</p>
<p>Now, paste in the following ClusterRoleBinding block:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br></pre></td></tr></table></figure>

<p>In this block, we define a ClusterRoleBinding called fluentd which binds the fluentd ClusterRole to the fluentd Service Account. This grants the fluentd ServiceAccount the permissions listed in the fluentd Cluster Role.</p>
<p>At this point we can begin pasting in the actual DaemonSet spec:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="string">Here,</span> <span class="attr">we define a DaemonSet called fluentd in the kube-logging Namespace and give it the app:</span> <span class="string">fluentd</span> <span class="string">label.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Next,</span> <span class="attr">paste in the following section:</span></span><br><span class="line"></span><br><span class="line"><span class="string">fluentd.yaml</span></span><br><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">fluentd</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">fluentd</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span>  <span class="string">FLUENT_ELASTICSEARCH_HOST</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;elasticsearch.kube-logging.svc.cluster.local&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span>  <span class="string">FLUENT_ELASTICSEARCH_PORT</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;9200&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_SCHEME</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;http&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENTD_SYSTEMD_CONF</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">disable</span></span><br></pre></td></tr></table></figure>

<p>Here, we match the app: fluentd label defined in .metadata.labels and then assign the DaemonSet the fluentd Service Account. We also select the app: fluentd as the Pods managed by this DaemonSet.</p>
<p>Next, we define a NoSchedule toleration to match the equivalent taint on Kubernetes master nodes. This will ensure that the DaemonSet also gets rolled out to the Kubernetes masters. If you don’t want to run a Fluentd Pod on your master nodes, remove this toleration. To learn more about Kubernetes taints and tolerations, consult “Taints and Tolerations” from the official Kubernetes docs.</p>
<p>Next, we begin defining the Pod container, which we call fluentd.</p>
<p>We use the official v1.4.2 Debian image provided by the Fluentd maintainers. If you’d like to use your own private or public Fluentd image, or use a different image version, modify the image tag in the container spec. The Dockerfile and contents of this image are available in Fluentd’s fluentd-kubernetes-daemonset Github repo.</p>
<p>Next, we configure Fluentd using some environment variables:</p>
<ul>
<li><code>FLUENT_ELASTICSEARCH_HOST</code>: We set this to the Elasticsearch headless Service address defined earlier: elasticsearch.kube-logging.svc.cluster.local. This will resolve to a list of IP addresses for the 3 Elasticsearch Pods. The actual Elasticsearch host will most likely be the first IP address returned in this list. To distribute logs across the cluster, you will need to modify the configuration for Fluentd’s Elasticsearch Output plugin. To learn more about this plugin, consult Elasticsearch Output Plugin.</li>
<li><code>FLUENT_ELASTICSEARCH_PORT</code>: We set this to the Elasticsearch port we configured earlier, 9200.</li>
<li><code>FLUENT_ELASTICSEARCH_SCHEME</code>: We set this to http.</li>
<li><code>FLUENTD_SYSTEMD_CONF</code>: We set this to disable to suppress output related to systemd not being set up in the container.</li>
</ul>
<p>Finally, paste in the following section:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">512Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/log</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/lib/docker/containers</span></span><br></pre></td></tr></table></figure>

<p>Here we specify a 512 MiB memory limit on the FluentD Pod, and guarantee it 0.1vCPU and 200MiB of memory. You can tune these resource limits and requests depending on your anticipated log volume and available resources.</p>
<p>Next, we mount the /var/log and /var/lib/docker/containers host paths into the container using the varlog and varlibdockercontainers volumeMounts. These volumes are defined at the end of the block.</p>
<p>The final parameter we define in this block is terminationGracePeriodSeconds, which gives Fluentd 30 seconds to shut down gracefully upon receiving a SIGTERM signal. After 30 seconds, the containers are sent a SIGKILL signal. The default value for terminationGracePeriodSeconds is 30s, so in most cases this parameter can be omitted. To learn more about gracefully terminating Kubernetes workloads, consult Google’s “Kubernetes best practices: terminating with grace.”</p>
<p>The entire Fluentd spec should look something like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">namespaces</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-logging</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">fluentd</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">fluentd</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">fluentd</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span>  <span class="string">FLUENT_ELASTICSEARCH_HOST</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;elasticsearch.kube-logging.svc.cluster.local&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span>  <span class="string">FLUENT_ELASTICSEARCH_PORT</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;9200&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENT_ELASTICSEARCH_SCHEME</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">&quot;http&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLUENTD_SYSTEMD_CONF</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">disable</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">512Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/log</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/lib/docker/containers</span></span><br></pre></td></tr></table></figure>

<p>Now, roll out the DaemonSet using kubectl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">fluentd.yaml</span></span><br></pre></td></tr></table></figure>

<p>You should see the following output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">serviceaccount/fluentd created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/fluentd created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/fluentd created</span><br><span class="line">daemonset.extensions/fluentd created</span><br></pre></td></tr></table></figure>

<p>Verify that your DaemonSet rolled out successfully using kubectl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">ds</span> <span class="string">--namespace=kube-logging</span></span><br></pre></td></tr></table></figure>

<p>You should see the following status output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">NAME      DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">fluentd   3         3         3         3            3           &lt;none&gt;          58s</span><br></pre></td></tr></table></figure>

<p>This indicates that there are 3 fluentd Pods running, which corresponds to the number of nodes in our Kubernetes cluster.</p>
<p>We can now check Kibana to verify that log data is being properly collected and shipped to Elasticsearch.</p>
<p>With the kubectl port-forward still open, navigate to <a href="http://localhost:5601/">http://localhost:5601</a>.</p>
<p>Click on Discover in the left-hand navigation menu, you should see a configuration window. This allows you to define the Elasticsearch indices you’d like to explore in Kibana. To learn more, consult Defining your index patterns in the official Kibana docs. For now, we’ll just use the logstash-* wildcard pattern to capture all the log data in our Elasticsearch cluster. Enter logstash-* in the text box and click on Next step.</p>
<p>You’ll then be brought to Kibana Index Pattern Settings. This allows you to configure which field Kibana will use to filter log data by time. In the dropdown, select the @timestamp field, and hit Create index pattern.</p>
<p>Now, hit Discover in the left hand navigation menu. You should see a histogram graph and some recent log entries. At this point you’ve successfully configured and rolled out the EFK stack on your Kubernetes cluster. </p>
<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Configure ELK Stack</title>
    <url>/2019/ELK/</url>
    <content><![CDATA[<p>The Elastic Stack — formerly known as the ELK Stack — is a collection of <a href="https://www.digitalocean.com/community/tags/elasticsearch?type=tutorials">open-source software produced by Elastic</a> which allows you to search, analyze, and visualize logs generated from any source in any format, a practice known as centralized logging. Centralized logging can be very useful when attempting to identify problems with your servers or applications, as it allows you to search through all of your logs in a single place. It’s also useful because it allows you to identify issues that span multiple servers by correlating their logs during a specific time frame.</p>
<br>

<span id="more"></span> 

<blockquote>
<p>Note:  </p>
<p><em>Before moving forwards, make sure to <a href="/2018/Initial-Server-Setup/">set up the Server configured with a non-root sudo user and a firewall</a>, have Java 8 (Java 9 isn’t supported by Logstash) and <a href="https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-18-04">Nginx</a> installed.</em></p>
</blockquote>
<br>

<p>The Elastic Stack has four main components:</p>
<ul>
<li><p><strong>Elasticsearch</strong>: a distributed RESTful search engine which stores all of the collected data.</p>
</li>
<li><p><strong>Logstash</strong>: the data processing component of the Elastic Stack which sends incoming data to Elasticsearch.</p>
</li>
<li><p><strong>Kibana</strong>: a web interface for searching and visualizing logs.</p>
</li>
<li><p><strong>Beats</strong>: lightweight, single-purpose data shippers that can send data from hundreds or thousands of machines to either Logstash or Elasticsearch.</p>
</li>
</ul>
<p>In this post, we will install the Elastic Stack on an Ubuntu 18.04 server. You will learn how to install all of the components of the Elastic Stack — including Filebeat, a Beat used for forwarding and centralizing logs and files — and configure them to gather and visualize system logs. Additionally, because Kibana is normally only available on the localhost, we will use Nginx to proxy it so it will be accessible over a web browser. We will install all of these components on a single server, which we will refer to as our Elastic Stack server.</p>
<blockquote>
<p>Note: When installing the Elastic Stack, you <strong>must use the same version across the entire stack</strong>. In this post, we will use Elasticsearch 6.4.3, Kibana 6.4.3, Logstash 6.4.3, and Filebeat 6.4.3.</p>
</blockquote>
<p>Because the Elastic Stack is used to access valuable information about your server that you would not want unauthorized users to access, it’s important that you keep your server secure by installing a TLS/SSL certificate. This is optional but strongly encouraged.</p>
<p>However, because you will ultimately make changes to your Nginx server block, it would likely make more sense for you to complete the <a href="http://localhost:4000/2018/Nginx-Config/#HTTPS-with-Let's-Encrypt">HTTPS &amp; Let’s Encrypt</a>  at the end of this post’s second step. With that in mind, if you plan to configure Let’s Encrypt on your server, you will need the following in place before doing so:</p>
<ul>
<li><p>A fully qualified domain name (FQDN). This post will use example.com throughout. You can purchase a domain name on Namecheap, get one for free on Freenom, or use the domain registrar of your choice.</p>
</li>
<li><p>Both of the following DNS records set up for your server. </p>
<ul>
<li>An A record with <code>example.com </code>pointing to your server’s public IP address.</li>
<li>An A record with <code>www.example.com</code> pointing to your server’s public IP address.</li>
</ul>
</li>
</ul>
<p><strong>Important</strong>: We can send just about any type of log or indexed data to Logstash using Beats, but the data becomes even more useful if it is parsed and structured with a Logstash filter, as this transforms the data into a consistent format that can be read easily by Elasticsearch.</p>
<br>

<hr>
<h2 id="Config-Elasticsearch"><a href="#Config-Elasticsearch" class="headerlink" title="Config Elasticsearch"></a>Config Elasticsearch</h2><p>The Elastic Stack components are not available in Ubuntu’s default package repositories. They can, however, be installed with APT after adding Elastic’s package source list.</p>
<p>All of the Elastic Stack’s packages are signed with the Elasticsearch signing key in order to protect your system from package spoofing. Packages which have been authenticated using the key will be considered trusted by your package manager. In this step, you will import the Elasticsearch public GPG key and add the Elastic package source list in order to install Elasticsearch.</p>
<p>To begin, run the following command to import the Elasticsearch public GPG key into APT:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -</span><br></pre></td></tr></table></figure>
<p>Next, add the Elastic source list to the sources.list.d directory, where APT will look for new sources:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb https://artifacts.elastic.co/packages/6.x/apt stable main&quot;</span> </span><br><span class="line">| sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list</span><br></pre></td></tr></table></figure>
<p>Next, update your package lists so APT will read the new Elastic source:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>
<p>Then install Elasticsearch with this command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure>
<p>Once Elasticsearch is finished installing, use your preferred text editor to edit Elasticsearch’s main configuration file, elasticsearch.yml. Here, we’ll use vim:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/elasticsearch/elasticsearch.yml</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: Elasticsearch’s configuration file is in YAML format, which means that indentation is very important! Be sure that you do not add any extra spaces as you edit this file.</p>
</blockquote>
<p>Elasticsearch listens for traffic from everywhere on port 9200. You will want to restrict outside access to your Elasticsearch instance to prevent outsiders from reading your data or shutting down your Elasticsearch cluster through the REST API. Find the line that specifies network.host, uncomment it, and replace its value with localhost so it looks like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="attr">network.host:</span> <span class="string">localhost</span></span><br><span class="line"><span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>

<p>Then, start the Elasticsearch service with systemctl:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure>
<p>Next, run the following command to enable Elasticsearch to start up every time your server boots:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure>
<p>You can test whether your Elasticsearch service is running by sending an HTTP request:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">curl</span> <span class="string">-X</span> <span class="string">GET</span> <span class="string">&quot;localhost:9200&quot;</span></span><br></pre></td></tr></table></figure>
<p>You will see a response showing some basic information about your local node, similar to this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;name&quot;</span> <span class="string">:</span> <span class="string">&quot;ZlJ0k2h&quot;</span>,</span><br><span class="line">  <span class="string">&quot;cluster_name&quot;</span> <span class="string">:</span> <span class="string">&quot;elasticsearch&quot;</span>,</span><br><span class="line">  <span class="string">&quot;cluster_uuid&quot;</span> <span class="string">:</span> <span class="string">&quot;beJf9oPSTbecP7_i8pRVCw&quot;</span>,</span><br><span class="line">  <span class="string">&quot;version&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">    <span class="string">&quot;number&quot;</span> <span class="string">:</span> <span class="string">&quot;6.4.2&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_flavor&quot;</span> <span class="string">:</span> <span class="string">&quot;default&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_type&quot;</span> <span class="string">:</span> <span class="string">&quot;deb&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_hash&quot;</span> <span class="string">:</span> <span class="string">&quot;04711c2&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_date&quot;</span> <span class="string">:</span> <span class="string">&quot;2018-09-26T13:34:09.098244Z&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_snapshot&quot;</span> <span class="string">:</span> <span class="literal">false</span>,</span><br><span class="line">    <span class="string">&quot;lucene_version&quot;</span> <span class="string">:</span> <span class="string">&quot;7.4.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;minimum_wire_compatibility_version&quot;</span> <span class="string">:</span> <span class="string">&quot;5.6.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;minimum_index_compatibility_version&quot;</span> <span class="string">:</span> <span class="string">&quot;5.0.0&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;tagline&quot;</span> <span class="string">:</span> <span class="string">&quot;You Know, for Search&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Now that Elasticsearch is up and running, let’s install Kibana, the next component of the Elastic Stack.</p>
<br>

<hr>
<h2 id="Config-Kibana-Dashboard"><a href="#Config-Kibana-Dashboard" class="headerlink" title="Config Kibana Dashboard"></a>Config Kibana Dashboard</h2><p>According to the official documentation, you should install Kibana only after installing Elasticsearch. Installing in this order ensures that the components each product depends on are correctly in place.</p>
<p>Because you’ve already added the Elastic package source in the previous step, you can just install the remaining components of the Elastic Stack using apt:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">kibana</span></span><br></pre></td></tr></table></figure>
<p>Then enable and start the Kibana service:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">kibana</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">kibana</span></span><br></pre></td></tr></table></figure>
<p>Because Kibana is configured to only listen on localhost, we must set up a reverse proxy to allow external access to it. We will use Nginx for this purpose, which should already be installed on your server.</p>
<p>First, use the openssl command to create an administrative Kibana user which you’ll use to access the Kibana web interface. As an example we will name this account kibanaadmin, but to ensure greater security we recommend that you choose a non-standard name for your user that would be difficult to guess.</p>
<p>The following command will create the administrative Kibana user and password, and store them in the htpasswd.users file. You will configure Nginx to require this username and password and read this file momentarily:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">&quot;kibanaadmin:`openssl passwd -apr1`&quot;</span> <span class="string">|</span> <span class="string">sudo</span> <span class="string">tee</span> <span class="string">-a</span> <span class="string">/etc/nginx/htpasswd.users</span></span><br></pre></td></tr></table></figure>
<p>Enter and confirm a password at the prompt. Remember or take note of this login, as you will need it to access the Kibana web interface.</p>
<p>Next, we will create an Nginx server block file. As an example, we will refer to this file as example.com, although you may find it helpful to give yours a more descriptive name. For instance, if you have a FQDN and DNS records set up for this server, you could name this file after your FQDN:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/sites-available/example.com</span></span><br></pre></td></tr></table></figure>
<p>Add the following code block into the file, being sure to update example.com to match your server’s FQDN or public IP address. This code configures Nginx to direct your server’s HTTP traffic to the Kibana application, which is listening on localhost:5601. Additionally, it configures Nginx to read the htpasswd.users file and require basic authentication.</p>
<p>Note that if you followed the <a href="/2018/Nginx-Config/">prerequisite Nginx post</a> through to the end, you may have already created this file and populated it with some content. In that case, delete all the existing content in the file before adding the following:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line"></span><br><span class="line">    server_name example.com;</span><br><span class="line"></span><br><span class="line">    auth_basic <span class="string">&quot;Restricted Access&quot;</span>;</span><br><span class="line">    auth_basic_user_file /etc/nginx/htpasswd.users;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://localhost:5601;</span><br><span class="line">        proxy_http_version 1.1;</span><br><span class="line">        proxy_set_header Upgrade <span class="variable">$http_upgrade</span>;</span><br><span class="line">        proxy_set_header Connection <span class="string">&#x27;upgrade&#x27;</span>;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_cache_bypass <span class="variable">$http_upgrade</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>Next, enable the new configuration by creating a symbolic link to the sites-enabled directory. If you already created a server block file with the same name in the Nginx prerequisite, you do not need to run this command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ln</span> <span class="string">-s</span> <span class="string">/etc/nginx/sites-available/example.com</span> <span class="string">/etc/nginx/sites-enabled/example.com</span></span><br></pre></td></tr></table></figure>
<p>Then check the configuration for syntax errors:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">nginx</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>
<p>If any errors are reported in your output, go back and double check that the content you placed in your configuration file was added correctly. Once you see syntax is ok in the output, go ahead and restart the Nginx service:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>
<p>If you followed the <a href="2018/Initial-Server-Setup/">initial server setup guide</a>, you should have a UFW firewall enabled. To allow connections to Nginx, we can adjust the rules by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ufw</span> <span class="string">allow</span> <span class="string">&#x27;Nginx Full&#x27;</span></span><br></pre></td></tr></table></figure>

<p>Kibana is now accessible via your FQDN or the public IP address of your Elastic Stack server. You can check the Kibana server’s status page by navigating to the following address and entering your login credentials when prompted:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">http://your_server_ip/status</span></span><br></pre></td></tr></table></figure>
<p>This status page displays information about the server’s resource usage and lists the installed plugins.</p>
<p><img data-src="/images/posts/190614-1.png" alt="01"></p>
<blockquote>
<p>Note: It is recommended that you enable SSL/TLS on your server. Please just <a href="/2018/Nginx-Config/#HTTPS-with-Let's-Encrypt">follow this post</a> to set it up.</p>
</blockquote>
<p>Now that the Kibana dashboard is configured, let’s install the next component: Logstash.</p>
<br>

<hr>
<h2 id="Config-Logstash"><a href="#Config-Logstash" class="headerlink" title="Config Logstash"></a>Config Logstash</h2><p>Although it’s possible for Beats to send data directly to the Elasticsearch database, we recommend using Logstash to process the data. This will allow you to collect data from different sources, transform it into a common format, and export it to another database.</p>
<p>Install Logstash with this command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">logstash</span></span><br></pre></td></tr></table></figure>
<p>After installing Logstash, you can move on to configuring it. Logstash’s configuration files are written in the JSON format and reside in the /etc/logstash/conf.d directory. As you configure it, it’s helpful to think of Logstash as a pipeline which takes in data at one end, processes it in one way or another, and sends it out to its destination (in this case, the destination being Elasticsearch). A Logstash pipeline has two required elements, input and output, and one optional element, filter. The input plugins consume data from a source, the filter plugins process the data, and the output plugins write the data to a destination.</p>
<p><img data-src="/images/posts/190614-2.png" alt="02"></p>
<p>Create a configuration file called 02-beats-input.conf where you will set up your Filebeat input:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/logstash/conf.d/02-beats-input.conf</span></span><br></pre></td></tr></table></figure>
<p>Insert the following input configuration. This specifies a beats input that will listen on TCP port 5044.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Save and close the file. Next, create a configuration file called 10-syslog-filter.conf, where we will add a filter for system logs, also known as syslogs:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/logstash/conf.d/10-syslog-filter.conf</span></span><br></pre></td></tr></table></figure>
<p>Insert the following syslog filter configuration. This example system logs configuration was taken from official Elastic documentation. This filter is used to parse incoming system logs to make them structured and usable by the predefined Kibana dashboards:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  <span class="keyword">if</span> [fileset][module] == <span class="string">&quot;system&quot;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> [fileset][name] == <span class="string">&quot;auth&quot;</span> &#123;</span><br><span class="line">      grok &#123;</span><br><span class="line">        match =&gt; &#123; <span class="string">&quot;message&quot;</span> =&gt; [<span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; sshd(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: %&#123;DATA:[system][auth][ssh][event]&#125; %&#123;DATA:[system][auth][ssh][method]&#125; for (invalid user )?%&#123;DATA:[system][auth][user]&#125; from %&#123;IPORHOST:[system][auth][ssh][ip]&#125; port %&#123;NUMBER:[system][auth][ssh][port]&#125; ssh2(: %&#123;GREEDYDATA:[system][auth][ssh][signature]&#125;)?&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; sshd(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: %&#123;DATA:[system][auth][ssh][event]&#125; user %&#123;DATA:[system][auth][user]&#125; from %&#123;IPORHOST:[system][auth][ssh][ip]&#125;&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; sshd(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: Did not receive identification string from %&#123;IPORHOST:[system][auth][ssh][dropped_ip]&#125;&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; sudo(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: \s*%&#123;DATA:[system][auth][user]&#125; :( %&#123;DATA:[system][auth][sudo][error]&#125; ;)? TTY=%&#123;DATA:[system][auth][sudo][tty]&#125; ; PWD=%&#123;DATA:[system][auth][sudo][pwd]&#125; ; USER=%&#123;DATA:[system][auth][sudo][user]&#125; ; COMMAND=%&#123;GREEDYDATA:[system][auth][sudo][command]&#125;&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; groupadd(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: new group: name=%&#123;DATA:system.auth.groupadd.name&#125;, GID=%&#123;NUMBER:system.auth.groupadd.gid&#125;&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; useradd(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: new user: name=%&#123;DATA:[system][auth][user][add][name]&#125;, UID=%&#123;NUMBER:[system][auth][user][add][uid]&#125;, GID=%&#123;NUMBER:[system][auth][user][add][gid]&#125;, home=%&#123;DATA:[system][auth][user][add][home]&#125;, shell=%&#123;DATA:[system][auth][user][add][shell]&#125;$&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][auth][timestamp]&#125; %&#123;SYSLOGHOST:[system][auth][hostname]&#125; %&#123;DATA:[system][auth][program]&#125;(?:\[%&#123;POSINT:[system][auth][pid]&#125;\])?: %&#123;GREEDYMULTILINE:[system][auth][message]&#125;&quot;</span>] &#125;</span><br><span class="line">        pattern_definitions =&gt; &#123;</span><br><span class="line">          <span class="string">&quot;GREEDYMULTILINE&quot;</span>=&gt; <span class="string">&quot;(.|\n)*&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        remove_field =&gt; <span class="string">&quot;message&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">      date &#123;</span><br><span class="line">        match =&gt; [ <span class="string">&quot;[system][auth][timestamp]&quot;</span>, <span class="string">&quot;MMM  d HH:mm:ss&quot;</span>, <span class="string">&quot;MMM dd HH:mm:ss&quot;</span> ]</span><br><span class="line">      &#125;</span><br><span class="line">      geoip &#123;</span><br><span class="line">        <span class="built_in">source</span> =&gt; <span class="string">&quot;[system][auth][ssh][ip]&quot;</span></span><br><span class="line">        target =&gt; <span class="string">&quot;[system][auth][ssh][geoip]&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> [fileset][name] == <span class="string">&quot;syslog&quot;</span> &#123;</span><br><span class="line">      grok &#123;</span><br><span class="line">        match =&gt; &#123; <span class="string">&quot;message&quot;</span> =&gt; [<span class="string">&quot;%&#123;SYSLOGTIMESTAMP:[system][syslog][timestamp]&#125; %&#123;SYSLOGHOST:[system][syslog][hostname]&#125; %&#123;DATA:[system][syslog][program]&#125;(?:\[%&#123;POSINT:[system][syslog][pid]&#125;\])?: %&#123;GREEDYMULTILINE:[system][syslog][message]&#125;&quot;</span>] &#125;</span><br><span class="line">        pattern_definitions =&gt; &#123; <span class="string">&quot;GREEDYMULTILINE&quot;</span> =&gt; <span class="string">&quot;(.|\n)*&quot;</span> &#125;</span><br><span class="line">        remove_field =&gt; <span class="string">&quot;message&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">      date &#123;</span><br><span class="line">        match =&gt; [ <span class="string">&quot;[system][syslog][timestamp]&quot;</span>, <span class="string">&quot;MMM  d HH:mm:ss&quot;</span>, <span class="string">&quot;MMM dd HH:mm:ss&quot;</span> ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Save and close the file when finished.</p>
<p>Lastly, create a configuration file called 30-elasticsearch-output.conf:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/logstash/conf.d/30-elasticsearch-output.conf</span></span><br></pre></td></tr></table></figure>
<p>Insert the following output configuration. Essentially, this output configures Logstash to store the Beats data in Elasticsearch, which is running at localhost:9200, in an index named after the Beat used. The Beat used in this post is Filebeat:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">output</span> &#123;</span><br><span class="line">  <span class="string">elasticsearch</span> &#123;</span><br><span class="line">    <span class="string">hosts</span> <span class="string">=&gt;</span> [<span class="string">&quot;localhost:9200&quot;</span>]</span><br><span class="line">    <span class="string">manage_template</span> <span class="string">=&gt;</span> <span class="literal">false</span></span><br><span class="line">    <span class="string">index</span> <span class="string">=&gt;</span> <span class="string">&quot;<span class="template-variable">%&#123;[@metadata][beat]&#125;</span>-<span class="template-variable">%&#123;[@metadata][version]&#125;</span>-<span class="template-variable">%&#123;+YYYY.MM.dd&#125;</span>&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Save and close the file.</p>
<p>If you want to add filters for other applications that use the Filebeat input, be sure to name the files so they’re sorted between the input and the output configuration, meaning that the file names should begin with a two-digit number between 02 and 30.</p>
<p>Test your Logstash configuration with this command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">-u</span> <span class="string">logstash</span> <span class="string">/usr/share/logstash/bin/logstash</span> <span class="string">--path.settings</span> <span class="string">/etc/logstash</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>
<p>If there are no syntax errors, your output will display Configuration OK after a few seconds. If you don’t see this in your output, check for any errors that appear in your output and update your configuration to correct them.</p>
<p>If your configuration test is successful, start and enable Logstash to put the configuration changes into effect:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">logstash</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">logstash</span></span><br></pre></td></tr></table></figure>
<p>Now that Logstash is running correctly and is fully configured, let’s install Filebeat.</p>
<br>



<hr>
<h2 id="Config-Filebeat"><a href="#Config-Filebeat" class="headerlink" title="Config Filebeat"></a>Config Filebeat</h2><p>The Elastic Stack uses several lightweight data shippers called Beats to collect data from various sources and transport them to Logstash or Elasticsearch. Here are the Beats that are currently available from Elastic:</p>
<ul>
<li><strong>Filebeat</strong>: collects and ships log files.<br>Metricbeat: collects metrics from your systems and services.</li>
<li><strong>Packetbeat</strong>: collects and analyzes network data.</li>
<li><strong>Winlogbeat</strong>: collects Windows event logs.</li>
<li><strong>Auditbeat</strong>: collects Linux audit framework data and monitors file integrity.</li>
<li><strong>Heartbeat</strong>: monitors services for their availability with active probing. In this post we will use Filebeat to forward local logs to our Elastic Stack.</li>
</ul>
<p>Install Filebeat using apt:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">filebeat</span></span><br></pre></td></tr></table></figure>
<p>Next, configure Filebeat to connect to Logstash. Here, we will modify the example configuration file that comes with Filebeat.</p>
<p>Open the Filebeat configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/filebeat/filebeat.yml</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: As with Elasticsearch, Filebeat’s configuration file is in YAML format. This means that proper indentation is crucial, so be sure to use the same number of spaces that are indicated in these instructions.</p>
</blockquote>
<p>Filebeat supports numerous outputs, but you’ll usually only send events directly to Elasticsearch or to Logstash for additional processing. In this post, we’ll use Logstash to perform additional processing on the data collected by Filebeat. Filebeat will not need to send any data directly to Elasticsearch, so let’s disable that output. To do so, find the output.elasticsearch section and comment out the following lines by preceding them with a #:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="comment">#output.elasticsearch:</span></span><br><span class="line">  <span class="comment"># Array of hosts to connect to.</span></span><br><span class="line">  <span class="comment"># hosts: [&quot;localhost:9200&quot;]</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>Then, configure the output.logstash section. Uncomment the lines output.logstash: and hosts: [“localhost:5044”] by removing the #. This will configure Filebeat to connect to Logstash on your Elastic Stack server at port 5044, the port for which we specified a Logstash input earlier:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">output.logstash:</span></span><br><span class="line">  <span class="comment"># The Logstash hosts</span></span><br><span class="line">  <span class="attr">hosts:</span> [<span class="string">&quot;localhost:5044&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>Save and close the file.</p>
<p>The functionality of Filebeat can be extended with Filebeat modules. In this post we will use the system module, which collects and parses logs created by the system logging service of common Linux distributions.</p>
<p>Let’s enable it:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">filebeat</span> <span class="string">modules</span> <span class="string">enable</span> <span class="string">system</span></span><br></pre></td></tr></table></figure>
<p>You can see a list of enabled and disabled modules by running:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">filebeat</span> <span class="string">modules</span> <span class="string">list</span></span><br></pre></td></tr></table></figure>
<p>You will see a list similar to the following:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">Enabled:</span></span><br><span class="line"><span class="string">system</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Disabled:</span></span><br><span class="line"><span class="string">apache2</span></span><br><span class="line"><span class="string">auditd</span></span><br><span class="line"><span class="string">elasticsearch</span></span><br><span class="line"><span class="string">icinga</span></span><br><span class="line"><span class="string">iis</span></span><br><span class="line"><span class="string">kafka</span></span><br><span class="line"><span class="string">kibana</span></span><br><span class="line"><span class="string">logstash</span></span><br><span class="line"><span class="string">mongodb</span></span><br><span class="line"><span class="string">mysql</span></span><br><span class="line"><span class="string">nginx</span></span><br><span class="line"><span class="string">osquery</span></span><br><span class="line"><span class="string">postgresql</span></span><br><span class="line"><span class="string">redis</span></span><br><span class="line"><span class="string">traefik</span></span><br></pre></td></tr></table></figure>
<p>By default, Filebeat is configured to use default paths for the syslog and authorization logs. In the case of this post, you do not need to change anything in the configuration. You can see the parameters of the module in the /etc/filebeat/modules.d/system.yml configuration file.</p>
<p>Next, load the index template into Elasticsearch. An Elasticsearch index is a collection of documents that have similar characteristics. Indexes are identified with a name, which is used to refer to the index when performing various operations within it. The index template will be automatically applied when a new index is created.</p>
<p>To load the template, use the following command:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo filebeat setup --template \</span><br><span class="line">-E output.logstash.enabled=<span class="literal">false</span> \</span><br><span class="line">-E <span class="string">&#x27;output.elasticsearch.hosts=[&quot;localhost:9200&quot;]&#x27;</span></span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Loaded</span> <span class="string">index</span> <span class="string">template</span></span><br></pre></td></tr></table></figure>
<p>Filebeat comes packaged with sample Kibana dashboards that allow you to visualize Filebeat data in Kibana. Before you can use the dashboards, you need to create the index pattern and load the dashboards into Kibana.</p>
<p>As the dashboards load, Filebeat connects to Elasticsearch to check version information. To load dashboards when Logstash is enabled, you need to disable the Logstash output and enable Elasticsearch output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo filebeat setup -e -E output.logstash.enabled=<span class="literal">false</span> </span><br><span class="line">-E output.elasticsearch.hosts=[<span class="string">&#x27;localhost:9200&#x27;</span>] -E setup.kibana.host=localhost:5601</span><br></pre></td></tr></table></figure>
<p>You will see output that looks like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Output</span><br><span class="line">2018-09-10T08:39:15.844Z        INFO    instance/beat.go:273    Setup Beat: filebeat; Version: 6.4.2</span><br><span class="line">2018-09-10T08:39:15.845Z        INFO    elasticsearch/client.go:163     Elasticsearch url: http://localhost:9200</span><br><span class="line">2018-09-10T08:39:15.845Z        INFO    pipeline/module.go:98   Beat name: elk</span><br><span class="line">2018-09-10T08:39:15.845Z        INFO    elasticsearch/client.go:163     Elasticsearch url: http://localhost:9200</span><br><span class="line">2018-09-10T08:39:15.849Z        INFO    elasticsearch/client.go:708     Connected to Elasticsearch version 6.4.2</span><br><span class="line">2018-09-10T08:39:15.856Z        INFO    template/load.go:129    Template already exists and will not be overwritten.</span><br><span class="line">Loaded index template</span><br><span class="line">Loading dashboards (Kibana must be running and reachable)</span><br><span class="line">2018-09-10T08:39:15.857Z        INFO    elasticsearch/client.go:163     Elasticsearch url: http://localhost:9200</span><br><span class="line">2018-09-10T08:39:15.865Z        INFO    elasticsearch/client.go:708     Connected to Elasticsearch version 6.4.2</span><br><span class="line">2018-09-10T08:39:15.865Z        INFO    kibana/client.go:113    Kibana url: http://localhost:5601</span><br><span class="line">2018-09-10T08:39:45.357Z        INFO    instance/beat.go:659    Kibana dashboards successfully loaded.</span><br><span class="line">Loaded dashboards</span><br><span class="line">2018-09-10T08:39:45.358Z        INFO    elasticsearch/client.go:163     Elasticsearch url: http://localhost:9200</span><br><span class="line">2018-09-10T08:39:45.361Z        INFO    elasticsearch/client.go:708     Connected to Elasticsearch version 6.4.2</span><br><span class="line">2018-09-10T08:39:45.361Z        INFO    kibana/client.go:113    Kibana url: http://localhost:5601</span><br><span class="line">2018-09-10T08:39:45.455Z        WARN    fileset/modules.go:388  X-Pack Machine Learning is not enabled</span><br></pre></td></tr></table></figure>
<p>Loaded machine learning job configurations<br>Now you can start and enable Filebeat:</p>
<pre><code>sudo systemctl start filebeat
sudo systemctl enable filebeat
</code></pre>
<p>If you’ve set up your Elastic Stack correctly, Filebeat will begin shipping your syslog and authorization logs to Logstash, which will then load that data into Elasticsearch.</p>
<p>To verify that Elasticsearch is indeed receiving this data, query the Filebeat index with this command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">curl</span> <span class="string">-XGET</span> <span class="string">&#x27;http://localhost:9200/filebeat-*/_search?pretty&#x27;</span></span><br></pre></td></tr></table></figure>
<p>You will see an output that looks similar to this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Output</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;took&quot;</span> <span class="string">:</span> <span class="number">32</span>,</span><br><span class="line">  <span class="string">&quot;timed_out&quot;</span> <span class="string">:</span> <span class="literal">false</span>,</span><br><span class="line">  <span class="string">&quot;_shards&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">    <span class="string">&quot;total&quot;</span> <span class="string">:</span> <span class="number">3</span>,</span><br><span class="line">    <span class="string">&quot;successful&quot;</span> <span class="string">:</span> <span class="number">3</span>,</span><br><span class="line">    <span class="string">&quot;skipped&quot;</span> <span class="string">:</span> <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;failed&quot;</span> <span class="string">:</span> <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;hits&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">    <span class="string">&quot;total&quot;</span> <span class="string">:</span> <span class="number">1641</span>,</span><br><span class="line">    <span class="string">&quot;max_score&quot;</span> <span class="string">:</span> <span class="number">1.0</span>,</span><br><span class="line">    <span class="string">&quot;hits&quot;</span> <span class="string">:</span> [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">&quot;_index&quot;</span> <span class="string">:</span> <span class="string">&quot;filebeat-6.4.2-2018.10.10&quot;</span>,</span><br><span class="line">        <span class="string">&quot;_type&quot;</span> <span class="string">:</span> <span class="string">&quot;doc&quot;</span>,</span><br><span class="line">        <span class="string">&quot;_id&quot;</span> <span class="string">:</span> <span class="string">&quot;H_bZ62UBB4D0uxFRu_h3&quot;</span>,</span><br><span class="line">        <span class="string">&quot;_score&quot;</span> <span class="string">:</span> <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;_source&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">          <span class="string">&quot;@version&quot;</span> <span class="string">:</span> <span class="string">&quot;1&quot;</span>,</span><br><span class="line">          <span class="string">&quot;message&quot;</span> <span class="string">:</span> <span class="string">&quot;Oct 10 06:22:36 elk systemd[1]: Reached target Local File Systems (Pre).&quot;</span>,</span><br><span class="line">          <span class="string">&quot;@timestamp&quot;</span> <span class="string">:</span> <span class="string">&quot;2018-10-10T08:43:56.969Z&quot;</span>,</span><br><span class="line">          <span class="string">&quot;host&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span> <span class="string">:</span> <span class="string">&quot;elk&quot;</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">&quot;source&quot;</span> <span class="string">:</span> <span class="string">&quot;/var/log/syslog&quot;</span>,</span><br><span class="line">          <span class="string">&quot;input&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span> <span class="string">:</span> <span class="string">&quot;log&quot;</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">&quot;tags&quot;</span> <span class="string">:</span> [</span><br><span class="line">            <span class="string">&quot;beats_input_codec_plain_applied&quot;</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="string">&quot;offset&quot;</span> <span class="string">:</span> <span class="number">296</span>,</span><br><span class="line">          <span class="string">&quot;prospector&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span> <span class="string">:</span> <span class="string">&quot;log&quot;</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">&quot;beat&quot;</span> <span class="string">:</span> &#123;</span><br><span class="line">            <span class="string">&quot;version&quot;</span> <span class="string">:</span> <span class="string">&quot;6.4.2&quot;</span>,</span><br><span class="line">            <span class="string">&quot;hostname&quot;</span> <span class="string">:</span> <span class="string">&quot;elk&quot;</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span> <span class="string">:</span> <span class="string">&quot;elk&quot;</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>If your output shows 0 total hits, Elasticsearch is not loading any logs under the index you searched for, and you will need to review your setup for errors. If you received the expected output, continue to the next step, in which we will see how to navigate through some of Kibana’s dashboards.</p>
<br>

<hr>
<h2 id="Explore-Kibana-Dashboards"><a href="#Explore-Kibana-Dashboards" class="headerlink" title="Explore Kibana Dashboards"></a>Explore Kibana Dashboards</h2><p>Let’s look at Kibana, the web interface that we installed earlier.</p>
<p>In a web browser, go to the FQDN or public IP address of your Elastic Stack server. After entering the login credentials you defined in Step 2, you will see the Kibana homepage:</p>
<p><img data-src="/images/posts/190614-3.png" alt="03"></p>
<p>Click the Discover link in the left-hand navigation bar. On the Discover page, select the predefined filebeat-* index pattern to see Filebeat data. By default, this will show you all of the log data over the last 15 minutes. You will see a histogram with log events, and some log messages below:</p>
<p><img data-src="/images/posts/190614-4.png" alt="04"></p>
<p>Here, you can search and browse through your logs and also customize your dashboard. At this point, though, there won’t be much in there because you are only gathering syslogs from your Elastic Stack server.</p>
<p>Use the left-hand panel to navigate to the Dashboard page and search for the Filebeat System dashboards. Once there, you can search for the sample dashboards that come with Filebeat’s system module.</p>
<p>For example, you can view detailed stats based on your syslog messages:</p>
<p><img data-src="/images/posts/190614-5.png" alt="05"></p>
<p>You can also view which users have used the sudo command and when:</p>
<p><img data-src="/images/posts/190614-6.png" alt="06"></p>
<p>Kibana has many other features, such as graphing and filtering, so feel free to explore.</p>
<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Manage Redis Replicas and Clients</title>
    <url>/2019/Manage-Redis/</url>
    <content><![CDATA[<p>One of Redis’s most sought-after features is its <strong>support for replication</strong>: any Redis server can replicate its data to any number of replicas, allowing for high read scalability and strong data redundancy. </p>
<p>Additionally, Redis was designed to allow many clients (up to 10000, by default) to connect and interact with data, making it a good choice for cases where many users need access to the same dataset.</p>
<span id="more"></span> 

<blockquote>
<p><a href="https://www.digitalocean.com/community/cheatsheets/how-to-manage-replicas-and-clients-in-redis?status=moved_permanently">How To Manage Replicas and Clients in Redis</a></p>
<p><a href="https://www.digitalocean.com/community/tutorial_series/how-to-manage-a-redis-database">Tag: How to Manage a Redis Database</a></p>
</blockquote>
<br>

<hr>
<h2 id="Manage-Replicas"><a href="#Manage-Replicas" class="headerlink" title="Manage Replicas"></a>Manage Replicas</h2><p>One of Redis’s most distinguishing features is its built-in replication. When using replication, Redis creates exact copies of the primary instance. These secondary instances reconnect to the primary any time their connections break and will always aim to remain an exact copy of the primary.</p>
<p>If you’re not sure whether the Redis instance you’re currently connected to is a primary instance or a replica, you can check by running the role command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">role</span></span><br></pre></td></tr></table></figure>
<p>This command will return either master or slave, or potentially sentinel if you’re using Redis Sentinel.</p>
<p>To designate a Redis instance as a replica of another instance on the fly, run the <code>replicaof</code> command. This command takes the intended primary server’s hostname or IP address and port as arguments:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">replicaof</span> <span class="string">hostname_or_IP</span> <span class="string">port</span></span><br></pre></td></tr></table></figure>
<p>If the server was already a replica of another primary, it will stop replicating the old server and immediately start synchronizing with the new one. It will also discard the old dataset.</p>
<p>To promote a replica back to being a primary, run the following <code>replicaof</code> command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">replicaof</span> <span class="literal">no</span> <span class="string">one</span></span><br></pre></td></tr></table></figure>
<p>This will stop the instance from replicating the primary server, but will not discard the dataset it has already replicated. This syntax is useful in cases where the original primary fails. After running <code>replicaof</code> no one on a replica of the failed primary, the former replica can be used as the new primary and have its own replicas as a failsafe.</p>
<blockquote>
<p>Note: Prior to version 5.0.0, Redis instead included a version of this command named <code>slaveof</code>.</p>
</blockquote>
<br>

<hr>
<h2 id="Manage-Clients"><a href="#Manage-Clients" class="headerlink" title="Manage Clients"></a>Manage Clients</h2><p>A client is any machine or software that connects to a server in order to access a service. Redis comes with several commands that help with tracking and managing client connections.</p>
<p>The client list command returns a set of human-readable information about current client connections:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">list</span></span><br></pre></td></tr></table></figure>

<p>And the Output:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;id=18165 addr=[2001:db8:0:0::12]:47460 fd=7 name=jerry age=72756 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping</span></span><br><span class="line"><span class="string">id=18166 addr=[2001:db8:0:1::12]:47466 fd=8 name= age=72755 idle=5 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=info</span></span><br><span class="line"><span class="string">id=19381 addr=[2001:db8:0:2::12]:54910 fd=9 name= age=9 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client</span></span><br><span class="line"><span class="string">&quot;</span></span><br></pre></td></tr></table></figure>
<p>Here is what each of these fields mean:</p>
<ul>
<li><code>id</code>: a unique 64-bit client ID</li>
<li><code>name</code>: the name of the client connection, as defined by a prior client setname command</li>
<li><code>addr</code>: the address and port from which the client is connecting</li>
<li><code>fd</code>: the file descriptor that corresponds to the socket over which the client is connecting</li>
<li><code>age</code>: the total duration of the client connection, in seconds</li>
<li><code>flags</code>: a set of one or more single-character flags that provide more granular detail about the clients; see the client list command documentation for more details</li>
<li><code>db</code>: the current database ID number that the client is connected to (can be from 0 to 15)</li>
<li><code>sub</code>: the number of channels the client is subscribed to</li>
<li><code>psub</code>: the number of the client’s pattern-matching subscriptions</li>
<li><code>mutli</code>: the number of commands the client has queued in a transaction (will show -1 if the client hasn’t begun a transaction or 0 if it has only started a transaction and not queued any commands)</li>
<li><code>qbuf</code>: the client’s query buffer length, with 0 meaning it has no pending queries</li>
<li><code>qbuf-free</code>: the amount of free space in the client’s query buffer, with 0 meaning that the query buffer is full</li>
<li><code>obl</code>: the client’s output buffer length</li>
<li><code>oll</code>: the length of the client’s output list, where replies are queued when its buffer is full</li>
<li><code>omem</code>: the memory used by the client’s output buffer</li>
<li><code>events</code>: the client’s file descriptor events, these can be r for “readable”, w for “writable,” or both</li>
<li><code>cmd</code>: the last command run by the client</li>
</ul>
<p>Setting client names is useful for debugging connection leaks in whatever application is using Redis. Every new connection starts without an assigned name, but client <code>setname</code> can be used to create one for the current client connection. There’s no limit to how long client names can be, although Redis usually limits string lengths to 512 MB. Note, though, that client names cannot include spaces:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">setname</span> <span class="string">elaine</span></span><br></pre></td></tr></table></figure>
<p>To retrieve the name of a client connection, use the client <code>getname</code> command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">getname</span></span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;elaine&quot;</span></span><br></pre></td></tr></table></figure>
<p>To retrieve a client’s connection ID, use the client id command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">id</span></span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">(integer)</span> <span class="string">&quot;19492&quot;</span></span><br></pre></td></tr></table></figure>
<p>Redis client IDs are never repeated and are monotonically incremental. This means that if one client has an ID greater than another, then it was established at a later time.</p>
<br>

<hr>
<h2 id="Block-amp-Close-Client-Connections"><a href="#Block-amp-Close-Client-Connections" class="headerlink" title="Block &amp; Close Client Connections"></a>Block &amp; Close Client Connections</h2><p>Replication systems are typically described as being either synchronous or asynchronous. In synchronous replication, whenever a client adds or changes data it must receive some kind of acknowledgement from a certain number of replicas for the change to register as having been committed. This helps to prevent nodes from having data conflicts but it comes at a cost of latency, since the client must wait to perform another operation until it has heard back from a certain number of replicas.</p>
<p>In asynchronous replication, on the other hand, the client sees a confirmation that the operation is finished as soon as the data is written to local storage. There can, however, be a lag between this and when the replicas actually write the data. If one of the replicas fails before it can write the change, that write will be lost forever. So while asynchronous replication allows clients to continue performing operations without the latency caused by waiting for replicas, it can lead to data conflicts between nodes and may require extra work on the part of the database administrator to resolve those conflicts.</p>
<p>Because of its focus on performance and low latency, Redis implements asynchronous replication by default. However, you can simulate synchronous replication with the wait command. wait blocks the current client connection for a specified amount of time (in milliseconds) until all the previous write commands are successfully transferred and accepted by a specified number of replicas. This command uses the following syntax:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">wait</span> <span class="string">number_of_replicas</span> <span class="string">number_of_milliseconds</span></span><br></pre></td></tr></table></figure>
<p>For example, if you want to block your client connection until all the previous writes are registered by at least 3 replicas within a 30 millisecond timeout, your wait syntax would look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">wait</span> <span class="number">3</span> <span class="number">30</span></span><br></pre></td></tr></table></figure>
<p>The wait command returns an integer representing the number of replicas that acknowledged the write commands, even if not every replica does so:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>To unblock a client connection that has been previously blocked, whether from a wait, brpop, or xread command, you can run a client unblock command with the following syntax:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">unblock</span> <span class="string">client_id</span></span><br></pre></td></tr></table></figure>
<p>To temporarily suspend every client currently connected to the Redis server, you can use the client pause command. This is useful in cases where you need to make changes to your Redis setup in a controlled way. For example, if you’re promoting one of your replicas to be the primary instance, you might pause every client beforehand so you can promote the replica and have the clients connect to it as the new primary without losing any write operations in the process.</p>
<p>The client pause command requires you to specify the amount of time (in milliseconds) you’d like to suspend the clients. The following example will suspend all clients for one second:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">pause</span> <span class="number">1000</span></span><br></pre></td></tr></table></figure>
<p>The client kill syntax allows you to close a single connection or a set of specific connections based on a number of different filters. The syntax looks like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">client</span> <span class="string">kill</span> <span class="string">filter_1</span> <span class="string">value_1</span> <span class="string">...</span> <span class="string">filter_n</span> <span class="string">value_n</span></span><br></pre></td></tr></table></figure>
<p>In Redis versions 2.8.12 and later, the following filters are available:</p>
<ul>
<li><code>addr</code>: allows you to close a client connection from a specified IP address and port</li>
<li><code>client-id</code>: allows you to close a client connection based on its unique ID field</li>
<li><code>type</code>: closes every client of a given type, which can be either normal, master, slave, or pubsub</li>
<li><code>skipme</code>: the value options for this filter are yes and no:<ul>
<li><code>if no</code> is specified, the client calling the client kill command will not get skipped, and will be killed if the other filters apply to it</li>
<li><code>if yes</code> is specified, the client running the command will be skipped and the kill command will have no effect on the client. <code>skipme</code> is always yes by default</li>
</ul>
</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Install &amp; Secure Redis</title>
    <url>/2019/Redis/</url>
    <content><![CDATA[<p>Redis is an in-memory key-value store known for its flexibility, performance, and wide language support. This post demonstrates how to install, configure, and secure Redis on an <a href="https://www.digitalocean.com/community/tags/redis?type=tutorials">Ubuntu server</a>.</p>
<blockquote>
<p>  Before moving forwards, make sure to <a href="/2018/Initial-Server-Setup/">set up the Server configured with a non-root sudo user and a firewall</a>. </p>
</blockquote>
<p>Keep in mind that once someone is logged in to your server, it’s very easy to circumvent the Redis-specific security features we’ve put in place. Therefore, <strong>the most important security feature on your Redis server is your firewall</strong> (which configured in the initial setup), as this makes it extremely difficult for malicious actors to jump that fence.</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Config-Redis"><a href="#Config-Redis" class="headerlink" title="Config Redis"></a>Config Redis</h2><p>First install Redis:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">redis-server</span></span><br></pre></td></tr></table></figure>

<p>Following this, there is one important configuration change to make in the Redis configuration file, which was generated automatically during the installation.</p>
<p>Open this file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/redis/redis.conf</span></span><br></pre></td></tr></table></figure>
<p>Inside the file, find the supervised directive. This directive allows you to declare an init system to manage Redis as a service, providing you with more control over its operation. The supervised directive is set to no by default. Since you are running Ubuntu, which uses the <code>systemd init</code> system, change this to <code>systemd</code>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">. . .</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you run Redis from upstart or systemd, Redis can interact with your</span></span><br><span class="line"><span class="comment"># supervision tree. Options:</span></span><br><span class="line"><span class="comment">#   supervised no      - no supervision interaction</span></span><br><span class="line"><span class="comment">#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode</span></span><br><span class="line"><span class="comment">#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET</span></span><br><span class="line"><span class="comment">#   supervised auto    - detect upstart or systemd method based on</span></span><br><span class="line"><span class="comment">#                        UPSTART_JOB or NOTIFY_SOCKET environment variables</span></span><br><span class="line"><span class="comment"># Note: these supervision methods only signal &quot;process is ready.&quot;</span></span><br><span class="line"><span class="comment">#       They do not enable continuous liveness pings back to your supervisor.</span></span><br><span class="line">supervised systemd</span><br><span class="line"></span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>
<p>That’s the only change you need to make to the Redis configuration file at this point, so save and close it when you are finished. Then, restart the Redis service to reflect the changes you made to the configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">redis.service</span></span><br></pre></td></tr></table></figure>
<p>With that, you’ve installed and configured Redis and it’s running on your machine. Before you begin using it, though, it’s prudent to first check whether Redis is functioning correctly.</p>
<br>

<hr>
<h2 id="Testing-Redis"><a href="#Testing-Redis" class="headerlink" title="Testing Redis"></a>Testing Redis</h2><p>As with any newly-installed software, it’s a good idea to ensure that Redis is functioning as expected before making any further changes to its configuration. We will go over a handful of ways to check that Redis is working correctly in this step.</p>
<p>Start by checking that the Redis service is running:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure>
<p>Here, we can see that Redis is running and is already enabled, meaning that it is set to start up every time the server boots.</p>
<blockquote>
<p>Note: This setting is desirable for many common use cases of Redis. If, however, you prefer to start up Redis manually every time your server boots, you can configure this with the following command:</p>
<p><code>sudo systemctl disable redis</code></p>
</blockquote>
<p>To test that Redis is functioning correctly, connect to the server using the command-line client:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">redis-cli</span></span><br></pre></td></tr></table></figure>
<p>In the prompt that follows, test connectivity with the ping command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ping</span></span><br></pre></td></tr></table></figure>

<p>This output <code>PONG</code> confirms that the server connection is still alive. Next, check that you’re able to set keys by running:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">set</span> <span class="string">test</span> <span class="string">&quot;It&#x27;s working!&quot;</span></span><br></pre></td></tr></table></figure>

<p>Retrieve the value by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">get</span> <span class="string">test</span></span><br></pre></td></tr></table></figure>

<p>Assuming everything is working, you will be able to retrieve the value you stored: </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;It&#x27;s working!&quot;</span></span><br></pre></td></tr></table></figure>

<p>Use <code>exit</code> to quit Redis. As a final test, we will check whether Redis is able to persist data even after it’s been stopped or restarted. To do this, first restart the Redis instance:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure>
<p>Then connect with the command-line client once again and confirm that your test value is still available:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">redis-cli</span></span><br><span class="line"><span class="string">get</span> <span class="string">test</span></span><br></pre></td></tr></table></figure>
<p>The value of your key should still be accessible:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;It&#x27;s working!&quot;</span></span><br></pre></td></tr></table></figure>


<p>With that, your Redis installation is fully operational and ready for you to use. However, some of its default configuration settings are insecure and provide malicious actors with opportunities to attack and gain access to your server and its data. The remaining steps in this post cover methods for mitigating these vulnerabilities, as prescribed by the official Redis website. Although these steps are optional and Redis will still function if you choose not to follow them, it is strongly recommended that you complete them in order to harden your system’s security.</p>
<br>

<hr>
<h2 id="Bind-to-localhost"><a href="#Bind-to-localhost" class="headerlink" title="Bind to localhost"></a>Bind to localhost</h2><p><strong>By default, Redis is only accessible from localhost</strong>. However, if you installed and configured Redis differently, you might have updated the configuration file to allow connections from anywhere. <u>This is not as secure as binding to localhost</u>.</p>
<p>To correct this, open the Redis configuration file for editing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/redis/redis.conf</span></span><br></pre></td></tr></table></figure>
<p>Locate this line and make sure it is uncommented:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">bind</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="string">::1</span></span><br></pre></td></tr></table></figure>

<p>Then, restart the service to ensure that <code>systemd</code> reads your changes:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure>
<p>To check that this change has gone into effect, run the following netstat command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">netstat</span> <span class="string">-lnp</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      14222/redis-server  </span><br><span class="line">tcp6       0      0 ::1:6379                :::*                    LISTEN      14222/redis-server  </span><br></pre></td></tr></table></figure>

<p>This output shows that the redis-server program is bound to localhost (127.0.0.1), reflecting the change you just made to the configuration file. If you see another IP address in that column (0.0.0.0, for example), then you should double check that you uncommented the correct line and restart the Redis service again.</p>
<p>Now that your Redis installation is only listening in on localhost, it will be more difficult for malicious actors to make requests or gain access to your server. However, Redis isn’t currently set to require users to authenticate themselves before making changes to its configuration or the data it holds. To remedy this, Redis allows you to require users to authenticate with a password before making changes via the Redis client (redis-cli).</p>
<br>



<hr>
<h2 id="Set-a-Redis-Password"><a href="#Set-a-Redis-Password" class="headerlink" title="Set a Redis Password"></a>Set a Redis Password</h2><p>Configuring a Redis password enables one of its two built-in security features — the auth command, which requires clients to authenticate to access the database. The password is configured directly in Redis’s configuration file, <code>/etc/redis/redis.conf</code>, so open that file again with your preferred editor:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/redis/redis.conf</span></span><br></pre></td></tr></table></figure>
<p>Scroll to the SECURITY section and uncomment the following line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">requirepass</span> <span class="string">foobared</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: Above the requirepass directive in the redis.conf file, there is a commented warning:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Warning: since Redis is pretty fast an outside user can try up to</span></span><br><span class="line"><span class="comment"># 150k passwords per second against a good box. This means that you should</span></span><br><span class="line"><span class="comment"># use a very strong password otherwise it will be very easy to break.</span></span><br></pre></td></tr></table></figure>


<p>Thus, it’s important that you specify a very strong and very long value as your password. Rather than make up a password yourself, you can use the openssl command to generate a random one, as in the following example. By piping the output of the first command to the second openssl command, as shown here, it will remove any line breaks produced by that the first command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">openssl</span> <span class="string">rand</span> <span class="number">60</span> <span class="string">|</span> <span class="string">openssl</span> <span class="string">base64</span> <span class="string">-A</span></span><br></pre></td></tr></table></figure>


<p>Your output should look something like:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">RBOJ9cCNoGCKhlEBwQLHri1g+atWgn4Xn4HwNUbtzoVxAYxkiYBi7aufl4MILv1nxBqR4L6NNzI0X6cE</span><br></pre></td></tr></table></figure>


<p>After copying and pasting the output of that command as the new value for requirepass, it should read:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /etc/redis/redis.conf</span></span><br><span class="line"></span><br><span class="line"><span class="string">requirepass</span> <span class="string">RBOJ9cCNoGCKhlEBwQLHri1g+atWgn4Xn4HwNUbtzoVxAYxkiYBi7aufl4MILv1nxBqR4L6NNzI0X6cE</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>After setting the password, save and close the file, then restart Redis:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">redis.service</span></span><br></pre></td></tr></table></figure>
<p>To test that the password works, access the Redis command line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">redis-cli</span></span><br></pre></td></tr></table></figure>
<p>The following shows a sequence of commands used to test whether the Redis password works. The first command tries to set a key to a value before authentication:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">set</span> <span class="string">key1</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>
<p>That won’t work because you didn’t authenticate, so Redis returns an error:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">(error) NOAUTH Authentication required.</span><br></pre></td></tr></table></figure>
<p>The next command authenticates with the password specified in the Redis configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">auth</span> <span class="string">your_redis_password</span></span><br></pre></td></tr></table></figure>
<p>Redis acknowledges with <code>OK</code>. After that, running the previous command again will succeed:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">set</span> <span class="string">key1</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>And the output should be <code>OK</code>. Then type the following command: </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">get</span> <span class="string">key1</span></span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;10&quot;</span></span><br></pre></td></tr></table></figure>
<p>After confirming that you’re able to run commands in the Redis client after authenticating, we can exit. Next, we’ll look at renaming Redis commands which, if entered by mistake or by a malicious actor, could cause serious damage to your machine.</p>
<br>

<hr>
<h2 id="Rename-Dangerous-Commands"><a href="#Rename-Dangerous-Commands" class="headerlink" title="Rename Dangerous Commands"></a>Rename Dangerous Commands</h2><p>The other security feature built into Redis involves renaming or completely disabling certain commands that are considered dangerous.</p>
<p>When run by unauthorized users, such commands can be used to reconfigure, destroy, or otherwise wipe your data. Like the authentication password, renaming or disabling commands is configured in the same SECURITY section of the <code>/etc/redis/redis.conf</code> file.</p>
<p>Some of the commands that are considered dangerous include: <strong>FLUSHDB, FLUSHALL, KEYS, PEXPIRE, DEL, CONFIG, SHUTDOWN, BGREWRITEAOF, BGSAVE, SAVE, SPOP, SREM, RENAME, and DEBUG</strong>. This is not a comprehensive list, but renaming or disabling all of the commands in that list is a good starting point for enhancing your Redis server’s security.</p>
<p>Whether you should disable or rename a command depends on your specific needs or those of your site. If you know you will never use a command that could be abused, then you may disable it. Otherwise, it might be in your best interest to rename it.</p>
<p>To enable or disable Redis commands, open the configuration file once more:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span>  <span class="string">/etc/redis/redis.conf</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Warning: The following steps showing how to disable and rename commands are examples. You should only choose to disable or rename the commands that make sense for you. You can review the full list of commands for yourself and determine how they might be misused at redis.io/commands.</p>
</blockquote>
<p>To disable a command, simply rename it to an empty string (signified by a pair of quotation marks with no characters between them), as shown below:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">. . .</span><br><span class="line"><span class="comment"># It is also possible to completely kill a command by renaming it into</span></span><br><span class="line"><span class="comment"># an empty string:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">rename-command FLUSHDB <span class="string">&quot;&quot;</span></span><br><span class="line">rename-command FLUSHALL <span class="string">&quot;&quot;</span></span><br><span class="line">rename-command DEBUG <span class="string">&quot;&quot;</span></span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>
<p>To rename a command, give it another name as shown in the examples below. Renamed commands should be difficult for others to guess, but easy for you to remember:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">. . .</span><br><span class="line"><span class="comment"># rename-command CONFIG &quot;&quot;</span></span><br><span class="line">rename-command SHUTDOWN SHUTDOWN_MENOT</span><br><span class="line">rename-command CONFIG ASC12_CONFIG</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>After renaming a command, apply the change by restarting Redis:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">redis.service</span></span><br></pre></td></tr></table></figure>
<p>To test the new command, enter the Redis command line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">redis-cli</span></span><br></pre></td></tr></table></figure>
<p>Then, authenticate:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">auth</span> <span class="string">your_redis_password</span></span><br></pre></td></tr></table></figure>

<p>And the output should be <code>OK</code>. Let’s assume that you renamed the CONFIG command to <code>ASC12_CONFIG</code>, as in the preceding example. First, try using the original CONFIG command. It should fail, because you’ve renamed it:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">config</span> <span class="string">get</span> <span class="string">requirepass</span></span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">(error)</span> <span class="string">ERR</span> <span class="string">unknown</span> <span class="string">command</span> <span class="string">&#x27;config&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Calling the renamed command, however, will be successful. It is not case-sensitive:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">asc12_config</span> <span class="string">get</span> <span class="string">requirepass</span></span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span><span class="string">)</span> <span class="string">&quot;requirepass&quot;</span></span><br><span class="line"><span class="number">2</span><span class="string">)</span> <span class="string">&quot;your_redis_password&quot;</span></span><br></pre></td></tr></table></figure>
<p>Then we can exit. Note that if you’re already using the Redis command line and then restart Redis, you’ll need to re-authenticate. Otherwise, you’ll get this error if you type a command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">NOAUTH</span> <span class="string">Authentication</span> <span class="string">required.</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Warning"><a href="#Warning" class="headerlink" title="Warning"></a>Warning</h3><p>Regarding the practice of renaming commands, there’s a cautionary statement at the end of the SECURITY section in <code>/etc/redis/redis.conf</code> which reads:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Please note that changing the name of commands that are logged into the AOF file or transmitted to slaves may cause problems.</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: The Redis project chooses to use the terms <strong>master</strong> and <strong>slave</strong>, while some prefers the alternatives <strong>primary</strong> and <strong>secondary</strong>. In order to avoid confusion,  we will use the terms used in the Redis documentation here.</p>
</blockquote>
<p>That means if the renamed command is not in the AOF file, or if it is but the AOF file has not been transmitted to slaves, then there should be no problem.</p>
<p>So, keep that in mind when you’re trying to rename commands. The best time to rename a command is when you’re not using AOF persistence, or right after installation, that is, before your Redis-using application has been deployed.</p>
<p>When you’re using AOF and dealing with a master-slave installation, consider this answer from the project’s GitHub issue page. The following is a reply to the author’s question:</p>
<blockquote>
<p>The commands are logged to the AOF and replicated to the slave the same way they are sent, so if you try to replay the AOF on an instance that doesn’t have the same renaming, you may face inconsistencies as the command cannot be executed (same for slaves).</p>
</blockquote>
<p>Thus, the best way to handle renaming in cases like that is to make sure that renamed commands are applied to all instances in master-slave installations.</p>
<br>

<br>
]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Install &amp; Secure MongoDB</title>
    <url>/2019/MongoDB/</url>
    <content><![CDATA[<p>MongoDB is a <strong>document-oriented database</strong> that is free and open-source. It is classified as a NoSQL database because it does not rely on a traditional table-based relational database structure. Instead, it uses JSON-like documents with dynamic schemas. Unlike relational databases, MongoDB does not require a predefined schema before you add data to a database. You can alter the schema at any time and as often as is necessary without having to setup a new database with an updated schema.</p>
<span id="more"></span> 

<p><a href="https://www.digitalocean.com/community/tags/mongodb?type=tutorials">In this post</a>, we will first use the MongoDB Repository to install the latest version of MongoDB. Then we’ll enable authentication to secure it on the local system. Finally, we’ll show how to more securely allow remote connections if they’re needed.</p>
<blockquote>
<p>  Before moving forwards, make sure to <a href="/2018/Initial-Server-Setup/">set up the Server configured with a non-root sudo user and a firewall</a>. </p>
</blockquote>
<br>

<hr>
<h2 id="Set-Up-the-Server"><a href="#Set-Up-the-Server" class="headerlink" title="Set Up the Server"></a>Set Up the Server</h2><h3 id="Add-the-MongoDB-Repository"><a href="#Add-the-MongoDB-Repository" class="headerlink" title="Add the MongoDB Repository"></a><u>Add the MongoDB Repository</u></h3><p>MongoDB is already included in Ubuntu package repositories, but the official MongoDB repository provides the most up-to-date version and is the recommended way of installing the software. In this step, we will add this official repository to our server.</p>
<p>Ubuntu ensures the authenticity of software packages by verifying that they are signed with GPG keys, so we first have to import the key for the official MongoDB repository.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 \</span><br><span class="line">--recv 0C49F3730359A14518585931BC711F9BA15703C6</span><br></pre></td></tr></table></figure>
<p>The following output confirms that we’ve successfully imported the key:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">Executing: /tmp/tmp.IdwenTia0s/gpg.1.sh --keyserver</span><br><span class="line">hkp://keyserver.ubuntu.com:80</span><br><span class="line">--recv</span><br><span class="line">0C49F3730359A14518585931BC711F9BA15703C6</span><br><span class="line">gpg: requesting key A15703C6 from hkp server keyserver.ubuntu.com</span><br><span class="line">gpg: key A15703C6: public key <span class="string">&quot;MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt;&quot;</span> imported</span><br><span class="line">gpg: Total number processed: 1</span><br><span class="line">gpg:               imported: 1  (RSA: 1)</span><br></pre></td></tr></table></figure>

<p>Next, we’ll add MongoDB repository details so apt will know where to download the packages. Issue the following command to create a list file for MongoDB.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 \</span></span><br><span class="line"><span class="string">multiverse&quot;</span> | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list</span><br></pre></td></tr></table></figure>
<p>Finally, we’ll update the packages list.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>
<p>Now we’re ready to install MongoDB.</p>
<br>

<h3 id="Install-MongoDB"><a href="#Install-MongoDB" class="headerlink" title="Install MongoDB"></a><u>Install MongoDB</u></h3><p>We’ll install the <code>mongodb-org</code> meta-package, which includes the daemon, configuration and init scripts, shell, and management tools on the server.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">mongodb-org</span></span><br></pre></td></tr></table></figure>
<p>Press enter or type Y to proceed when prompted. Once the installation is complete, we’ll start the Mongo daemon:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">start</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>
<p>Since systemctl doesn’t provide output, we’ll check the status to verify that the service has started properly.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>

<p>Now that we’ve manually started the daemon and verified that it’s running, we’ll ensure that it restarts automatically at boot:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">enable</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>
<p>The following output confirms that the command was successful:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Created</span> <span class="string">symlink</span> <span class="string">from</span> <span class="string">/etc/systemd/system/multi-user.target.wants/mongod.service</span></span><br><span class="line"><span class="string">to</span> <span class="string">/lib/systemd/system/mongod.service.</span></span><br></pre></td></tr></table></figure>

<p>Next, we’ll take essential steps to secure our databases.</p>
<br>

<hr>
<h2 id="Secure-MongoDB"><a href="#Secure-MongoDB" class="headerlink" title="Secure MongoDB"></a>Secure MongoDB</h2><p>Earlier versions of MongoDB were vulnerable to automated exploits because by default no authentication was required to interact with the database. Any user could create and destroy databases, as well as read from and write to their contents by default. This was compounded because those earlier versions also configured the MongoDB daemon to listen on all interfaces by default, which meant that automated scripts could detect MongoDB instances that weren’t protected by a firewall and, if authentication hadn’t been enabled, gain complete access to MongoDB.</p>
<p>The situation has been mitigated in the 3.x release as well as earlier versions provided by some package managers because the daemon is now bound to 127.0.0.1 so it will only accept connections on the Unix socket. It is not automatically open to the Internet.</p>
<p>However, authentication is still disabled by default, so any users on the local system have complete access to the databases. To secure this we’ll create an administrative user, enable authentication and test.</p>
<br>

<h3 id="Add-an-Admin"><a href="#Add-an-Admin" class="headerlink" title="Add an Admin"></a><u>Add an Admin</u></h3><p>To add our user, we’ll connect to the Mongo shell:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mongo</span></span><br></pre></td></tr></table></figure>
<p>The output when we use the Mongo shell warns us that access control is not enabled for the database and that read/write access to data and configuration is unrestricted.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">MongoDB shell version v3.4.2</span><br><span class="line">connecting to: mongodb://127.0.0.1:27017</span><br><span class="line">MongoDB server version: 3.4.2</span><br><span class="line">Welcome to the MongoDB shell.</span><br><span class="line">For interactive <span class="built_in">help</span>, <span class="built_in">type</span> <span class="string">&quot;help&quot;</span>.</span><br><span class="line">For more comprehensive documentation, see</span><br><span class="line">        http://docs.mongodb.org/</span><br><span class="line">Questions? Try the support group</span><br><span class="line">        http://groups.google.com/group/mongodb-user</span><br><span class="line">Server has startup warnings:</span><br><span class="line">2017-02-21T19:10:42.446+0000 I STORAGE  [initandlisten]</span><br><span class="line">2017-02-21T19:10:42.446+0000 I STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine</span><br><span class="line">2017-02-21T19:10:42.446+0000 I STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem</span><br><span class="line">2017-02-21T19:10:42.534+0000 I CONTROL  [initandlisten]</span><br><span class="line">2017-02-21T19:10:42.534+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled <span class="keyword">for</span> the database.</span><br><span class="line">2017-02-21T19:10:42.534+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.</span><br><span class="line">2017-02-21T19:10:42.534+0000 I CONTROL  [initandlisten]</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>We’re free to choose the name for the administrative user since the privilege level comes from the assignment of the role <code>userAdminAnyDatabas</code>e. The database, admin designates where the credentials are stored. You can learn more about authentication in the MongoDB Security Authentication section.</p>
<p>Set the username of your choice and be sure to pick your own secure password and substitute them in the command below:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">use</span> <span class="string">admin</span></span><br><span class="line"><span class="string">db.createUser(</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">user:</span> <span class="string">&quot;Merikanto&quot;</span>,</span><br><span class="line">    <span class="attr">pwd:</span> <span class="string">&quot;Merikanto&#x27;sSecurePassword&quot;</span>,</span><br><span class="line">    <span class="attr">roles:</span> [ &#123; <span class="attr">role:</span> <span class="string">&quot;userAdminAnyDatabase&quot;</span>, <span class="attr">db:</span> <span class="string">&quot;admin&quot;</span> &#125; ]</span><br><span class="line">  &#125;</span><br><span class="line"><span class="string">)</span></span><br></pre></td></tr></table></figure>
<p>When we issue the <code>db.createUser</code> command, the shell will prepend three dots before each line until the command is complete. After that, we should receive feedback like the following when the user has been added.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">&gt; use admin</span><br><span class="line">switched to db admin</span><br><span class="line"></span><br><span class="line">&gt; db.createUser(</span><br><span class="line">...   &#123;</span><br><span class="line">...     user: <span class="string">&quot;Merikanto&quot;</span>,</span><br><span class="line">...     <span class="built_in">pwd</span>: <span class="string">&quot;Merikanto&#x27;sSecurePassword&quot;</span>,</span><br><span class="line">...     roles: [ &#123; role: <span class="string">&quot;userAdminAnyDatabase&quot;</span>, db: <span class="string">&quot;admin&quot;</span> &#125; ]</span><br><span class="line">...   &#125;</span><br><span class="line">... )</span><br><span class="line">Successfully added user: &#123;</span><br><span class="line">        <span class="string">&quot;user&quot;</span> : <span class="string">&quot;Merikanto&quot;</span>,</span><br><span class="line">        <span class="string">&quot;roles&quot;</span> : [</span><br><span class="line">                &#123;</span><br><span class="line">                        <span class="string">&quot;role&quot;</span> : <span class="string">&quot;userAdminAnyDatabase&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;db&quot;</span> : <span class="string">&quot;admin&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>At this point, our user will be allowed to enter credentials, but they will not be required to do so until we enable authentication and restart the MongoDB daemon.</p>
<br>

<h3 id="Enable-Authentication"><a href="#Enable-Authentication" class="headerlink" title="Enable Authentication"></a><u>Enable Authentication</u></h3><p>Authentication is enabled in the <code>mongod.conf</code> file. Once we enable it and restart mongod, users still will be able to connect to Mongo without authenticating, but they will be required to provide a username and password before they can interact.</p>
<p>Let’s open the configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/mongod.conf</span></span><br></pre></td></tr></table></figure>
<p>In the #security section, we’ll remove the hash in front of security to enable the stanza. Then we’ll add the authorization setting. When we’re done, the lines should look like the excerpt below:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mongodb.conf</span></span><br><span class="line"> <span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="attr">security:</span></span><br><span class="line">  <span class="attr">authorization:</span> <span class="string">&quot;enabled&quot;</span></span><br><span class="line"> <span class="string">.</span> <span class="string">.</span> <span class="string">.</span> </span><br></pre></td></tr></table></figure>
<p>Note that the “security” line has no spaces at the beginning, and the “authorization” line must be indented with two spaces</p>
<p>Once we’ve saved and exited the file, we’ll restart the daemon:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>
<p>If we’ve made an error in the configuration, the daemon won’t start. Since systemctl doesn’t provide output, we’ll use its status option to be sure that it did:.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>
<p>If we see Active: active (running) in the output and it ends with something like the text below, we can be sure the restart command was successful:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Apr</span> <span class="number">25</span> <span class="number">19</span><span class="string">:15:42</span> <span class="string">MongoHost</span> <span class="string">systemd[1]:</span> <span class="string">Started</span> <span class="string">High-performance,</span> <span class="string">schema-free</span> <span class="string">document-oriented</span> <span class="string">database.</span></span><br></pre></td></tr></table></figure>
<p>Having verified the daemon is up, let’s test authentication.</p>
<br>

<h3 id="Restrict-Unauthed-Users"><a href="#Restrict-Unauthed-Users" class="headerlink" title="Restrict Unauthed Users"></a><u>Restrict Unauthed Users</u></h3><p>First, let’s connect without credentials to verify that our actions are restricted:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mongo</span> </span><br></pre></td></tr></table></figure>
<p>Now that we’ve enabled authentication, all of the earlier warnings are resolved.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">MongoDB shell version v3.4.2</span><br><span class="line">connecting to: mongodb://127.0.0.1:27017</span><br><span class="line">MongoDB server version: 3.4.2</span><br></pre></td></tr></table></figure>
<p>We’re connected to the test database. We’ll test that our access is restricted with the show dbs command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">show</span> <span class="string">dbs</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">2017-02-21T19:20:42.919</span><span class="string">+0000</span> <span class="string">E</span> <span class="string">QUERY</span>    [<span class="string">thread1</span>] <span class="attr">Error:</span> <span class="string">listDatabases</span> <span class="string">failed:&#123;</span></span><br><span class="line">        <span class="string">&quot;ok&quot;</span> <span class="string">:</span> <span class="number">0</span><span class="string">,</span></span><br><span class="line">        <span class="string">&quot;errmsg&quot;</span> <span class="string">:</span> <span class="string">&quot;not authorized on admin to execute command &#123; listDatabases: 1.0 &#125;&quot;</span><span class="string">,</span></span><br><span class="line">        <span class="string">&quot;code&quot;</span> <span class="string">:</span> <span class="number">13</span><span class="string">,</span></span><br><span class="line">        <span class="string">&quot;codeName&quot;</span> <span class="string">:</span> <span class="string">&quot;Unauthorized&quot;</span></span><br><span class="line"> <span class="string">.</span> <span class="string">.</span> <span class="string">.</span> </span><br></pre></td></tr></table></figure>

<p>We wouldn’t be able to create users or similarily privileged tasks without authenticating. Next, we’ll make sure our Administrative user does have access.</p>
<br>

<h3 id="Verify-Admin’s-Access"><a href="#Verify-Admin’s-Access" class="headerlink" title="Verify Admin’s Access"></a><u>Verify Admin’s Access</u></h3><p>We’ll connect as our administrator with the -u option to supply a username and -p to be prompted for a password. We will also need to supply the database where we stored the user’s authentication credentials with the –authenticationDatabase option.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mongo</span> <span class="string">-u</span> <span class="string">Merikanto</span> <span class="string">-p</span> <span class="string">--authenticationDatabase</span> <span class="string">admin</span></span><br></pre></td></tr></table></figure>
<p>We’ll be prompted for the password, so supply it. Once we enter the correct password, we’ll be dropped into the shell, where we can issue the show dbs command:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">MongoDB shell version v3.4.2</span><br><span class="line">Enter password:</span><br><span class="line">connecting to: mongodb://127.0.0.1:27017</span><br><span class="line">MongoDB server version: 3.4.2</span><br></pre></td></tr></table></figure>
<p>Rather than being denied access, we should see the available databases:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">show</span> <span class="string">dbs</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">admin</span>  <span class="number">0.</span><span class="string">000GB</span></span><br><span class="line"><span class="string">local</span>  <span class="number">0.</span><span class="string">000GB</span></span><br></pre></td></tr></table></figure>

<p>See the MongoDB documentation to learn more about <a href="https://docs.mongodb.com/manual/core/authentication/">Authentication</a>, <a href="https://docs.mongodb.com/manual/core/authorization/">Role-Based Access Control</a>, and <a href="https://docs.mongodb.com/manual/tutorial/manage-users-and-roles/">Users and Roles</a>.</p>
<br>

<hr>
<h2 id="Configuring-Remote-Access"><a href="#Configuring-Remote-Access" class="headerlink" title="Configuring Remote Access"></a>Configuring Remote Access</h2><p>Before we start working with an installation that allows remote connections, ideally we’ll have MongoDB behind an external firewall, protected by a virtual private network (VPN), or restricted through a bastion host. As we work toward that, however, we can take the somewhat less-complicated step of enabling a firewall on the database server and restricting access to the specific host or hosts that need it.</p>
<br>

<h3 id="Enable-UFW"><a href="#Enable-UFW" class="headerlink" title="Enable UFW"></a><u>Enable UFW</u></h3><p>In the Initial Server Setup with Ubuntu 16.04 prerequisite, we enabled UFW and allowed only SSH connections. Before we open a port for our client machine, let’s verify UFW’s status:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ufw</span> <span class="string">status</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: If the output indicates that the firewall is inactive, activate it with:</p>
<p><code>sudo ufw enable</code></p>
<p>Once it’s enabled, rerunning the status command, sudo ufw status will show the rules. If necessary, be sure to allow SSH.</p>
<p><code>sudo ufw allow OpenSSH</code></p>
</blockquote>
<p>Unless we made changes to the prerequisites, the output should show that only OpenSSH is allowed:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Status: active</span><br><span class="line"></span><br><span class="line">To                         Action      From</span><br><span class="line">--                         ------      ----</span><br><span class="line">OpenSSH                    ALLOW       Anywhere</span><br><span class="line">OpenSSH (v6)               ALLOW       Anywhere (v6)</span><br></pre></td></tr></table></figure>
<p>Next, we’ll allow access to the default MongoDB port, 27017, but restrict that access to a specific host. If you’ve changed the default port, be sure to update it in the command below.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ufw</span> <span class="string">allow</span> <span class="string">from</span> <span class="string">client_ip_address</span> <span class="string">to</span> <span class="string">any</span> <span class="string">port</span> <span class="number">27017</span></span><br></pre></td></tr></table></figure>
<p>Re-run this command using the IP address for each additional client that needs access. To double-check the rule, we’ll run ufw status again:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ufw</span> <span class="string">status</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">To                         Action      From</span><br><span class="line">--                         ------      ----</span><br><span class="line">OpenSSH                    ALLOW       Anywhere</span><br><span class="line">27017                       ALLOW      client_ip_address</span><br><span class="line">OpenSSH (v6)               ALLOW       Anywhere (v6)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: If you’re new to UFW, you can learn more in the guide, UFW Essentials: Common Firewall Rules and Commands.</p>
</blockquote>
<p>With this firewall rule in place, we’re ready to configure MongoDB to listen on its public interface.</p>
<br>

<h3 id="Configure-a-Public-bindIP"><a href="#Configure-a-Public-bindIP" class="headerlink" title="Configure a Public bindIP"></a><u>Configure a Public bindIP</u></h3><p>To allow remote connections, we will add our host’s publically-routable IP address to the mongod.conf file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/mongod.conf</span></span><br></pre></td></tr></table></figure>
<p>In the net stanza, add the MongoHost’s IP to the bindIp line:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"> <span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br><span class="line"><span class="attr">net:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">27017</span></span><br><span class="line">  <span class="attr">bindIp:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">,IP_of_MongoHost</span></span><br><span class="line"> <span class="string">.</span> <span class="string">.</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>
<p>We’ll save and exit the file, then restart the daemon:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>
<p>As we did earlier, we’ll confirm restart was successful:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">status</span> <span class="string">mongod</span></span><br></pre></td></tr></table></figure>
<p>The output should contain Active: active (running), and we can proceed to our final test. Mongo is now listening on its default port.</p>
<br>

<h3 id="Test-the-Remote-Connection"><a href="#Test-the-Remote-Connection" class="headerlink" title="Test the Remote Connection"></a><u>Test the Remote Connection</u></h3><p>We’ll test that Mongo is listening on its public interface by adding the –host flag with the IP address from the mongodb.conf file.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mongo -u Merikanto -p --authenticationDatabase admin --host IP_address_of_MongoHost</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">MongoDB shell version v3.4.2</span><br><span class="line">Enter password:</span><br><span class="line">connecting to: mongodb://107.170.233.82:27017/</span><br><span class="line">MongoDB server version: 3.4.2</span><br></pre></td></tr></table></figure>

<p>Reaching the prompt confirms that the daemon is listening on its public IP. At this point, any transaction between a remote connection and the MongoDB host is unencrypted so the next step, before testing the firewall, should be to secure those transations. For help with this, see MongoDB’s Security documentation on Transport Encryption.</p>
<br>

<br>
]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Java - The Language Design</title>
    <url>/2019/Java-Overview/</url>
    <content><![CDATA[<p>Today let us briefly talk about the language design and unique features in Java. We will compare Java with other languages, and we will also go through JVM and the security design &amp; implementation. We will see that Java is a modern language designed to address all the three pillars:</p>
<blockquote>
<p>  <strong>Portability, Speed, and Security.</strong></p>
</blockquote>
<div class="note primary"><p>Java is a <strong>statically typed, late-binding</strong> language.</p>
</div>

<span id="more"></span>

<br>

<p>Historically, the <strong>speed</strong> and <strong>portability</strong> requirement of a language has been mutually exclusive (for the most part). Fast languages usually provide speed by <strong>binding themselves to particular platforms</strong>, so portability becomes a problem. Also, safe languages were generally not portable either.</p>
<br>



<hr>
<h2 id="A-Virtual-Machine"><a href="#A-Virtual-Machine" class="headerlink" title="A Virtual Machine"></a>A Virtual Machine</h2><p>Java is both a <strong>compiled &amp; interpreted</strong> language. While C / C++ source code is reduced to native instructions for a particular processor model, Java source is compiled to a universal format — <strong>bytecode</strong> (instructions for a virtual machine).</p>
<p>Compiled bytecode is then executed by a Java runtime interpreter. The <strong>runtime system</strong> does the hardware processor’s job, but in a safe, virtual environment: </p>
<ul>
<li>  Executes a stack-based instruction set, and manages memory like the OS</li>
<li>  Creates &amp; manipulates primitive data types, and loads &amp; invokes newly referenced code block</li>
</ul>
<p>The runtime system abides by a strictly defined <strong>open specification</strong>, that can be implemented by anyone who wants to produce a Java-compliant virtual machine. </p>
<div class="note success"><p>Together, the virtual machine and language definition provide a <strong>complete specification</strong>.</p>
</div>

<p><strong>Interpretation:</strong> </p>
<blockquote>
<p>  There are no features of the base Java language left undefined, or implementation-dependent. </p>
<p>  E.g.  Java specifies the size &amp; properties of all primitive data types, rather than leaving it up to the platform implementation.</p>
</blockquote>
<br>

<p>The graph below shows the <strong>Java runtime environment</strong>. </p>
<img data-src="/images/posts/190412-1.png" style="zoom:85%;" />

<br>

<p>The fundamental unit of Java code is the <strong>class</strong>, which are application components that hold executable code &amp; data. Compiled Java classes are in a universal binary format that contains Java bytecode &amp; other class information. </p>
<p>Apart from platform-specific runtime system, Java also has <strong>fundamental classes</strong> (i.e. <em>native methods</em>) that contain architecture-dependent methods. These <strong>native methods</strong> serve as gateway between JVM &amp; the real world. They are implemented based on different OS, and provide low-level access to resources such as network &amp; host filesystem.  But still, the vast majority of Java is written in Java itself. This includes Java compiler, GUI libraries. </p>
<p>The JVM compiles source code to portable bytecode. It improves the performance via <strong>JIT</strong> (Just-In-Time), or <strong>dynamic compilation</strong>. With JIT, Java can execute almost as fast as native code, while maintain portability and security.</p>
<p>For the sake of security, there is <u>only one intrinsic performance penalty that compiled Java code suffers at runtime</u>, which is <strong>array bounds checking</strong> (prevent overflow). Everything else can be optimized to native code, just as it can with a statically compiled language.</p>
<p>The problem with <strong>traditional JIT</strong> is that, optimizing code takes time. A JIT compiler can produce decent results, but may suffer a significant latency when the application starts up. This isn’t a problem for long-running server-side applications, but problematic for  client-side apps with limited capabilities. Hence a Java compiler technology called <strong>HotSpot</strong> uses <strong>adaptive compilation</strong> to address this issue. </p>
<blockquote>
<p>  <em>If we look at what programs spend their time doing, they actually spend almost all their time executing a relatively small part of the code again and again. <u>The chunk of code that is executed repeatedly may be only a small fraction of the total program, but its behavior determines the program’s overall performance</u>.</em></p>
<p>  <em>Also, <strong>adaptive compilation</strong> allows the Java runtime to take advantage of new kinds of optimizations that simply can’t be done in a statically compiled language, hence Java can run faster than C / C++ in some cases.</em></p>
</blockquote>
<p>HotSpot profiles the code to see which parts are being executed repeatedly. Once it knows, it compiles those sections into optimal native machine code. The rest of the program will just get interpreted to save memory &amp; time. In fact, the JVM runs in one of the two modes:</p>
<ul>
<li>  <strong>Client</strong>: Focus on quick startup time &amp; memory conservation</li>
<li>  <strong>Server</strong>: Focus on speeding up performance (but slow startup)</li>
</ul>
<div class="note info"><p>A trade-off: 　<strong>Compile time</strong> &amp; <strong>Runtime</strong> (start up time)</p>
</div>

<p>With the release of Java 5, the profiling information is stored persistently in an optimized form, via shared &amp; read-only classes.</p>
<br>

<hr>
<h2 id="Comparing-with-Other-Languages"><a href="#Comparing-with-Other-Languages" class="headerlink" title="Comparing with Other Languages"></a>Comparing with Other Languages</h2><p>Comparison based on <strong>portability, speed, security</strong>:</p>
<img data-src="/images/posts/190412-2.png" style="zoom:85%;" />



<ul>
<li>  Java’s basic syntax looks like C / C++, but that’s where the similarities end</li>
<li>  <strong>C#</strong> is Microsoft’s answer to Java (C# uses virtual machine, bytecode, sandbox)</li>
<li>  <strong>C trades functionality for portability; Java initially traded speed for portability</strong></li>
<li>  Smalltalk is compiled to an interpreted bytecode format, and can be dynamically compiled to native code. However, Java improves the design by using a <strong>bytecode verifier</strong> to ensure the <strong>correctness</strong> of compiled Java code, which requires fewer runtime checks.</li>
</ul>
<p><u>Most scripting languages are not well suited for serious, large-scale programming</u>. Apart from speed, another problem is that: </p>
<blockquote>
<p>  They are rather casual about program structure and data typing. Also, they have simplified type systems, and generally don’t provide sophisticated scoping of variables &amp; functions.</p>
</blockquote>
<div class="note primary"><p>Fundamental tradeoff:</p>
<p>Scripting languages were born as <strong>loose, less structured</strong> alternatives to systems programming languages, and are generally not ideal for large / complex projects.</p>
</div>



<br>

<hr>
<h2 id="Design-Security"><a href="#Design-Security" class="headerlink" title="Design Security"></a>Design Security</h2><blockquote>
<p>  Java <strong>class loader</strong>: The bytecode loading mechanism of the Java interpreter</p>
</blockquote>
<br>

<h3 id="Simplicity"><a href="#Simplicity" class="headerlink" title="Simplicity"></a><u>Simplicity</u></h3><p>Java doesn’t allow programmer-defined operator overloading (e.g. redefine meanings of basic symbols like  <code>+</code>, <code>-</code> ).  Java doesn’t have a source code processor, so it doesn’t have macros, <code>#define</code> statements, or conditional source compilation. Since these constructs exist primarily to support platform dependencies. </p>
<p>Java supports only single inheritance class hierarchy, but allows <strong>multiple inheritance of interfaces</strong> (<code>implements</code>). An <strong>interface</strong> (like abstract class in C++) <u>specifies the behavior of an object, without defining its implementation</u>.  Interfaces in Java eliminates the need for multiple inheritance of classes. </p>
<br>

<h3 id="Type-Safety-amp-Method-Binding"><a href="#Type-Safety-amp-Method-Binding" class="headerlink" title="Type Safety &amp; Method Binding"></a><u>Type Safety &amp; Method Binding</u></h3><h4 id="Type-Checking"><a href="#Type-Checking" class="headerlink" title="Type Checking"></a>Type Checking</h4><p>Generally, languages are classified as <strong>static</strong> &amp; <strong>dynamic</strong>. For static languages, information about variables are known at compile time, while for dynamic languages, information about variables are known at runtime.</p>
<p>In a strictly statically typed language like C / C++, <u>data types are firmly established when the source code is compiled</u>. Hence the compiler will have enough information to catch errors before the code is executed. In contrast, dynamic languages only performs type checking at runtime. This allows more complex  &amp; powerful behaviors, but generally slower, less safe and harder to debug.</p>
<br>

<h4 id="Method-Binding"><a href="#Method-Binding" class="headerlink" title="Method Binding"></a>Method Binding</h4><p>Static  dynamic languages also differ in the way they <u>bind method calls to their definitions</u>. In C / C++, they’re binded at compile time (<strong>early binding</strong>), while in dynamic languages, method definitions are located dynamically at runtime (<strong>late binding</strong>). </p>
<p>Early binding can speed up performance; An application can run without the overhead incurred by searching for methods at runtime, but late binding is more flexible. It’s also necessary in an object-oriented language (C is not OOP), where new types can be loaded dynamically and only runtime system can determine which method to run. </p>
<p><strong>Java is a statically typed, late-binding language</strong>. Each object in Java has a well-defined type that is known at compile time. This means Java compiler can do the same static type checking like in C++. </p>
<p>However, Java is also fully runtime-typed:</p>
<ul>
<li>  We can inspect an object at runtime to determine what it is</li>
<li>  <strong>Casts</strong> from one type of object to another are checked by the runtime system</li>
<li>  Possible to use new kinds of dynamically loaded objects with type safety</li>
</ul>
<p>Also, since Java is late-binding, it’s always possible for a subclass to <strong>override</strong> methods in the superclass.</p>
<br>

<h3 id="Dynamic-Memory-Management"><a href="#Dynamic-Memory-Management" class="headerlink" title="Dynamic Memory Management"></a><u>Dynamic Memory Management</u></h3><p>One of the most important differences between Java &amp; other low-level languages like C / C++ is how Java manages memory. <strong>Java does not have pointers</strong>. Instead, Java adds object garbage collection &amp; high-level arrays. </p>
<p><strong>Garbage collection</strong> frees programmers from manually allocate &amp; deallocate memory. When an object is no longer in use, Java <strong>automatically</strong> removes it from memory. Java has a sophisticated garbage collector running in the background, and <u>most garbage collecting happens during idle times</u>. For instance, between I/O pauses, mouse clicks, keyboard hits. Advanced runtime systems like <strong>HotSpot</strong> use improved garbage collectors that can differentiate object usage patterns (short-lived &amp; long-lived) and optimize their collection.</p>
<p><u>Java does not have pointers, but it provides <strong>references</strong>, which are safe kinds of pointers</u>. A reference is a strongly typed handle for an object. All objects (except primitive numeric types) are <strong>accessed via references</strong>. We cannot perform pointer arithmetic with references, because a reference is <strong>atomic</strong>: we cannot manipulate the reference’s value except by assigning it to an object. </p>
<div class="note success"><p>Fundamental aspect of Java security: <strong>Reference Protection</strong></p>
<p>References are passed by value, and we cannot reference an object via more than a single level of indirection.</p>
</div>

<p><strong>Java references can only point to class types, there are no pointers to methods</strong>. Most tasks that call for pointers can be more cleanly done using <u>interfaces &amp; adapter classes</u>. </p>
<blockquote>
<p>   Arrays in Java are truly <strong>first-class objects</strong>. They can be dynamically allocated &amp; assigned like other objects. <u>Having true arrays alleviates much need for pointer arithmetic.</u></p>
</blockquote>
<br>

<h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a><u>Other</u></h3><p>In most cases, Java threads need to be synchronized. Java supports synchronization based on the <strong>monitor</strong> and <strong>condition</strong> model: a lock &amp; key system for accessing resources.</p>
<br>

<hr>
<h2 id="Implementation-Security"><a href="#Implementation-Security" class="headerlink" title="Implementation Security"></a>Implementation Security</h2><p><strong>Encapsulation</strong> hides data &amp; behavior within a class, and it is an important part of object-oriented design (<strong>OOD</strong>). <u>Arbitrary casting &amp; pointer arithmetic</u> in C / C++ makes it easy to violate access permission on classes without breaking languages rules:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Finances</span> &#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">char</span> creditCardNumber[<span class="number">16</span>];</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">main</span>() &#123;</span><br><span class="line">    Finances finances;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Forge a pointer to peek inside the class</span></span><br><span class="line"><span class="keyword">char</span> *cardno = (<span class="keyword">char</span> *)&amp;finances;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Card Number = %.16s\n&quot;</span>, cardno);</span><br></pre></td></tr></table></figure>

<p>The code in line 12 &amp; 13 violates the encapsulation of the <code>Finance</code> class, and pulls out secret information. However in Java, the security model wraps 3 layers of protection around imported classes:</p>
<img data-src="/images/posts/190412-3.png" style="zoom:100%;" />

<ul>
<li>  <strong>Security Manager</strong>: Application-level security is managed by the <strong>security manager</strong> &amp; a flexible security policy. A security manager controls access to system resources such as filesystem, network ports. Security manager relies on class loader to protect basic system classes.</li>
<li>  <strong>Class Loader</strong>: Handles loading classes from local storage / the network. </li>
<li>  <strong>Verifier</strong>: At the innermost level, all system security ultimately depends on the <strong>Java bytecode verifier</strong>.</li>
</ul>
<p>The Verifier is a fixed part of the Java runtime system , while class loaders &amp; security managers are <strong>components</strong> that may be implemented differently by different applications. </p>
<br>

<h3 id="Verifier"><a href="#Verifier" class="headerlink" title="Verifier"></a><u>Verifier</u></h3><p>The verifier is Java’s 1st line of defense. It reads bytecode before running it, and ensures the integrity and correctness. For instance, verified code cannot forge reference or perform illegal casts. </p>
<p><strong>Fundamental innovations in Java</strong>: The Java bytecode is a relatively light &amp; low-level instruction set. The ability to <strong>statically verify bytecode before execution</strong> lets Java perform with <u>full speed at runtime with full safety</u> (without expensive runtime checks).</p>
<p><strong>Three rules</strong> the bytecode has to follow:</p>
<ul>
<li>  Most bytecode instructions operate only on individual data types</li>
<li>  Object type resulting from any operation is always known in advance</li>
<li>  All paths to the same point in the bytecode must arrive with exactly the same type state (Feasible to analyze type state of the stack)</li>
</ul>
<p>Because an operation always produces a known type, it’s possible to determine the types of all items on the stack and in local variables at any point in the future by looking at the starting state. The <u>collection of all this type information at any given time</u> is called the <strong>type state</strong> of the stack, and this is what Java tries to analyze before it runs an application.</p>
<p>Java doesn’t know anything about the actual values of stack and variable items at this time. It only knows what kind of items they are. However, this is enough information to enforce the security rules and to ensure that objects are not manipulated illegally.</p>
<br>



<h3 id="Class-Loader"><a href="#Class-Loader" class="headerlink" title="Class Loader"></a><u>Class Loader</u></h3><p>A class loader is responsible for <strong>bringing the Java class bytecode into the interpreter</strong>. </p>
<p>After a class has been loaded &amp; passed through the verifier, it remains associated with its class loader. Then classes are partitioned into separate namespaces based on their origin. When a loaded class references another class name, the location of the new class is provided by the original class loader.</p>
<p>The search for classes always begins with Java system built-in classes, and they are loaded from the locations specified by the Java interpreter’s <strong>classpath</strong>. </p>
<p>Class loaders guarantee that an application is using the core Java system classes, and these classes are the only way to access basic system resources.</p>
<br>



<h3 id="Security-Manager"><a href="#Security-Manager" class="headerlink" title="Security Manager"></a><u>Security Manager</u></h3><p>A security manager is responsible for application-level security. The security manager works with an <strong>access controller</strong> that lets us implement security policies at a high level by editing a <strong>declarative</strong> security policy file.</p>
<p>The integrity of a security manager is based on the protection afforded by the lower levels of the Java security model. </p>
<hr>
<h2 id="Road-Map"><a href="#Road-Map" class="headerlink" title="Road Map"></a>Road Map</h2><p><strong>Java 1.2 / Java 2</strong>: </p>
<ul>
<li>  Major release in Dec. 1998</li>
<li>  Include Swing GUI packages</li>
</ul>
<br>

<p><strong>Java 1.5 / Java 5:</strong></p>
<ul>
<li>  2004</li>
<li>  Generics, typesafe, enums</li>
<li>  Concurrency API</li>
</ul>
<br>

<p><strong>Java 1.7 / Java 7:</strong></p>
<ul>
<li>  <strong>JDBC</strong></li>
<li><strong>JNDI</strong> (Java Naming &amp; Directory Interface)<ul>
<li>  General service for looking up resources. JNDI unifies access to directory services, such as LDAP, Novell’s NDS.</li>
</ul>
</li>
<li>  Java Cryptography &amp; Java Security</li>
</ul>
<br>

<p><strong>Java 1.8  / Java 8:</strong></p>
<ul>
<li>  2014, major release</li>
<li>  Lambda &amp; Functional programming (Collections)</li>
<li>  Stream API</li>
<li>  Default methods (interface)</li>
<li>  New Data &amp; Time API</li>
<li>  Java profiles (provide different versions of Java for headless / server deployment)</li>
</ul>
<br>

<br>

]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Language Design</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Well-Architected Framework</title>
    <url>/2019/AWS-Well-Architected/</url>
    <content><![CDATA[<p>Today we will walk through the <a href="https://aws.amazon.com/architecture/well-architected/"><strong>AWS Well-Architected Framework</strong></a>:</p>
<ul>
<li>  Operational Excellence (<strong>CloudFormation</strong>)</li>
<li>  Security (<strong>IAM</strong>)</li>
<li>  Reliability (<strong>CloudWatch</strong>)</li>
<li>  Performance Efficiency (<strong>CloudWatch</strong>)</li>
<li>  Cost Optimization (<strong>Cost Explorer</strong>)</li>
</ul>
<span id="more"></span>

<br>

<hr>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a><u>Definitions</u></h3><p>The Five Pillars of the AWS Well-Architected Framework:</p>
<ul>
<li><strong>Operational Excellence</strong><ul>
<li>  Run &amp; monitor systems</li>
<li>  Continually improve supporting processes &amp; procedures</li>
</ul>
</li>
<li><strong>Security</strong><ul>
<li>  Protect information, systems, and assets via risk assessments &amp; mitigation strategies</li>
</ul>
</li>
<li><strong>Reliability</strong><ul>
<li>  Recover from infrastructure / service disruptions</li>
<li>  Dynamically acquire computing resources to meet demand</li>
<li>  Mitigate disruptions (misconfigs, transient network issues)</li>
</ul>
</li>
<li><strong>Performance Efficiency</strong><ul>
<li>  Use computing resources efficiently to meet system requirements</li>
<li>  Maintain this efficiency as demand changes</li>
</ul>
</li>
<li><strong>Cost Optimization</strong><ul>
<li>  Run at lowest cost</li>
</ul>
</li>
</ul>
<br>

<p>Terms used:</p>
<ul>
<li><p>  <strong>Component</strong>: Code &amp; configs &amp; AWS Resources to deliver a requirement together. <strong>Decoupled</strong> from other components</p>
</li>
<li><p>  <strong>Workload</strong>: Collection of  components</p>
</li>
<li><p>  <strong>Technology Portfolio</strong>: Collection of workloads</p>
</li>
<li><p>  <strong>Architecture</strong>: How components work together in a workload</p>
</li>
<li><p><strong>Milestone</strong>: Key changes in the architecture, as it evolves in the <strong>product lifecycle</strong></p>
  <div class="note primary"><p>Product Lifecycle:</p>
<p>Design -&gt; Test -&gt; Go Live -&gt; In Production</p>
</div></li>
</ul>
<br>

<p>When architecting workloads, we make <strong>trade-offs</strong> between pillars based on the needs (e.g. reduce cost at the expense of reliability). <strong>Security &amp; Operation Excellence</strong> are generally not traded-off against other pillars.</p>
<br>

<h3 id="On-Architecture"><a href="#On-Architecture" class="headerlink" title="On Architecture"></a><u>On Architecture</u></h3><p>Enterprise architecture capability:</p>
<ul>
<li>  <a href="https://pubs.opengroup.org/architecture/togaf9-doc/arch/">TOGAF</a></li>
<li>  <a href="https://www.zachman.com/about-the-zachman-framework">Zachman Framework</a></li>
</ul>
<br>

<p>AWS distributes capabilities to <strong>teams</strong>, rather than having a centralized team manage all.</p>
<br>



<h3 id="Design-Principles"><a href="#Design-Principles" class="headerlink" title="Design Principles"></a><u>Design Principles</u></h3><p><strong>1. Stop guessing capacity needs</strong></p>
<ul>
<li>  Use &amp; pay on-demand</li>
</ul>
<p><strong>2. Test systems at production scale</strong></p>
<ul>
<li>  Create a production-scale test environment on demand (to simulate the real live environment)</li>
<li>  Decommission the resource after complete testing</li>
</ul>
<p><strong>3. Automate to make architectural experimentation easier</strong></p>
<ul>
<li>  Track changes</li>
<li>  Audit impact</li>
<li>  Revert to previous parameters</li>
</ul>
<p><strong>4. Allow for evolutionary architecture</strong></p>
<ul>
<li>  Infrastructure as code</li>
<li>  Constantly change architecture based on demand</li>
</ul>
<p><strong>5. Use data-driven architectures</strong></p>
<ul>
<li>  Collect data on how architectural choices affect the workload behavior</li>
<li>  Make <strong>fact-based</strong> decisions</li>
<li>  <strong>Data-driven</strong>: Cloud infrastructure is code, souse that data to make informed decisions</li>
</ul>
<p><strong>6. Improve through game days</strong></p>
<ul>
<li>  <strong>Game Days</strong>: Simulating events in production</li>
<li>  E.g. load testing, test to trigger failures</li>
</ul>
<br>



<h2 id="Operational-Excellence"><a href="#Operational-Excellence" class="headerlink" title="Operational Excellence"></a>Operational Excellence</h2><blockquote>
<p>  Run &amp; monitor systems</p>
<p>  Continually improve supporting processes &amp; procedures</p>
</blockquote>
<br>

<h3 id="Principles-5"><a href="#Principles-5" class="headerlink" title="Principles (5)"></a><u>Principles (5)</u></h3><p><strong>1.  Operations as code</strong></p>
<ul>
<li>  Define entire workload (application / infrastructure) as code</li>
<li>  Automate operations executions by <strong>triggering them in response to events</strong></li>
<li>  Limit human error, enable consistent response</li>
</ul>
<p><strong>2.  Annotate Documentation</strong></p>
<ul>
<li>  Automate doc creation after each build</li>
</ul>
<p><strong>3.  Make frequent, small, reversible changes</strong></p>
<ul>
<li>  Rollbacks are more difficult in large changes</li>
</ul>
<p><strong>4.  Refine operation procedures frequently</strong></p>
<ul>
<li>  Set up regular game days to review &amp; evaluate</li>
</ul>
<p><strong>5.  Anticipate failure &amp; Learn from them</strong></p>
<ul>
<li>  Test failure scenarios</li>
<li>  Share lessons across teams</li>
</ul>
<br>

<h3 id="Best-Practices-3"><a href="#Best-Practices-3" class="headerlink" title="Best Practices (3)"></a><u>Best Practices (3)</u></h3><p>Three Best Practices:</p>
<ul>
<li>  Prepare</li>
<li>  Operate</li>
<li>  Evolve</li>
</ul>
<br>

<h4 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h4><p>Prior to transition to different workload, <strong>test responses to operational events &amp; failures</strong>. Practice responses in supported environments through failure injection &amp; game day events.</p>
<p><strong>Operations as code</strong>: Use <strong>CloudFormation</strong> to build templates for the entire infrastructure, and maintain versioning.</p>
<p>Visibility into workloads at all layers: <strong>log collection &amp; monitoring</strong>.</p>
<ul>
<li>  Data on resource usage, application programming, API, network flow logs: Collected with <strong>CloudWatch, CloudTrail</strong>, and VPC Flow Logs.</li>
</ul>
<br>

<p>Design workloads to understand its <strong>state</strong>:</p>
<ul>
<li>  <strong>Metrics</strong></li>
<li>  <strong>Logs</strong></li>
<li>  <strong>Traces</strong></li>
</ul>
<br>

<h4 id="Operate"><a href="#Operate" class="headerlink" title="Operate"></a>Operate</h4><p>Define expected outcomes, determine how success will be measured, and identify the workload &amp; operations metrics.</p>
<p><strong>Operational health</strong></p>
<ul>
<li>  Workload health</li>
<li>  Health of the operations acting upon the workload (e.g. deployment &amp; incident response)</li>
</ul>
<br>

<p>Use established <strong>runbooks</strong> for well-understood events, and <strong>playbooks</strong> to aid in the resolution.</p>
<ul>
<li>  If an alert is triggered by an event, make sure there’s an associated process to be executed with a specifically identified owner</li>
</ul>
<br>

<p>Communicate workloads’ operational status via <strong>dashboards &amp; notifications</strong> that are tailored to target audience (e.g. customer, business, developers, operations). </p>
<br>

<p>Determine <strong>root cause</strong> of the unplanned events &amp; unexpected impacts. Then use this information to mitigate future occurrence of such events.</p>
<br>

<p>In AWS, generate dashboard views of the metrics collected from workloads &amp; AWS native. Gain workload insights via logging tools: <strong>X-Ray, CloudWatch, CloudTrail, VPC Flow Logs</strong>.</p>
<p><br>Routine operations &amp; response to unplanned events should be <strong>automated</strong>, and avoid manual processes. </p>
<p>Align metrics to business needs, so that responses are effective at maintaining business continuity.</p>
<br>

<p><strong>Understand the health of workload</strong>: Define, capture &amp; analyze workload metrics.</p>
<p><strong>Manage workload &amp; operations events</strong>: Prepare &amp; validate procedures for responding to events.</p>
<br>

<h4 id="Evolve"><a href="#Evolve" class="headerlink" title="Evolve"></a>Evolve</h4><p>Dedicate work cycles to making continuous incremental improvements. </p>
<p>Regularly evaluate &amp; prioritize opportunities for improvement</p>
<ul>
<li>  Feature requests</li>
<li>  Issue remediation</li>
<li>  Compliance requirements</li>
</ul>
<br>

<p>Include <strong>feedback loops</strong> within procedure to rapidly identify areas for improvement.</p>
<br>

<p>Successful evolution of operations is founded in:</p>
<ul>
<li>  Frequent &amp; small improvements</li>
<li>  Provide safe env &amp; time for experiment, develop &amp; test</li>
<li>  Learn from failures</li>
</ul>
<br>

<h3 id="Key-AWS-Services"><a href="#Key-AWS-Services" class="headerlink" title="Key AWS Services"></a><u>Key AWS Services</u></h3><p>Most important: <strong>CloudFormation</strong></p>
<p><strong>Prepare</strong></p>
<ul>
<li>  AWS <strong>Config</strong> &amp; AWS Config rules: Create standards for workloads</li>
<li>  Determine if environments are compliant with those standards</li>
</ul>
<p><strong>Operate</strong></p>
<ul>
<li>  <strong>CloudWatch</strong>: Monitor operational health</li>
</ul>
<p><strong>Evolve</strong></p>
<ul>
<li>  Amazon <strong>ElasticSearch</strong> Services (ES): Analyze log data to gain quick insights</li>
</ul>
<br>







<h2 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h2><blockquote>
<p>  Protect information, systems, and assets via risk assessments &amp; mitigation strategies</p>
</blockquote>
<br>



<h3 id="Principles-7"><a href="#Principles-7" class="headerlink" title="Principles (7)"></a><u>Principles (7)</u></h3><p><strong>1. Implement a strong identity foundation</strong></p>
<ul>
<li>  Principle of least privilege</li>
<li>  Enforce separation of duties</li>
<li>  Centralize privilege management</li>
</ul>
<p><strong>2. Enable traceability</strong></p>
<ul>
<li>  Monitor, alert &amp; audit actions / changes to the environment in <strong>real time</strong></li>
<li>  Integrate logs &amp; metrics</li>
</ul>
<p><strong>3. Apply security at all layers</strong></p>
<ul>
<li>  Defense-in-depth</li>
<li>All layers<ul>
<li>  Edge network</li>
<li>  VPC, Subnet</li>
<li>  Load balancer</li>
<li>  Every instance, OS, and application</li>
</ul>
</li>
</ul>
<p><strong>4. Automate security best practices</strong></p>
<ul>
<li>  Implementation of controls that are defined &amp; managed as code, in <strong>version-controlled</strong> templates</li>
</ul>
<p><strong>5. Protect data in transit &amp; at rest</strong></p>
<ul>
<li>  Classify data sensitivity levels</li>
<li>  Use encryption, tonkenization &amp; access control</li>
</ul>
<p><strong>6. Keep people away from data</strong></p>
<ul>
<li>  Reduce / eliminate the need for direct access &amp; manual processing of data</li>
<li>  Hence reduce risk of human error</li>
</ul>
<p><strong>7. Prepare for security events</strong></p>
<ul>
<li>  Have an incident management process, and run incident response simulations</li>
<li>  Use automated tools to speed up detection, investigation &amp; recovery</li>
</ul>
<br>

<h3 id="Best-Practices-5"><a href="#Best-Practices-5" class="headerlink" title="Best Practices (5)"></a><u>Best Practices (5)</u></h3><p>Five best practices:</p>
<ul>
<li>  Identity &amp; Access Management</li>
<li>  Detective Controls</li>
<li>  Infrastructure Protection</li>
<li>  Data Protection</li>
<li>  Incident Response</li>
</ul>
<br>

<h4 id="Identity-amp-Access-Management"><a href="#Identity-amp-Access-Management" class="headerlink" title="Identity &amp; Access Management"></a>Identity &amp; Access Management</h4><p>In AWS, privilege management is primarily supported by <strong>IAM</strong>. Only authorized &amp; authenticated AWS account users / AWS Resources are able to access the resources. </p>
<ul>
<li><p>Define principals (Use a <strong>role-based</strong> approach)</p>
<ul>
<li>  Users</li>
<li>  Groups</li>
<li>  Services</li>
<li>  Roles</li>
</ul>
</li>
<li><p>  Build security policies</p>
</li>
<li><p>  Implement strong credential</p>
</li>
</ul>
<br>

<p>Credentials must not be shared between any user / system. Programmatic access should be performed using <strong>temporary &amp; limited-privileged</strong> credentials, using AWS <strong>Security Token Service</strong>.</p>
<br>

<h4 id="Detective-Controls"><a href="#Detective-Controls" class="headerlink" title="Detective Controls"></a>Detective Controls</h4><div class="note success"><p><strong>Log management</strong> is important to a well-Architected design. </p>
</div>

<p>Use detective control to identify a potential security threat / incident. </p>
<ul>
<li>  Conduct an inventory of assets &amp; their detailed attributes</li>
<li>  <strong>Internal auditing</strong>: Examination of controls related to information systems</li>
</ul>
<br>

<p><strong>Implement detective controls</strong></p>
<ul>
<li>  Process logs &amp; events</li>
<li>  Monitor logs &amp; events for auditing, alarming &amp; automated analysis</li>
<li>  Create a <strong>threat model</strong> to defend against emerging security threats</li>
<li>  Define a <strong>data-retention lifecycle</strong> (Preserved, archived, deleted)</li>
</ul>
<br>

<p><strong>With AWS</strong></p>
<ul>
<li>  <strong>CloudTrail logs, AWS API calls &amp; CloudWatch</strong>: Monitor metrics with alarming. Capture &amp; analyze events from logs &amp; metrics to gain <strong>visibility</strong></li>
<li>  <strong>AWS Config</strong>: Provides configuration history</li>
<li>  <strong>GuardDuty</strong>: Threat detection</li>
<li>  <strong>S3</strong>: Access service-level logs. Use <strong>S3</strong> to log access requests</li>
</ul>
<br>







<h4 id="Infrastructure-Protection"><a href="#Infrastructure-Protection" class="headerlink" title="Infrastructure Protection"></a>Infrastructure Protection</h4><p>Encompass control methodologies, such as defense in depth. </p>
<ul>
<li>  In AWS, implement <strong>stateful &amp; stateless</strong> packet inspection</li>
<li>Use VPC to create a private, secured &amp; scalable environment to define the <strong>network topology</strong><ul>
<li>  Gateways</li>
<li>  Routing tables</li>
<li>  Public &amp; private subnets</li>
</ul>
</li>
</ul>
<br>

<p><strong>Compute resources include</strong></p>
<ul>
<li>  EC2 instances</li>
<li>  ECS / Beanstalk / Containers</li>
<li>  Lambda functions</li>
<li>  Database services</li>
<li>  IoT devices</li>
</ul>
<br>

<p><strong>Multiple layers of defense</strong> is advisable</p>
<ul>
<li>  Enforce boundary protection</li>
<li>  Monitor points of <strong>ingress &amp; egress</strong></li>
<li>  Comprehensive logging, monitoring &amp; alerting</li>
</ul>
<br>

<p>AWS provides the option to customize the configs of EC2 / ECS, and <strong>persist</strong> the config to an <strong>immutable</strong> Amazon Machine Image (<strong>AMI</strong>). When triggered by Auto Scaling / manual launch, all new instances launched with this AMI receive the customized config.</p>
<br>

<h4 id="Data-Protection"><a href="#Data-Protection" class="headerlink" title="Data Protection"></a>Data Protection</h4><p>Practices to facilitate data protection</p>
<ul>
<li>  Data classification</li>
<li>  Encryption &amp; regular <strong>key rotation</strong></li>
<li>  <strong>S3</strong>: storage for exceptional <strong>resiliency</strong></li>
<li>Encrypt data <strong>in transit &amp; at rest</strong> <ul>
<li>  Server-side encryption (<strong>SSE</strong>) for S3, store data in an encrypted form</li>
<li>  Use <strong>ELB</strong> to handle HTTPS encryption &amp; decryption (SSL Termination)</li>
</ul>
</li>
<li>  Versioning</li>
<li>  Data placed in one Region will remain in that Region, unless user move data between Regions</li>
</ul>
<br>

<h4 id="Incident-Response"><a href="#Incident-Response" class="headerlink" title="Incident Response"></a>Incident Response</h4><p>Routinely practice incident response through <strong>game days</strong>. </p>
<ul>
<li>  Detailed logging</li>
<li>  Auto process events, and trigger auto response</li>
<li>  Pre-provision tooling &amp; clean room with <strong>CloudFormation</strong>, carry out forensics in a safe &amp; isolate environment</li>
</ul>
<br>



<h3 id="Key-AWS-Services-1"><a href="#Key-AWS-Services-1" class="headerlink" title="Key AWS Services"></a><u>Key AWS Services</u></h3><p>Most important: <strong>IAM</strong></p>
<p><strong>Identity &amp; Access Management</strong></p>
<ul>
<li>  <strong>IAM</strong> controls access to AWS services &amp; resources (use with <strong>MFA</strong>)</li>
<li>  <strong>AWS Organizations</strong> centrally manage &amp; enforce polices for multiple AWS accounts</li>
</ul>
<p><strong>Detective Controls</strong></p>
<ul>
<li>  <strong>CloudTrail</strong> records AWS API calls</li>
<li>  <strong>AWS Config</strong> provides a detailed inventory of AWS resources &amp; configurations</li>
<li>  <strong>GuardDuty</strong> is for threat detection, it monitors malicious / unauthorized behavior</li>
<li>  <strong>CloudWatch Events</strong> can be triggered to <strong>automate</strong> security responses</li>
</ul>
<p><strong>Infrastructure Protection</strong></p>
<ul>
<li>  <strong>VPC</strong> enables user to launch AWS resources into a <strong>virtual network</strong></li>
<li>  <strong>CloudFront</strong> is a CDN, integrated with <strong>AWS Shield</strong> for DDoS mitigation</li>
<li>  <strong>AWS WAF</strong> can be deployed on CloudFront / Application Load Balancer, protect from common web exploits</li>
</ul>
<p><strong>Data Protection</strong></p>
<ul>
<li>  In transit &amp; at rest: <strong>ELB, EBS, S3, RDS</strong> (encryption)</li>
<li>  Amazon <strong>Macie</strong> auto discovers &amp; classifies sensitive data</li>
<li>  <strong>KMS</strong> (Key Management Service) helps with create &amp; control encryption keys</li>
</ul>
<p><strong>Incident Response</strong></p>
<ul>
<li>  Use <strong>IAM</strong> to grant authorizations to incident response teams &amp; response tools</li>
<li>  Use <strong>CloudFormation</strong> to create a trusted environment for forensics</li>
<li>  Use <strong>CloudWatch Events</strong> to create rules that trigger automated response with <strong>Lambda</strong></li>
</ul>
<br>



<h2 id="Reliability"><a href="#Reliability" class="headerlink" title="Reliability"></a>Reliability</h2><p>System should be designed to detect failure &amp; <strong>automatically heal itself</strong>.</p>
<blockquote>
<p>  Recover from infrastructure / service disruptions</p>
<p>  Dynamically acquire computing resources to meet demand</p>
<p>  Mitigate disruptions (misconfigs, transient network issues)</p>
</blockquote>
<br>

<h3 id="Principles-5-1"><a href="#Principles-5-1" class="headerlink" title="Principles (5)"></a><u>Principles (5)</u></h3><p><strong>1. Test recovery procedures</strong></p>
<ul>
<li>  Test how the system fails &amp; validate recovery procedures</li>
<li>  Use automation to simulate failures</li>
</ul>
<p><strong>2. Automatically recover from failure</strong></p>
<ul>
<li>  Monitor a system for Key Performance Indicators (<strong>KPI</strong>)</li>
<li>  Trigger automation when a threshold is breached</li>
<li>  Anticipate &amp; remediate failures before they occur</li>
</ul>
<p><strong>3. Scale horizontally to increase aggregate system availability</strong></p>
<ul>
<li>  Replace single large resource with multiple small resources, reduce the impact of a <strong>single failure</strong></li>
</ul>
<p><strong>4. Stop guessing capacity</strong></p>
<ul>
<li>  Monitor demand &amp; system utilization to avoid <strong>resource saturation</strong></li>
<li>  Automate addition / removal of resources</li>
</ul>
<p><strong>5. Manage change in automation</strong></p>
<ul>
<li>  Changes should be done with <strong>automation</strong></li>
</ul>
<br>



<h3 id="Best-Practices-3-1"><a href="#Best-Practices-3-1" class="headerlink" title="Best Practices (3)"></a><u>Best Practices (3)</u></h3><p>Three best practices:</p>
<ul>
<li>  Foundations</li>
<li>  Change Management</li>
<li>  Failure Management</li>
</ul>
<br>

<h4 id="Foundations"><a href="#Foundations" class="headerlink" title="Foundations"></a>Foundations</h4><p>First check foundational requirements that influence reliability, e.g. Sufficient network <strong>bandwidth</strong>. The requirements must be incorporated during initial planning. With the cloud, it is AWS’s responsibility to satisfy <strong>sufficient network bandwidth &amp; compute capacity</strong>. </p>
<br>

<p><strong>Manage service limits</strong></p>
<ul>
<li>  Default service limits exist to prevent provisioning of more resources than needed.</li>
<li>  AWS <strong>Direct Connect</strong> has limits on the amount of data that can be transferred</li>
</ul>
<br>

<p><strong>Manage network topology</strong></p>
<ul>
<li>  Intra &amp; inter system connectivity</li>
<li>  Public &amp; private IP address management</li>
<li>  Name resolution</li>
</ul>
<br>

<p><strong>Moving from on-premise to the cloud:</strong></p>
<p>First use a <strong>hybrid</strong> model, then gradually transit to the complete cloud approach.</p>
<br>



<h4 id="Change-Management"><a href="#Change-Management" class="headerlink" title="Change Management"></a>Change Management</h4><p>A scalable system provides <strong>elasticity</strong> to automatically add / remove resources. </p>
<br>

<p><strong>How to monitor resources</strong></p>
<ul>
<li>  Configure workload to monitor <strong>logs &amp; metrics</strong> (automatic logging allows to audit &amp; quickly identify actions)</li>
<li>  Send notification when threshold are breached / significant events occur</li>
<li>  Configure workload to self-heal automatically</li>
</ul>
<br>

<h4 id="Failure-Management"><a href="#Failure-Management" class="headerlink" title="Failure Management"></a>Failure Management</h4><br>

<p>Rather than trying to fix a failed resource, better to <strong>replace</strong> it with a new one, and analyze the failed resource out of band. </p>
<br>

<p><strong>Key to managing failures</strong></p>
<p>Frequent &amp; automated testing of systems to cause failure, then observe how they recover.</p>
<br>

<p><strong>Plan for Disaster Recovery (DR)</strong>: </p>
<ul>
<li>  <strong>Back up data</strong>: Meet requirements for Mean Time To Recovery (<strong>MTTR</strong>) &amp; Recovery Point Objectives (<strong>RPO</strong>)</li>
<li>  Actively track KPIs, such as <strong>RPO &amp; RTO</strong> (Recovery Time Objective), to assess system’s resiliency (avoid single point of failure)</li>
</ul>
<br>

<h3 id="Key-AWS-Services-2"><a href="#Key-AWS-Services-2" class="headerlink" title="Key AWS Services"></a><u>Key AWS Services</u></h3><p>Most important: <strong>CloudWatch</strong> (monitor runtime metrics)</p>
<p><strong>Foundations</strong></p>
<ul>
<li>  <strong>IAM</strong> enables secure access</li>
<li>  <strong>VPC</strong> provide s private &amp; isolated virtual network</li>
<li>  AWS <strong>Trusted Advisor</strong> provides visibility into service limits</li>
<li>  AWS <strong>Shield</strong> protect against DDoS</li>
</ul>
<p><strong>Change Management</strong></p>
<ul>
<li>  <strong>CloudTrail</strong> records API calls &amp; delivers log files for auditing</li>
<li>  AWS <strong>Config</strong> provides detailed inventory of AWS resources &amp; configuration</li>
<li>  <strong>Auto Scaling</strong> auto manages demand for deployed workload</li>
<li>  Use <strong>CloudWatch</strong> to get alerts on (custom) metrics, and <strong>aggregate</strong> logs from resources</li>
</ul>
<p><strong>Failure Management</strong></p>
<ul>
<li>  <strong>CloudFormation</strong> provides templates for resource creation</li>
<li>  <strong>S3</strong> for keeping backups, <strong>S3 Glacier</strong> for archives</li>
<li>  <strong>KMS</strong> provides reliable key management</li>
</ul>
<br>





<br>



<h2 id="Performance-Efficiency"><a href="#Performance-Efficiency" class="headerlink" title="Performance Efficiency"></a>Performance Efficiency</h2><blockquote>
<p>   Use computing resources efficiently to meet system requirements</p>
<p>  Maintain this efficiency as demand changes</p>
</blockquote>
<br>

<h3 id="Principles-5-2"><a href="#Principles-5-2" class="headerlink" title="Principles (5)"></a><u>Principles (5)</u></h3><p><strong>Democratize advanced technologies</strong></p>
<ul>
<li>  Buy &amp; consume as a service, rather than build it yourself</li>
</ul>
<p><strong>Go global in minutes</strong></p>
<ul>
<li>  Provide lower latency</li>
</ul>
<p><strong>Use serverless architectures</strong></p>
<ul>
<li>  <strong>Storage</strong> service as static websites (<strong>S3</strong>)</li>
<li>  <strong>Event</strong> services to host the app code (<strong>Lambda</strong>)</li>
</ul>
<p><strong>Experiment more often</strong></p>
<ul>
<li>  Use virtual &amp; automated resources to test with different types of instances / configs</li>
</ul>
<p><strong>Mechanical sympathy</strong></p>
<ul>
<li><p>Use technology that best aligns with what you’re trying to achieve</p>
<blockquote>
<p>  <em>e.g. Consider <strong>data access patterns</strong> when selecting database / storage options</em></p>
</blockquote>
</li>
</ul>
<br>

<h3 id="Best-Practices-4"><a href="#Best-Practices-4" class="headerlink" title="Best Practices (4)"></a><u>Best Practices (4)</u></h3><p>Four best practices:</p>
<ul>
<li>  Selection</li>
<li>  Review</li>
<li>  Monitoring</li>
<li>  Tradeoffs (e.g.  Compression / caching, relax consistency requirements)</li>
</ul>
<div class="note success"><p>Take a <strong>data-driven</strong> approach to select a high-performance architecture.</p>
</div>

<br>



<h4 id="Selection"><a href="#Selection" class="headerlink" title="Selection"></a>Selection</h4><p>Data-driven approach is the most optimal solution, and data obtained through <strong>benchmarking / load testing</strong> will be required to optimize the architecture.</p>
<p>Different architectural approaches:</p>
<ul>
<li>  Event-driven</li>
<li>  ETL</li>
<li>  Pipeline</li>
</ul>
<p>Four main resource types to consider:</p>
<ul>
<li>  Compute</li>
<li>  Storage</li>
<li>  Database</li>
<li>  Network</li>
</ul>
<br>

<h5 id="I-Compute"><a href="#I-Compute" class="headerlink" title="I. Compute"></a>I. Compute</h5><p>The optimal compute solution is based on application design, usage patterns, and configuration settings. In AWS, compute is available in 3 forms: instances (EC2), containers (ECS), functions (Lambda).</p>
<ul>
<li>  <strong>Instances</strong> are virtual servers, offer HDDs, SSDs &amp; GPUs</li>
<li>  <strong>Containers</strong> are OS virtualization, allow user to run apps &amp; dependencies in <strong>resource-isolated</strong> processes</li>
<li>  <strong>Functions</strong> abstract the execution env from the code. Lambda executes code <strong>without running an instance</strong></li>
</ul>
<br>

<h5 id="II-Storage"><a href="#II-Storage" class="headerlink" title="II. Storage"></a>II. Storage</h5><p>Select optimal storage solution based on:</p>
<ul>
<li>  Access <strong>method</strong> (block / file / object)</li>
<li>  Access <strong>pattern</strong> (random / sequential)</li>
<li>  Access <strong>frequency</strong> (online / offline / archival)</li>
<li>  Update frequency (WORM / dynamic)</li>
<li>  Required <strong>throughput</strong></li>
<li>  <strong>Availability &amp; durability</strong> constraints</li>
</ul>
<br>

<h5 id="III-Database"><a href="#III-Database" class="headerlink" title="III. Database"></a>III. Database</h5><p>Optimal database solution is based on:</p>
<ul>
<li>  Availability</li>
<li>  Consistency</li>
<li>  Partition tolerance</li>
<li>  Latency</li>
<li>  Durability</li>
<li>  Scalability</li>
<li>  Query capability</li>
</ul>
<blockquote>
<p>  Sometimes, <strong>non-database solutions</strong> solve the problem more efficiently (e.g. search engine / data warehouse)</p>
</blockquote>
<br>

<p><strong>AWS Services</strong></p>
<ul>
<li>  RDS</li>
<li>  DynamoDB</li>
<li>  Redshift (data warehouse)</li>
</ul>
<br>

<h5 id="IV-Network"><a href="#IV-Network" class="headerlink" title="IV. Network"></a>IV. Network</h5><p>Optimal network solution is based on:</p>
<ul>
<li>  Latency (<em><strong>Need to consider <u>location</u> when selecting network solutions</strong></em>)</li>
<li>  Throughput requirements</li>
</ul>
<br>

<p>Physical constraints (user / on-premise resources) can be offset using <strong>edge techniques</strong> / <strong>resource placement</strong>.</p>
<br>

<p><strong>AWS Services</strong></p>
<p>Product Features:</p>
<ul>
<li>  Enhanced networking</li>
<li>  EBS-optimized instances</li>
<li>  S3 Transfer Acceleration</li>
<li>  Dynamic Amazon CloudFront</li>
</ul>
<br>

<p>Network Features (reduce network distance / latency):</p>
<ul>
<li>  Route 53 latency routing</li>
<li>  VPC endpoints</li>
<li>  AWS Direct Connect</li>
</ul>
<br>

<h4 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h4><p>Understand where the architecture is performance-constrained.</p>
<br>

<h4 id="Monitoring"><a href="#Monitoring" class="headerlink" title="Monitoring"></a>Monitoring</h4><p>Monitoring metrics should be used to raise alarms, when threshold breached.</p>
<ul>
<li>  Degradation of system performance over time</li>
<li>  Remediate OS / application load</li>
</ul>
<blockquote>
<p>  Make sure there aren’t too many false positives, or you’re overwhelmed with data.</p>
</blockquote>
<br>

<p><strong>AWS Services</strong>:</p>
<ul>
<li>  <strong>CloudWatch</strong>: monitor &amp; send notification alarms</li>
<li>  Use <strong>automation</strong> by <strong>triggering</strong> actions via Kinesis / SQS / Lambda</li>
</ul>
<br>

<h4 id="Tradeoffs"><a href="#Tradeoffs" class="headerlink" title="Tradeoffs"></a>Tradeoffs</h4><p>Trade <u>consistency, durability &amp; space</u> for <u>time / latency</u>.</p>
<p><strong>AWS Services</strong>:</p>
<ul>
<li>  Caching solution: <strong>ElastiCache</strong> (Redis / Memcached, in-memory data store)</li>
<li>  Cache content closer to end users: <strong>CloudFront</strong></li>
<li>  <u>Distributed caching tier</u>: <strong>DAX</strong> (DynamoDB Accelerator, read-through / write-through)</li>
</ul>
<br>

<h3 id="Key-AWS-Services-3"><a href="#Key-AWS-Services-3" class="headerlink" title="Key AWS Services"></a><u>Key AWS Services</u></h3><p>Most important: <strong>CloudWatch</strong> </p>
<ul>
<li>  Monitor resources &amp; systems</li>
<li>  Provide visibility into overall performance &amp; operational health</li>
</ul>
<br>

<p><strong>Selection</strong></p>
<ul>
<li>  Compute: <strong>Auto Scaling</strong></li>
<li>Storage: <ul>
<li>  <strong>EBS</strong> (SSD, PIOPS (provisioned input/output operations per second) )</li>
<li>  <strong>S3</strong> (serverless content delivery, S3 transfer acceleration)</li>
</ul>
</li>
<li>  Database</li>
</ul>
<p><strong>Review</strong></p>
<ul>
<li>  <a href="https://aws.amazon.com/blogs/aws/">AWS Blog</a></li>
</ul>
<p><strong>Monitoring</strong></p>
<ul>
<li>  <strong>CloudWatch</strong> provides metrics, alarms &amp; notifications</li>
</ul>
<p><strong>Tradeoffs</strong></p>
<ul>
<li>  Improve performance: <strong>ElastiCache</strong>, <strong>CloudFront</strong>, <strong>Snowball</strong></li>
<li>  Scale read-heavy workloads: Use <strong>read replicas</strong> in <strong>RDS</strong></li>
</ul>
<br>



<h2 id="Cost-Optimization"><a href="#Cost-Optimization" class="headerlink" title="Cost Optimization"></a>Cost Optimization</h2><blockquote>
<p>  Run at lowest cost</p>
</blockquote>
<br>

<h3 id="Principles-5-3"><a href="#Principles-5-3" class="headerlink" title="Principles (5)"></a><u>Principles (5)</u></h3><ul>
<li>  Adopt a consumption model</li>
<li>  Measure overall efficiency</li>
<li>  Stop spending money on data center operations</li>
<li>  Analyze &amp; attribute expenditure</li>
<li>  Use managed &amp; application-level services to reduce cost of ownership</li>
</ul>
<br>





<h3 id="Best-Practices-4-1"><a href="#Best-Practices-4-1" class="headerlink" title="Best Practices (4)"></a><u>Best Practices (4)</u></h3><div class="note success"><p>Spend time benchmarking for the most <strong>cost-optimal</strong> workload over time.</p>
</div>



<p>Four best practices:</p>
<ul>
<li>  Expenditure awareness</li>
<li>  Cost-effective resources</li>
<li>  Matching supply &amp; demand</li>
<li>  Optimizing over time</li>
</ul>
<br>



<h3 id="Key-AWS-Services-4"><a href="#Key-AWS-Services-4" class="headerlink" title="Key AWS Services"></a><u>Key AWS Services</u></h3><p>Most Important: <strong>Cost Explorer</strong></p>
<p><u>Expenditure awareness</u></p>
<ul>
<li>  <strong>Cost Explorer</strong></li>
</ul>
<p><u>Cost-effective resources</u></p>
<ul>
<li><p>  <strong>CloudWatch</strong> &amp; <strong>Trusted Advisor</strong> for the right size of the resources</p>
</li>
<li><p>  AWS <strong>Direct Connect</strong> &amp; <strong>CloudFront</strong> for optimizing data transfer</p>
</li>
</ul>
<p><u>Matching supply &amp; demand</u></p>
<ul>
<li>  <strong>Auto Scaling</strong></li>
</ul>
<p><u>Optimizing over time</u></p>
<ul>
<li>  <strong>Trusted Advisor</strong> inspects AWS environment, finds &amp; eliminates idle / unused resources, or commits to <strong>Reserved Instance</strong> capacity</li>
<li>  Read <a href="https://aws.amazon.com/blogs/aws/">AWS Blog</a></li>
</ul>
<br>



<h2 id="Review-1"><a href="#Review-1" class="headerlink" title="Review"></a>Review</h2><p>Use AWS Well-Architected Framework to continually review the architecture, rather than holding formal review meetings. Reviews should be applied at:</p>
<ul>
<li>  Early on in the design phase</li>
<li>  Key milestones in the product lifecycle</li>
<li>  Before the go live date</li>
</ul>
<br>



<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q &amp; A"></a>Q &amp; A</h2><h3 id="Operational-Excellence-1"><a href="#Operational-Excellence-1" class="headerlink" title="Operational Excellence"></a><u>Operational Excellence</u></h3><p><strong>Automation</strong></p>
<p>Fully automate integration &amp; deployment</p>
<br>

<p><strong>How do you know you’re ready to support a workload</strong></p>
<ul>
<li>  Use <strong>runbooks</strong> to perform procedures</li>
<li>  Use <strong>playbooks</strong> to identify issues</li>
<li>  Ensure consistent review of operational readiness</li>
</ul>
<br>

<p><strong>Understand the health of workload / operations</strong></p>
<ul>
<li>  Identify <strong>KPI</strong> (key performance indicators)</li>
<li>  Define &amp; collect workload metrics</li>
<li>  Establish workload metrics <strong>baseline</strong>, and learn expected patterns of activities (for benchmarking)</li>
<li>  Alert when workload at risk &amp; anomalies detected</li>
</ul>
<br>



<h3 id="Security-1"><a href="#Security-1" class="headerlink" title="Security"></a><u>Security</u></h3><p><strong>Manage credentials &amp; authentication</strong></p>
<ul>
<li>  Define <strong>IAM</strong> requirements</li>
<li>  Secure AWS root user, create <strong>IAM users</strong> for access</li>
<li>  <strong>Automate</strong> enforcement of access controls</li>
<li>  <strong>Rotate</strong> credentials regularly</li>
</ul>
<br>

<p><strong>Control human access</strong></p>
<ul>
<li>  Grant least privileges</li>
<li>  <strong>Unique</strong> credentials for each individual (segregation &amp; traceability)</li>
</ul>
<br>

<p><strong>Detect &amp; investigate security events</strong></p>
<ul>
<li>  Collect metrics &amp; define baselines</li>
<li>  All logs should be collected centrally &amp; automatically</li>
</ul>
<br>

<h3 id="Reliability-1"><a href="#Reliability-1" class="headerlink" title="Reliability"></a><u>Reliability</u></h3><p><strong>Manage network topology</strong></p>
<ul>
<li>  Use Highly Available connectivity between private addresses in public clouds &amp; on-premise environment</li>
<li>  Enforce <u>non-overlapping private IP address</u> range in <u>multiple private address spaces</u> where they’re connected</li>
</ul>
<br>

<p><strong>Data backup</strong></p>
<ul>
<li>  Perform data backup automatically</li>
<li>  Perform <strong>periodic recovery</strong> of data, to verify backup integrity &amp; processes</li>
</ul>
<br>

<p><strong>Dealing with failures</strong></p>
<ul>
<li>  <strong>Monitor</strong> all layers of the workload, send notifications upon failure detection</li>
<li>  Implement <strong>loosely-coupled</strong> dependencies</li>
<li>  Deploy workload to multiple locations</li>
<li>  <strong>Automate self-healing on all layers</strong></li>
</ul>
<br>

<p><strong>Test resilience</strong></p>
<ul>
<li>  Use <strong>playbooks</strong> for unanticipated failures</li>
<li>  Conduct <strong>RCA</strong> (Root Cause Analysis)</li>
<li>  Inject failures to test resiliency</li>
<li>  Game days</li>
</ul>
<br>

<p><strong>Plan for DR (Disaster Recovery)</strong></p>
<ul>
<li>  Define recovery objectives for downtime &amp; data loss (RTO, RPO)</li>
<li>  Use defined recovery strategies to meet recovery objectives</li>
<li>  Manage <strong>configuration drift</strong> on all changes</li>
<li>  <strong>Automate</strong> recovery</li>
</ul>
<br>

<h3 id="Performance-Efficiency-1"><a href="#Performance-Efficiency-1" class="headerlink" title="Performance Efficiency"></a><u>Performance Efficiency</u></h3><p><strong>Select best-performing architecture</strong></p>
<ul>
<li>  Use reference architectures / policies</li>
<li>  <strong>Load test</strong> the workload</li>
</ul>
<br>

<p><strong>Select compute solution</strong></p>
<ul>
<li>  Collect compute-related metrics</li>
<li>  Re-evaluate compute needs based on metrics</li>
</ul>
<br>

<p><strong>Select storage solution</strong></p>
<ul>
<li>  Know storage characteristics &amp; requirements (S3, EBS, EFS, EC2 instance store)</li>
<li>  Decide based on <strong>access patterns &amp; metrics</strong></li>
</ul>
<br>

<p><strong>Select networking solution</strong></p>
<ul>
<li>  Use minimal network <strong>ACLs</strong></li>
<li>  Leverage encryption offloading &amp; load-balancing</li>
<li>  Optimize network configs based on metrics</li>
</ul>
<br>

<h3 id="Cost-Optimization-1"><a href="#Cost-Optimization-1" class="headerlink" title="Cost Optimization"></a><u>Cost Optimization</u></h3><p><strong>Govern usage</strong></p>
<ul>
<li>  Implement <strong>account structure</strong></li>
<li>  Implement groups &amp; roles</li>
<li>  Track <strong>project / product lifecycle</strong></li>
<li>  Analyze all components of a chosen workload</li>
</ul>
<br>

<br>

<p>``</p>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Overview</title>
    <url>/2019/AWS-Overview/</url>
    <content><![CDATA[<p>Today we will go over the structure of AWS, and some of the AWS services. </p>
<p>AWS provides building blocks for users to quickly assemble together.</p>
<blockquote>
<p>   <a href="https://docs.aws.amazon.com/">AWS Documentation &amp; All Services</a></p>
</blockquote>
<span id="more"></span>

<br>

<hr>
<h2 id="Cloud-Computing"><a href="#Cloud-Computing" class="headerlink" title="Cloud Computing"></a>Cloud Computing</h2><p><strong>Goal</strong>: Replace capital infrastructure expenses with low variable costs that scale with the business</p>
<br>

<p><strong>Definition</strong>: On-demand delivery of computer power, database storage, applications, and other resources via a cloud service platform.</p>
<br>

<p><strong>A Cloud Service Platform</strong>: </p>
<ul>
<li>  Provides rapid access to flexible &amp; low-cost resources</li>
<li>  Owns and maintains the network-connected hardware required for these application services, and users only need to provision and use the part they need.</li>
</ul>
<br>

<p><strong>Benefits</strong>:</p>
<ul>
<li>  Benefit from massive economies of scale</li>
<li>  Stop guessing capacity</li>
<li>  Increase speed &amp; agility</li>
<li>  Stop spending money running &amp; maintaining data centers</li>
</ul>
<br>

<p><strong>Classification</strong>:</p>
<ul>
<li><strong>IaaS (Infrastrcture)</strong><ul>
<li>  Basic building blocks for cloud</li>
<li>  Provide access to networking features, data storage space, and computers (virtual / on dedicated hardwares)</li>
<li>  <u>Highest level of flexibility &amp; control</u> over resources</li>
</ul>
</li>
<li><strong>PaaS (Platform)</strong><ul>
<li>  More efficient in development </li>
<li>  No need to worry about resource procurement, capacity planning, and software maintenance &amp; patching </li>
</ul>
</li>
<li><strong>SaaS(Software)</strong><ul>
<li>  End-user applications</li>
</ul>
</li>
</ul>
<br>

<p><strong>Deployment Models</strong>:</p>
<ul>
<li><strong>Cloud</strong><ul>
<li>  All parts of the application run in the cloud</li>
</ul>
</li>
<li><strong>Hybrid</strong><ul>
<li>  Connect infrastructure &amp; application between cloud-based resources, and existing on-premise resources </li>
<li>  Use cloud to extend the existing infrastrtucture, connect cloud resources to the internal system</li>
</ul>
</li>
<li><strong>On-premises</strong><ul>
<li>  “Private cloud”, provide dedicated resources</li>
<li>  Use virtualization &amp; resource management for business’ private environment</li>
</ul>
</li>
</ul>
<br>

<p><strong>Security</strong></p>
<ul>
<li>  <strong>Shared responsibility model</strong></li>
<li>  Users retain control of the security they choose to implement</li>
</ul>
<br>

<h2 id="Global-Infrastructure"><a href="#Global-Infrastructure" class="headerlink" title="Global Infrastructure"></a>Global Infrastructure</h2><p>AWS Cloud infrastructure is built around <strong>Regions &amp; Availability Zones (AZ)</strong>. </p>
<ul>
<li><p>  A <strong>Region</strong> is a physical location to have multiple <strong>AZ</strong></p>
</li>
<li><p>  One <strong>AZ</strong> consists of multiple <strong>data centers</strong>, each is housed in separate facilities</p>
</li>
</ul>
<br>

<p>AWS operates in <strong>60+ AZs</strong> and <strong>20+ Regions</strong>.</p>
<ul>
<li>  <strong>Fault tolerance &amp; Stability</strong>: Each region is designed to be completely isolated from other regions</li>
<li>  Each AZ is isolated, but AZs in the same region are connected through <strong>low-latency links</strong></li>
<li>  Each AZ is designed as independent failure zone, with discrete uninterrupted power supply, and onsite backup genertaion facilities</li>
<li>  AZs are all redundantly connected to multiple <strong>tier-1 transit providers</strong></li>
</ul>
<br>

<h2 id="AWS-Services-C1"><a href="#AWS-Services-C1" class="headerlink" title="AWS Services - C1"></a>AWS Services - C1</h2><h3 id="Manage-Services"><a href="#Manage-Services" class="headerlink" title="Manage Services"></a><u>Manage Services</u></h3><h4 id="For-Access"><a href="#For-Access" class="headerlink" title="For Access"></a>For Access</h4><p>AWS Management Console (GUI)</p>
<p>AWS CLI (<code>aws --version</code>)</p>
<p>AWS SDKs</p>
<br>



<h4 id="Cost-Management"><a href="#Cost-Management" class="headerlink" title="Cost Management"></a>Cost Management</h4><h5 id="Cost-Explorer"><a href="#Cost-Explorer" class="headerlink" title="Cost Explorer"></a>Cost Explorer</h5><h5 id="AWS-Budgets"><a href="#AWS-Budgets" class="headerlink" title="AWS Budgets"></a>AWS Budgets</h5><h5 id="AWS-Cost-amp-Usage-Report"><a href="#AWS-Cost-amp-Usage-Report" class="headerlink" title="AWS Cost &amp; Usage Report"></a>AWS Cost &amp; Usage Report</h5><h5 id="Reserved-Instance-RI-Reporting"><a href="#Reserved-Instance-RI-Reporting" class="headerlink" title="Reserved Instance (RI) Reporting"></a>Reserved Instance (RI) Reporting</h5><br>

<h3 id="Analytics"><a href="#Analytics" class="headerlink" title="Analytics"></a><u>Analytics</u></h3><h4 id="Athena"><a href="#Athena" class="headerlink" title="Athena"></a>Athena</h4><p>Interactive query service. </p>
<p>Analyze data in S3 using standard SQL.</p>
<br>

<h4 id="Amazon-ElasticSearch-Service"><a href="#Amazon-ElasticSearch-Service" class="headerlink" title="Amazon ElasticSearch Service"></a>Amazon ElasticSearch Service</h4><p>AWS’s version of ElasticSearch</p>
<br>

<h4 id="Redshift"><a href="#Redshift" class="headerlink" title="Redshift"></a>Redshift</h4><p>Data warehouse</p>
<br>

<h4 id="Lake-Formation"><a href="#Lake-Formation" class="headerlink" title="Lake Formation"></a>Lake Formation</h4><p>Data lake</p>
<br>

<h4 id="AWS-Data-Pipeline"><a href="#AWS-Data-Pipeline" class="headerlink" title="AWS Data Pipeline"></a>AWS Data Pipeline</h4><p>Process &amp; move data between different AWS compute &amp; storage services, as well ass on-premise data sources.</p>
<br>

<h4 id="Glue"><a href="#Glue" class="headerlink" title="Glue"></a>Glue</h4><p>Extract, transform, and load <strong>(ETL)</strong> service.</p>
<p>Prepare and load data for analytics.</p>
<br>

<h4 id="Kinesis"><a href="#Kinesis" class="headerlink" title="Kinesis"></a>Kinesis</h4><p>AWS’s version of the Elastic Stack.</p>
<p>Collect, process, and analyze real-time, streaming data. </p>
<p>Used with <strong>Lambda</strong> &amp; <strong>DynamoDB</strong> to format &amp; store the data for business to query</p>
<br>

<h5 id="Kinesis-Data-Firehouse"><a href="#Kinesis-Data-Firehouse" class="headerlink" title="Kinesis Data Firehouse"></a>Kinesis Data Firehouse</h5><p>Load streaming data into data stores &amp; analytics tools</p>
<br>

<h5 id="Kinesis-Data-Analytics"><a href="#Kinesis-Data-Analytics" class="headerlink" title="Kinesis Data Analytics"></a>Kinesis Data Analytics</h5><p>Analyze streaming data in real time</p>
<br>

<h5 id="Kinesis-Data-Streams-KDS"><a href="#Kinesis-Data-Streams-KDS" class="headerlink" title="Kinesis Data Streams (KDS)"></a>Kinesis Data Streams (KDS)</h5><p>Real time streaming services.</p>
<p>E.g. Financial transactions, social media feeds, location-tracking events</p>
<br>

<h5 id="Kinesis-Video-Streams"><a href="#Kinesis-Video-Streams" class="headerlink" title="Kinesis Video Streams"></a>Kinesis Video Streams</h5><p>Securely stream videos from connected devices to AWS</p>
<br>

<h4 id="Managed-Streaming-for-Kafka-MSK"><a href="#Managed-Streaming-for-Kafka-MSK" class="headerlink" title="Managed Streaming for Kafka (MSK)"></a>Managed Streaming for Kafka (MSK)</h4><p>Use Apache <strong>Kafka</strong> to process streaming data.</p>
<p>Kafka is for building real-time streaming data pipelines &amp; applications.</p>
<br>

<h4 id="EMR"><a href="#EMR" class="headerlink" title="EMR"></a>EMR</h4><p>Managed Hadoop framework</p>
<br>

<h4 id="CloudSearch"><a href="#CloudSearch" class="headerlink" title="CloudSearch"></a>CloudSearch</h4><p>Set up &amp; scale a search solution</p>
<br>

<h4 id="QuickSight"><a href="#QuickSight" class="headerlink" title="QuickSight"></a>QuickSight</h4><p>Business Intelligence (BI) service</p>
<br>

<h3 id="Application-Integration"><a href="#Application-Integration" class="headerlink" title="Application Integration"></a><u>Application Integration</u></h3><h4 id="AWS-Step-Functions"><a href="#AWS-Step-Functions" class="headerlink" title="AWS Step Functions"></a>AWS Step Functions</h4><p>Coordinate multiple AWS services into serverless workflows</p>
<br>

<h4 id="Amazon-MQ"><a href="#Amazon-MQ" class="headerlink" title="Amazon MQ"></a>Amazon MQ</h4><p>Message broker service for Apache <strong>ActiveMQ</strong></p>
<br>

<h4 id="Simple-Queue-Service-SQS"><a href="#Simple-Queue-Service-SQS" class="headerlink" title="Simple Queue Service (SQS)"></a>Simple Queue Service (SQS)</h4><p>Message queuing service, decouple &amp; scale <strong>microservices</strong></p>
<p>Two Types:</p>
<ul>
<li><strong>Standard  queues</strong>: <ul>
<li>  Maximum throughput</li>
<li>  Best-effort ordering</li>
<li>  At-least-once delivery</li>
</ul>
</li>
<li><strong>FIFO queues</strong>:  <ul>
<li>  Guarantee that messages are processed <strong>exactly once</strong>, in the <strong>exact order</strong> they’re sent</li>
</ul>
</li>
</ul>
<br>

<h4 id="Simple-Notification-Service-SNS"><a href="#Simple-Notification-Service-SNS" class="headerlink" title="Simple Notification Service (SNS)"></a>Simple Notification Service (SNS)</h4><p>Pub / sub messaging service, for decoupling microservices.</p>
<p>High throughput, push-based, many-to-many messaging.</p>
<br>

<h4 id="Simple-WorkFlow-SWF"><a href="#Simple-WorkFlow-SWF" class="headerlink" title="Simple WorkFlow(SWF)"></a>Simple WorkFlow(SWF)</h4><p>Build &amp; scale background jobs that have <strong>parallel or sequential</strong> steps</p>
<br>



<h3 id="Compute"><a href="#Compute" class="headerlink" title="Compute"></a><u>Compute</u></h3><h4 id="Elastic-Compute-Cloud-EC2"><a href="#Elastic-Compute-Cloud-EC2" class="headerlink" title="Elastic Compute Cloud (EC2)"></a>Elastic Compute Cloud (EC2)</h4><p>Linux Virtual Machine.  Provide secure, resizable compute capacity.</p>
<p>Instance types:</p>
<ul>
<li>  <strong>On-Demand</strong>: pay per use</li>
<li>  <strong>Reserved</strong></li>
<li>  <strong>Spot</strong></li>
</ul>
<br>

<h4 id="EC2-Auto-Scaling"><a href="#EC2-Auto-Scaling" class="headerlink" title="EC2 Auto Scaling"></a>EC2 Auto Scaling</h4><p>Automatically add / remove EC2 instances</p>
<br>

<h4 id="Elastic-Beanstalk"><a href="#Elastic-Beanstalk" class="headerlink" title="Elastic Beanstalk"></a>Elastic Beanstalk</h4><p>PaaS for deploying &amp; scaling web applications.</p>
<p>EB <strong>automatically handle the deployment</strong> after user upload the code.</p>
<ul>
<li>  Capacity provisioning</li>
<li>  Load balancing</li>
<li>  Auto scaling</li>
<li>  Health monitoring</li>
</ul>
<br>

<h4 id="AWS-Fargate"><a href="#AWS-Fargate" class="headerlink" title="AWS Fargate"></a>AWS Fargate</h4><p><strong>Compute engine for ECS</strong>, allow users to run containers without managing servers / clusters.</p>
<p>Focus on designing &amp; building applications, no need to worry about managing the infrastructure.</p>
<br>

<h4 id="Elastic-Container-Service-ECS"><a href="#Elastic-Container-Service-ECS" class="headerlink" title="Elastic Container Service (ECS)"></a>Elastic Container Service (ECS)</h4><p>AWS’s version of Kubernetes.</p>
<p>Container orchestration service, eliminate the need to operate your own container orchestration software.</p>
<p>Two modes:</p>
<ul>
<li>  <strong>Fargate launch type</strong>: Only need to package the application in containers</li>
<li><strong>EC2 launch type</strong>: <ul>
<li>  Server-level, more granular control</li>
<li>  Responsible for provisioning, patching, and scaling clusters of servers</li>
</ul>
</li>
</ul>
<br>

<h4 id="Elastic-Container-Service-for-Kubernetes-EKS"><a href="#Elastic-Container-Service-for-Kubernetes-EKS" class="headerlink" title="Elastic Container Service for Kubernetes (EKS)"></a>Elastic Container Service for Kubernetes (EKS)</h4><p>Integrates with K8S.</p>
<p>Application running on any standard K8S environment are <strong>fully compatible</strong>, and can be easily migrated to EKS.</p>
<br>

<h4 id="AWS-Lambda"><a href="#AWS-Lambda" class="headerlink" title="AWS Lambda"></a>AWS Lambda</h4><p>Run code directly, used with <strong>serverless</strong></p>
<br>

<h4 id="Serverless-Application-Repository-SAR"><a href="#Serverless-Application-Repository-SAR" class="headerlink" title="Serverless Application Repository (SAR)"></a>Serverless Application Repository (SAR)</h4><p>Quickly deploy code samples &amp; complete application for common use cases. E.g. Mobile backend, Monitoring, etc.</p>
<p>Each application is packaged with AWS Serverless Application Model <strong>(SAM)</strong> template that defines the resources used.</p>
<p>To share the application, publish it to the AWS <strong>SAR</strong>.</p>
<br>

<h4 id="Lightsail"><a href="#Lightsail" class="headerlink" title="Lightsail"></a>Lightsail</h4><p>Launch &amp; manage Virtual Priavte Server (VPS)</p>
<br>

<h4 id="AWS-Batch"><a href="#AWS-Batch" class="headerlink" title="AWS Batch"></a>AWS Batch</h4><p>Do batch computing jobs</p>
<br>

<h4 id="AWS-Outposts"><a href="#AWS-Outposts" class="headerlink" title="AWS Outposts"></a>AWS Outposts</h4><p>Bring AWS services to data centers. Two variants:</p>
<ul>
<li><p>  VMware Cloud on AWS Outposts (Same VMware control panel &amp; APIs)</p>
</li>
<li><p>AWS native variant of AWS Outposts</p>
  <br></li>
</ul>
<h3 id="Database"><a href="#Database" class="headerlink" title="Database"></a><u>Database</u></h3><h4 id="Relational-Database-Service-RDS"><a href="#Relational-Database-Service-RDS" class="headerlink" title="Relational Database Service (RDS)"></a>Relational Database Service (RDS)</h4><p>Scale a relational database in the cloud.</p>
<ul>
<li>  Aurora</li>
<li>  MySQL</li>
<li>  SQL Server</li>
<li>  PostgreSQL</li>
<li>  MariaDB</li>
<li>  Oracle Database</li>
</ul>
<p>Use <strong>AWS Database Migration Service</strong> to migrate / replicate existing DBs to RDS.</p>
<br>

<h4 id="Aurora"><a href="#Aurora" class="headerlink" title="Aurora"></a>Aurora</h4><p>AWS’s version of a <strong>relational database engine</strong>, managed by <strong>RDS</strong>.</p>
<p>Aurora is MySQL &amp; Postgres compatible, and it’s <strong>5x faster</strong> than MySQL, <strong>3x</strong> faster than Postgres. </p>
<p>Features:</p>
<ul>
<li>  Auto-scales up to 64TB per DB instance</li>
<li>  Up to 15 low-latency read replicas</li>
<li>  Replication across 3 AZs</li>
<li>  Point-in-time recovery</li>
<li>  Continuous backup to S3</li>
</ul>
<br>

<h4 id="DynamoDB"><a href="#DynamoDB" class="headerlink" title="DynamoDB"></a>DynamoDB</h4><p><strong>Key-value &amp; document</strong> NoSQL database, delivers single-digit millisecond performance at any scale.</p>
<ul>
<li>  Multi-region, multi-master</li>
<li>  Built-in security, backup &amp; restore</li>
<li>  In-memory caching</li>
<li>  <strong>10 trillion+</strong> requests per day, <strong>20 million+</strong> requests per second</li>
</ul>
<br>

<h4 id="ElastiCache"><a href="#ElastiCache" class="headerlink" title="ElastiCache"></a>ElastiCache</h4><p>In-memory cache. Support:</p>
<ul>
<li>  <strong>Redis</strong>: In-memory data store &amp; cache</li>
<li>  <strong>Memcached</strong>: Memory object caching system</li>
</ul>
<br>

<h4 id="Timestream"><a href="#Timestream" class="headerlink" title="Timestream"></a>Timestream</h4><p>Time series database</p>
<br>

<h4 id="Amazon-Neptune"><a href="#Amazon-Neptune" class="headerlink" title="Amazon Neptune"></a>Amazon Neptune</h4><p>Graph database</p>
<br>

<h4 id="Quantum-Ledger-Database-QLDB"><a href="#Quantum-Ledger-Database-QLDB" class="headerlink" title="Quantum Ledger Database (QLDB)"></a>Quantum Ledger Database (QLDB)</h4><p>Transparent, immutable, cryptographically verifiable transaction log, owned by a <strong>central trusted authority</strong>.</p>
<br>





<h3 id="Developer-Tools"><a href="#Developer-Tools" class="headerlink" title="Developer Tools"></a><u>Developer Tools</u></h3><h4 id="Cloud9"><a href="#Cloud9" class="headerlink" title="Cloud9"></a>Cloud9</h4><p>AWS’s IDE. Write &amp; debug the code in the browser.</p>
<br>



<h4 id="CodeCommit"><a href="#CodeCommit" class="headerlink" title="CodeCommit"></a>CodeCommit</h4><p>Source-control service that hosts secure Git-based repositories</p>
<br>

<h4 id="CodeBuild"><a href="#CodeBuild" class="headerlink" title="CodeBuild"></a>CodeBuild</h4><p>A <strong>build service</strong>.</p>
<ul>
<li>  Compile source code</li>
<li>  Run tests</li>
<li>  Produce software packages for deployment</li>
</ul>
<br>

<h4 id="CodeDeploy"><a href="#CodeDeploy" class="headerlink" title="CodeDeploy"></a>CodeDeploy</h4><p>Automates code deployment to any instance, including <strong>EC2</strong> instances, and instances running <strong>on premise</strong>.</p>
<br>

<h4 id="CodePipeline"><a href="#CodePipeline" class="headerlink" title="CodePipeline"></a>CodePipeline</h4><p>Continuous Delivery service</p>
<br>

<h4 id="CodeStar"><a href="#CodeStar" class="headerlink" title="CodeStar"></a>CodeStar</h4><p>Quickly develop, build &amp; deploy applications.</p>
<p>Provide a unified user interface, manage all activities in one place.</p>
<br>

<h4 id="Corretto"><a href="#Corretto" class="headerlink" title="Corretto"></a>Corretto</h4><p>Multi-platform, production-ready distribution of the Open Java Development Kit (<strong>OpenJDK</strong>).</p>
<br>

<h4 id="X-Ray"><a href="#X-Ray" class="headerlink" title="X-Ray"></a>X-Ray</h4><p>Analyze &amp; debug distributed application in production / development, such as <strong>microservices</strong>.</p>
<br>

<h3 id="Management-amp-Governance"><a href="#Management-amp-Governance" class="headerlink" title="Management &amp; Governance"></a><u>Management &amp; Governance</u></h3><h4 id="CloudWatch"><a href="#CloudWatch" class="headerlink" title="CloudWatch"></a>CloudWatch</h4><p>Monitoring &amp; management service. </p>
<p>Collects monitoring &amp; operational data in the form of logs, metrics, and events</p>
<br>

<h4 id="AWS-Auto-Scaling"><a href="#AWS-Auto-Scaling" class="headerlink" title="AWS Auto Scaling"></a>AWS Auto Scaling</h4><p>Auto adjust capacity to maintain steady &amp; predictable performance at lowest cost</p>
<br>

<h4 id="CloudFormation"><a href="#CloudFormation" class="headerlink" title="CloudFormation"></a>CloudFormation</h4><p>Create &amp; manage a collection of related AWS resources</p>
<br>

<h4 id="OpsWorks"><a href="#OpsWorks" class="headerlink" title="OpsWorks"></a>OpsWorks</h4><p>Provides managed instances of <strong>Chef</strong> and <strong>Puppet</strong></p>
<br>

<h4 id="CloudTrail"><a href="#CloudTrail" class="headerlink" title="CloudTrail"></a>CloudTrail</h4><p>Records AWS API calls for account, and delivers logs. Trace user / API caller  identity, time, IP address, etc.</p>
<br>

<h4 id="AWS-Control-Tower"><a href="#AWS-Control-Tower" class="headerlink" title="AWS Control Tower"></a>AWS Control Tower</h4><p>Automates the set-up of baseline environment</p>
<br>

<h4 id="AWS-System-Manager"><a href="#AWS-System-Manager" class="headerlink" title="AWS System Manager"></a>AWS System Manager</h4><p>Visibility &amp; control of your infrastructure on AWS. It contains the following tools:</p>
<ul>
<li>  Resource groups</li>
<li>  Insights Dashboard</li>
<li>  Run Command</li>
<li>  State Manager</li>
<li>  Inventory</li>
<li>  Maintenance Window</li>
<li>  Patch Manager</li>
<li>  Automation</li>
<li>  Parameter Store</li>
<li>  Distributor</li>
<li>  Session Manager</li>
</ul>
<br>

<h4 id="AWS-Config"><a href="#AWS-Config" class="headerlink" title="AWS Config"></a>AWS Config</h4><p>Provides AWS resource inventory, config history, and config change notifications to enable security</p>
<br>

<h4 id="Service-Catalog"><a href="#Service-Catalog" class="headerlink" title="Service Catalog"></a>Service Catalog</h4><p>Manage service based on the catalogs they belong to</p>
<br>

<h4 id="Trusted-Advisor"><a href="#Trusted-Advisor" class="headerlink" title="Trusted Advisor"></a>Trusted Advisor</h4><p>Reduce cost, increase performance, and improve security by optimizing AWS environment</p>
<br>

<h4 id="Personal-Health-Dashboard"><a href="#Personal-Health-Dashboard" class="headerlink" title="Personal Health Dashboard"></a>Personal Health Dashboard</h4><p>Alerts &amp; remediation guidance</p>
<br>

<h4 id="AWS-Managed-Services"><a href="#AWS-Managed-Services" class="headerlink" title="AWS Managed Services"></a>AWS Managed Services</h4><p>Ongoing management of AWS infrastructure</p>
<br>

<h4 id="AWS-Console-Mobile-Application"><a href="#AWS-Console-Mobile-Application" class="headerlink" title="AWS Console Mobile Application"></a>AWS Console Mobile Application</h4><p>Lets customers view &amp; manager a select set of  resources to support <strong>incident response</strong> on-the-go</p>
<br>

<h4 id="AWS-License-Manager"><a href="#AWS-License-Manager" class="headerlink" title="AWS License Manager"></a>AWS License Manager</h4><p>Manage software license</p>
<br>

<h4 id="AWS-Well-Architectured-Tool"><a href="#AWS-Well-Architectured-Tool" class="headerlink" title="AWS Well-Architectured Tool"></a>AWS Well-Architectured Tool</h4><p>Review the state of your workloads, compares them to the latest AWS architectural <strong>best practices</strong>.</p>
<br>



<h3 id="Migration-amp-Transfer"><a href="#Migration-amp-Transfer" class="headerlink" title="Migration &amp; Transfer"></a><u>Migration &amp; Transfer</u></h3><h4 id="AWS-Migration-Hub"><a href="#AWS-Migration-Hub" class="headerlink" title="AWS Migration Hub"></a>AWS Migration Hub</h4><p>Provides single location to track the progress of application migration across multiple AWS &amp; partner tools</p>
<br>

<h4 id="Application-Discovery-Service"><a href="#Application-Discovery-Service" class="headerlink" title="Application Discovery Service"></a>Application Discovery Service</h4><p>Plan migration projects by gathering information about on-premise data centers</p>
<br>

<h4 id="Database-Migration-Service"><a href="#Database-Migration-Service" class="headerlink" title="Database Migration Service"></a>Database Migration Service</h4><p>Migrate database to AWS</p>
<br>

<h4 id="Server-Migration-Service-SMS"><a href="#Server-Migration-Service-SMS" class="headerlink" title="Server Migration Service (SMS)"></a>Server Migration Service (SMS)</h4><p>Agentless service to migrate thousands of on-premise workloads to AWS</p>
<br>

<h4 id="AWS-Snowball"><a href="#AWS-Snowball" class="headerlink" title="AWS Snowball"></a>AWS Snowball</h4><p>Transfer large amount of data in / out of AWS</p>
<br>

<h4 id="AWS-Snowball-Edge"><a href="#AWS-Snowball-Edge" class="headerlink" title="AWS Snowball Edge"></a>AWS Snowball Edge</h4><p>Data migration &amp; edge computing device. Two options:</p>
<ul>
<li>  Snowball Edge Storage Optimized</li>
<li>  Snowball Edge Compute Optimized</li>
</ul>
<br>

<h4 id="AWS-Snowmobile"><a href="#AWS-Snowmobile" class="headerlink" title="AWS Snowmobile"></a>AWS Snowmobile</h4><p>Data transfer service. Transfer up to <strong>100PB</strong> per Snowmobile</p>
<br>

<h4 id="AWS-DataSync"><a href="#AWS-DataSync" class="headerlink" title="AWS DataSync"></a>AWS DataSync</h4><p>Data transfer service. <strong>Automate</strong> moving data between on-premise storage &amp; <strong>S3 / EFS</strong> (Elastic File System)</p>
<br>

<h4 id="AWS-Transfer-for-SFTP"><a href="#AWS-Transfer-for-SFTP" class="headerlink" title="AWS Transfer for SFTP"></a>AWS Transfer for SFTP</h4><p>Transfer files in / out of S3 directly using <strong>SFTP</strong> (Secure File Transfer Protocol)</p>
<br>



<h3 id="Networking-amp-Content-Delivery"><a href="#Networking-amp-Content-Delivery" class="headerlink" title="Networking &amp; Content Delivery"></a><u>Networking &amp; Content Delivery</u></h3><h4 id="Amazon-VPC"><a href="#Amazon-VPC" class="headerlink" title="Amazon VPC"></a>Amazon VPC</h4><p>Let user provision a logically isolated section of the AWS Cloud</p>
<br>

<h4 id="CloudFront"><a href="#CloudFront" class="headerlink" title="CloudFront"></a>CloudFront</h4><p>AWS’s CDN</p>
<br>

<h4 id="Route-53"><a href="#Route-53" class="headerlink" title="Route 53"></a>Route 53</h4><p>AWS’s DNS</p>
<br>

<h4 id="PrivateLink"><a href="#PrivateLink" class="headerlink" title="PrivateLink"></a>PrivateLink</h4><p>Simplifies security of data sharing, by eliminating the exposure of data to the public Internet.</p>
<br>

<h4 id="Direct-Connect"><a href="#Direct-Connect" class="headerlink" title="Direct Connect"></a>Direct Connect</h4><p>Establish a dedicated network connection from the premise to AWS</p>
<br>

<h4 id="Global-Accelerator"><a href="#Global-Accelerator" class="headerlink" title="Global Accelerator"></a>Global Accelerator</h4><p>Networking service that improves the global availability &amp; performance</p>
<br>

<h4 id="API-Gateway"><a href="#API-Gateway" class="headerlink" title="API Gateway"></a>API Gateway</h4><p>Old version: use REST API</p>
<p>New version (starting from 2019): HTTP API</p>
<br>

<h5 id="Transit-Gateway"><a href="#Transit-Gateway" class="headerlink" title="Transit Gateway"></a>Transit Gateway</h5><p>Enable customers to connect to Amazon VPC</p>
<br>

<h4 id="App-Mesh"><a href="#App-Mesh" class="headerlink" title="App Mesh"></a>App Mesh</h4><p>Use App Mesh with <strong>ECS &amp; EKS</strong></p>
<ul>
<li>  App Mesh uses the <strong>Envoy proxy</strong></li>
<li>  Monitor &amp; control microservices running on AWS</li>
<li>  Standardize how the microservice communicate, give user end-to-end visibility, and help to ensure high availability</li>
<li>  Allow each component to scale independently based on demand</li>
</ul>
<br>

<h4 id="Cloud-Map"><a href="#Cloud-Map" class="headerlink" title="Cloud Map"></a>Cloud Map</h4><p>AWS’s version of Spring Cloud Eureka.</p>
<p>Cloud resource discovery service. </p>
<br>

<h4 id="Elastic-Load-Balancing-ELB"><a href="#Elastic-Load-Balancing-ELB" class="headerlink" title="Elastic Load Balancing (ELB)"></a>Elastic Load Balancing (ELB)</h4><p>Three types:</p>
<ul>
<li>  <strong>Application LB</strong> (HTTP traffic, Layer 7)</li>
<li>  <strong>Network LB</strong> (TCP traffic, Layer 4)</li>
<li>  <strong>Classic LB</strong> (across multiple EC2)</li>
</ul>
<br>









<h3 id="Security-amp-Identity"><a href="#Security-amp-Identity" class="headerlink" title="Security &amp; Identity"></a><u>Security &amp; Identity</u></h3><h4 id="Security-Hub"><a href="#Security-Hub" class="headerlink" title="Security Hub"></a>Security Hub</h4><p>Comprehensive view of high-priority security alerts &amp; compliance status across AWS accounts</p>
<br>

<h4 id="Cloud-Directory"><a href="#Cloud-Directory" class="headerlink" title="Cloud Directory"></a>Cloud Directory</h4><p>Build cloud-native directories for organizing hierarchies of data</p>
<br>

<h4 id="Identity-amp-Access-Management-IAM"><a href="#Identity-amp-Access-Management-IAM" class="headerlink" title="Identity &amp; Access Management (IAM)"></a>Identity &amp; Access Management (IAM)</h4><p>Securely control access to AWS services &amp; resources for your users</p>
<ul>
<li>  Manage IAM users &amp; their access</li>
<li>  Manage IAM roles &amp; their permissions</li>
<li>  Manage federated users &amp; their permissions</li>
</ul>
<br>

<h4 id="Amazon-GuardDuty"><a href="#Amazon-GuardDuty" class="headerlink" title="Amazon GuardDuty"></a>Amazon GuardDuty</h4><p>Threat detection service, continuously monitors for malicious / unauthorized behavior to protect AWS accounts</p>
<br>

<h4 id="Amazon-Inspector"><a href="#Amazon-Inspector" class="headerlink" title="Amazon Inspector"></a>Amazon Inspector</h4><p>Automated security assessment service, improve security &amp; compliance of application deployed on AWS</p>
<br>

<h4 id="Amazon-Macie"><a href="#Amazon-Macie" class="headerlink" title="Amazon Macie"></a>Amazon Macie</h4><p>Security service. Uses machine learning to automatically discover, classify &amp; protect sensitive data in AWS</p>
<br>

<h4 id="AWS-Artifact"><a href="#AWS-Artifact" class="headerlink" title="AWS Artifact"></a>AWS Artifact</h4><p>Central resource for compliance-related information </p>
<br>

<h4 id="Certification-Manager"><a href="#Certification-Manager" class="headerlink" title="Certification Manager"></a>Certification Manager</h4><p>Provision, manage &amp; deploy SSL / TLS certificates</p>
<br>

<h4 id="AWS-CloudHSM"><a href="#AWS-CloudHSM" class="headerlink" title="AWS CloudHSM"></a>AWS CloudHSM</h4><p><strong>HSM</strong>: Hardware Security Model</p>
<p>CloudHSM is a cloud-based HSM, allow users to generate &amp; use your own encryption keys on the AWS cloud</p>
<br>

<h4 id="AWS-Directory-Service"><a href="#AWS-Directory-Service" class="headerlink" title="AWS Directory Service"></a>AWS Directory Service</h4><p>Also known as AWS Managed Microsoft AD. For Microsoft Active Directory. </p>
<br>

<h4 id="AWS-WAF"><a href="#AWS-WAF" class="headerlink" title="AWS WAF"></a>AWS WAF</h4><p>Used with Firewall Manager</p>
<br>

<h4 id="AWS-Firewall-Manager"><a href="#AWS-Firewall-Manager" class="headerlink" title="AWS Firewall Manager"></a>AWS Firewall Manager</h4><p>Manage AWS WAF (Web Application Firewalls) rules across accounts &amp; applications</p>
<br>

<h4 id="AWS-Key-Management-Service-KMS"><a href="#AWS-Key-Management-Service-KMS" class="headerlink" title="AWS Key Management Service (KMS)"></a>AWS Key Management Service (KMS)</h4><p>Create &amp; manage keys, control the use of encryption across a wide range of AWS service</p>
<br>

<h4 id="AWS-Organizations"><a href="#AWS-Organizations" class="headerlink" title="AWS Organizations"></a>AWS Organizations</h4><p>Policy-based management for multiple AWS accounts</p>
<br>

<h4 id="AWS-Secrets-Manager"><a href="#AWS-Secrets-Manager" class="headerlink" title="AWS Secrets Manager"></a>AWS Secrets Manager</h4><p>Protect secrets needed to access your applications &amp; services.</p>
<ul>
<li>  Rotate, manage &amp; retrieve database credentials, API keys, and other secrets throughout their lifecycle</li>
<li>  Offers <strong>secret rotation</strong> with built-in integration for Amazon RDS</li>
<li>  Extend to other types of secrets, including API keys &amp; OAuth tokens</li>
</ul>
<br>

<h4 id="AWS-Shield"><a href="#AWS-Shield" class="headerlink" title="AWS Shield"></a>AWS Shield</h4><p>Distributed Denial of Service (<strong>DDoS</strong>) <strong>protection</strong></p>
<br>

<h4 id="AWS-Single-Sign-On-SSO"><a href="#AWS-Single-Sign-On-SSO" class="headerlink" title="AWS Single Sign-On (SSO)"></a>AWS Single Sign-On (SSO)</h4><p>单点登陆</p>
<br>



<h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a><u>Storage</u></h3><h4 id="Elastic-Block-Store-EBS"><a href="#Elastic-Block-Store-EBS" class="headerlink" title="Elastic Block Store (EBS)"></a>Elastic Block Store (EBS)</h4><p>Persistent <strong>block storage</strong> service</p>
<br>

<h4 id="Simple-Storage-Service-S3"><a href="#Simple-Storage-Service-S3" class="headerlink" title="Simple Storage Service (S3)"></a>Simple Storage Service (S3)</h4><p><strong>Object storage</strong> service</p>
<br>

<h4 id="S3-Glacier"><a href="#S3-Glacier" class="headerlink" title="S3 Glacier"></a>S3 Glacier</h4><ul>
<li>  For data archiving &amp; long-term backup</li>
<li>  Query-in-place functionality</li>
</ul>
<br>

<h4 id="Storage-Gateway"><a href="#Storage-Gateway" class="headerlink" title="Storage Gateway"></a>Storage Gateway</h4><p><strong>Hybrid storage</strong> service, enables <strong>on-premise</strong> applications to use AWS cloud storage</p>
<br>

<h4 id="Elastic-File-System-EFS"><a href="#Elastic-File-System-EFS" class="headerlink" title="Elastic File System(EFS)"></a>Elastic File System(EFS)</h4><p>Scalable &amp; elastic file system for <strong>Linux-based</strong> workloads</p>
<br>

<h4 id="FSx-for-Lustre"><a href="#FSx-for-Lustre" class="headerlink" title="FSx for Lustre"></a>FSx for Lustre</h4><p>File system optimized for compute-intensive workloads</p>
<br>

<h4 id="Amazon-FSx-for-Windows-File-Server"><a href="#Amazon-FSx-for-Windows-File-Server" class="headerlink" title="Amazon FSx for Windows File Server"></a>Amazon FSx for Windows File Server</h4><p>For Windows file system</p>
<br>



<h2 id="AWS-Services-C2"><a href="#AWS-Services-C2" class="headerlink" title="AWS Services - C2"></a>AWS Services - C2</h2><h3 id="Internet-of-Things-IoT"><a href="#Internet-of-Things-IoT" class="headerlink" title="Internet of Things (IoT)"></a><u>Internet of Things (IoT)</u></h3><h4 id="AWS-IoT-Core"><a href="#AWS-IoT-Core" class="headerlink" title="AWS IoT Core"></a>AWS IoT Core</h4><p>Lets connected devices interact with cloud applications &amp; other devices</p>
<br>

<h4 id="FreeRTOS"><a href="#FreeRTOS" class="headerlink" title="FreeRTOS"></a>FreeRTOS</h4><p>OS for microcontrollers</p>
<br>

<h4 id="IoT-Greengrass"><a href="#IoT-Greengrass" class="headerlink" title="IoT Greengrass"></a>IoT Greengrass</h4><p>Act locally on the data they generate</p>
<br>

<h4 id="IoT-1-Click"><a href="#IoT-1-Click" class="headerlink" title="IoT 1-Click"></a>IoT 1-Click</h4><p>Enable simple devices to trigger <strong>AWS Lambda</strong> functions that can execute an action</p>
<br>

<h4 id="IoT-Analytics"><a href="#IoT-Analytics" class="headerlink" title="IoT Analytics"></a>IoT Analytics</h4><p>Analytics on massive volumes of IoT data</p>
<br>

<h4 id="IoT-Button"><a href="#IoT-Button" class="headerlink" title="IoT Button"></a>IoT Button</h4><p>Programmable button based on <strong>Amazon Dash Button Hardware</strong>.</p>
<br>

<h4 id="IoT-Device-Defender"><a href="#IoT-Device-Defender" class="headerlink" title="IoT Device Defender"></a>IoT Device Defender</h4><p>IoT device security</p>
<br>

<h4 id="IoT-Device-Management"><a href="#IoT-Device-Management" class="headerlink" title="IoT Device Management"></a>IoT Device Management</h4><p>Monitor, and remotely manage IoT devices at scale</p>
<br>

<h4 id="IoT-Events"><a href="#IoT-Events" class="headerlink" title="IoT Events"></a>IoT Events</h4><p>Detect &amp; respond to events from IoT sensors / applications</p>
<br>

<h4 id="IoT-SiteWise"><a href="#IoT-SiteWise" class="headerlink" title="IoT SiteWise"></a>IoT SiteWise</h4><p>Collect &amp; organize data from industrial equipment</p>
<br>

<h4 id="IoT-Things-Graph"><a href="#IoT-Things-Graph" class="headerlink" title="IoT Things Graph"></a>IoT Things Graph</h4><p>Visually connect different devices &amp; web services to build IoT applications</p>
<br>

<h4 id="AWS-Partner-Device-Catalog"><a href="#AWS-Partner-Device-Catalog" class="headerlink" title="AWS Partner Device Catalog"></a>AWS Partner Device Catalog</h4><p>Devices &amp; hardware that works with AWS</p>
<br>





<h3 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a><u>Machine Learning</u></h3><h4 id="SageMaker"><a href="#SageMaker" class="headerlink" title="SageMaker"></a>SageMaker</h4><p>Build, train &amp; deploy machine learning models at any scale</p>
<br>

<h4 id="SageMaker-Ground-Truth"><a href="#SageMaker-Ground-Truth" class="headerlink" title="SageMaker Ground Truth"></a>SageMaker Ground Truth</h4><p>Build highly accurate training datasets for machine learning</p>
<br>

<h4 id="Elastic-Inference"><a href="#Elastic-Inference" class="headerlink" title="Elastic Inference"></a>Elastic Inference</h4><p>Attach low-cost GPU-powered acceleration to EC2 &amp; SageMake instances, to reduce cost of running <strong>deep learning</strong>  inferences</p>
<br>

<h4 id="Amazon-Comprehend"><a href="#Amazon-Comprehend" class="headerlink" title="Amazon Comprehend"></a>Amazon Comprehend</h4><p>Natural Language Processing (NLP) service</p>
<br>

<h4 id="Amazon-Lex"><a href="#Amazon-Lex" class="headerlink" title="Amazon Lex"></a>Amazon Lex</h4><p>Build conversational interfaces into any application using voice &amp; text</p>
<br>

<h4 id="Amazon-Polly"><a href="#Amazon-Polly" class="headerlink" title="Amazon Polly"></a>Amazon Polly</h4><p>Turns text into lifelike speech</p>
<br>

<h4 id="Amazon-Rekognition"><a href="#Amazon-Rekognition" class="headerlink" title="Amazon Rekognition"></a>Amazon Rekognition</h4><p>Add image analysis to your application</p>
<br>

<h4 id="Amazon-Translate"><a href="#Amazon-Translate" class="headerlink" title="Amazon Translate"></a>Amazon Translate</h4><p>Neural machine translation service </p>
<br>

<h4 id="Amazon-Transcribe"><a href="#Amazon-Transcribe" class="headerlink" title="Amazon Transcribe"></a>Amazon Transcribe</h4><p>Automatic Speech Recognition (<strong>ASR</strong>) service, easy for developers to add speech-to-text capability</p>
<br>

<h4 id="Amazon-Forecast"><a href="#Amazon-Forecast" class="headerlink" title="Amazon Forecast"></a>Amazon Forecast</h4><p>Use ML to deliver forecasts</p>
<br>

<h4 id="Amazon-Textact"><a href="#Amazon-Textact" class="headerlink" title="Amazon Textact"></a>Amazon Textact</h4><p>AWS’s <strong>OCR</strong> (Optional Character Recognition).</p>
<p>Auto extract text &amp; data from scanned documents.</p>
<br>

<h4 id="Amazon-Personalize"><a href="#Amazon-Personalize" class="headerlink" title="Amazon Personalize"></a>Amazon Personalize</h4><p>Personalized news feed.</p>
<p>Created individual recommendations for customers</p>
<br>

<h4 id="Deep-Learning-AMIs"><a href="#Deep-Learning-AMIs" class="headerlink" title="Deep Learning AMIs"></a>Deep Learning AMIs</h4><p>Provide infrastructure &amp; tools to accelerate deep learning.</p>
<p>E.g. Build custom ensvironments &amp; workflows with TensorFlow</p>
<br>

<h4 id="AWS-DeepLens"><a href="#AWS-DeepLens" class="headerlink" title="AWS DeepLens"></a>AWS DeepLens</h4><p>With fully programmable video camera, code &amp; pre-trained models</p>
<br>

<h4 id="AWS-DeepRacer"><a href="#AWS-DeepRacer" class="headerlink" title="AWS DeepRacer"></a>AWS DeepRacer</h4><p>1/18th scale race car, get started with <strong>Reinforcement Learning (RL)</strong></p>
<br>

<h4 id="Apache-MXNet-on-AWS"><a href="#Apache-MXNet-on-AWS" class="headerlink" title="Apache MXNet on AWS"></a>Apache MXNet on AWS</h4><p>Apache’s version of TensorFlow</p>
<p>Training &amp; inference framework with easy APIs</p>
<br>

<h4 id="TensorFlow-on-AWS"><a href="#TensorFlow-on-AWS" class="headerlink" title="TensorFlow on AWS"></a>TensorFlow on AWS</h4><p>Use Google TensorFlow on AWS. Use with <strong>SageMaker &amp; Deep Learning AMIs</strong>.</p>
<br>

<h4 id="AWS-Inferentia"><a href="#AWS-Inferentia" class="headerlink" title="AWS Inferentia"></a>AWS Inferentia</h4><p>ML inference chip</p>
<br>



<h3 id="Mobile"><a href="#Mobile" class="headerlink" title="Mobile"></a><u>Mobile</u></h3><h4 id="Amplify"><a href="#Amplify" class="headerlink" title="Amplify"></a>Amplify</h4><p>Easier to create, config &amp; implement scalable mobile applications</p>
<ul>
<li>  Provision &amp; manage mobile backend</li>
<li>  Amplify Console will automatically manage <strong>S3</strong> for you</li>
<li>  Automates application release process</li>
<li>Manages: <ul>
<li>  Offline data synchronization</li>
<li>  Storage</li>
<li>  Data sharing across multiple users</li>
</ul>
</li>
</ul>
<br>

<h4 id="Amazon-Cognito"><a href="#Amazon-Cognito" class="headerlink" title="Amazon Cognito"></a>Amazon Cognito</h4><p>Add user signup, login, and access control to your web / mobile application, even when it’s <strong>offline</strong>.</p>
<p><strong>Multi-device</strong>: Synchronize data across users’ device, so the app experience remains <strong>consistent</strong> regardless of  what device they use.</p>
<p>Allow third-party login via <strong>SAML</strong> identity solutions.</p>
<br>

<h4 id="Amazon-Pinpoint"><a href="#Amazon-Pinpoint" class="headerlink" title="Amazon Pinpoint"></a>Amazon Pinpoint</h4><p>Send targeted messages to your customers through multiple engagement channels</p>
<br>

<h4 id="Amazon-Device-Farm"><a href="#Amazon-Device-Farm" class="headerlink" title="Amazon Device Farm"></a>Amazon Device Farm</h4><p>App testing service (mobile / web)</p>
<br>

<h4 id="AWS-AppSync"><a href="#AWS-AppSync" class="headerlink" title="AWS AppSync"></a>AWS AppSync</h4><p><strong>Serverless backend</strong> for mobile / web application</p>
<p>AppSync uses <strong>GraphQL</strong> (API Query language, build client apps by providing intuitive syntax for describing data requirement)</p>
<br>











<h3 id="Robotics"><a href="#Robotics" class="headerlink" title="Robotics"></a><u>Robotics</u></h3><h4 id="AWS-RoboMaker"><a href="#AWS-RoboMaker" class="headerlink" title="AWS RoboMaker"></a>AWS RoboMaker</h4><p>Develop, test &amp; deploy intelligent robotics application at scale</p>
<br>



<h3 id="Satellite"><a href="#Satellite" class="headerlink" title="Satellite"></a><u>Satellite</u></h3><h4 id="AWS-Ground-Station"><a href="#AWS-Ground-Station" class="headerlink" title="AWS Ground Station"></a>AWS Ground Station</h4><p>Control satellite communications, downlink, and process satellite data</p>
<br>









<h2 id="AWS-Services-C3"><a href="#AWS-Services-C3" class="headerlink" title="AWS Services - C3"></a>AWS Services - C3</h2><h3 id="AR-amp-VR"><a href="#AR-amp-VR" class="headerlink" title="AR &amp; VR"></a><u>AR &amp; VR</u></h3><h4 id="Amazon-Sumerian"><a href="#Amazon-Sumerian" class="headerlink" title="Amazon Sumerian"></a>Amazon Sumerian</h4><br>

<h3 id="Blockchain"><a href="#Blockchain" class="headerlink" title="Blockchain"></a><u>Blockchain</u></h3><h4 id="Amazon-Managed-Blockchain"><a href="#Amazon-Managed-Blockchain" class="headerlink" title="Amazon Managed Blockchain"></a>Amazon Managed Blockchain</h4><br>

<h3 id="Business-Applications"><a href="#Business-Applications" class="headerlink" title="Business Applications"></a><u>Business Applications</u></h3><h4 id="Alexa-for-Business"><a href="#Alexa-for-Business" class="headerlink" title="Alexa for Business"></a>Alexa for Business</h4><h4 id="WorkDocs"><a href="#WorkDocs" class="headerlink" title="WorkDocs"></a>WorkDocs</h4><h4 id="WorkMail"><a href="#WorkMail" class="headerlink" title="WorkMail"></a>WorkMail</h4><h4 id="Chime"><a href="#Chime" class="headerlink" title="Chime"></a>Chime</h4><p>Communications service, for online meetings</p>
<br>







<h3 id="Customer-Engagement"><a href="#Customer-Engagement" class="headerlink" title="Customer Engagement"></a><u>Customer Engagement</u></h3><h4 id="Amazon-Connect"><a href="#Amazon-Connect" class="headerlink" title="Amazon Connect"></a>Amazon Connect</h4><h4 id="Simple-Email-Service-SES"><a href="#Simple-Email-Service-SES" class="headerlink" title="Simple Email Service (SES)"></a>Simple Email Service (SES)</h4><br>

<h3 id="Desktop-amp-App-Streaming"><a href="#Desktop-amp-App-Streaming" class="headerlink" title="Desktop &amp; App Streaming"></a><u>Desktop &amp; App Streaming</u></h3><h4 id="Amazon-Workspaces"><a href="#Amazon-Workspaces" class="headerlink" title="Amazon Workspaces"></a>Amazon Workspaces</h4><h4 id="AppStream-2-0"><a href="#AppStream-2-0" class="headerlink" title="AppStream 2.0"></a>AppStream 2.0</h4><br>

<h3 id="Game-Tech"><a href="#Game-Tech" class="headerlink" title="Game Tech"></a><u>Game Tech</u></h3><h4 id="GameLift"><a href="#GameLift" class="headerlink" title="GameLift"></a>GameLift</h4><h4 id="Luberyard"><a href="#Luberyard" class="headerlink" title="Luberyard"></a>Luberyard</h4><br>

<h3 id="Media-Services"><a href="#Media-Services" class="headerlink" title="Media Services"></a><u>Media Services</u></h3><h4 id="Elastic-Transcoder"><a href="#Elastic-Transcoder" class="headerlink" title="Elastic Transcoder"></a>Elastic Transcoder</h4><h4 id="Elemental-MeidaConnect"><a href="#Elemental-MeidaConnect" class="headerlink" title="Elemental MeidaConnect"></a>Elemental MeidaConnect</h4><h4 id="Elemental-MediaConvert"><a href="#Elemental-MediaConvert" class="headerlink" title="Elemental MediaConvert"></a>Elemental MediaConvert</h4><h4 id="Elemental-MediaLive"><a href="#Elemental-MediaLive" class="headerlink" title="Elemental MediaLive"></a>Elemental MediaLive</h4><h4 id="Elemental-Media-PAckage"><a href="#Elemental-Media-PAckage" class="headerlink" title="Elemental Media PAckage"></a>Elemental Media PAckage</h4><h4 id="Elemental-MediaStore"><a href="#Elemental-MediaStore" class="headerlink" title="Elemental MediaStore"></a>Elemental MediaStore</h4><h4 id="Elemental-MediaTailor"><a href="#Elemental-MediaTailor" class="headerlink" title="Elemental MediaTailor"></a>Elemental MediaTailor</h4><br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>Install &amp; Manage Supervisor</title>
    <url>/2019/Supervisor/</url>
    <content><![CDATA[<p>In many VPS environments, it is often the case that you will have a number of small programs that you want to run persistently, whether these be small shell scripts, Node.js apps, or any large-sized packages.</p>
<p>Conventionally, you may write a init script for each of these programs, but this can quickly become time consuming to manage and isn’t always particularly transparent for newer users.</p>
<p>Supervisor is a process manager which makes managing a number of long-running programs a trivial task by providing a consistent interface through which they can be monitored and controlled.</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>Installation of Supervisor on both Ubuntu and Debian is incredibly simple, as prebuilt packages already exist within both distributions’ repositories.</p>
<p>As the root user, run the following command to install the Supervisor package:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-get</span> <span class="string">install</span> <span class="string">supervisor</span></span><br></pre></td></tr></table></figure>
<p>Once this has completed, the supervisor daemon should already be started, as the prebuilt packages come with an init script that will also ensure the Supervisor is restarted after a system reboot. You can ensure this is the case by running:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">service</span> <span class="string">supervisor</span> <span class="string">restart</span></span><br></pre></td></tr></table></figure>
<p>Now that we have Supervisor installed, we can look at adding our first programs.</p>
<br>

<hr>
<h2 id="Adding-a-Program"><a href="#Adding-a-Program" class="headerlink" title="Adding a Program"></a>Adding a Program</h2><p>New programs are given to Supervisor through configuration files, which inform it of the executable to run, any environmental variables, and how output should be handled.</p>
<blockquote>
<p>Note: All programs run under Supervisor must be run in a non-daemonising mode (sometimes also called ‘foreground mode’). If, by default, the program forks and returns on startup, then you may need to consult the program’s manual to find the option to enable this mode, otherwise Supervisor will not be able to properly determine the status of the program.</p>
</blockquote>
<p>For the sake of this article, we’ll assume we have a shell script we wish to keep persistently running that we have saved at /usr/local/bin/long.sh and looks like the following:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">    <span class="comment"># Echo current date to stdout</span></span><br><span class="line">    <span class="built_in">echo</span> `date`</span><br><span class="line">    <span class="comment"># Echo &#x27;error!&#x27; to stderr</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&#x27;error!&#x27;</span> &gt;&amp;2</span><br><span class="line">    sleep 1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>Then run it:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">chmod</span> <span class="string">+x</span> <span class="string">/usr/local/bin/long.sh</span></span><br></pre></td></tr></table></figure>
<p>In a practical sense, this script is clearly rather pointless, but it will allow us to cover the fundamentals of Supervisor configuration.</p>
<p>The program configuration files for Supervisor programs are found in the /etc/supervisor/conf.d directory, normally with one program per file and a .conf extension. A simple configuration for our script, saved at /etc/supervisor/conf.d/long_script.conf, would look like so:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[program:long_script]</span><br><span class="line"><span class="built_in">command</span>=/usr/<span class="built_in">local</span>/bin/long.sh</span><br><span class="line">autostart=<span class="literal">true</span></span><br><span class="line">autorestart=<span class="literal">true</span></span><br><span class="line">stderr_logfile=/var/<span class="built_in">log</span>/long.err.log</span><br><span class="line">stdout_logfile=/var/<span class="built_in">log</span>/long.out.log</span><br></pre></td></tr></table></figure>
<p>We’ll look at the significance of each line and some of the tweaks that may be desirable for your program below:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[program:long_script]</span><br><span class="line"><span class="built_in">command</span>=/usr/<span class="built_in">local</span>/bin/long.sh</span><br></pre></td></tr></table></figure>
<p>The configuration begins by defining a program with the name ‘long_script’ and the full path to the program:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">autostart=true</span></span><br><span class="line"><span class="string">autorestart=true</span></span><br></pre></td></tr></table></figure>
<p>The next two lines define the basic automatic behaviour of the script under certain conditions.</p>
<p>The autostart option tells Supervisor that this program should be started when the system boots. Setting this to false will require a manual start command following any system shutdown.</p>
<p>autorestart defines how Supervisor should manage the program in the event it exits and has three options:</p>
<ul>
<li><code>false</code> tells Supervisor not to ever restart the program after it exits</li>
<li><code>true</code> tells Supervisor to always restart the program after it exits</li>
<li><code>unexpected</code> tells Supervisor to only restart the program if it exits with an unexpected error code (by default anything other than codes 0 or 2).</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">stderr_logfile=/var/log/long.err.log</span></span><br><span class="line"><span class="string">stdout_logfile=/var/log/long.out.log</span></span><br></pre></td></tr></table></figure>

<p>The final two lines define the locations of the two main log files for the program. As suggested by the option names, stdout and stderr will be directed to the stdout_logfile and stderr_logfile locations respectively. The specified directory specified must exist before we start the program, as Supervisor will not attempt to create any missing directories.</p>
<p>The configuration we have created here is a minimal reasonable template for a Supervisor program. The documentation lists many more optional configuration options that are available to fine tune how the program is executed.</p>
<p>Once our configuration file is created and saved, we can inform Supervisor of our new program through the supervisorctl command. First we tell Supervisor to look for any new or changed program configurations in the /etc/supervisor/conf.d directory with:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">supervisorctl</span> <span class="string">reread</span></span><br></pre></td></tr></table></figure>
<p>Followed by telling it to enact any changes with:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">supervisorctl</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>
<p>Any time you make a change to any program configuration file, running the two previous commands will bring the changes into effect.</p>
<p>At this point our program should now be running and we can check this is the case by looking at the output log file:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ tail /var/<span class="built_in">log</span>/long.out.log</span><br><span class="line"></span><br><span class="line">Sat Jul 20 22:21:22 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:23 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:24 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:25 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:26 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:27 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:28 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:29 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:30 UTC 2013</span><br><span class="line">Sat Jul 20 22:21:31 UTC 2013</span><br><span class="line">Success!</span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Managing-Programs"><a href="#Managing-Programs" class="headerlink" title="Managing Programs"></a>Managing Programs</h2><p>Once our programs are running, there will undoubtedly be a time when we want to stop, restart, or see their status. The supervisorctl program, which we first used above, also has an interactive mode through which we can issue commands to control our programs.</p>
<p>To enter the interactive mode, start supervisorctl with no arguments:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ supervisorctl</span><br><span class="line">long_script                      RUNNING    pid 12614, uptime 1:49:37</span><br><span class="line">supervisor&gt;</span><br></pre></td></tr></table></figure>
<p>When started, supervisorctl will initially print the status and uptime of all programs, followed by showing a command prompt. Entering help will reveal all of the available commands that we can use:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">supervisor&gt; <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line">default commands (<span class="built_in">type</span> <span class="built_in">help</span> ):</span><br><span class="line">=====================================</span><br><span class="line">add    clear  <span class="built_in">fg</span>        open  quit    remove  restart   start   stop  update</span><br><span class="line">avail  <span class="built_in">exit</span>   maintail  pid   reload  reread  shutdown  status  tail  version</span><br><span class="line">To start <span class="keyword">in</span> a simple manner, we can start, stop and restart a program with the associated commands followed by the program name:</span><br><span class="line">supervisor&gt; stop long_script</span><br><span class="line">long_script: stopped</span><br><span class="line">supervisor&gt; start long_script</span><br><span class="line">long_script: started</span><br><span class="line">supervisor&gt; restart long_script</span><br><span class="line">long_script: stopped</span><br><span class="line">long_script: started</span><br></pre></td></tr></table></figure>
<p>Using the tail command, we can view the most recent entries in the stdout and stderr logs for our program:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">supervisor&gt; tail long_script</span><br><span class="line">Sun Jul 21 00:36:10 UTC 2013</span><br><span class="line">Sun Jul 21 00:36:11 UTC 2013</span><br><span class="line">Sun Jul 21 00:36:12 UTC 2013</span><br><span class="line">Sun Jul 21 00:36:13 UTC 2013</span><br><span class="line">Sun Jul 21 00:36:14 UTC 2013</span><br><span class="line">Sun Jul 21 00:36:15 UTC 2013</span><br><span class="line">Sun Jul 21 00:36:17 UTC 2013</span><br><span class="line"></span><br><span class="line">supervisor&gt; tail long_script stderr</span><br><span class="line">error!</span><br><span class="line">error!</span><br><span class="line">error!</span><br><span class="line">error!</span><br><span class="line">error!</span><br><span class="line">error!</span><br><span class="line">error!</span><br></pre></td></tr></table></figure>
<p>Using status we can view again the current execution state of each program after making any changes:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">supervisor&gt; status</span><br><span class="line">long_script                      STOPPED    Jul 21 01:07 AM</span><br></pre></td></tr></table></figure>
<p>Finally, once we are finished, we can exit supervisorctl with Ctrl-C or by entering quit into the prompt:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">supervisor&gt; quit</span><br></pre></td></tr></table></figure>
<p>And that’s it! You’ve mastered the basics of managing persistent programs through Supervisor and extending this to your own programs should be a relatively simple task. </p>
<br>

<br>
]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx &amp; Log Rotation on LVS</title>
    <url>/2019/Nginx-Log-Rotation/</url>
    <content><![CDATA[<p>One of the easiest ways to save yourself trouble with your web server is to <strong>configure appropriate logging</strong>. Logging information on your server gives you access to the data that will help you troubleshoot and assess situations as they arise.</p>
<p>In this post, we will examine Nginx’s <strong><a href="https://www.digitalocean.com/community/tutorials/how-to-configure-logging-and-log-rotation-in-nginx-on-an-ubuntu-vps">logging capabilities</a></strong>. We will configure logging and log rotation in Nginx on LVS (Linux Virtual Server).</p>
<span id="more"></span> 

<p>Proper log configuration and management can save you time and energy in the event of a problem with your server. Having easy access to the information that will help you diagnose a problem can be the difference between a trivial fix and a persistent headache.</p>
<p>It is important to keep an eye on server logs in order to maintain a functional site and ensure that you are not exposing sensitive information. This guide should serve only as an introduction to your experience with logging.</p>
<br>

<hr>
<h2 id="The-Error-log-Directive"><a href="#The-Error-log-Directive" class="headerlink" title="The Error_log Directive"></a>The Error_log Directive</h2><p>Nginx uses a few different directives to control system logging. The one included in the core module is called <code>error_log</code>.</p>
<br>

<h3 id="Error-log-Syntax"><a href="#Error-log-Syntax" class="headerlink" title="Error_log Syntax"></a><u>Error_log Syntax</u></h3><p>The <code>error_log</code> directive is used to handle logging general error messages. If you are coming from Apache, this is very similar to Apache’s <code>ErrorLog</code> directive.</p>
<p>The <code>error_log</code> directive takes the following syntax:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">error_log</span> <span class="string">log_file</span> [ <span class="string">log_level</span> ]</span><br></pre></td></tr></table></figure>
<p>The <code>log_file</code> in the example specifies the file where the logs will be written. The <code>log_level</code> specifies the lowest level of logging that you would like to record.</p>
<br>

<h3 id="Logging-Levels"><a href="#Logging-Levels" class="headerlink" title="Logging Levels"></a><u>Logging Levels</u></h3><p>The error_log directive can be configured to log more or less information as required. The level of logging can be any one of the following:</p>
<ul>
<li><strong>emerg</strong>: Emergency situations where the system is in an unusable state.</li>
<li><strong>alert</strong>: Severe situation where action is needed promptly.</li>
<li><strong>crit</strong>: Important problems that need to be addressed.</li>
<li><strong>error</strong>: An Error has occurred. Something was unsuccessful.</li>
<li><strong>warn</strong>: Something out of the ordinary happened, but not a cause for concern.<br>notice: Something normal, but worth noting has happened.</li>
<li><strong>info</strong>: An informational message that might be nice to know.</li>
<li><strong>debug</strong>: Debugging information that can be useful to pinpoint where a problem is occurring.</li>
</ul>
<p>The levels higher on the list are considered a higher priority. If you specify a level, the log will capture that level, and any level higher than the specified level.</p>
<p>For example, if you specify “error”, the log will capture messages labeled <code>error</code>, <code>crit</code>, <code>alert</code>, and <code>emerg</code>.</p>
<p>We can see this directive in use if we look in the main configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/nginx.conf</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">. . .</span><br><span class="line">access_log /var/<span class="built_in">log</span>/nginx/access.log;</span><br><span class="line">error_log /var/<span class="built_in">log</span>/nginx/error.log;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>If you do not want the error_log to log anything, you must send the output into <code>/dev/null</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">error_log</span> <span class="string">/dev/null</span> <span class="string">crit;</span></span><br></pre></td></tr></table></figure>

<p>The other logging directive that we see above, the “access_log” directive, will be discussed in the next section.</p>
<br>

<hr>
<h2 id="HttpLogModule-Logging-Directives"><a href="#HttpLogModule-Logging-Directives" class="headerlink" title="HttpLogModule Logging Directives"></a>HttpLogModule Logging Directives</h2><p>While the error_log directive is part of the core module, the access_log directive is part of the HttpLogModule. It provides the ability to customize logs.</p>
<p>There are a few other directives included with this module that assist in configuring custom logs.</p>
<br>

<h3 id="The-Log-format-Directive"><a href="#The-Log-format-Directive" class="headerlink" title="The Log_format Directive"></a><u>The Log_format Directive</u></h3><p>The <code>log_format</code> directive is used to describe the format of a log entry using plain text and variables.</p>
<p>There is one format that comes predefined with Nginx called “combined”. This is a common format used by many servers.</p>
<p>This is what the combined format would look like if it was not defined internally and needed to be specified with the log_format directive:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">log_format combined <span class="string">&#x27;$remote_addr - $remote_user [$time_local]  &#x27;</span></span><br><span class="line">            <span class="string">&#x27;&quot;$request&quot; $status $body_bytes_sent &#x27;</span></span><br><span class="line">            <span class="string">&#x27;&quot;$http_referer&quot; &quot;$http_user_agent&quot;&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>This definition spans multiple lines until it finds the semi-colon (;).</p>
<p>The pieces beginning with a dollar sign ($) indicate variables, while the characters like <code>-</code>, <code>[</code>, and <code>]</code> are interpreted literally.</p>
<p>The general syntax of the command is:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">log_format</span> <span class="string">format_name</span> <span class="string">string_describing_formatting;</span></span><br></pre></td></tr></table></figure>

<p>You can use variables supported by the core module to formulate your logging strings.</p>
<br>

<h3 id="The-Access-log-Directive"><a href="#The-Access-log-Directive" class="headerlink" title="The Access_log Directive"></a><u>The Access_log Directive</u></h3><p>The access_log directive uses some similar syntax to the error_log directive, but is more flexible. It is used to configure custom logging.</p>
<p>The access_log directive uses the following syntax:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">access_log</span> <span class="string">/path/to/log/location</span> [ <span class="string">format_of_log</span> <span class="string">buffer_size</span> ]<span class="string">;</span></span><br></pre></td></tr></table></figure>
<p>The default value for access_log is the <code>combined</code> format we saw in the log_format section. You can use any format defined by a log_format definition.</p>
<p>The buffer size is the maximum size of data that Nginx will hold before writing it all to the log. You can also specify compression of the log file by adding <code>gzip</code> into the definition:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">access_log</span> <span class="string">location</span> <span class="string">format</span> <span class="string">gzip;</span></span><br></pre></td></tr></table></figure>
<p>Unlike the error_log directive, if you do not want logging, you can turn it off by specifying:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">access_log</span> <span class="string">off;</span></span><br></pre></td></tr></table></figure>
<p>It is not necessary to write to <code>/dev/null</code> in this case.</p>
<br>

<hr>
<h2 id="Log-Rotation"><a href="#Log-Rotation" class="headerlink" title="Log Rotation"></a>Log Rotation</h2><p>As log files grow, it becomes necessary to manage the logging mechanisms to avoid filling up disk space. Log rotation is the process of switching out log files and possibly archiving old files for a set amount of time.</p>
<p>Nginx does not provide tools to manage log files, but it does include mechanisms that make log rotation simple.</p>
<br>

<h3 id="Manual-Log-Rotation"><a href="#Manual-Log-Rotation" class="headerlink" title="Manual Log Rotation"></a><u>Manual Log Rotation</u></h3><p>If you would like to manually rotate your logs (or more likely, create a script to rotate them), you can do so by following the example in the Nginx wiki:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mv /path/to/access.log /path/to/access.log.0</span><br><span class="line"></span><br><span class="line"><span class="built_in">kill</span> -USR1 `cat /var/run/nginx.pid`</span><br><span class="line"></span><br><span class="line">sleep 1</span><br><span class="line"></span><br><span class="line">[ post-rotation processing of old <span class="built_in">log</span> file ]</span><br></pre></td></tr></table></figure>
<p>First, we move the current log to a new file for archiving. A common scheme is to name the most recent log file with a suffix of <code>.0</code>, and then name older files with <code>.1</code>, and so on.</p>
<p>The command that actually rotates the logs is <code>kill -USR1 /var/run/nginx.pid</code>. This does not kill the Nginx process, but instead sends it a signal causing it to reload its log files. This will cause new requests to be logged to the refreshed log file.</p>
<p>The <code>/var/run/nginx.pid</code> file is where Nginx stores the master process’s pid. It is specified in the configuration file with a line that begins with <code>pid</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">. . .</span><br><span class="line">pid /path/to/pid/file;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>After the rotation, we execute <code>sleep 1</code> to allow the process to complete the transfer. We can then zip the old files or do whatever post-rotation processes we would like.</p>
<br>

<hr>
<h3 id="Log-Rotation-with-logrotate"><a href="#Log-Rotation-with-logrotate" class="headerlink" title="Log Rotation with logrotate"></a><u>Log Rotation with logrotate</u></h3><p>The logrotate application is a simple program to rotate logs. It is installed on Ubuntu by default, and Nginx on Ubuntu comes with a custom logrotate script.</p>
<p>We can see the log rotation script by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/logrotate.d/nginx</span></span><br></pre></td></tr></table></figure>
<p>The first line of the file specifies the location that the subsequent lines will apply to. Keep this in mind if you switch the location of logging in the Nginx configuration files.</p>
<p>The rest of the file specifies that the logs will be rotate daily and that 52 older copies will be preserved. The general configuration of logrotate is outside of the scope of this article.</p>
<p>We can see that the <code>postrotate</code> section contains a command similar to the manual rotation mechanisms we were employing:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">postrotate</span><br><span class="line">    [ ! -f /var/run/nginx.pid ] || <span class="built_in">kill</span> -USR1 `cat /var/run/nginx.pid`</span><br><span class="line">endscript</span><br></pre></td></tr></table></figure>
<p>This section tells Nginx to reload the log files once the rotation is complete.</p>
<br>



<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Understanding Nginx</title>
    <url>/2019/Nginx-LB-Buffer-Cache/</url>
    <content><![CDATA[<p>In this post, we will discuss Nginx’s <a href="https://www.digitalocean.com/community/tutorials/understanding-nginx-http-proxying-load-balancing-buffering-and-caching">HTTP proxying</a> capabilities, which allow Nginx to pass requests off to backend http servers for further processing. Nginx is often set up as a reverse proxy solution to help scale out infrastructure or to pass requests to other servers that are not designed to handle large client loads. We will discuss:</p>
<ul>
<li>  HTTP Proxying</li>
<li>  How to scale out using Nginx’s built-in <strong>load balancing</strong> capabilities</li>
<li>  <strong>Buffering</strong> and <strong>Caching</strong>: improve the performance of proxying operations for clients</li>
</ul>
<span id="more"></span> 

<br>

<p><strong>Nginx is first and foremost a reverse proxy</strong>, which also happens to have the ability to work as a web server. Because of this design decision, proxying requests to other servers is fairly straight forward. Nginx is very flexible though, allowing for more complex control over your proxying configuration if desired.</p>
<br>

<hr>
<h2 id="General-Proxying-Info"><a href="#General-Proxying-Info" class="headerlink" title="General Proxying Info"></a>General Proxying Info</h2><p>If you have only used web servers in the past for simple, single server configurations, you may be wondering why you would need to proxy requests.</p>
<p>One reason to proxy to other servers from Nginx is the ability to scale out your infrastructure. Nginx is built to handle many concurrent connections at the same time. This makes it ideal for being the point-of-contact for clients. The server can pass requests to any number of backend servers to handle the bulk of the work, which spreads the load across your infrastructure. This design also provides you with flexibility in easily adding backend servers or taking them down as needed for maintenance.</p>
<p>Another instance where an http proxy might be useful is when using an application servers that might not be built to handle requests directly from clients in production environments. Many frameworks include web servers, but most of them are not as robust as servers designed for high performance like Nginx. Putting Nginx in front of these servers can lead to a better experience for users and increased security.</p>
<p>Proxying in Nginx is accomplished by <u>manipulating a request aimed at the Nginx server and passing it to other servers for the actual processing</u>. The result of the request is passed back to Nginx, which then relays the information to the client. The other servers in this instance can be remote machines, local servers, or even other virtual servers defined within Nginx. The servers that Nginx proxies requests to are known as upstream servers.</p>
<p>Nginx can proxy requests to servers that communicate using the <code>http(s)</code>, <code>FastCGI</code>, <code>SCGI</code>, and <code>uwsgi</code>, or <code>memcached</code> protocols through separate sets of directives for each type of proxy. In this guide, we will be focusing on the http protocol. The Nginx instance is responsible for passing on the request and massaging any message components into a format that the upstream server can understand.</p>
<br>

<hr>
<h2 id="Deconstruct-HTTP-Proxy-Pass"><a href="#Deconstruct-HTTP-Proxy-Pass" class="headerlink" title="Deconstruct HTTP Proxy Pass"></a>Deconstruct HTTP Proxy Pass</h2><p>The most straight-forward type of proxy involves handing off a request to a single server that can communicate using http. This type of proxy is known as a generic “proxy pass” and is handled by the aptly named <code>proxy_pass</code> directive.</p>
<p>The <code>proxy_pass</code> directive is mainly found in location contexts. It is also valid in if blocks within a location context and in <code>limit_except</code> contexts. When a request matches a location with a <code>proxy_pass</code> directive inside, the request is forwarded to the URL given by the directive.</p>
<p>Let’s take a look at an example:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">location /match/here &#123;</span><br><span class="line">    proxy_pass http://example.com;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>In the above configuration snippet, no URI is given at the end of the server in the <code>proxy_pass</code> definition. For definitions that fit this pattern, the URI requested by the client will be passed to the upstream server as-is.</p>
<p>For example, when a request for /match/here/please is handled by this block, the request URI will be sent to the <code>example.com </code>server as <a href="http://example.com/match/here/please">http://example.com/match/here/please</a>.</p>
<p>Let’s take a look at the alternative scenario:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">location /match/here &#123;</span><br><span class="line">    proxy_pass http://example.com/new/prefix;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>In the above example, the proxy server is defined with a URI segment on the end (<code>/new/prefix</code>). When a URI is given in the <code>proxy_pass</code> definition, the portion of the request that matches the location definition is replaced by this URI during the pass.</p>
<p>For example, a request for <code>/match/here/please</code> on the Nginx server will be passed to the upstream server as <a href="http://example.com/new/prefix/please">http://example.com/new/prefix/please</a>. The <code>/match/here</code> is replaced by /new/prefix. This is an important point to keep in mind.</p>
<p>Sometimes, this kind of replacement is impossible. In these cases, the URI at the end of the <code>proxy_pass</code> definition is ignored and either the original URI from the client or the URI as modified by other directives will be passed to the upstream server.</p>
<p>For instance, when the location is matched using regular expressions, Nginx cannot determine which part of the URI matched the expression, so it sends the original client request URI. Another example is when a rewrite directive is used within the same location, causing the client URI to be rewritten, but still handled in the same block. In this case, the rewritten URI will be passed.</p>
<br>

<hr>
<h2 id="How-Nginx-Processes-Headers"><a href="#How-Nginx-Processes-Headers" class="headerlink" title="How Nginx Processes Headers"></a>How Nginx Processes Headers</h2><p>One thing that might not be immediately clear is that it is important to pass more than just the URI if you expect the upstream server handle the request properly. The request coming from Nginx on behalf of a client will look different than a request coming directly from a client. A big part of this is the headers that go along with the request.</p>
<p>When Nginx proxies a request, it automatically makes some adjustments to the request headers it receives from the client:</p>
<ul>
<li><p>Nginx gets rid of any empty headers. There is no point of passing along empty values to another server; it would only serve to bloat the request.</p>
</li>
<li><p>Nginx, by default, will consider any header that contains underscores as invalid. It will remove these from the proxied request. If you wish to have Nginx interpret these as valid, you can set the underscores_in_headers directive to “on”, otherwise your headers will never make it to the backend server.</p>
</li>
<li><p>The “Host” header is re-written to the value defined by the $proxy_host variable. This will be the IP address or name and port number of the upstream, directly as defined by the proxy_pass directive.</p>
</li>
<li><p>The “Connection” header is changed to “close”. This header is used to signal information about the particular connection established between two parties. In this instance, Nginx sets this to “close” to indicate to the upstream server that this connection will be closed once the original request is responded to. The upstream should not expect this connection to be persistent.</p>
</li>
</ul>
<p>The first point that we can extrapolate from the above is that any header that you do not want passed should be set to an empty string. Headers with empty values are completely removed from the passed request.</p>
<p>The next point to glean from the above information is that if your backend application will be processing non-standard headers, you must make sure that they do not have underscores. If you need headers that use an underscore, you can set the underscores_in_headers directive to “on” further up in your configuration (valid either in the http context or in the context of the default server declaration for the IP address/port combination). If you do not do this, Nginx will flag these headers as invalid and silently drop them before passing to your upstream.</p>
<p>The “Host” header is of particular importance in most proxying scenarios. As stated above, by default, this will be set to the value of <code>$proxy_host</code>, a variable that will contain the domain name or IP address and port taken directly from the proxy_pass definition. This is selected by default as it is the only address Nginx can be sure the upstream server responds to (as it is pulled directly from the connection info).</p>
<p>The most common values for the “Host” header are below:</p>
<ul>
<li><p><code>$proxy_host</code>: This sets the “Host” header to the domain name or IP address and port combo taken from the proxy_pass definition. This is the default and “safe” from Nginx’s perspective, but not usually what is needed by the proxied server to correctly handle the request.</p>
</li>
<li><p><code>$http_host</code>: Sets the “Host” header to the “Host” header from the client request. The headers sent by the client are always available in Nginx as variables. The variables will start with an <code>$http_prefix</code>, followed by the header name in lowercase, with any dashes replaced by underscores. Although the $http_host variable works most of the time, when the client request does not have a valid “Host” header, this can cause the pass to fail.</p>
</li>
<li><p><code>$host</code>: This variable is set, in order of preference to: the host name from the request line itself, the “Host” header from the client request, or the server name matching the request.</p>
</li>
</ul>
<p>In most cases, you will want to set the “Host” header to the <code>$host</code> variable. It is the most flexible and will usually provide the proxied servers with a “Host” header filled in as accurately as possible.</p>
<br>

<hr>
<h2 id="Setting-Resetting-Headers"><a href="#Setting-Resetting-Headers" class="headerlink" title="Setting / Resetting Headers"></a>Setting / Resetting Headers</h2><p>To adjust or set headers for proxy connections, we can use the proxy_set_header directive. For instance, to change the “Host” header as we have discussed, and add some additional headers common with proxied requests, we could use something like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">location /match/here &#123;</span><br><span class="line">    proxy_set_header HOST <span class="variable">$host</span>;</span><br><span class="line">    proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">    proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line"></span><br><span class="line">    proxy_pass http://example.com/new/prefix;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>The above request sets the “Host” header to the $host variable, which should contain information about the original host being requested. The X-Forwarded-Proto header gives the proxied server information about the schema of the original client request (whether it was an http or an https request).</p>
<p>The X-Real-IP is set to the IP address of the client so that the proxy can correctly make decisions or log based on this information. The X-Forwarded-For header is a list containing the IP addresses of every server the client has been proxied through up to this point. In the example above, we set this to the $proxy_add_x_forwarded_for variable. This variable takes the value of the original X-Forwarded-For header retrieved from the client and adds the Nginx server’s IP address to the end.</p>
<p>Of course, we could move the proxy_set_header directives out to the server or http context, allowing it to be referenced in more than one location:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">proxy_set_header HOST <span class="variable">$host</span>;</span><br><span class="line">proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line"></span><br><span class="line">location /match/here &#123;</span><br><span class="line">    proxy_pass http://example.com/new/prefix;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location /different/match &#123;</span><br><span class="line">    proxy_pass http://example.com;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Upstream-Context-for-LB-Proxied-Connections"><a href="#Upstream-Context-for-LB-Proxied-Connections" class="headerlink" title="Upstream Context for LB Proxied Connections"></a>Upstream Context for LB Proxied Connections</h2><p>In the previous examples, we demonstrated how to do a simple http proxy to a single backend server. Nginx allows us to easily scale this configuration out by specifying entire pools of backend servers that we can pass requests to.</p>
<p>We can do this by using the upstream directive to define a pool of servers. This configuration assumes that any one of the listed servers is capable of handling a client’s request. This allows us to scale out our infrastructure with almost no effort. The upstream directive must be set in the http context of your Nginx configuration.</p>
<p>Let’s look at a simple example:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># http context</span></span><br><span class="line"></span><br><span class="line">upstream backend_hosts &#123;</span><br><span class="line">    server host1.example.com;</span><br><span class="line">    server host2.example.com;</span><br><span class="line">    server host3.example.com;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name example.com;</span><br><span class="line"></span><br><span class="line">    location /proxy-me &#123;</span><br><span class="line">        proxy_pass http://backend_hosts;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In the above example, we’ve set up an upstream context called backend_hosts. Once defined, this name will be available for use within proxy passes as if it were a regular domain name. As you can see, within our server block we pass any request made to <code>example.com/proxy-me/...</code> to the pool we defined above. Within that pool, a host is selected by applying a configurable algorithm. By default, this is just a simple round-robin selection process (each request will be routed to a different host in turn).</p>
<br>

<h3 id="Upstream-LB-Algorithm"><a href="#Upstream-LB-Algorithm" class="headerlink" title="Upstream LB Algorithm"></a><u>Upstream LB Algorithm</u></h3><p>You can modify the balancing algorithm used by the upstream pool by including directives or flags within the upstream context:</p>
<ul>
<li><p><strong>round robin</strong>: The default load balancing algorithm that is used if no other balancing directives are present. Each server defined in the upstream context is passed requests sequentially in turn.</p>
</li>
<li><p><strong>least_conn</strong>: Specifies that new connections should always be given to the backend that has the least number of active connections. This can be especially useful in situations where connections to the backend may persist for some time.</p>
</li>
<li><p><strong>ip_hash</strong>: This balancing algorithm distributes requests to different servers based on the client’s IP address. The first three octets are used as a key to decide on the server to handle the request. The result is that clients tend to be served by the same server each time, which can assist in session consistency.</p>
</li>
<li><p><strong>hash</strong>: This balancing algorithm is mainly used with memcached proxying. The servers are divided based on the value of an arbitrarily provided hash key. This can be text, variables, or a combination. This is the only balancing method that requires the user to provide data, which is the key that should be used for the hash.</p>
</li>
</ul>
<p>When changing the balancing algorithm, the block may look something like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># http context</span></span><br><span class="line"></span><br><span class="line">upstream backend_hosts &#123;</span><br><span class="line"></span><br><span class="line">    least_conn;</span><br><span class="line"></span><br><span class="line">    server host1.example.com;</span><br><span class="line">    server host2.example.com;</span><br><span class="line">    server host3.example.com;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>In the above example, the server will be selected based on which one has the least connections. The <code>ip_hash</code> directive could be set in the same way to get a certain amount of session “stickiness”.</p>
<p>As for the hash method, you must provide the key to hash against. This can be whatever you wish:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># http context</span></span><br><span class="line"></span><br><span class="line">upstream backend_hosts &#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hash</span> $remote_addr<span class="variable">$remote_port</span> consistent;</span><br><span class="line"></span><br><span class="line">    server host1.example.com;</span><br><span class="line">    server host2.example.com;</span><br><span class="line">    server host3.example.com;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>The above example will distribute requests based on the value of the client ip address and port. We also added the optional parameter consistent, which implements the ketama consistent hashing algorithm. Basically, this means that if your upstream servers change, there will be minimal impact on your cache.</p>
<br>

<h3 id="Set-Server-Weight-for-LB"><a href="#Set-Server-Weight-for-LB" class="headerlink" title="Set Server Weight for LB"></a><u>Set Server Weight for LB</u></h3><p>In declarations of the backend servers, by default, each servers is equally “weighted”. This assumes that each server can and should handle the same amount of load (taking into account the effects of the balancing algorithms). However, you can also set an alternative weight to servers during the declaration:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># http context</span></span><br><span class="line"></span><br><span class="line">upstream backend_hosts &#123;</span><br><span class="line">    server host1.example.com weight=3;</span><br><span class="line">    server host2.example.com;</span><br><span class="line">    server host3.example.com;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>In the above example, <code>host1.example.com</code> will receive three times the traffic as the other two servers. By default, each server is assigned a weight of one.</p>
<br>

<h2 id="Use-Buffers-to-Free-Up-Servers"><a href="#Use-Buffers-to-Free-Up-Servers" class="headerlink" title="Use Buffers to Free Up Servers"></a>Use Buffers to Free Up Servers</h2><p>One issue with proxying that concerns many users is the performance impact of adding an additional server to the process. In most cases, this can be largely mitigated by taking advantage of Nginx’s buffering and caching capabilities.</p>
<p>When proxying to another server, the speed of two different connections will affect the client’s experience:</p>
<ul>
<li><p>The connection from the client to the Nginx proxy.</p>
</li>
<li><p>The connection from the Nginx proxy to the backend server.<br>Nginx has the ability to adjust its behavior based on whichever one of these connections you wish to optimize.</p>
</li>
</ul>
<p>Without buffers, data is sent from the proxied server and immediately begins to be transmitted to the client. If the clients are assumed to be fast, buffering can be turned off in order to get the data to the client as soon as possible. With buffers, the Nginx proxy will temporarily store the backend’s response and then feed this data to the client. If the client is slow, this allows the Nginx server to close the connection to the backend sooner. It can then handle distributing the data to the client at whatever pace is possible.</p>
<p>Nginx defaults to a buffering design since clients tend to have vastly different connection speeds. We can adjust the buffering behavior with the following directives. These can be set in the http, server, or location contexts. It is important to keep in mind that the sizing directives are configured per request, so increasing them beyond your need can affect your performance when there are many client requests:</p>
<ul>
<li><p><code>proxy_buffering</code>: This directive controls whether buffering for this context and child contexts is enabled. By default, this is “on”.</p>
</li>
<li><p><code>proxy_buffers</code>: This directive controls the number (first argument) and size (second argument) of buffers for proxied responses. The default is to configure 8 buffers of a size equal to one memory page (either 4k or 8k). Increasing the number of buffers can allow you to buffer more information.</p>
</li>
<li><p><code>proxy_buffer_size</code>: The initial portion of the response from a backend server, which contains headers, is buffered separately from the rest of the response. This directive sets the size of the buffer for this portion of the response. By default, this will be the same size as proxy_buffers, but since this is used for header information, this can usually be set to a lower value.</p>
</li>
<li><p><code>proxy_busy_buffers_size</code>: This directive sets the maximum size of buffers that can be marked “client-ready” and thus busy. While a client can only read the data from one buffer at a time, buffers are placed in a queue to send to the client in bunches. This directive controls the size of the buffer space allowed to be in this state.</p>
</li>
<li><p><code>proxy_max_temp_file_size</code>: This is the maximum size, per request, for a temporary file on disk. These are created when the upstream response is too large to fit into a buffer.</p>
</li>
<li><p><code>proxy_temp_file_write_size</code>: This is the amount of data Nginx will write to the temporary file at one time when the proxied server’s response is too large for the configured buffers.</p>
</li>
<li><p><code>proxy_temp_path</code>: This is the path to the area on disk where Nginx should store any temporary files when the response from the upstream server cannot fit into the configured buffers.</p>
</li>
</ul>
<p>As you can see, Nginx provides quite a few different directives to tweak the buffering behavior. Most of the time, you will not have to worry about the majority of these, but it can be useful to adjust some of these values. Probably the most useful to adjust are the proxy_buffers and proxy_buffer_size directives.</p>
<p>An example that increases the number of available proxy buffers for each upstream request, while trimming down the buffer that likely stores the headers would look like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">proxy_buffering on;</span><br><span class="line">proxy_buffer_size 1k;</span><br><span class="line">proxy_buffers 24 4k;</span><br><span class="line">proxy_busy_buffers_size 8k;</span><br><span class="line">proxy_max_temp_file_size 2048m;</span><br><span class="line">proxy_temp_file_write_size 32k;</span><br><span class="line"></span><br><span class="line">location / &#123;</span><br><span class="line">    proxy_pass http://example.com;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In contrast, if you have fast clients that you want to immediately serve data to, you can turn buffering off completely. Nginx will actually still use buffers if the upstream is faster than the client, but it will immediately try to flush data to the client instead of waiting for the buffer to pool. If the client is slow, this can cause the upstream connection to remain open until the client can catch up. When buffering is “off” only the buffer defined by the proxy_buffer_size directive will be used:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">proxy_buffering off;</span><br><span class="line">proxy_buffer_size 4k;</span><br><span class="line"></span><br><span class="line">location / &#123;</span><br><span class="line">    proxy_pass http://example.com;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h3><p>Nginx proxying can be made more robust by adding in a redundant set of load balancers, creating a high availability infrastructure.</p>
<p>A high availability (HA) setup is an infrastructure without a single point of failure, and your load balancers are a part of this configuration. By having more than one load balancer, you prevent potential downtime if your load balancer is unavailable or if you need to take them down for maintenance.</p>
<p>Here is a diagram of a basic high availability setup:</p>
<p><img data-src="/images/posts/181122-1.gif" alt="01"></p>
<p>In this example, you have multiple load balancers (one active and one or more passive) behind a static IP address that can be remapped from one server to another. Client requests are routed from the static IP to the active load balancer, then on to your backend servers. </p>
<br>

<hr>
<h2 id="Proxy-Cache-to-Decrease-Response-Times"><a href="#Proxy-Cache-to-Decrease-Response-Times" class="headerlink" title="Proxy Cache to Decrease Response Times"></a>Proxy Cache to Decrease Response Times</h2><p>While buffering can help free up the backend server to handle more requests, Nginx also provides a way to cache content from backend servers, eliminating the need to connect to the upstream at all for many requests.</p>
<br>

<h3 id="Config-a-Proxy-Cache"><a href="#Config-a-Proxy-Cache" class="headerlink" title="Config a Proxy Cache"></a>Config a Proxy Cache</h3><p>To set up a cache to use for proxied content, we can use the proxy_cache_path directive. This will create an area where data returned from the proxied servers can be kept. The proxy_cache_path directive must be set in the http context.</p>
<p>In the example below, we will configure this and some related directives to set up our caching system.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># http context</span></span><br><span class="line"></span><br><span class="line">proxy_cache_path /var/lib/nginx/cache levels=1:2 keys_zone=backcache:8m max_size=50m;</span><br><span class="line">proxy_cache_key <span class="string">&quot;$scheme$request_method$host$request_uri$is_args<span class="variable">$args</span>&quot;</span>;</span><br><span class="line">proxy_cache_valid 200 302 10m;</span><br><span class="line">proxy_cache_valid 404 1m;</span><br></pre></td></tr></table></figure>

<p>With the proxy_cache_path directive, we have have defined a directory on the filesystem where we would like to store our cache. In this example, we’ve chosen the /var/lib/nginx/cache directory. If this directory does not exist, you can create it with the correct permission and ownership by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">mkdir</span> <span class="string">-p</span> <span class="string">/var/lib/nginx/cache</span></span><br><span class="line"></span><br><span class="line"><span class="string">sudo</span> <span class="string">chown</span> <span class="string">www-data</span> <span class="string">/var/lib/nginx/cache</span></span><br><span class="line"></span><br><span class="line"><span class="string">sudo</span> <span class="string">chmod</span> <span class="number">700</span> <span class="string">/var/lib/nginx/cache</span></span><br></pre></td></tr></table></figure>

<p>The <code>levels=</code> parameter specifies how the cache will be organized. Nginx will create a cache key by hashing the value of a key (configured below). The levels we selected above dictate that a single character directory (this will be the last character of the hashed value) with a two character subdirectory (taken from the next two characters from the end of the hashed value) will be created. You usually won’t have to be concerned with the specifics of this, but it helps Nginx quickly find the relevant values.</p>
<p>The <code>keys_zone=</code> parameter defines the name for this cache zone, which we have called backcache. This is also where we define how much metadata to store. In this case, we are storing 8 MB of keys. For each megabyte, Nginx can store around 8000 entries. The max_size parameter sets the maximum size of the actual cached data.</p>
<p>Another directive we use above is proxy_cache_key. This is used to set the key that will be used to store cached values. This same key is used to check whether a request can be served from the cache. We are setting this to a combination of the scheme (http or https), the HTTP request method, as well as the requested host and URI.</p>
<p>The <code>proxy_cache_valid</code> directive can be specified multiple times. It allows us to configure how long to store values depending on the status code. In our example, we store successes and redirects for 10 minutes, and expire the cache for 404 responses every minute.</p>
<p>Now, we have configured the cache zone, but we still need to tell Nginx when to use the cache.</p>
<p>In locations where we proxy to a backend, we can configure the use of this cache:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server context</span></span><br><span class="line"></span><br><span class="line">location /proxy-me &#123;</span><br><span class="line">    proxy_cache backcache;</span><br><span class="line">    proxy_cache_bypass <span class="variable">$http_cache_control</span>;</span><br><span class="line">    add_header X-Proxy-Cache <span class="variable">$upstream_cache_status</span>;</span><br><span class="line"></span><br><span class="line">    proxy_pass http://backend;</span><br><span class="line">&#125;</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>Using the <code>proxy_cache</code> directive, we can specify that the backcache cache zone should be used for this context. Nginx will check here for a valid entry before passing to the backend.</p>
<p>The <code>proxy_cache_bypass</code> directive is set to the <code>$http_cache_control</code> variable. This will contain an indicator as to whether the client is explicitly requesting a fresh, non-cached version of the resource. Setting this directive allows Nginx to correctly handle these types of client requests. No further configuration is required.</p>
<p>We also added an extra header called X-Proxy-Cache. We set this header to the value of the $upstream_cache_status variable. Basically, this sets a header that allows us to see if the request resulted in a cache hit, a cache miss, or if the cache was explicitly bypassed. This is especially valuable for debugging, but is also useful information for the client.</p>
<br>

<h3 id="Notes-about-Caching-Results"><a href="#Notes-about-Caching-Results" class="headerlink" title="Notes about Caching Results"></a>Notes about Caching Results</h3><p>Caching can improve the performance of your proxy enormously. However, there are definitely considerations to keep in mind when configuring cache.</p>
<p>First, any user-related data should not be cached. This could result in one user’s data being presented to another user. If your site is completely static, this is probably not an issue.</p>
<p>If your site has some dynamic elements, you will have to account for this in the backend servers. How you handle this depends on what application or server is handling the backend processing. For private content, you should set the Cache-Control header to “no-cache”, “no-store”, or “private” depending on the nature of the data:</p>
<ul>
<li><strong>no-cache</strong>: Indicates that the response shouldn’t be served again without first checking that the data hasn’t changed on the backend. This can be used if the data is dynamic and important. An ETag hashed metadata header is checked on each request and the previous value can be served if the backend returns the same hash value.</li>
<li><strong>no-store</strong>: Indicates that at no point should the data received ever be cached. This is the safest option for private data, as it means that the data must be retrieved from the server every time.</li>
<li><strong>privat</strong>e: This indicates that no shared cache space should cache this data. This can be useful for indicating that a user’s browser can cache the data, but the proxy server shouldn’t consider this data valid for subsequent requests.</li>
<li><strong>public</strong>: This indicates that the response is public data that can be cached at any point in the connection.</li>
</ul>
<p>A related header that can control this behavior is the max-age header, which indicates the number of seconds that any resource should be cached.</p>
<p>Setting these headers correctly, depending on the sensitivity of the content, will help you take advantage of cache while keeping your private data safe and your dynamic data fresh.</p>
<p>If your backend also uses Nginx, you can set some of this using the expires directive, which will set the max-age for Cache-Control:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">    expires 60m;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location /check-me &#123;</span><br><span class="line">    expires -1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In the above example, the first block allows content to be cached for an hour. The second block sets the Cache-Control header to “no-cache”. To set other values, you can use the add_header directive, like this:</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">location /private &#123;</span><br><span class="line">    expires -1;</span><br><span class="line">    add_header Cache-Control <span class="string">&quot;no-store&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>RESTful API Design</title>
    <url>/2019/REST-API/</url>
    <content><![CDATA[<p>As software developers, most of us use or build REST APIs in a day to day life. APIs are the default means of communication between the systems. Amazon is the best example how of APIs can be efficiently used for communication. In this article, I am going to talk about how to design your RESTful APIs better to avoid common mistakes.</p>
<span id="more"></span> 

<br>

<h2 id="Jeff-Bezos’-Key-to-Success-Mandate"><a href="#Jeff-Bezos’-Key-to-Success-Mandate" class="headerlink" title="Jeff Bezos’ (Key to Success) Mandate"></a>Jeff Bezos’ (Key to Success) Mandate</h2><p>Some of you might have been already aware of Jeff Bezos’ mandate to the developers in Amazon. If you never got a chance to hear about it, following points are the crux of it —</p>
<ul>
<li><p>All teams will henceforth expose their data and functionality through service interfaces.</p>
</li>
<li><p>Teams must communicate with each other through these interfaces.</p>
</li>
<li><p>There will be no other form of interprocess communication allowed: no direct linking, no direct reads of another team’s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network.</p>
</li>
<li><p>It doesn’t matter what technology they use. HTTP, Corba, Pubsub, custom protocols — doesn’t matter. Bezos doesn’t care.</p>
</li>
<li><p>All service interfaces, without exception, must be designed from the ground up to be externalizable. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world. No exceptions.</p>
</li>
<li><p><strong>Anyone who doesn’t do this will be fired.</strong></p>
</li>
</ul>
<p>Eventually this turned to be the key to Amazon’s success. Amazon could build scalable systems and later could also offer those as services as Amazon Web Services.</p>
<br>

<h2 id="Principles-of-Designing-RESTful-APIs"><a href="#Principles-of-Designing-RESTful-APIs" class="headerlink" title="Principles of Designing RESTful APIs"></a>Principles of Designing RESTful APIs</h2><p>Now let’s understand the principles we should follow while designing the RESTful APIs —</p>
<br>

<h3 id="Keep-it-simple"><a href="#Keep-it-simple" class="headerlink" title="Keep it simple"></a>Keep it simple</h3><p>We need to make sure that the base URL of the API is simple. For example, if we want to design APIs for products, it should be designed like —</p>
<pre><code>/products
/products/12345
</code></pre>
<p>The first API is to get all products and the second one is to get specific product.</p>
<br>

<h3 id="Use-nouns-and-NOT-the-verbs"><a href="#Use-nouns-and-NOT-the-verbs" class="headerlink" title="Use nouns and NOT the verbs"></a>Use nouns and NOT the verbs</h3><p>A lot of developers make this mistake. They generally forget that we have HTTP methods with us to describe the APIs better and end up using verbs in the API URLs. For instance, API to get all products should be:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">/products</span></span><br></pre></td></tr></table></figure>

<p>and NOT as shown below:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">/getAllProducts</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Use-of-right-HTTP-methods"><a href="#Use-of-right-HTTP-methods" class="headerlink" title="Use of right HTTP methods"></a>Use of right HTTP methods</h3><p>RESTful APIs have various methods to indicate the type of operation we are going to perform with this API —</p>
<ul>
<li><p>GET — To get a resource or collection of resources.</p>
</li>
<li><p>POST — To create a resource or collection of resources.</p>
</li>
<li><p>PUT/PATCH — To update the existing resource or collection of resources.</p>
</li>
<li><p>DELETE — To delete the existing resource or the collection of resources.<br>We need to make sure we use the right HTTP method for given operation.</p>
</li>
</ul>
<br>

<h3 id="Use-Plurals"><a href="#Use-Plurals" class="headerlink" title="Use Plurals"></a>Use Plurals</h3><p>This topic is bit debatable. Some of people like to keep the resource URL with plural names while others like to keep it singular. For instance —</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">/products/product</span></span><br></pre></td></tr></table></figure>

<p>I like to keep it plural since it avoids confusion whether we are talking about getting single resource or a collection. It also avoids adding additional things like attaching all to the base URL e.g. /product/all</p>
<p>Some people might not like this but my only suggestion is to keep is uniform across the project.</p>
<br>

<h3 id="Use-parameters"><a href="#Use-parameters" class="headerlink" title="Use parameters"></a>Use parameters</h3><p>Sometime we need to have an API which should be telling more story than just by id. Here we should make use of query parameters to design the API.</p>
<ul>
<li><p><code>/products?name=’ABC’</code> should be prefered over <code>/getProductsByName</code></p>
</li>
<li><p><code>/products?type=’xyz’</code> should be preferred over <code>/getProductsByType</code></p>
</li>
</ul>
<p>This way you can avoid long URLs with simplicity in design.</p>
<br>

<h3 id="Use-proper-HTTP-codes"><a href="#Use-proper-HTTP-codes" class="headerlink" title="Use proper HTTP codes"></a>Use proper HTTP codes</h3><p>We have plenty of HTTP codes. Most of us only end up using two — 200 and 500! This is certainly not a good practice. Following are some commonly used HTTP codes.</p>
<ul>
<li><strong>200 OK</strong> — This is most commonly used HTTP code to show that the operation performed is successful.</li>
<li><strong>201 CREATED</strong> — This can be used when you use POST method to create a new resource.</li>
<li><strong>202 ACCEPTED</strong> — This can be used to acknowledge the request sent to the server.</li>
<li><strong>400 BAD REQUEST</strong> — This can be used when client side input validation fails.</li>
<li><strong>401 UNAUTHORIZED</strong> / <strong>403 FORBIDDEN</strong>— This can be used if the user or the system is not authorised to perform certain operation.</li>
<li><strong>404 NOT FOUND</strong>— This can be used if you are looking for certain resource and it is not available in the system.</li>
<li><strong>500 INTERNAL SERVER ERROR</strong> — This should never be thrown explicitly but might occur if the system fails.</li>
<li><strong>502 BAD GATEWAY</strong> — This can be used if server received an invalid response from the upstream server.</li>
</ul>
<br>

<h3 id="Versioning"><a href="#Versioning" class="headerlink" title="Versioning"></a>Versioning</h3><p>Versioning of APIs is very important. Many different companies use versions in different ways, some use versions as dates while some use versions as query parameters. I generally like to keep it prefixed to the resource. For instance —</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">/v1/products</span></span><br><span class="line"><span class="string">/v2/products</span></span><br></pre></td></tr></table></figure>

<p>I would also like to avoid using /v1.2/products as it implies the API would be frequently changing. Also dots (.) might not be easily visible in the URLs. So keep it simple.</p>
<p>It is always good practice to keep backward compatibility so that if you change the API version, consumers get enough time to move to the next version.</p>
<br>

<h3 id="Use-Pagination"><a href="#Use-Pagination" class="headerlink" title="Use Pagination"></a>Use Pagination</h3><p>Use of pagination is a must when you expose an API which might return huge data and if proper load balancing is not done, the a consumer might end up bringing down the service.</p>
<blockquote>
<p>We need to always keep in mind that the API design should be full proof and fool proof.</p>
</blockquote>
<p>Use of limit and offset is recommended here. For example, <code>/products?limit=25&amp;offset=50</code>. It is also advised to keep a default limit and default offset.</p>
<br>

<h3 id="Supported-Formats"><a href="#Supported-Formats" class="headerlink" title="Supported Formats"></a>Supported Formats</h3><p>If is also important to choose how your API responds. Most of the modern day applications should return JSON responses unless you have an legacy app which still needs to get XML response.</p>
<br>

<h3 id="Use-Proper-Error-Messages"><a href="#Use-Proper-Error-Messages" class="headerlink" title="Use Proper Error Messages"></a>Use Proper Error Messages</h3><p>It is always a good practice to keep set of error messages application sends and respond that with proper id. For example, if you use Facebook graph APIs, in case of errors, it returns message like this —</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;error&quot;:</span> &#123;</span><br><span class="line">    <span class="attr">&quot;message&quot;:</span> <span class="string">&quot;(#803) Some of the aliases you requested do not exist: products&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;OAuthException&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;code&quot;:</span> <span class="number">803</span>,</span><br><span class="line">    <span class="attr">&quot;fbtrace_id&quot;:</span> <span class="string">&quot;FOXX2AhLh80&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>I have also seen some examples in which people return URL with error message which tells you more about the error message and how to handle it as well.</p>
<br>

<h3 id="Use-of-Open-API-specifications"><a href="#Use-of-Open-API-specifications" class="headerlink" title="Use of Open API specifications"></a>Use of Open API specifications</h3><p>In order to keep all teams in your company abide to certain principles, use of OpenAPI Specification can be useful. Open API allows you to design your APIs first and share that with the consumers in easier manner.</p>
<br>


]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Seven Important API Design Tips</title>
    <url>/2019/API-Design/</url>
    <content><![CDATA[<p>In this post, we’ll sum up important API design lessons  — practical tips on technical implementation, and considerations on how to hide (or not hide) complexity when designing an API.</p>
<span id="more"></span> 

<blockquote>
<p>  Reference:</p>
<p>  <a href="https://nordicapis.com/7-api-design-lessons-world-tour-roundup/">7 Important API Design Lessons</a></p>
<p>  <a href="https://www.youtube.com/watch?v=Hc-lDZALeXQ">Talk: Introducing The API Lifecycle</a></p>
<p>  <a href="https://www.youtube.com/watch?v=fUVLhLKil44">Talk: Delivering API First - Is Your API A First Class Citizen?</a></p>
</blockquote>
<br>

<h3 id="Know-Your-API-Requirements"><a href="#Know-Your-API-Requirements" class="headerlink" title="Know Your API Requirements"></a>Know Your API Requirements</h3><p>API design should not begin with technical documentation, but should rather originate from your fundamental goals. Knowing what your API needs to accomplish is of the highest importance. This is defined in the <a href="https://nordicapis.com/api-lifecycle-analysis-stage-preparing-your-api-strategy-pre-launch/">analysis phase of the API lifecycle</a>.</p>
<p>As Phillipp Schöne from Axway pointed out, API designers should ask “how APIs can support the business function and not how they can support the needs of IT.”</p>
<br>

<h3 id="Think-of-APIs-as-Building-Blocks"><a href="#Think-of-APIs-as-Building-Blocks" class="headerlink" title="Think of APIs as Building Blocks"></a>Think of APIs as Building Blocks</h3><p>It’s important to remember the unique characteristics of APIs. As a consumer, tying into a service’s underlying data or functionality is inherently a unique process. Though comparable to SaaS products, Andreas Krohn from Dopter highlights two key differences:</p>
<p>The first is that APIs are building blocks and not finished products: “If somebody is using your API they are basically outsourcing a part of their business to you”.</p>
<p>His second lesson is that machines are not flexible. If a SaaS product changes, a person can adapt, but if an API changes, a machine is not as adaptable. This influences the design and the whole lifecycle of the API, and affects how we prepare for parameter changes and versioning.</p>
<br>

<h3 id="Understand-Your-Audience"><a href="#Understand-Your-Audience" class="headerlink" title="Understand Your Audience"></a>Understand Your Audience</h3><p>Developers are unique consumers in that they come with a handful of specific considerations. During his talk, Bill Doerrfeld reccomends API hosts to treat their platform as a product, with a primary concern being assembling a comprehensive demographic analysis. Knowing who your target developer is can refine both API functionality and segment future marketing attempts.</p>
<p>The need to understand your audience is just as applicable during an API’s Operations stage. If you are updating, versioning, or performing major redesigns on an existing API, you need to carefully respond to the feedback from your users to make the new version as good as possible.</p>
<p>Marjukka Niinioja, Senior Consultant and Manager at PlanMill shares her experience with leveraging user feedback during a major redesign: developing PlanMill’s new RESTful API, UI, and back-end architecture.</p>
<p>PlanMill payed close attention to the feedback they were receiving internally, noticing three main recurring points:</p>
<ul>
<li>The API was too complex for the developers to use.</li>
<li>The documentation was not sufficient.</li>
<li>The error handling needed work.</li>
</ul>
<p>Using this feedback, and by testing and consuming the API themselves, the PlanMill team was able to hone in on important aspects to consider during redeployment. The takeaway is that if you are redesigning an API, you are poised to release killer API improvements — as you already have real world data on how API functionality is used, which can be repurposed to improve efficiency and overall API user experience.</p>
<br>

<h3 id="Decrease-Confusion-For-The-User-Let-Provider-Handle-Complexity"><a href="#Decrease-Confusion-For-The-User-Let-Provider-Handle-Complexity" class="headerlink" title="Decrease Confusion For The User, Let Provider Handle Complexity"></a>Decrease Confusion For The User, Let Provider Handle Complexity</h3><p>Who pays the price for complexity? Nordic APIs veteran Ronnie Mitra of API Academy argues that complexity is necessary — what should be avoided instead is confusion. Mitra contends “it is a designers job to reduce confusion and embrace complexity in their business domain.”</p>
<p>There has been a move toward simpler products and simpler interface designs. Mitra, an expert in developer experience and API design, advocates for smartly designed software and APIs that retain simplicity but also cater to complex requirements. Quoting John Maeda’s Laws of Simplicity, Mitra notes that “Simplicity is about subtracting the obvious and adding the meaningful.”</p>
<p>A steering wheel in a F1 car is very complex compared to the steering wheel of a normal car, “designed and optimised for its user and the situation”. Ronnie makes a great point that “every design decision is a decision of if you [as an API provider] or client app developers will pay the price of complexity”. As an example, OAuth is complex to implement by the service provider but easy to use by the client developer. We cannot avoid complexity, but we can architect our APIs so that the user-facing side is deceptively simple.</p>
<p>Ross Garrett from Axway also talks about what applying an API-first strategy means for enterprise organizations. In dealing with legacy systems, he notes that a missmash of tangled infrastructure can be masked by using proper API management tactics.</p>
<blockquote>
<p>“Your old architecture [may not have] useful APIs, or may be older SOAP services that don’t perform well in the context of mobility or cloud integration. Some legacy things need to remain, but API management can extend and reuse by translating all old interfaces”</p>
</blockquote>
<p>What’s important is having a clean business appearance for the end user.</p>
<br>

<h3 id="Use-Hypermedia-For-Evolvability"><a href="#Use-Hypermedia-For-Evolvability" class="headerlink" title="Use Hypermedia For Evolvability"></a>Use Hypermedia For Evolvability</h3><p>It is impossible to talk about API design without mentioning Hypermedia, a subject that came up in several presentations during the Nordic APIs World Tour 2015. Pedro Felix of Lisbon Polytechnic Institute, offers a deep dive into HTTP. He summarizes his presentation about API design this way:</p>
<blockquote>
<p>“if you have a problem, keep calm and look for an HTTP RFC”</p>
</blockquote>
<p>Pedro considers hypermedia as the key factor for evolvability, allowing API providers to react to new business requirements quickly without breaking client applications. Related to Mitra’s theory on the distribution of complexity, using hypermedia means more initial complexity for client app developers, but an overall reduced complexity considering the ease of future changes.</p>
<br>

<h3 id="Learn-From-Real-World-Information-Design"><a href="#Learn-From-Real-World-Information-Design" class="headerlink" title="Learn From Real World Information Design"></a>Learn From Real World Information Design</h3><p>Brian Mulloy from Apigee demoes a hypermedia API for the Internet of Things. By using hypermedia it is easy to introduce new devices into the IoT since all possible states, actions and feeds are described in the API itself.</p>
<p>Mulloy describes API design for the Internet of Things as using information design for physical objects. He compared this to the early days of mass car production in his hometown Detroit. Suddenly the city had lots of cars, but infrastructure was not prepared for a large automobile influx. The resulting confusion lead to chaos and even a large number of traffic related deaths.</p>
<p>The solution was to use information design that resulted in standard designs used all over the world today. Pedestrian crossings, traffic lights, stop signs, and lane markers make it clear how to behave in traffic. Akin to the early days of cars, we are still working on how to organize and design today’s APIs for the IoT.</p>
<br>

<h3 id="API-Design-Needs-To-Convince-the-Architect"><a href="#API-Design-Needs-To-Convince-the-Architect" class="headerlink" title="API Design Needs To Convince the Architect"></a>API Design Needs To Convince the Architect</h3><p>Having a shared vision within an organization is key for API interconnectivity to be accepted. To help convince API naysayers, whether they be architects or engineers, in his talk, Adam Duvander of Orchestrate walks through four ways API providers can frame their API product to foster confident adoption. These factors should be considered when designing an API in order to respond to common stigma associated with API integrations.</p>
<ul>
<li><p>The architect wants control: Accustomed to traditional methods of infrastructure — data storage on local servers — the architect may be opposed to cloud operations, desiring to ‘touch’ the software. To workaround this stigma, API providers can offer the ability to download and store data sets locally, or even offer an on premise, dedicated, managed option the API.</p>
</li>
<li><p>The architect wants zero downtime: To foster reliability in the service, having transparent developer-facing logs that communicate API uptime is critical. Quality examples are the Stripe system status and live twitter feed, which allow transparent and helpful status updates on downtime. Others to model are Facebook, Twilio, and Github.</p>
</li>
<li><p>The architect wants to see responsibility: API systems need to be designed as secure systems using modern approaches. From a process oriented perspective, DuVander notes that providers need to be very clear with what types of data they are able to access. Share best practices with developers. A good model is Bit.ly — they make licensing clear, sharing security best practices on a dedicated channel.</p>
</li>
<li><p>The architect requires an integration that guarantees longevity: With public APIs falling off the map from both small and large players, architects have a good reason to be skeptical. DuVander recommends that API providers clearly understand and communicate their monetization model, and demonstrate to consumers that their situation guarantees longevity. According to Duvander, when it comes down to it, “worrying about API longevity is just another way to ask for more control”</p>
</li>
</ul>
<br>

<h3 id="Summarizing-API-Design-Points"><a href="#Summarizing-API-Design-Points" class="headerlink" title="Summarizing API Design Points"></a>Summarizing API Design Points</h3><p>As an API has two users — the human developer and the machine client — designing can be a bit tricky. By analyzing feedback from developers we can design better APIs for them, and by using proper techniques we can assure that APIs are designed for efficient machine consumption, handling most of the complexity, and simplify processes for your client application developers. Above all, do not forget that the API design should serve your overall business requirements.</p>
<br>


<br>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Isolate Vocals with Adobe Audition</title>
    <url>/2018/Audition/</url>
    <content><![CDATA[<p><strong>Adobe Audition CC</strong> is a powerful tool for audio processing. Today I’m going to introduce how to remove vocals using Audition. Note that this method isn’t perfect; In order to get the perfect result, we need to use Audition’s other <a href="https://helpx.adobe.com/audition/using/adding-third-party-plug-ins.html">VST plugins</a>. The method I’m introducing here today is called <strong>Central Channel Extracting (CCE)</strong>.</p>
<span id="more"></span> 

<p>The logic behind CCE is that, the human voice’s vocal range is generally in the midrange, so by removing the midrange part, we could isolate the vocals from the tracks.</p>
<br>

<h2 id="Central-Channel-Extractor"><a href="#Central-Channel-Extractor" class="headerlink" title="Central Channel Extractor"></a>Central Channel Extractor</h2><p>First we choose an audio file and open it in Audition’s interface. </p>
<p><img data-src="/images/posts/181228-1.png"></p>
<p>Then we create a Multitrack session. It’s Okay to just use the default values.</p>
<p><img data-src="/images/posts/181228-2.png"></p>
<p>Then we drag the audio file to track 1 &amp; 2.</p>
<p><img data-src="/images/posts/181228-3.png"></p>
<p>Now we select Track 1, and in the <strong>Effects Rack</strong> on the left, we choose Stereo Imagery -&gt; Central Channel Extractor.</p>
<p><img data-src="/images/posts/181228-4.png"></p>
<p>In the settings here, we choose Vocal Remove, and in the Frequency Range, we could choose either Male Voice or Female Voice depending on the audio file.</p>
<p><img data-src="/images/posts/181228-5.png"></p>
<p>Then we are done with Track 1. The reason to create a multitrack session instead of editing directly on the original audio file is that, <strong>CCE can hurt the quality of the audio file</strong>, and sometimes the lowrange part will be blurry and muffuled. So we add one more track and do a little bit of the repair work.</p>
<br>

<h2 id="Little-Repair-Work"><a href="#Little-Repair-Work" class="headerlink" title="Little Repair Work"></a>Little Repair Work</h2><p>If your audio file is a selection form an opera, then we need other methods to reapir. But for most of the rock and pop songs, this should render a satisfactory result. Since most of the songs use <strong>drum sets</strong> heavily, and they are often in the lowrange, so we simply filter the original audio file, and add the lowrange drum beats, so then the sound won’t be that “broken”.</p>
<br>

<p>Now let us move on to Track 2. In the <strong>Effects Rack</strong> on the left, we choose Filter and EQ -&gt; FFT Filter.</p>
<p><img data-src="/images/posts/181228-6.png"></p>
<p>In the settings here, we mute the waves after 200Hz (drag the line all the way down).</p>
<p><img data-src="/images/posts/181228-7.png"></p>
<p>And now we are done with the repair work. To get the edited audio file, we go to File -&gt; Export -&gt; Multitrack Mixdown -&gt; Entire Session, and then save the edited file.</p>
<p><img data-src="/images/posts/181228-8.png"></p>
<p>Again, the methods shown above is merely a simplified way of removing vocals. To get perfect results, we might need other Audition’s plugins, or softwares, such as <a href="https://www.izotope.com/content/izotope/en/products/ozone.html">iZotope’s Ozone 8</a>, or <a href="https://www.antarestech.com/product/soundsoap-p-5/">Antares’ Soundsoap+ 5</a>.</p>
<br>

]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>Customize Mac&#39;s Terminal</title>
    <url>/2018/Customize-Terminal/</url>
    <content><![CDATA[<p>The standard Mac’s terminal appearance is just some boring black texts on a white background, like the one shown below:</p>
<p><img data-src="/images/posts/181210-1.png" alt="Normal Terminal"></p>
<p>Even though Apple includes a few nice themes, but to really makes your terminal unique, certain customization is needed. In this post we’re going to talk about some tips for customization.</p>
<blockquote>
<p>  Reference: <a href="https://www.cnblogs.com/archoncap/p/5031496.html">Shell Color Codes</a></p>
</blockquote>
<span id="more"></span> 

<br>

<h2 id="First-Step"><a href="#First-Step" class="headerlink" title="First Step"></a>First Step</h2><p>We first go to Terminal -&gt; Preferences, and choose <strong>Pro</strong> under the <strong>Profiles</strong> tab. This will render a half-transparent black background. After that, we can adjust the <strong>ANSI colors</strong> as marked below:</p>
<p><img data-src="/images/posts/181210-2.jpg" alt="ANSI colors"></p>
<p>So now we have finished out first step. The purpose of adjusting ANSI colors will be obvious as we proceed.<br><br></p>
<h2 id="Bash-Profile"><a href="#Bash-Profile" class="headerlink" title="Bash Profile"></a>Bash Profile</h2><p>Now we type the commands below in Terminal to get <strong>.bash_profile</strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">~</span> </span><br><span class="line"><span class="string">open</span> <span class="string">.bash_profile</span></span><br></pre></td></tr></table></figure>

<p>That will open the bash profile in TextEdit. Now we add these two lines:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> CLICOLOR=1</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LSCOLORS=gxfxaxdxcxegedabagacad</span><br></pre></td></tr></table></figure>

<p>Then save and quit. After we restart terminal, we could see that the folders are in light blue. </p>
<p>In the second line, the bunch of charaters after the “=” sign means the color assignment. As we can see, there’re 22 characters, i.e. 11 pairs (for 11 types of files). The first character in each pair represents the foreground color, while the second represents the background color. Below is the listing:</p>
<br>

<table>
<thead>
<tr>
<th>Char</th>
<th>Color</th>
</tr>
</thead>
<tbody><tr>
<td>a</td>
<td>black</td>
</tr>
<tr>
<td>b</td>
<td>red</td>
</tr>
<tr>
<td>c</td>
<td>green</td>
</tr>
<tr>
<td>d</td>
<td>brown</td>
</tr>
<tr>
<td>e</td>
<td>blue</td>
</tr>
<tr>
<td>f</td>
<td>magenta</td>
</tr>
<tr>
<td>g</td>
<td>cyan</td>
</tr>
<tr>
<td>h</td>
<td>light grey</td>
</tr>
</tbody></table>
<ul>
<li>| -<br>A    |   bold black, usually shows up as dark grey<br>B    |   bold red<br>C     |  bold green<br>D     |  bold brown, usually shows up as yellow<br>E   |    bold blue<br>F    |   bold magenta<br>G    |   bold cyan<br>H    |   bold light grey; looks like bright white<br>x     |  default foreground or background</li>
</ul>
<br>

<h2 id="Terminal-Prompt"><a href="#Terminal-Prompt" class="headerlink" title="Terminal Prompt"></a>Terminal Prompt</h2><p>Our last step is to customize the Terminal prompt. To edit your Mac’s name, we go to <strong>System Preferences -&gt; Sharing</strong>. Then we open <strong>.bash_profile</strong>, and add these two lines:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> TERM=<span class="string">&quot;xterm-color&quot;</span></span><br><span class="line"></span><br><span class="line">PS1=<span class="string">&#x27;\[\e[0;32m\]\u\[\e[0;32m\]:\[\e[0;33m\]\W\[\e[0m\] \[\e[0;32m\]\h\[\e[0;33m\]\$\[\e[0m\] &#x27;</span> </span><br></pre></td></tr></table></figure>

<p>And now our customization is done. Let us first use a table to see what the second line means:</p>
<table>
<thead>
<tr>
<th>Char</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><code>\u</code></td>
<td>Current username</td>
</tr>
<tr>
<td><code>\!</code></td>
<td>History command’s number</td>
</tr>
<tr>
<td><code>\h</code></td>
<td>Host</td>
</tr>
<tr>
<td><code>\#</code></td>
<td>Current command’s number</td>
</tr>
<tr>
<td><code>\$</code></td>
<td>Prompt (root is <code>#</code>)</td>
</tr>
<tr>
<td><code>\d</code></td>
<td>Date</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>Time</td>
</tr>
<tr>
<td><code>\s</code></td>
<td>Shell’s name</td>
</tr>
<tr>
<td><code>\w</code></td>
<td>Current dir.’s path</td>
</tr>
<tr>
<td><code>\W</code></td>
<td>Current dir’s name</td>
</tr>
<tr>
<td><code>\nnn</code></td>
<td>nnn in octal</td>
</tr>
</tbody></table>
<br>

<p><strong>And the ANSI color codes</strong>:</p>
<table>
<thead>
<tr>
<th>Forground</th>
<th>Background</th>
<th>Color</th>
</tr>
</thead>
<tbody><tr>
<td>30</td>
<td>40</td>
<td>Black</td>
</tr>
<tr>
<td>31</td>
<td>41</td>
<td>Red</td>
</tr>
<tr>
<td>32</td>
<td>42</td>
<td>Green</td>
</tr>
<tr>
<td>33</td>
<td>43</td>
<td>Yellow</td>
</tr>
<tr>
<td>34</td>
<td>44</td>
<td>Blue</td>
</tr>
<tr>
<td>35</td>
<td>45</td>
<td>Pink</td>
</tr>
<tr>
<td>36</td>
<td>46</td>
<td>Skyblue</td>
</tr>
<tr>
<td>37</td>
<td>47</td>
<td>White</td>
</tr>
</tbody></table>
<br>

<p><strong>And the numbers before the <code>;</code></strong>:</p>
<table>
<thead>
<tr>
<th>Char</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>off</td>
</tr>
<tr>
<td>1</td>
<td>Highlight</td>
</tr>
<tr>
<td>4</td>
<td>Underline</td>
</tr>
<tr>
<td>5</td>
<td>Blink</td>
</tr>
<tr>
<td>8</td>
<td>Invisible</td>
</tr>
</tbody></table>
<br>

<p>Now let’s look at the second line again. Basically it redefines the color of the terminal prompt. I mentioned adjusting the ANSI colors in Terminal’s preference settings, since changing that will change the appearance of the colors. The effect is shown below:</p>
<p><img data-src="/images/posts/181210-3.png" alt="Effects"></p>
<br>

<br>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>HAProxy &amp; Load Balancing</title>
    <url>/2018/Load-Balancer/</url>
    <content><![CDATA[<p><strong>HAProxy</strong> is a popular open source software TCP/HTTP Load Balancer and proxying solution which can be run on Linux, Solaris, and FreeBSD. Its most common use is to improve the performance and reliability of a server environment by distributing the workload across multiple servers (e.g. web, application, database). It is used in many high-profile environments, including: GitHub, Imgur, Instagram, and Twitter.</p>
<p><strong>Load Balancers</strong> allow us to <strong>split incoming traffic between multiple backend servers</strong>. Often this is used to distribute HTTP requests among a group of application servers to increase overall capacity. This is a common way to scale the application.</p>
<span id="more"></span> 

<p>In this post, we will go through what HAProxy is, basic load-balancing terminology, and examples of how it might be used to improve the performance and reliability of the server environment.</p>
<blockquote>
<p><strong>Reference:</strong></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-haproxy-to-set-up-mysql-load-balancing--3">Use HAProxy to Set Up MySQL Load Balancing</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-haproxy-as-a-layer-4-load-balancer-for-wordpress-application-servers-on-ubuntu-14-04">Use HAProxy As A Layer 4 Load Balancer</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts">HAProxy and Load Balancing</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-highly-available-haproxy-servers-with-keepalived-and-floating-ips-on-ubuntu-14-04">HAProxy with <strong>Keepalived and Floating IP</strong></a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/5-digitalocean-load-balancer-use-cases">Load Balancer Use Cases</a></p>
</blockquote>
<br>

<hr>
<h2 id="HAProxy-Terminology"><a href="#HAProxy-Terminology" class="headerlink" title="HAProxy Terminology"></a>HAProxy Terminology</h2><p>There are many terms and concepts that are important when discussing load balancing and proxying. We will go over commonly used terms in the following sub-sections.</p>
<p>Before we get into the basic types of load balancing, we will talk about ACLs, backends, and frontends.</p>
<br>

<h3 id="Access-Control-List-ACL"><a href="#Access-Control-List-ACL" class="headerlink" title="Access Control List (ACL)"></a>Access Control List (ACL)</h3><p>In relation to load balancing, ACLs are used to test some condition and perform an action (e.g. select a server, or block a request) based on the test result. Use of ACLs allows flexible network traffic forwarding based on a variety of factors like pattern-matching and the number of connections to a backend, for example.</p>
<p>Example of an ACL:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">acl</span> <span class="string">url_blog</span> <span class="string">path_beg</span> <span class="string">/blog</span></span><br></pre></td></tr></table></figure>

<p>This ACL is matched if the path of a user’s request begins with /blog. This would match a request of <a href="http://domain/blog/blog-entry-1">http://domain/blog/blog-entry-1</a>, for example.</p>
<br>

<h3 id="Backend"><a href="#Backend" class="headerlink" title="Backend"></a>Backend</h3><p>A backend is a set of servers that receives forwarded requests. Backends are defined in the backend section of the HAProxy configuration. In its most basic form, a backend can be defined by:</p>
<ul>
<li><p>which load balance algorithm to use</p>
</li>
<li><p>a list of servers and ports</p>
</li>
</ul>
<p>A backend can contain one or many servers in it–generally speaking, adding more servers to your backend will increase your potential load capacity by spreading the load over multiple servers. Increase reliability is also achieved through this manner, in case some of your backend servers become unavailable.</p>
<p>Here is an example of a two backend configuration, web-backend and blog-backend with two web servers in each, listening on port 80:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">backend</span> <span class="string">web-backend</span></span><br><span class="line">   <span class="string">balance</span> <span class="string">roundrobin</span></span><br><span class="line">   <span class="string">server</span> <span class="string">web1</span> <span class="string">web1.yourdomain.com:80</span> <span class="string">check</span></span><br><span class="line">   <span class="string">server</span> <span class="string">web2</span> <span class="string">web2.yourdomain.com:80</span> <span class="string">check</span></span><br><span class="line"></span><br><span class="line"><span class="string">backend</span> <span class="string">blog-backend</span></span><br><span class="line">   <span class="string">balance</span> <span class="string">roundrobin</span></span><br><span class="line">   <span class="string">mode</span> <span class="string">http</span></span><br><span class="line">   <span class="string">server</span> <span class="string">blog1</span> <span class="string">blog1.yourdomain.com:80</span> <span class="string">check</span></span><br><span class="line">   <span class="string">server</span> <span class="string">blog1</span> <span class="string">blog1.yourdomain.com:80</span> <span class="string">check</span></span><br></pre></td></tr></table></figure>

<p>The <code>balance roundrobin</code> line specifies the load balancing algorithm, <code>mode http</code> specifies that layer 7 proxying will be used, which is explained in Types of Load Balancing section.</p>
<p>The check option at the end of the server directives specifies that health checks should be performed on those backend servers.</p>
<br>

<h3 id="Frontend"><a href="#Frontend" class="headerlink" title="Frontend"></a>Frontend</h3><p>A frontend defines how requests should be forwarded to backends. Frontends are defined in the frontend section of the HAProxy configuration. Their definitions are composed of the following components:</p>
<ul>
<li>a set of IP addresses and a port (e.g. 10.1.1.7:80, *:443, etc.)</li>
<li>ACLs</li>
<li>use_backend rules, which define which backends to use depending on which ACL conditions are matched, and/or a default_backend rule that handles every other case</li>
</ul>
<p>A frontend can be configured to various types of network traffic, as explained in the next section.</p>
<br>

<hr>
<h2 id="Types-of-Load-Balancing"><a href="#Types-of-Load-Balancing" class="headerlink" title="Types of Load Balancing"></a>Types of Load Balancing</h2><p>Now that we have an understanding of the basic components that are used in load balancing, let’s get into the basic types of load balancing.</p>
<br>

<h3 id="No-Load-Balancing"><a href="#No-Load-Balancing" class="headerlink" title="No Load Balancing"></a>No Load Balancing</h3><p>A simple web application environment with no load balancing might look like the following:</p>
<p><img data-src="/img/181122-1.png" alt="01"></p>
<p>In this example, the user connects directly to your web server, at <code>yourdomain.com</code> and there is no load balancing. If your single web server goes down, the user will no longer be able to access your web server. Additionally, if many users are trying to access your server simultaneously and it is unable to handle the load, they may have a slow experience or they may not be able to connect at all.</p>
<br>

<h3 id="Layer-4-Load-Balancing"><a href="#Layer-4-Load-Balancing" class="headerlink" title="Layer 4 Load Balancing"></a>Layer 4 Load Balancing</h3><p>The simplest way to load balance network traffic to multiple servers is to use layer 4 (transport layer) load balancing. Load balancing this way will forward user traffic based on IP range and port (i.e. if a request comes in for <a href="http://yourdomain.com/anything">http://yourdomain.com/anything</a>, the traffic will be forwarded to the backend that handles all the requests for <code>yourdomain.com</code> on port 80). For more details on layer 4, check out the TCP subsection of our Introduction to Networking.</p>
<br>

<p>Here is a diagram of a simple example of layer 4 load balancing:</p>
<p><img data-src="/img/181122-2.png" alt="02"></p>
<p>The user accesses the load balancer, which forwards the user’s request to the web-backend group of backend servers. Whichever backend server is selected will respond directly to the user’s request. Generally, all of the servers in the web-backend should be serving identical content–otherwise the user might receive inconsistent content. Note that both web servers connect to the same database server.</p>
<br>

<h3 id="Layer-7-Load-Balancing"><a href="#Layer-7-Load-Balancing" class="headerlink" title="Layer 7 Load Balancing"></a>Layer 7 Load Balancing</h3><p>Another, more complex way to load balance network traffic is to use layer 7 (application layer) load balancing. Using layer 7 allows the load balancer to forward requests to different backend servers based on the content of the user’s request. This mode of load balancing allows you to run multiple web application servers under the same domain and port. For more details on layer 7, check out the HTTP subsection of our Introduction to Networking.</p>
<br>

<p>Here is a diagram of a simple example of layer 7 load balancing:</p>
<p><img data-src="/img/181122-3.png" alt="03"></p>
<p>In this example, if a user requests yourdomain.com/blog, they are forwarded to the blog backend, which is a set of servers that run a blog application. Other requests are forwarded to web-backend, which might be running another application. Both backends use the same database server, in this example.</p>
<p>A snippet of the example frontend configuration would look like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">frontend</span> <span class="string">http</span></span><br><span class="line">  <span class="string">bind</span> <span class="string">*:80</span></span><br><span class="line">  <span class="string">mode</span> <span class="string">http</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># matches a request if the path of the user’s request begins with /blog</span></span><br><span class="line">  <span class="string">acl</span> <span class="string">url_blog</span> <span class="string">path_beg</span> <span class="string">/blog</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># uses the ACL to proxy the traffic to blog-backend</span></span><br><span class="line">  <span class="string">use_backend</span> <span class="string">blog-backend</span> <span class="string">if</span> <span class="string">url_blog</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># specifies that all other traffic will be forwarded to web-backend</span></span><br><span class="line">  <span class="string">default_backend</span> <span class="string">web-backend</span></span><br></pre></td></tr></table></figure>

<p>This configures a frontend named <code>http</code>, which handles all incoming traffic on port 80.</p>
<br>

<hr>
<h2 id="Load-Balancing-Algorithms"><a href="#Load-Balancing-Algorithms" class="headerlink" title="Load Balancing Algorithms"></a>Load Balancing Algorithms</h2><p>The load balancing algorithm that is used determines which server, in a backend, will be selected when load balancing. HAProxy offers several options for algorithms. In addition to the load balancing algorithm, servers can be assigned a weight parameter to manipulate how frequently the server is selected, compared to other servers.</p>
<p>Because HAProxy provides so many load balancing algorithms, we will only describe a few of them here. See the HAProxy Configuration Manual for a complete list of algorithms.</p>
<p>A few of the commonly used algorithms are as follows:</p>
<br>

<h3 id="roundrobin"><a href="#roundrobin" class="headerlink" title="roundrobin"></a>roundrobin</h3><p>Round Robin selects servers in turns. This is the default algorithm.</p>
<br>

<h3 id="leastconn"><a href="#leastconn" class="headerlink" title="leastconn"></a>leastconn</h3><p>Selects the server with the least number of connections–it is recommended for longer sessions. Servers in the same backend are also rotated in a round-robin fashion.</p>
<br>

<h3 id="source"><a href="#source" class="headerlink" title="source"></a>source</h3><p>This selects which server to use based on a hash of the source IP i.e. your user’s IP address. This is one method to ensure that a user will connect to the same server.</p>
<br>

<hr>
<h2 id="Sticky-Sessions"><a href="#Sticky-Sessions" class="headerlink" title="Sticky Sessions"></a>Sticky Sessions</h2><p>Some applications require that a user continues to connect to the same backend server. This persistence is achieved through sticky sessions, using the <code>appsession</code> parameter in the backend that requires it.</p>
<br>

<hr>
<h2 id="Health-Check"><a href="#Health-Check" class="headerlink" title="Health Check"></a>Health Check</h2><p>HAProxy uses health checks to determine if a backend server is available to process requests. This avoids having to manually remove a server from the backend if it becomes unavailable. The default health check is to try to establish a TCP connection to the server i.e. it checks if the backend server is listening on the configured IP address and port.</p>
<p>If a server fails a health check, and therefore is unable to serve requests, it is automatically disabled in the backend i.e. traffic will not be forwarded to it until it becomes healthy again. If all servers in a backend fail, the service will become unavailable until at least one of those backend servers becomes healthy again.</p>
<p>For certain types of backends, like database servers in certain situations, the default health check is insufficient to determine whether a server is still healthy.</p>
<br>

<hr>
<h2 id="Load-Balancer-Use-Cases"><a href="#Load-Balancer-Use-Cases" class="headerlink" title="Load Balancer Use Cases"></a>Load Balancer Use Cases</h2><p>Although Load Balancers (LB) are most often considered when <strong>scale</strong> is needed, we’ve shown that there are many other cases where it’s useful to have the ability to distribute or shuffle traffic among various backend servers. Whether it’s for <strong>high availability</strong> or leveraging various <strong>deployment</strong> techniques, Load Balancers are a flexible and powerful tool in your production infrastructure.</p>
<br>

<h3 id="Scale"><a href="#Scale" class="headerlink" title="Scale"></a>Scale</h3><p>As mentioned above, scaling traffic is the most common use case for a Load Balancer. Often times scaling is discussed in vertical and horizontal terms. Vertical scaling is basically moving your application to a more powerful server to meet increasing performance demands. Horizontal scaling is distributing your traffic among multiple servers to share the load. Load Balancers facilitate horizontal scaling.</p>
<p><img data-src="/img/181122-5.png" alt="05"></p>
<p>Load Balancers allow you to distribute load via two different algorithms: round robin and least connections. Round robin will send requests to each available backend server in turn, whereas least connections will send requests to the server with the fewest connections. Round robin is by far the most frequently used scheme for load balancing, but if you have an application that keeps connections open for a long time, least connections may do a better job of preventing any one server from becoming overloaded.</p>
<p>A side benefit of horizontal scaling with load balancers is the chance to increase your service’s reliability. We’ll talk about that next.</p>
<br>

<h3 id="HA"><a href="#HA" class="headerlink" title="HA"></a>HA</h3><p>High availability is a term that describes efforts to decrease downtime and increase system reliability. This is often addressed by improving performance and eliminating single points of failure.</p>
<p>A Load Balancer can increase availability by performing repeated health checks on your backend servers and automatically removing failed servers from the pool.</p>
<p><img data-src="/img/181122-6.png" alt="06"></p>
<p>By default, the Load Balancer will fetch a web page every ten seconds to make sure the server is responding properly. If this fails three times in a row, the server will be removed until the problem is resolved.</p>
<br>

<h3 id="Blue-Green-Deployments"><a href="#Blue-Green-Deployments" class="headerlink" title="Blue / Green Deployments"></a>Blue / Green Deployments</h3><p>Blue/green deployments refer to a technique where you deploy your new software on production infrastructure, test it thoroughly, then switch traffic over to it only after verifying that everything is working as you expect. If the deploy ends up failing in new and unexpected ways, you can easily recover by switching the Load Balancer back to the old version.</p>
<p><img data-src="181122-7.png" alt="07"></p>
<br>

<h3 id="Canary-Deployments"><a href="#Canary-Deployments" class="headerlink" title="Canary Deployments"></a>Canary Deployments</h3><p>Canary deployments are a way of testing a new version of your application on a subset of users before updating your entire pool of application servers. With Load Balancers you could do this by, for instance, adding just one canary server to your Load Balancer’s pool. If you don’t see any increase in errors or other undesirable results through your logging and monitoring infrastructure, you can then proceed to deploy updates to the rest of the pool.</p>
<p>You’ll want to turn on sticky sessions for this use case, so that your users aren’t bounced between different versions of your application when making new connections through the Load Balancer. Sticky sessions will use a cookie to ensure that future connections from a particular browser will continue to be routed to the same server. </p>
<br>

<h3 id="A-B-Deployment"><a href="#A-B-Deployment" class="headerlink" title="A/B Deployment"></a>A/B Deployment</h3><p>A/B deployments are functionally similar to canary deployments, but the purpose is different. A/B deployments test a new feature on a portion of your users in order to gather information that will inform your marketing and development efforts. You’ll need to do this in conjunction with your existing monitoring and logging infrastructure to get back meaningful results.</p>
<br>

<hr>
<h2 id="Other-Solutions"><a href="#Other-Solutions" class="headerlink" title="Other Solutions"></a>Other Solutions</h2><p>If you feel like HAProxy might be too complex for your needs, the following solutions may be a better fit:</p>
<ul>
<li><p>Linux Virtual Servers (LVS) - A simple, fast layer 4 load balancer included in many Linux distributions</p>
</li>
<li><p>Nginx - A fast and reliable web server that can also be used for proxy and load-balancing purposes. Nginx is often used in conjunction with HAProxy for its caching and compression capabilities</p>
</li>
</ul>
<br>

<hr>
<h2 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h2><p>The layer 4 and 7 load balancing setups described before both use a load balancer to direct traffic to one of many backend servers. However, your load balancer is a single point of failure in these setups; if it goes down or gets overwhelmed with requests, it can cause high latency or downtime for your service.</p>
<p>A high availability (HA) setup is an infrastructure without a single point of failure. It prevents a single server failure from being a downtime event by adding redundancy to every layer of your architecture. A load balancer facilitates redundancy for the backend layer (web/app servers), but for a true high availability setup, you need to have redundant load balancers as well.</p>
<br>

<p>Here is a diagram of a basic high availability setup:</p>
<p><img data-src="/img/181122-4.gif" alt="04"></p>
<p>In this example, you have multiple load balancers (one active and one or more passive) behind a static IP address that can be remapped from one server to another. When a user accesses your website, the request goes through the external IP address to the active load balancer. If that load balancer fails, your failover mechanism will detect it and automatically reassign the IP address to one of the passive servers, and there are a number of different ways to implement an active/passive HA setup. </p>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx as Web Server &amp; Reverse Proxy for Apache with SSL</title>
    <url>/2018/Nginx-Config/</url>
    <content><![CDATA[<p>Apache and Nginx are two popular open-source web servers often used with <strong>PHP</strong>. <u>It can be useful to run both of them on the same virtual machine when hosting multiple websites which have varied requirements</u>. The general solution for running two web servers on a single system is to either <u>use multiple IP addresses</u> or <u>use different port numbers</u>.</p>
<p>Servers which have both IPv4 and IPv6 addresses can be configured to serve Apache sites on one protocol and Nginx sites on the other, but this isn’t currently practical, as IPv6 adoption by ISPs is still not widespread. Having a different port number for the second web server is another solution, but sharing URLs with port numbers isn’t always ideal.</p>
<p>In this post, we will configure Nginx as <strong>both a web server and as a reverse proxy for Apache</strong> – all on a single server.</p>
<span id="more"></span> 

<br>

<p>Depending on the web application, code changes might be required to keep Apache reverse-proxy-aware, especially when SSL sites are configured. To avoid this, we will install an Apache module called <code>mod_rpaf</code> which rewrites certain environment variables so it appears that Apache is directly handling requests from web clients.</p>
<p>We will host four domain names on one server. Two will be served by Nginx: <code>example.com</code> (the default virtual host) and <code>sample.org</code>. The remaining two, <code>foobar.net</code> and <code>test.io</code>, will be served by Apache. We’ll also configure Apache to serve PHP applications using <code>PHP-FPM</code>, which offers better performance over <code>mod_php</code>.</p>
<br>

<blockquote>
<p>  Reference:</p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-server-blocks-virtual-hosts-on-ubuntu-16-04">Set Up Nginx Server Blocks</a></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/nginx-essentials-installation-and-configuration-troubleshooting">Nginx Troubleshoot</a></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-the-nginx-web-server-on-a-virtual-private-server">Configure Nginx</a></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-18-04-server">Configure Nginx as Server &amp; Reverse Proxy</a></p>
<p>  <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-apache-virtual-hosts-on-ubuntu-16-04">Set Up Apache Virtual Host</a></p>
</blockquote>
<br>

<hr>
<h2 id="Config-Apache-amp-PHP-FPM"><a href="#Config-Apache-amp-PHP-FPM" class="headerlink" title="Config Apache &amp; PHP-FPM"></a>Config Apache &amp; PHP-FPM</h2><p>First:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt install apache2 php-fpm</span><br><span class="line"></span><br><span class="line">wget https://mirrors.edge.kernel.org/ubuntu/pool/multiverse/liba \</span><br><span class="line">/libapache-mod-fastcgi/libapache2-mod-fastcgi_2.4.7~0910052141-1.2_amd64.deb</span><br><span class="line"></span><br><span class="line">sudo dpkg -i libapache2-mod-fastcgi_2.4.7~0910052141-1.2_amd64.deb</span><br></pre></td></tr></table></figure>

<p>In this step we will change Apache’s port number to 8080 and configure it to work with <code>PHP-FPM</code> using the <code>mod_fastcgi</code> module. Rename Apache’s <code>ports.conf</code> configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">mv</span> <span class="string">/etc/apache2/ports.conf</span> <span class="string">/etc/apache2/ports.conf.default</span></span><br></pre></td></tr></table></figure>

<p>Create a new <code>ports.conf</code> file with the port set to 8080:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">&quot;Listen 8080&quot;</span> <span class="string">|</span> <span class="string">sudo</span> <span class="string">tee</span> <span class="string">/etc/apache2/ports.conf</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>Note: </p>
<p><em>Web servers are generally set to listen on <code>127.0.0.1:8080</code> when configuring a reverse proxy but doing so would set the value of PHP’s environment variable <code>SERVER_ADDR</code> to the loopback IP address instead of the server’s public IP. Our aim is to set up Apache in such a way that its websites do not see a reverse proxy in front of it. So, we will configure it to listen on 8080 on all IP addresses.</em></p>
</blockquote>
<br>

<p>Next we’ll create a virtual host file for Apache. The <code>&lt;VirtualHost&gt;</code> directive in this file will be set to serve sites only on port 8080.</p>
<p>Disable the default virtual host:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2dissite</span> <span class="number">000</span><span class="string">-default</span></span><br></pre></td></tr></table></figure>

<p>Then create a new virtual host file, using the existing default site:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">cp</span> <span class="string">/etc/apache2/sites-available/000-default.conf</span> <span class="string">\</span></span><br><span class="line"><span class="string">/etc/apache2/sites-available/001-default.conf</span></span><br></pre></td></tr></table></figure>

<p>Now open the new configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/sites-available/001-default.conf</span></span><br></pre></td></tr></table></figure>

<p>Change the listening port to 8080:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">&lt;VirtualHost *:8080&gt;</span><br><span class="line">    ServerAdmin webmaster@localhost</span><br><span class="line">    DocumentRoot /var/www/html</span><br><span class="line">    ErrorLog <span class="variable">$&#123;APACHE_LOG_DIR&#125;</span>/error.log</span><br><span class="line">    CustomLog <span class="variable">$&#123;APACHE_LOG_DIR&#125;</span>/access.log combined</span><br><span class="line">&lt;/VirtualHost&gt;</span><br></pre></td></tr></table></figure>

<p>Save the file and activate the new configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2ensite</span> <span class="number">001</span><span class="string">-default</span></span><br></pre></td></tr></table></figure>

<p>Then reload Apache:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">apache2</span></span><br></pre></td></tr></table></figure>

<p>Verify that Apache is now listening on 8080:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">netstat</span> <span class="string">-tlpn</span></span><br></pre></td></tr></table></figure>

<p>The output should look like the following example, with apache2 listening on 8080:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address     Foreign Address   State    PID/Program name</span><br><span class="line">tcp        0      0 0.0.0.0:22        0.0.0.0:*         LISTEN   1086/sshd</span><br><span class="line">tcp6       0      0 :::8080           :::*              LISTEN   4678/apache2</span><br><span class="line">tcp6       0      0 :::22             :::*              LISTEN   1086/sshd</span><br></pre></td></tr></table></figure>

<p>Once we verify that Apache is listening on the correct port, we can configure support for PHP and <code>FastCGI</code>.</p>
<br>

<hr>
<h2 id="Use-mod-fastcgi"><a href="#Use-mod-fastcgi" class="headerlink" title="Use mod_fastcgi"></a>Use mod_fastcgi</h2><p>Apache serves PHP pages using <code>mod_php</code> by default, but it requires additional configuration to work with PHP-FPM.</p>
<blockquote>
<p>Note: If we are trying on an existing installation of LAMP with <code>mod_php</code>, disable it first with:</p>
<p><code>sudo a2dismod php7.3</code></p>
</blockquote>
<p>We will be adding a configuration block for <code>mod_fastcgi</code> which depends on <code>mod_action</code>. <code>mod_action</code> is disabled by default, so we first need to enable it:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2enmod</span> <span class="string">actions</span></span><br></pre></td></tr></table></figure>

<p>Rename the existing FastCGI configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">mv</span> <span class="string">/etc/apache2/mods-enabled/fastcgi.conf</span> <span class="string">\</span></span><br><span class="line"><span class="string">/etc/apache2/mods-enabled/fastcgi.conf.default</span></span><br></pre></td></tr></table></figure>

<p>Create a new configuration file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/mods-enabled/fastcgi.conf</span></span><br></pre></td></tr></table></figure>

<p>Add the following directives to the file to pass requests for <code>.php</code> files to the PHP-FPM UNIX socket:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Content --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">IfModule</span> <span class="attr">mod_fastcgi.c</span>&gt;</span></span><br><span class="line">  AddHandler fastcgi-script .fcgi</span><br><span class="line">  FastCgiIpcDir /var/lib/apache2/fastcgi</span><br><span class="line">  AddType application/x-httpd-fastphp .php</span><br><span class="line">  Action application/x-httpd-fastphp /php-fcgi</span><br><span class="line">  Alias /php-fcgi /usr/lib/cgi-bin/php-fcgi</span><br><span class="line">  FastCgiExternalServer /usr/lib/cgi-bin/php-fcgi -socket /run/php/php7.2-fpm.sock -pass-header Authorization</span><br><span class="line">    </span><br><span class="line">  <span class="tag">&lt;<span class="name">Directory</span> /<span class="attr">usr</span>/<span class="attr">lib</span>/<span class="attr">cgi-bin</span>&gt;</span></span><br><span class="line">    Require all granted</span><br><span class="line">  <span class="tag">&lt;/<span class="name">Directory</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">IfModule</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Save the changes and do a configuration test:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apachectl</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>

<p>Reload Apache if Syntax OK is displayed:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">apache2</span></span><br></pre></td></tr></table></figure>

<p>If we see the warning:</p>
<blockquote>
<p>  <em>Could not reliably determine the server’s fully qualified domain name, using 127.0.1.1. Set the ‘ServerName’ directive globally to suppress this message.</em></p>
</blockquote>
<p>We can safely ignore it for now. We’ll configure server names later.</p>
<p>Now let’s make sure we can serve PHP from Apache.</p>
<br>

<hr>
<h2 id="Verify-PHP-Functionality"><a href="#Verify-PHP-Functionality" class="headerlink" title="Verify PHP Functionality"></a>Verify PHP Functionality</h2><p>Let’s make sure that PHP works by creating a <code>phpinfo()</code> file and accessing it from a web browser.</p>
<p>Create the file <code>/var/www/html/info.php</code> which contains a call to the <code>phpinfo</code> function:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">&quot;&lt;?php phpinfo(); ?&gt;&quot;</span> <span class="string">|</span> <span class="string">sudo</span> <span class="string">tee</span> <span class="string">/var/www/html/info.php</span></span><br></pre></td></tr></table></figure>

<p>To see the file in a browser, go to <code>localhost:8080/info.php</code>. This will give us a list of the configuration settings PHP is using. We’ll see output similar to this:</p>
<p><img data-src="/images/posts/181111-0.png" alt="00"></p>
<p><img data-src="/images/posts/181111-1.png" alt="01"></p>
<p>At the top of the page, check that <strong>Server API</strong> says <strong>FPM/FastCGI</strong>. About two-thirds of the way down the page, the <strong>PHP Variables</strong> section will tell we the <strong>SERVER_SOFTWARE</strong> is Apache on Ubuntu. These confirm that mod_fastcgi is active and Apache is using PHP-FPM to process PHP files.</p>
<br>

<hr>
<h2 id="Create-Virtual-Hosts-for-Apache"><a href="#Create-Virtual-Hosts-for-Apache" class="headerlink" title="Create Virtual Hosts for Apache"></a>Create Virtual Hosts for Apache</h2><p>Let’s create Apache virtual host files for the domains <code>foobar.net</code> and <code>test.io</code>. To do that, we’ll first create document root directories for both sites and place some default files in those directories so we can easily test our configuration.</p>
<p>First, create the document root directories:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">mkdir</span> <span class="string">-v</span> <span class="string">/var/www/foobar.net</span> <span class="string">/var/www/test.io</span></span><br></pre></td></tr></table></figure>

<p>Then create an index file for each site:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;h1&gt;Foo Bar&lt;/h1&gt;&quot;</span> | sudo tee /var/www/foobar.net/index.html</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;h1&gt;Test IO&lt;/h1&gt;&quot;</span> | sudo tee /var/www/test.io/index.html</span><br></pre></td></tr></table></figure>

<p>Then create a <code>phpinfo()</code> file for each site so we can test that PHP is configured properly.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;?php phpinfo(); ?&gt;&quot;</span> | sudo tee /var/www/foobar.net/info.php</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;?php phpinfo(); ?&gt;&quot;</span> | sudo tee /var/www/test.io/info.php</span><br></pre></td></tr></table></figure>

<p>Now create the virtual host file for the <code>foobar.net</code> domain:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/sites-available/foobar.net.conf</span></span><br></pre></td></tr></table></figure>

<p>Add the following code to the file to define the host:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Content --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">VirtualHost</span> *<span class="attr">:8080</span>&gt;</span></span><br><span class="line">    ServerName foobar.net</span><br><span class="line">    ServerAlias www.foobar.net</span><br><span class="line">    DocumentRoot /var/www/foobar.net</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">Directory</span> /<span class="attr">var</span>/<span class="attr">www</span>/<span class="attr">foobar.net</span>&gt;</span></span><br><span class="line">        AllowOverride All</span><br><span class="line">    <span class="tag">&lt;/<span class="name">Directory</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">VirtualHost</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>The line <code>AllowOverride All</code> enables <code>.htaccess</code> support. Save and close the file. Then create a similar configuration for <code>test.io</code>. First create the file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/sites-available/test.io.conf</span></span><br></pre></td></tr></table></figure>

<p>Then add the configuration to the file:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Content --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">VirtualHost</span> *<span class="attr">:8080</span>&gt;</span></span><br><span class="line">    ServerName test.io</span><br><span class="line">    ServerAlias www.test.io</span><br><span class="line">    DocumentRoot /var/www/test.io</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">Directory</span> /<span class="attr">var</span>/<span class="attr">www</span>/<span class="attr">test.io</span>&gt;</span></span><br><span class="line">        AllowOverride All</span><br><span class="line">    <span class="tag">&lt;/<span class="name">Directory</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">VirtualHost</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Now that both Apache virtual hosts are set up, enable the sites using the <code>a2ensite</code> command. This creates a symbolic link to the virtual host file in the sites-enabled directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2ensite</span> <span class="string">foobar.net</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">a2ensite</span> <span class="string">test.io</span></span><br></pre></td></tr></table></figure>

<p>Check Apache for configuration errors again:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apachectl</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>

<p>We’ll see <strong>Syntax OK</strong> displayed if there are no errors. If we see anything else, review the configuration and try again.</p>
<p>Reload Apache to apply the changes once our configuration is error-free:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">apache2</span></span><br></pre></td></tr></table></figure>

<p>To confirm the sites are working, open <code>http://foobar.net:8080</code> and <code>http://test.io:8080</code> in the browser and verify that each site displays its <code>index.html</code> file.</p>
<p>We’ll see the following results:</p>
<p><img data-src="/images/posts/181111-2.png" alt="02"></p>
<p><img data-src="/images/posts/181111-3.png" alt="03"></p>
<p>Also, ensure that PHP is working by accessing the <code>info.php</code> files for each site. Visit <code>http://foobar.net:8080/info.php</code> and <code>http://test.io:8080/info.php</code> in the browser.</p>
<p>We now have two websites hosted on Apache at port 8080. Let’s configure Nginx next.</p>
<br>

<hr>
<h2 id="Install-amp-Config-Nginx"><a href="#Install-amp-Config-Nginx" class="headerlink" title="Install &amp; Config Nginx"></a>Install &amp; Config Nginx</h2><p>In this step we’ll install Nginx and configure the domains <code>example.com</code> and <code>sample.org</code> as Nginx’s virtual hosts. After install Nginx, remove the default virtual host’s symlink since we won’t be using it any more:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">rm</span> <span class="string">/etc/nginx/sites-enabled/default</span></span><br></pre></td></tr></table></figure>

<p>We’ll create our own default site later (<code>example.com</code>).</p>
<p>Now we’ll create virtual hosts for Nginx using the same procedure we used for Apache. First create document root directories for both the websites:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">mkdir</span> <span class="string">-v</span> <span class="string">/usr/share/nginx/example.com</span> <span class="string">/usr/share/nginx/sample.org</span></span><br></pre></td></tr></table></figure>

<p>We’ll keep the Nginx web sites in <code>/usr/share/nginx</code>, which is where Nginx wants them by default. We could put them under <code>/var/www/html</code> with the Apache sites, but this separation may help you associate sites with Nginx.</p>
<p>As you did with Apache’s virtual hosts, create index and <code>phpinfo()</code> files for testing after setup is complete:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;h1&gt;Example.com&lt;/h1&gt;&quot;</span> | sudo tee /usr/share/nginx/example.com/index.html</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;h1&gt;Sample.org&lt;/h1&gt;&quot;</span> | sudo tee /usr/share/nginx/sample.org/index.html</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;?php phpinfo(); ?&gt;&quot;</span> | sudo tee /usr/share/nginx/example.com/info.php</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;&lt;?php phpinfo(); ?&gt;&quot;</span> | sudo tee /usr/share/nginx/sample.org/info.php</span><br></pre></td></tr></table></figure>

<p>Now create a virtual host file for the domain <code>example.com</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/sites-available/example.com</span></span><br></pre></td></tr></table></figure>

<p>Nginx calls server {. . .} areas of a configuration file server blocks. Create a server block for the primary virtual host, <code>example.com</code>. The <code>default_server</code> configuration directive makes this the default virtual host which processes HTTP requests which do not match any other virtual host.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80 default_server;</span><br><span class="line"></span><br><span class="line">    root /usr/share/nginx/example.com;</span><br><span class="line">    index index.php index.html index.htm;</span><br><span class="line"></span><br><span class="line">    server_name example.com www.example.com;</span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        fastcgi_pass unix:/run/php/php7.2-fpm.sock;</span><br><span class="line">        include snippets/fastcgi-php.conf;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Now create a virtual host file for Nginx’s second domain, <code>sample.org</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">etc/nginx/sites-available/sample.org</span></span><br></pre></td></tr></table></figure>
<p>Add the following to the file:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    root /usr/share/nginx/sample.org;</span><br><span class="line">    index index.php index.html index.htm;</span><br><span class="line"></span><br><span class="line">    server_name sample.org www.sample.org;</span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        fastcgi_pass unix:/run/php/php7.2-fpm.sock;</span><br><span class="line">        include snippets/fastcgi-php.conf;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Then enable both sites by creating symbolic links to the sites-enabled directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ln</span> <span class="string">-s</span> <span class="string">/etc/nginx/sites-available/example.com</span> <span class="string">\</span></span><br><span class="line"><span class="string">/etc/nginx/sites-enabled/example.com</span></span><br><span class="line"></span><br><span class="line"><span class="string">sudo</span> <span class="string">ln</span> <span class="string">-s</span> <span class="string">/etc/nginx/sites-available/sample.org</span> <span class="string">\</span></span><br><span class="line"><span class="string">/etc/nginx/sites-enabled/sample.org</span></span><br></pre></td></tr></table></figure>

<p>Then test the Nginx configuration to ensure there are no configuration issues:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">nginx</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>

<p>Then reload Nginx if there are no errors:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>

<p>Now access the <code>phpinfo()</code> file of our Nginx virtual hosts in a web browser by visiting <code>http://example.com/info.php</code> and <code>http://sample.org/info.php</code>. Look under the PHP Variables sections again.</p>
<p><img data-src="/images/posts/181111-4.png" alt="04"></p>
<p><strong>[“SERVER_SOFTWARE”]</strong> should say nginx, indicating that the files were directly served by Nginx. <strong>[“DOCUMENT_ROOT”]</strong> should point to the directory we created earlier in this step for each Nginx site.</p>
<p>At this point, we have installed Nginx and created two virtual hosts. Next we will configure Nginx to proxy requests meant for domains hosted on Apache.</p>
<br>

<hr>
<h2 id="Nginx-for-Apache’s-Virtual-Hosts"><a href="#Nginx-for-Apache’s-Virtual-Hosts" class="headerlink" title="Nginx for Apache’s Virtual Hosts"></a>Nginx for Apache’s Virtual Hosts</h2><p>Let’s create an additional Nginx virtual host with multiple domain names in the server_name directives. Requests for these domain names will be proxied to Apache.</p>
<p>Create a new Nginx virtual host file to forward requests to Apache:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/sites-available/apache</span></span><br></pre></td></tr></table></figure>

<p>Add the following code block which specifies the names of both Apache virtual host domains and proxies their requests to Apache. Remember to use the public IP address in <code>proxy_pass</code>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name foobar.net www.foobar.net test.io www.test.io;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://your_server_ip:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Save the file and enable this new virtual host by creating a symbolic link:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">ln</span> <span class="string">-s</span> <span class="string">/etc/nginx/sites-available/apache</span> <span class="string">/etc/nginx/sites-enabled/apache</span></span><br></pre></td></tr></table></figure>

<p>Test the configuration to ensure there are no errors:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">nginx</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>

<p>If there are no errors, reload Nginx:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>

<p>Open the browser and access the URL <a href="http://foobar.net/info.php">http://foobar.net/info.php</a> in the browser. Scroll down to the PHP Variables section and check the values displayed.</p>
<p><img data-src="/images/posts/181111-5.png" alt="05"></p>
<p>The variables <strong>SERVER_SOFTWARE</strong> and <strong>DOCUMENT_ROOT</strong> confirm that this request was handled by Apache. The variables <strong>HTTP_X_REAL_IP</strong> and <strong>HTTP_X_FORWARDED_FOR</strong> were added by Nginx and should show the public IP address of the computer we’re using to access the URL.</p>
<p>We have successfully set up Nginx to proxy requests for specific domains to Apache. Next, let’s configure Apache to set the <code>REMOTE_ADDR</code> variable as if it were handling these requests directly.</p>
<br>

<hr>
<h2 id="Install-amp-Config-mod-rpaf"><a href="#Install-amp-Config-mod-rpaf" class="headerlink" title="Install &amp; Config mod_rpaf"></a>Install &amp; Config mod_rpaf</h2><p>Now we will install an Apache module called <code>mod\_rpaf</code> which rewrites the values of <code>REMOTE_ADDR</code>, HTTPS and HTTP_PORT based on the values provided by a reverse proxy. Without this module, some PHP applications would require code changes to work seamlessly from behind a proxy. This module is present in Ubuntu’s repository as <code>libapache2-mod-rpaf</code> but is outdated and doesn’t support certain configuration directives. Instead, we will install it from source.</p>
<p>Install the packages needed to build the module:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">unzip</span> <span class="string">build-essential</span> <span class="string">apache2-dev</span></span><br></pre></td></tr></table></figure>

<p>Download the latest stable release from GitHub:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">wget</span> <span class="string">https://github.com/gnif/mod_rpaf/archive/stable.zip</span></span><br></pre></td></tr></table></figure>

<p>Extract the downloaded file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">unzip</span> <span class="string">stable.zip</span></span><br></pre></td></tr></table></figure>

<p>Change into the new directory containing the files:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">mod_rpaf-stable</span></span><br></pre></td></tr></table></figure>

<p>Compile and install the module:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">make</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">make</span> <span class="string">install</span></span><br></pre></td></tr></table></figure>

<p>Next, create a file in the mods-available directory which will load the <code>rpaf</code> module:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/mods-available/rpaf.load</span></span><br></pre></td></tr></table></figure>

<p>Add the following code to the file to load the module:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">LoadModule rpaf_module /usr/lib/apache2/modules/mod_rpaf.so</span><br></pre></td></tr></table></figure>

<p>Create another file in this directory called <code>rpaf.conf</code> which will contain the configuration directives for <code>mod_rpaf</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/mods-available/rpaf.conf</span></span><br></pre></td></tr></table></figure>

<p>Add the following code block to configure <code>mod_rpaf</code>, making sure to specify the IP address of the server:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Content --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">IfModule</span> <span class="attr">mod_rpaf.c</span>&gt;</span></span><br><span class="line">    RPAF_Enable             On</span><br><span class="line">    RPAF_Header             X-Real-Ip</span><br><span class="line">    RPAF_ProxyIPs           your_server_ip </span><br><span class="line">    RPAF_SetHostName        On</span><br><span class="line">    RPAF_SetHTTPS           On</span><br><span class="line">    RPAF_SetPort            On</span><br><span class="line"><span class="tag">&lt;/<span class="name">IfModule</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Here’s a brief description of each directive. See the <code>mod_rpaf</code> README file for more information.</p>
<ul>
<li><p><code>RPAF_Header</code> - The header to use for the client’s real IP address.</p>
</li>
<li><p><code>RPAF_ProxyIPs</code> - The proxy IP to adjust HTTP requests for.</p>
</li>
<li><p><code>RPAF_SetHostName</code> - Updates the vhost name so <code>ServerName</code> and <code>ServerAlias</code> work.</p>
</li>
<li><p><code>RPAF_SetHTTPS</code> - Sets the HTTPS environment variable based on the value contained in <code>X-Forwarded-Proto</code>.</p>
</li>
<li><p><code>RPAF_SetPort</code> - Sets the SERVER_PORT environment variable. Useful for when Apache is behind a SSL proxy.</p>
</li>
</ul>
<p>Save <code>rpaf.conf</code> and enable the module:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2enmod</span> <span class="string">rpaf</span></span><br></pre></td></tr></table></figure>

<p>This creates symbolic links of the files <code>rpaf.load</code> and <code>rpaf.conf</code> in the mods-enabled directory. Now do a configuration test:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apachectl</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>

<p>Reload Apache if there are no errors:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">reload</span> <span class="string">apache2</span></span><br></pre></td></tr></table></figure>

<p>Access the <code>phpinfo()</code> pages <a href="http://foobar.net/info.php">http://foobar.net/info.php</a> and <a href="http://test.io/info.php">http://test.io/info.php</a> in our browser and check the PHP Variables section. The <code>REMOTE_ADDR</code> variable will now also be that of the local computer’s public IP address.</p>
<p>Now let’s set up TLS/SSL encryption for each site.</p>
<br>

<h2 id="HTTPS-with-Let’s-Encrypt"><a href="#HTTPS-with-Let’s-Encrypt" class="headerlink" title="HTTPS with Let’s Encrypt"></a>HTTPS with Let’s Encrypt</h2><p>In this step we will configure TLS/SSL certificates for both the domains hosted on Apache. We’ll obtain the certificates through <a href="https://letsencrypt.org/">Let’s Encrypt</a>. Nginx supports SSL termination so we can set up SSL without modifying Apache’s configuration files. The <code>mod_rpaf</code> module ensures the required environment variables are set on Apache to make applications work seamlessly behind a SSL reverse proxy.</p>
<p>First we will separate the server {…} blocks of both the domains so that each of them can have their own SSL certificates. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/sites-available/apache</span></span><br></pre></td></tr></table></figure>

<p>Modify the file so that it looks like this, with <code>foobar.net</code> and<code> test.io</code> in their own server blocks:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name foobar.net www.foobar.net;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://your_server_ip:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name test.io www.test.io;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://your_server_ip:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>We’ll use Certbot to generate our TLS/SSL certificates. Its Nginx plugin will take care of reconfiguring Nginx and reloading the config whenever necessary.</p>
<p>First, add the official Certbot repository:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">add-apt-repository</span> <span class="string">ppa:certbot/certbot</span></span><br></pre></td></tr></table></figure>

<p>Press ENTER when prompted to confirm that we want to add the new repository. Then update the package list to pick up the new repository’s package information:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>

<p>Then install Certbot’s Nginx package with apt:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">apt</span> <span class="string">install</span> <span class="string">python-certbot-nginx</span></span><br></pre></td></tr></table></figure>

<p>Once it’s installed, use the certbot command to generate the certificates for <code>foobar.net</code> and <a href="http://www.foobar.net/">www.foobar.net</a>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">certbot</span> <span class="string">--nginx</span> <span class="string">-d</span> <span class="string">foobar.net</span> <span class="string">-d</span> <span class="string">www.foobar.net</span></span><br></pre></td></tr></table></figure>

<p>This command tells Certbot to use the Nginx plugin, using -d to specify the names we’d like the certificate to be valid for.</p>
<p>If this is our first time running certbot, we will be prompted to enter an email address and agree to the terms of service. After doing so, certbot will communicate with the Let’s Encrypt server, then run a challenge to verify that we control the domain we’re requesting a certificate for.</p>
<p>Next, Certbot will ask how we’d like to configure our HTTPS settings:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">Please choose whether or not to redirect HTTP traffic to HTTPS, removing HTTP access.</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">1: No redirect - Make no further changes to the webserver configuration.</span><br><span class="line">2: Redirect - Make all requests redirect to secure HTTPS access. Choose this <span class="keyword">for</span></span><br><span class="line">new sites, or <span class="keyword">if</span> we<span class="string">&#x27;re confident your site works on HTTPS. You can undo this</span></span><br><span class="line"><span class="string">change by editing your web server&#x27;</span>s configuration.</span><br><span class="line">-------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>


<p>Select your choice, then press ENTER. The configuration will be updated, and Nginx will reload to pick up the new settings. Now execute the command for the second domain:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">certbot</span> <span class="string">--nginx</span> <span class="string">-d</span> <span class="string">test.io</span> <span class="string">-d</span> <span class="string">www.test.io</span></span><br></pre></td></tr></table></figure>

<p>Access one of Apache’s domains in the browser using the https:// prefix; visit <a href="https://foobar.net/info.php">https://foobar.net/info.php</a> and we’ll see this:</p>
<p><img data-src="/images/posts/181111-6.png" alt="06"></p>
<p>Look in the PHP Variables section. The variable <code>SERVER_PORT</code> has been set to 443 and HTTPS set to on, as though Apache was directly accessed over HTTPS. With these variables set, PHP applications do not have to be specially configured to work behind a reverse proxy.</p>
<p>Now let’s disable direct access to Apache.</p>
<br>

<hr>
<h2 id="Block-Direct-Access-to-Apache"><a href="#Block-Direct-Access-to-Apache" class="headerlink" title="Block Direct Access to Apache"></a>Block Direct Access to Apache</h2><p>Since Apache is listening on port 8080 on the public IP address, it is accessible by everyone. It can be blocked by working the following <code>IPtables</code> command into your firewall rule set.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">iptables</span> <span class="string">-I</span> <span class="string">INPUT</span> <span class="string">-p</span> <span class="string">tcp</span> <span class="string">--dport</span> <span class="number">8080</span> <span class="string">!</span> <span class="string">\</span></span><br><span class="line"><span class="string">-s</span> <span class="string">your_server_ip</span> <span class="string">-j</span> <span class="string">REJECT</span> <span class="string">--reject-with</span> <span class="string">tcp-reset</span></span><br></pre></td></tr></table></figure>

<p>Be sure to use your server’s IP address in place of the example in red. Once port 8080 is blocked in your firewall, test that Apache is unreachable on it. Open your web browser and try accessing one of Apache’s domain names on port 8080. For example: <a href="http://example.com:8080/">http://example.com:8080</a></p>
<p>The browser should display an <code>Unable to connect</code> or <code>Webpage is not available</code> error message. With the IPtables <code>tcp-reset </code>option in place, an outsider would see no difference between port 8080 and a port that doesn’t have any service on it.</p>
<blockquote>
<p>Note: </p>
<p><em>IPtables rules do not survive a system reboot by default. There are multiple ways to preserve IPtables rules, but the easiest is to use iptables-persistent in Ubuntu’s repository. Explore this article to learn more about how to configure IPTables.</em></p>
</blockquote>
<p>Now let’s configure Nginx to serve static files for the Apache sites.</p>
<br>

<hr>
<h2 id="Serve-Static-Files-with-Nginx"><a href="#Serve-Static-Files-with-Nginx" class="headerlink" title="Serve Static Files with Nginx"></a>Serve Static Files with Nginx</h2><p>When Nginx proxies requests for Apache’s domains, it sends every file request for that domain to Apache. Nginx is faster than Apache in serving static files like images, JavaScript and style sheets. So let’s configure Nginx’s apache virtual host file to directly serve static files but send PHP requests on to Apache.</p>
<p>Open the file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/nginx/sites-available/apache</span></span><br></pre></td></tr></table></figure>
<p>You’ll need to add two additional location blocks to each server block, as well as modify the existing location sections. In addition, you’ll need to tell Nginx where to find the static files for each site.</p>
<p>If you’ve decided not to use SSL and TLS certificates, modify your file so it looks like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name test.io www.test.io;</span><br><span class="line">    root /var/www/test.io;</span><br><span class="line">    index index.php index.htm index.html;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        proxy_pass http://your_server_ip:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name foobar.net www.foobar.net;</span><br><span class="line">    root /var/www/foobar.net;</span><br><span class="line">    index index.php index.htm index.html;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        proxy_pass http://your_ip_address:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>If you also want HTTPS to be available, use the following configuration instead:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Content</span></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name test.io www.test.io;</span><br><span class="line">    root /var/www/test.io;</span><br><span class="line">    index index.php index.htm index.html;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        proxy_pass http://your_server_ip:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    ssl_certificate /etc/letsencrypt/live/test.io/fullchain.pem;</span><br><span class="line">    ssl_certificate_key /etc/letsencrypt/live/test.io/privkey.pem;</span><br><span class="line">    include /etc/letsencrypt/options-ssl-nginx.conf;</span><br><span class="line">    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name foobar.net www.foobar.net;</span><br><span class="line">    root /var/www/foobar.net;</span><br><span class="line">    index index.php index.htm index.html;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        proxy_pass http://your_ip_address:8080;</span><br><span class="line">        proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    ssl_certificate /etc/letsencrypt/live/foobar.net/fullchain.pem;</span><br><span class="line">    ssl_certificate_key /etc/letsencrypt/live/foobar.net/privkey.pem;</span><br><span class="line">    include /etc/letsencrypt/options-ssl-nginx.conf;</span><br><span class="line">    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The <code>try_files</code> directive makes Nginx look for files in the document root and directly serve them. If the file has a <code>.php</code> extension, the request is passed to Apache. Even if the file is not found in the document root, the request is passed on to Apache so that application features like permalinks work without problems.</p>
<blockquote>
<p><strong>Warning:</strong> </p>
<p>The location <code>~ /.ht</code> directive is very important; this prevents Nginx from serving the contents of Apache configuration files like <code>.htaccess</code> and <code>.htpasswd</code> which contain sensitive information.</p>
</blockquote>
<p>Save the file and perform a configuration test:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">nginx</span> <span class="string">-t</span></span><br></pre></td></tr></table></figure>

<p>Reload Nginx if the test succeeds:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">nginx</span> <span class="string">reload</span></span><br></pre></td></tr></table></figure>

<p>To verify things are working, you can examine Apache’s log files in <code>/var/log/apache2</code> and see the GET requests for the <code>info.php </code>files of <code>test.io</code> and <code>foobar.net</code>. Use the tail command to see the last few lines of the file, and use the -f switch to watch the file for changes:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/var/log/apache2/other_vhosts_access.log</span></span><br></pre></td></tr></table></figure>

<p>Now visit <a href="http://test.io/info.php">http://test.io/info.php</a> in your browser and then look at the output from the log. You’ll see that Apache is indeed replying:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line">test.io:80 your_server_ip - - [01/Jul/2016:18:18:34 -0400] </span><br><span class="line"><span class="string">&quot;GET /info.php HTTP/1.0&quot;</span> 200 20414 <span class="string">&quot;-&quot;</span> </span><br><span class="line"><span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 \</span></span><br><span class="line"><span class="string">(KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36&quot;</span></span><br></pre></td></tr></table></figure>

<p>Then visit the <code>index.html</code> page for each site and you won’t see any log entries from Apache. Nginx is serving them.</p>
<p>With this setup, Apache will not be able to restrict access to static files. And access control for static files would need to be configured in Nginx’s apache virtual host file.</p>
<br>

<br>]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Configure Apache on Ubuntu</title>
    <url>/2018/Apache-Config/</url>
    <content><![CDATA[<p>Apache is the most popular web server on the internet. It is used to serve more than half of all active websites. Although there are many viable web servers, it is helpful to understand how Apache works because of its ubiquity. Moreover, we should have a good understanding of what the main configuration files are used for and how they interact with each other.</p>
<p>In this post, we will examine some general <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-the-apache-web-server-on-an-ubuntu-or-debian-vps">configuration files</a> and <a href="https://www.digitalocean.com/community/tutorials/apache-basics-installation-and-configuration-troubleshooting">options</a> that can be controlled within them, and we will follow the Ubuntu/Debian layout of Apache files. </p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Apache-File-Hierarchy"><a href="#Apache-File-Hierarchy" class="headerlink" title="Apache File Hierarchy"></a>Apache File Hierarchy</h2><p>On Ubuntu and Debian, Apache keeps its main configuration files within the <code>/etc/apache2</code> folder:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">/etc/apache2</span></span><br><span class="line"><span class="string">ls</span> <span class="string">-F</span></span><br><span class="line"></span><br><span class="line"><span class="string">apache2.conf</span>  <span class="string">envvars</span>     <span class="string">magic</span>            <span class="string">mods-enabled/</span>  <span class="string">sites-available/</span></span><br><span class="line"><span class="string">conf.d/</span>       <span class="string">httpd.conf</span>  <span class="string">mods-available/</span>  <span class="string">ports.conf</span>     <span class="string">sites-enabled/</span></span><br></pre></td></tr></table></figure>

<p>There are a number of plain text files and some sub-directories in this directory. These are some of the more useful locations to be familiar with:</p>
<ul>
<li><p><strong>apache2.conf</strong>: This is the main configuration file for the server. Almost all configuration can be done from within this file, although it is recommended to use separate, designated files for simplicity. This file will configure defaults and be the central point of access for the server to read configuration details.</p>
</li>
<li><p><strong>ports.conf</strong>: This file is used to specify the ports that virtual hosts should listen on. Be sure to check that this file is correct if you are configuring SSL.</p>
</li>
<li><p><strong>conf.d/</strong>: This directory is used for controlling specific aspects of the Apache configuration. For example, it is often used to define SSL configuration and default security choices.</p>
</li>
<li><p><strong>sites-available/</strong>: This directory contains all of the virtual host files that define different web sites. These will establish which content gets served for which requests. These are available configurations, not active configurations.</p>
</li>
<li><p><strong>sites-enabled/</strong>: This directory establishes which virtual host definitions are actually being used. Usually, this directory consists of symbolic links to files defined in the “sites-available” directory.</p>
</li>
<li><p><strong>mods-[enabled,available]/</strong>: These directories are similar in function to the sites directories, but they define modules that can be optionally loaded instead.</p>
</li>
</ul>
<p>As we can see, Apache configuration does not take place in a single monolithic file, but instead happens through a modular design where new files can be added and modified as needed.</p>
<br>



<hr>
<h2 id="Apache2-conf"><a href="#Apache2-conf" class="headerlink" title="Apache2.conf"></a>Apache2.conf</h2><p>The main configuration details for your Apache server are held in the <code>/etc/apache2/apache2.conf</code> file.</p>
<p>This file is divided into three main sections: configuration for the global Apache server process, configuration for the default server, and configuration of Virtual Hosts.</p>
<p>In Ubuntu and Debian, the majority of the file is for global definitions, and the configuration of the default server and virtual hosts is handled at the end, by using the <code>Include ...</code> directive.</p>
<p>The “Include” directive allows Apache to read other configuration files into the current file at the location that the statement appears. The result is that Apache dynamically generates an overarching configuration file on startup.</p>
<p>If you scroll to the bottom of the file, there are a number of different “Include” statements. These load module definitions, the <code>ports.conf</code> document, the specific configuration files in the <code>conf.d/</code> directory, and finally, the Virtual Host definitions in the “sites-enabled/“ directory.</p>
<p>We will focus on the first part of the file to learn how Apache defines its global settings.</p>
<br>

<hr>
<h2 id="Global-Configuration-Section"><a href="#Global-Configuration-Section" class="headerlink" title="Global Configuration Section"></a>Global Configuration Section</h2><p>This section is for configuring some options that control how Apache works as a whole.</p>
<br>

<h3 id="Timeout"><a href="#Timeout" class="headerlink" title="Timeout"></a><u>Timeout</u></h3><p>By default, this parameter is set to “300”, which means that the server has a maximum of 300 seconds to fulfill each request.</p>
<p>This is probably too high for most set ups and can safely be dropped to something between 30 and 60 seconds.</p>
<br>

<h3 id="KeepAlive"><a href="#KeepAlive" class="headerlink" title="KeepAlive"></a><u>KeepAlive</u></h3><p>This option, if set to “On”, will allow each connection to remain open to handle multiple requests from the same client.</p>
<p>If this is set to “Off”, each request will have to establish a new connection, which can result in significant overhead depending on your setup and traffic situation.</p>
<br>

<h3 id="MaxKeepAliveRequests"><a href="#MaxKeepAliveRequests" class="headerlink" title="MaxKeepAliveRequests"></a><u>MaxKeepAliveRequests</u></h3><p>This controls how many separate request each connection will handle before dying. Keeping this number high will allow Apache to serve content to each client more effectively.</p>
<p>Setting this value to 0 will allow Apache to serve an unlimited amount of request for each connection.</p>
<br>

<h3 id="KeepAliveTimeout"><a href="#KeepAliveTimeout" class="headerlink" title="KeepAliveTimeout"></a><u>KeepAliveTimeout</u></h3><p>This setting specifies how long to wait for the next request after finishing the last one. If the timeout threshold is reached, then the connection will die.</p>
<p>This just means that the next time content is requested, the server will establish a new connection to handle the request for the content that make up the page the client is visiting.</p>
<br>

<h3 id="MPM-Configuration"><a href="#MPM-Configuration" class="headerlink" title="MPM Configuration"></a><u>MPM Configuration</u></h3><p>Next we specify the configuration of the <strong>MPM (Multi-Processing Module)</strong> options. we can cross-reference which section our Apache installation was compiled with by exiting into the terminal and typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apache2</span> <span class="string">-l</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line">Compiled <span class="keyword">in</span> modules:</span><br><span class="line">  core.c</span><br><span class="line">  mod_log_config.c</span><br><span class="line">  mod_logio.c</span><br><span class="line">  prefork.c</span><br><span class="line">  http_core.c</span><br><span class="line">  mod_so.c</span><br></pre></td></tr></table></figure>

<p>As we can see, in this server, <code>prefork.c</code> is a module that was compiled in and is also in the <code>apache2.conf</code> file. Our installation may have multiple to choose from, but only one can be selected.</p>
<p>We can adjust the configuration of the prefork MPM in the appropriate section.</p>
<br>

<hr>
<h2 id="Default-Virtual-Host-File"><a href="#Default-Virtual-Host-File" class="headerlink" title="Default Virtual Host File"></a>Default Virtual Host File</h2><p>The default Virtual Host declaration can be found in a file called <code>default</code> in the <code>sites-available</code> directory.</p>
<p>We can learn about the general format of a Virtual Host file by examining this file. Open the file with the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">vim</span> <span class="string">/etc/apache2/sites-available/default</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- output --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">VirtualHost</span> *<span class="attr">:80</span>&gt;</span></span><br><span class="line">        ServerAdmin webmaster@localhost</span><br><span class="line"></span><br><span class="line">        DocumentRoot /var/www</span><br><span class="line">        <span class="tag">&lt;<span class="name">Directory</span> /&gt;</span></span><br><span class="line">                Options FollowSymLinks</span><br><span class="line">                AllowOverride None</span><br><span class="line">        <span class="tag">&lt;/<span class="name">Directory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">Directory</span> /<span class="attr">var</span>/<span class="attr">www</span>/&gt;</span></span><br><span class="line">                Options Indexes FollowSymLinks MultiViews</span><br><span class="line">                AllowOverride None</span><br><span class="line">                Order allow,deny</span><br><span class="line">                allow from all</span><br><span class="line">        <span class="tag">&lt;/<span class="name">Directory</span>&gt;</span></span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>

<p>The default Virtual Host is configured to handle any request on port 80, the standard HTTP port. This is defined in the declaration header where it says <code>*:80</code>, meaning port 80 on any interface.</p>
<p>This does not mean that it will necessarily handle each request to the server on this port however. Apache uses the most specific Virtual Host definition that matches the request. This means that if there was a more specific definition, it could supersede this definition.</p>
<br>

<h3 id="Virtual-Host-Top-Level-Config"><a href="#Virtual-Host-Top-Level-Config" class="headerlink" title="Virtual Host Top Level Config"></a><u>Virtual Host Top Level Config</u></h3><p>These options are set within the Virtual Host definition outside of any other lower level sub-declaration. They apply to the whole Virtual Host.</p>
<p>The <code>ServerAdmin</code> option specifies a contact email that should be used when there are server problems.</p>
<p>This can be inserted into an error page if you have <code>ServerSignature</code> set to <code>Email</code> in the <code>/etc/apache2/conf.d/security</code> file, so make sure you are willing to receive the mail if you adjust that setting.</p>
<p>If we were using this as a template for other Virtual Host definitions, we would want to add a <code>ServerName</code> definition that specifies the domain name or IP address that this request should handle. This is the option that would add specificity to the Virtual Host, allowing it to trump the default definition if it matches the <code>ServerName</code> value.</p>
<p>You can also make the Virtual Host apply to more than one name by using the <code>ServerAlias</code> definition. This provide alternate paths to get to the same content. A good use-case for this is adding the same domain, preceded by <code>www</code>.</p>
<p>The <code>DocumentRoot</code> option specifies where the content that is requested for this Virtual Host will be located. The default Virtual Host is set up to serve content out of the<code>/var/www</code> directory on Ubuntu.</p>
<br>

<h3 id="Directory-Definitions"><a href="#Directory-Definitions" class="headerlink" title="Directory Definitions"></a><u>Directory Definitions</u></h3><p>Within the Virtual Host definition, there are definitions for how the server handles different directories within the file system. Apache will apply all of these directions in order from shortest to longest, so there is again a chance to override previous options.</p>
<p>The first directory definition applies rules for the <code>/</code>, or root, directory. This will provide the baseline configuration for your Virtual Host, as it applies to all files served on the file system.</p>
<p>By default, Ubuntu does not set up any access restrictions to the filesystem. Apache recommends that you add some default access restrictions. You can modify this like so:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Directory</span> /&gt;</span></span><br><span class="line">    Options FollowSymLinks</span><br><span class="line">    AllowOverride None</span><br><span class="line">    Order Deny,Allow</span><br><span class="line">    Deny from All</span><br><span class="line"><span class="tag">&lt;/<span class="name">Directory</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>This will deny access to all content unless specified otherwise in subsequent directory definitions.</p>
<p>The next directory definition is for the document root, so it specifies the “allow from all” option that overrides the “/“ option for this directory.</p>
<p>The <code>AllowOverride</code> option is used to decide whether an <code>.htaccess</code> file can override settings if it is placed in the content directory. This is not allowed by default, but can be useful to enable in a variety of circumstances.</p>
<br>

<h3 id="Alias-amp-ScriptAlias"><a href="#Alias-amp-ScriptAlias" class="headerlink" title="Alias &amp; ScriptAlias"></a><u>Alias &amp; ScriptAlias</u></h3><p>Directory definitions are sometimes preceded by <code>Alias</code> or <code>ScriptAlias</code> statements. Alias maps a <code>url</code> path to a directory path.</p>
<p><code>ScriptAlias</code> operates in the same way, but is used to define directories that will have executable components in them.</p>
<p>For instance, this line in a Virtual Host that handles request to <code>example.com</code> would allow access to content within <code>/path/to/content/</code> by navigating to <code>example.com/content/</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Alias</span> <span class="string">/content/</span> <span class="string">/path/to/content/</span></span><br></pre></td></tr></table></figure>

<p>Following the alias, you should remember to define the directory with access privileges as discussed in the previous section.</p>
<br>

<hr>
<h2 id="Enabling-Sites-and-Modules"><a href="#Enabling-Sites-and-Modules" class="headerlink" title="Enabling Sites and Modules"></a>Enabling Sites and Modules</h2><p>Once you have a Virtual Host file that meets your requirements, you can use the tools included with Apache to transition them into live sites.</p>
<p>To automatically create a symbolic link in the “sites-enabled” directory to an existing file in the “sites-available” directory, issue the following command:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2ensite</span> <span class="string">virtual_host_file_name</span></span><br></pre></td></tr></table></figure>

<p>After enabling a site, issue the following command to tell Apache to re-read its configuration files, allowing the change to propagate:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">apache2</span> <span class="string">reload</span></span><br></pre></td></tr></table></figure>

<p>There is also a companion command for disabling a Virtual Host. It operates by removing the symbolic link from the “sites-enabled” directory:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">a2dissite</span> <span class="string">virtual_host_file_name</span></span><br></pre></td></tr></table></figure>

<p>Again, reload the configuration to make the change happen:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">apache2</span> <span class="string">reload</span></span><br></pre></td></tr></table></figure>

<p>Modules can be enabled or disabled by using the <code>a2enmod</code> and <code>a2dismod</code> commands respectively. They work in the same way as the <code>site</code> versions of these commands.</p>
<p>Remember to reload your configuration changes after modules have been enabled or disabled as well.</p>
<br>


<br>]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Initial Server Setup - Ubuntu 18.04</title>
    <url>/2018/Initial-Server-Setup/</url>
    <content><![CDATA[<p>When we first create a new Ubuntu 18.04 server, there are a few configuration steps that we should take early on as part of the basic setup. This will increase the security and usability of the server and will give us a solid foundation for subsequent actions.</p>
<blockquote>
<p>Note: If you wish to get up and running more quickly, please see the <a href="/2018/Initial-Server-Setup/#The-Script">initial server setup script</a> in the last section.</p>
</blockquote>
<span id="more"></span> 

<br>

<h2 id="Logging-in-as-Root"><a href="#Logging-in-as-Root" class="headerlink" title="Logging in as Root"></a>Logging in as Root</h2><p>To log into your server, you will need to know your server’s public IP address. You will also need the password or, if you installed an SSH key for authentication, the private key for the root user’s account. If you have not already logged into your server, you may want to follow our guide on how to connect to your Droplet with SSH, which covers this process in detail.</p>
<p>If you are not already connected to your server, go ahead and log in as the root user using the following command (substitute the highlighted portion of the command with your server’s public IP address):</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">root@your_server_ip</span></span><br></pre></td></tr></table></figure>
<p>Accept the warning about host authenticity if it appears. If you are using password authentication, provide your root password to log in. If you are using an SSH key that is passphrase protected, you may be prompted to enter the passphrase the first time you use the key each session. If this is your first time logging into the server with a password, you may also be prompted to change the root password.</p>
<br>

<h3 id="About-Root"><a href="#About-Root" class="headerlink" title="About Root"></a>About Root</h3><p>The root user is the administrative user in a Linux environment that has very broad privileges. Because of the heightened privileges of the root account, you are discouraged from using it on a regular basis. This is because part of the power inherent with the root account is the ability to make very destructive changes, even by accident.</p>
<p>The next step is to set up an alternative user account with a reduced scope of influence for day-to-day work. We’ll teach you how to gain increased privileges during the times when you need them.</p>
<br>

<h2 id="Creating-a-New-User"><a href="#Creating-a-New-User" class="headerlink" title="Creating a New User"></a>Creating a New User</h2><p>Once you are logged in as root, we’re prepared to add the new user account that we will use to log in from now on.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">adduser</span> <span class="string">merikanto</span></span><br></pre></td></tr></table></figure>
<p>You will be asked a few questions, starting with the account password.</p>
<p>Enter a strong password and, optionally, fill in any of the additional information if you would like. This is not required and you can just hit ENTER in any field you wish to skip.</p>
<br>

<h2 id="Granting-Administrative-Privileges"><a href="#Granting-Administrative-Privileges" class="headerlink" title="Granting Administrative Privileges"></a>Granting Administrative Privileges</h2><p>Now, we have a new user account with regular account privileges. However, we may sometimes need to do administrative tasks.</p>
<p>To avoid having to log out of our normal user and log back in as the root account, we can set up what is known as “superuser” or root privileges for our normal account. This will allow our normal user to run commands with administrative privileges by putting the word sudo before each command.</p>
<p>To add these privileges to our new user, we need to add the new user to the sudo group. By default, on Ubuntu 18.04, users who belong to the sudo group are allowed to use the sudo command.</p>
<p>As root, run this command to add your new user to the sudo group (substitute the highlighted word with your new user):</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">usermod</span> <span class="string">-aG</span> <span class="string">sudo</span> <span class="string">merikanto</span></span><br></pre></td></tr></table></figure>
<p>Now, when logged in as your regular user, you can type sudo before commands to perform actions with superuser privileges.</p>
<br>

<h2 id="Setting-Up-a-Basic-Firewall"><a href="#Setting-Up-a-Basic-Firewall" class="headerlink" title="Setting Up a Basic Firewall"></a>Setting Up a Basic Firewall</h2><p>Ubuntu 18.04 servers can use the <strong>UFW firewall</strong> to make sure only connections to certain services are allowed. We can set up a basic firewall very easily using this application.</p>
<p>Different applications can register their profiles with UFW upon installation. These profiles allow UFW to manage these applications by name. OpenSSH, the service allowing us to connect to our server now, has a profile registered with UFW.</p>
<p>You can see this by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ufw</span> <span class="string">app</span> <span class="string">list</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="attr">Available applications:</span></span><br><span class="line">  <span class="string">OpenSSH</span></span><br></pre></td></tr></table></figure>

<p>We need to make sure that the firewall allows SSH connections so that we can log back in next time. We can allow these connections by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ufw</span> <span class="string">allow</span> <span class="string">OpenSSH</span></span><br></pre></td></tr></table></figure>
<p>Afterwards, we can enable the firewall by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ufw</span> <span class="string">enable</span></span><br></pre></td></tr></table></figure>
<p>Type “y” and press ENTER to proceed. You can see that SSH connections are still allowed by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ufw</span> <span class="string">status</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Status:</span> <span class="string">active</span></span><br><span class="line"><span class="string">To</span>                         <span class="string">Action</span>      <span class="string">From</span></span><br><span class="line"><span class="string">--</span>                         <span class="string">------</span>      <span class="string">----</span></span><br><span class="line"><span class="string">OpenSSH</span>                    <span class="string">ALLOW</span>       <span class="string">Anywhere</span></span><br><span class="line"><span class="string">OpenSSH</span> <span class="string">(v6)</span>               <span class="string">ALLOW</span>       <span class="string">Anywhere</span> <span class="string">(v6)</span></span><br></pre></td></tr></table></figure>

<p>As the <strong>firewall is currently blocking all connections except for SSH</strong>, if you install and configure additional services, you will need to adjust the firewall settings to allow acceptable traffic in. You can learn some common UFW operations in this guide.</p>
<br>

<h2 id="Enabling-External-Access-for-Your-Regular-User"><a href="#Enabling-External-Access-for-Your-Regular-User" class="headerlink" title="Enabling External Access for Your Regular User"></a>Enabling External Access for Your Regular User</h2><p>Now that we have a regular user for daily use, we need to make sure we can SSH into the account directly.</p>
<p>Note: Until verifying that you can log in and use sudo with your new user, we recommend staying logged in as root. This way, if you have problems, you can troubleshoot and make any necessary changes as root. </p>
<p>The process for configuring SSH access for your new user depends on whether your server’s root account uses a password or SSH keys for authentication.</p>
<br>

<h3 id="Root-Account-Uses-Password-Authentication"><a href="#Root-Account-Uses-Password-Authentication" class="headerlink" title="Root Account Uses Password Authentication"></a>Root Account Uses Password Authentication</h3><p>If you logged in to your root account using a password, then password authentication is enabled for SSH. You can SSH to your new user account by opening up a new terminal session and using SSH with your new username:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">merikanto@your_server_ip</span></span><br></pre></td></tr></table></figure>
<p>After entering your regular user’s password, you will be logged in. Remember, if you need to run a command with administrative privileges, type sudo before it like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">command_to_run</span></span><br></pre></td></tr></table></figure>
<p>You will be prompted for your regular user password when using sudo for the first time each session (and periodically afterwards).</p>
<p>To enhance your server’s security, we strongly recommend setting up SSH keys instead of using password authentication. Follow our guide on setting up SSH keys on Ubuntu 18.04 to learn how to configure key-based authentication.</p>
<br>

<h3 id="Root-Account-Uses-SSH-Key-Authentication"><a href="#Root-Account-Uses-SSH-Key-Authentication" class="headerlink" title="Root Account Uses SSH Key Authentication"></a>Root Account Uses SSH Key Authentication</h3><p>If you logged in to your root account using SSH keys, then password authentication is disabled for SSH. You will need to add a copy of your local public key to the new user’s <code>~/.ssh/authorized_keys</code> file to log in successfully.</p>
<p>Since your public key is already in the root account’s <code>~/.ssh/authorized_keys</code> file on the server, we can copy that file and directory structure to our new user account in our existing session.</p>
<p>The simplest way to copy the files with the correct ownership and permissions is with the <strong>rsync</strong> command. This will copy the root user’s .ssh directory, preserve the permissions, and modify the file owners, all in a single command. Make sure to change the highlighted portions of the command below to match your regular user’s name:</p>
<br>

<blockquote>
<p><strong>Note</strong>: </p>
<p>The rsync command treats sources and destinations that end with a trailing slash differently than those without a trailing slash. When using rsync below, be sure that the source directory (~/.ssh) does not include a trailing slash (check to make sure you are not using ~/.ssh/).</p>
<p>If you accidentally add a trailing slash to the command, rsync will copy the contents of the root account’s ~/.ssh directory to the sudo user’s home directory instead of copying the entire ~/.ssh directory structure. The files will be in the wrong location and SSH will not be able to find and use them.</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">rsync</span> <span class="string">--archive</span> <span class="string">--chown=merikanto:merikanto</span> <span class="string">~/.ssh</span> <span class="string">/home/merikanto</span></span><br></pre></td></tr></table></figure>

<p>Now, open up a new terminal session and using SSH with your new username:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">merikanto@your_server_ip</span></span><br></pre></td></tr></table></figure>
<p>You should be logged in to the new user account without using a password. Remember, if you need to run a command with administrative privileges, type sudo before it like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">command_to_run</span></span><br></pre></td></tr></table></figure>
<p>You will be prompted for your regular user password when using sudo for the first time each session (and periodically afterwards).</p>
<br>

<h2 id="Setup-Script"><a href="#Setup-Script" class="headerlink" title="Setup Script"></a>Setup Script</h2><h3 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h3><p>This script is an alternative to manually running through the procedure outlined above. The following variables affect how the script is run, and please update these variables as needed before running the script:</p>
<ul>
<li>  <code>USERNAME</code>: The name of the regular user account to create and grant <code>sudo</code> privileges to.</li>
<li>  <code>COPY_AUTHORIZED_KEYS_FROM_ROOT</code>: Whether to copy the SSH key assets from the <strong>root</strong> account to the new <code>sudo</code> account.</li>
<li>  <code>OTHER_PUBLIC_KEYS_TO_ADD</code>: An array of strings representing other public keys to add to the <code>sudo</code>-enabled account. This can optionally be used in addition to or instead of copying the keys from the <strong>root</strong> account.</li>
</ul>
<br>



<p>When the script runs, the following actions are performed:</p>
<ul>
<li>  Create a regular user account with <code>sudo</code> privileges using the name specified by the <code>USERNAME</code> variable.</li>
<li>Configure the initial password state for the new account:<ul>
<li>  If the server was configured for password authentication, the original, generated administrative password is moved from the <strong>root</strong> account to the new <code>sudo</code> account. The password for the <strong>root</strong> account is then locked.</li>
<li>  If the server was configured for SSH key authentication, a blank password is set for the <code>sudo</code> account.</li>
</ul>
</li>
<li>  The <code>sudo</code> user’s password is marked as expired so that it must be changed upon first login.</li>
<li>  The <code>authorized_keys</code> file from the <strong>root</strong> account is copied over to the <code>sudo</code> user if <code>COPY_AUTHORIZED_KEYS_FROM_ROOT</code> is set to <code>true</code>.</li>
<li>  Any keys defined in <code>OTHER_PUBLIC_KEYS_TO_ADD</code> are added to the <code>sudo</code> user’s <code>authorized_keys</code> file.</li>
<li>  Password-based SSH authentication is disabled for the <strong>root</strong> user.</li>
<li>  The UFW firewall is enabled with SSH connections permitted.</li>
</ul>
<br>



<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>The script can be run in two ways: </p>
<ul>
<li>  Add it to <a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-droplet-metadata#about-user-data">the server’s user data field during creation</a> </li>
<li>  Log in as <strong>root</strong> and execute it after provisioning</li>
</ul>
<br>

<p>If you do not want to use user data, you can also run the script manually over SSH once the server is booted up.</p>
<p>If you have downloaded the script to your local computer, you can pass the script directly to SSH by typing:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">root@servers_public_IP</span> <span class="string">&quot;bash -s&quot;</span> <span class="string">--</span> <span class="string">&lt;</span> <span class="string">/path/to/script/file</span></span><br></pre></td></tr></table></figure>

<p>You should now be able to log in using your <code>sudo</code> account for any further configuration.</p>
<br>

<p>If you do not have the script downloaded to your local computer, start by logging into the <strong>root</strong> account on your server:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ssh</span> <span class="string">root@servers_public_IP</span></span><br></pre></td></tr></table></figure>

<p>Next, download the raw script to the server:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">curl</span> <span class="string">-L</span> <span class="string">&lt;SCRIPT_LINK&gt;</span> <span class="string">-o</span> <span class="string">/tmp/initial_setup.sh</span></span><br></pre></td></tr></table></figure>

<p>Inspect the script to ensure that it downloaded properly and update any variables that you wish to change:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">/tmp/initial_setup.sh</span></span><br></pre></td></tr></table></figure>

<p>Once satisfied, run the script manually using <code>bash</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">bash</span> <span class="string">/tmp/initial_setup.sh</span></span><br></pre></td></tr></table></figure>

<p>You should be able to log in using the <code>sudo</code>-enabled user to complete any further configuration.</p>
<br>

<h3 id="The-Script"><a href="#The-Script" class="headerlink" title="The Script"></a><a href="https://www.digitalocean.com/community/tutorials/automating-initial-server-setup-with-ubuntu-18-04">The Script</a></h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">set</span> -euo pipefail</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================== #</span></span><br><span class="line"><span class="comment">#   SCRIPT VARIABLES   #</span></span><br><span class="line"><span class="comment"># ==================== #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name of the user to create and grant sudo privileges</span></span><br><span class="line">USERNAME=merikanto</span><br><span class="line"></span><br><span class="line"><span class="comment"># Whether to copy over the root user&#x27;s `authorized_keys` file to the new sudo</span></span><br><span class="line"><span class="comment"># user.</span></span><br><span class="line">COPY_AUTHORIZED_KEYS_FROM_ROOT=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Additional public keys to add to the new sudo user</span></span><br><span class="line"><span class="comment"># OTHER_PUBLIC_KEYS_TO_ADD=(</span></span><br><span class="line"><span class="comment">#     &quot;ssh-rsa AAAAB...&quot;</span></span><br><span class="line"><span class="comment">#     &quot;ssh-rsa AAAAB...&quot;</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line">OTHER_PUBLIC_KEYS_TO_ADD=(</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================== #</span></span><br><span class="line"><span class="comment">#    SCRIPT LOGIC      #</span></span><br><span class="line"><span class="comment"># ==================== #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add sudo user and grant privileges</span></span><br><span class="line">useradd --create-home --shell <span class="string">&quot;/bin/bash&quot;</span> --groups sudo <span class="string">&quot;<span class="variable">$&#123;USERNAME&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check whether the root account has a real password set</span></span><br><span class="line">encrypted_root_pw=<span class="string">&quot;<span class="subst">$(grep root /etc/shadow | cut --delimiter=: --fields=2)</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$&#123;encrypted_root_pw&#125;</span>&quot;</span> != <span class="string">&quot;*&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transfer auto-generated root password to user if present</span></span><br><span class="line">    <span class="comment"># and lock the root account to password-based access</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;USERNAME&#125;</span>:<span class="variable">$&#123;encrypted_root_pw&#125;</span>&quot;</span> | chpasswd --encrypted</span><br><span class="line">    passwd --lock root</span><br><span class="line">    </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Delete invalid password for user if using keys so that a new password</span></span><br><span class="line">    <span class="comment"># can be set without providing a previous value</span></span><br><span class="line">    passwd --delete <span class="string">&quot;<span class="variable">$&#123;USERNAME&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Expire the sudo user&#x27;s password immediately to force a change</span></span><br><span class="line">chage --lastday 0 <span class="string">&quot;<span class="variable">$&#123;USERNAME&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create SSH directory for sudo user</span></span><br><span class="line">home_directory=<span class="string">&quot;<span class="subst">$(eval echo ~$&#123;USERNAME&#125;)</span>&quot;</span></span><br><span class="line">mkdir --parents <span class="string">&quot;<span class="variable">$&#123;home_directory&#125;</span>/.ssh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy `authorized_keys` file from root if requested</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$&#123;COPY_AUTHORIZED_KEYS_FROM_ROOT&#125;</span>&quot;</span> = <span class="literal">true</span> ]; <span class="keyword">then</span></span><br><span class="line">    cp /root/.ssh/authorized_keys <span class="string">&quot;<span class="variable">$&#123;home_directory&#125;</span>/.ssh&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add additional provided public keys</span></span><br><span class="line"><span class="keyword">for</span> pub_key <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;OTHER_PUBLIC_KEYS_TO_ADD[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;pub_key&#125;</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$&#123;home_directory&#125;</span>/.ssh/authorized_keys&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Adjust SSH configuration ownership and permissions</span></span><br><span class="line">chmod 0700 <span class="string">&quot;<span class="variable">$&#123;home_directory&#125;</span>/.ssh&quot;</span></span><br><span class="line">chmod 0600 <span class="string">&quot;<span class="variable">$&#123;home_directory&#125;</span>/.ssh/authorized_keys&quot;</span></span><br><span class="line">chown --recursive <span class="string">&quot;<span class="variable">$&#123;USERNAME&#125;</span>&quot;</span>:<span class="string">&quot;<span class="variable">$&#123;USERNAME&#125;</span>&quot;</span> <span class="string">&quot;<span class="variable">$&#123;home_directory&#125;</span>/.ssh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable root SSH login with password</span></span><br><span class="line">sed --in-place <span class="string">&#x27;s/^PermitRootLogin.*/PermitRootLogin prohibit-password/g&#x27;</span> /etc/ssh/sshd_config</span><br><span class="line"><span class="keyword">if</span> sshd -t -q; <span class="keyword">then</span></span><br><span class="line">    systemctl restart sshd</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add exception for SSH and then enable UFW firewall</span></span><br><span class="line">ufw allow OpenSSH</span><br><span class="line">ufw --force <span class="built_in">enable</span></span><br></pre></td></tr></table></figure>





<br>

<br>
]]></content>
      <categories>
        <category>Debug &amp; Config</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Anatomy of a System Design Interview</title>
    <url>/2018/System-Design-Anatomy/</url>
    <content><![CDATA[<p>System Design interviews are less about getting lucky and more about actually doing the hard work of attaining knowledge. When companies ask design questions, they want to evaluate your design skills and experience in designing large scale distributed systems. At the end, your performance in these interviews depends on the following 2 factors.</p>
<ul>
<li><strong>Your knowledge</strong> — gained either through studying or practical experience.</li>
<li><strong>Your ability to articulate your thoughts.</strong></li>
</ul>
<span id="more"></span> 

<br>

<p>Here’s a 7-step framework that I recommend to approach each problem. For keeping the examples real, we will pick up a common interview question: <strong>Design a scalable service like Twitter</strong>.</p>
<blockquote>
<p><strong>Resources:</strong></p>
<p><a href="https://www.educative.io/courses/grokking-the-system-design-interview">Grokking</a></p>
<p><a href="https://www.educative.io/courses/coderust-hacking-the-coding-interview">Coderust</a></p>
<p><a href="https://hackernoon.com/top-10-system-design-interview-questions-for-software-engineers-8561290f0444">System Design Questions</a></p>
</blockquote>
<br>

<h2 id="Requirement-Gathering"><a href="#Requirement-Gathering" class="headerlink" title="Requirement Gathering"></a>Requirement Gathering</h2><p>Many candidates think that system design interviews are all about “scale”, forgetting to put required emphasis on the “system” part of the interview.</p>
<blockquote>
<p><strong>You need to have a working “system” before you can scale it.</strong></p>
</blockquote>
<p>As the first step in your interview, you should ask questions to find the exact scope of the problem. Design questions are mostly open-ended, and they don’t have ONE correct answer. That’s why <strong>clarifying ambiguities early</strong> in the interview becomes critical. Candidates who spend time in clearly defining the end goals of the system, always have a better chance of success.</p>
<br>

<p>Here are some questions for designing Twitter that should be answered before moving on to next steps:</p>
<ul>
<li><p>Who can post a tweet? (answer: any user)</p>
</li>
<li><p>Who can read the tweet? (answer: any user — as all tweets are public)</p>
</li>
<li><p>Will a tweet contain photos or videos (answer: for now, just photos)</p>
</li>
<li><p>Can a user follow another user? (answer: yes).</p>
</li>
<li><p>Can a user ‘like’ a tweet? (answer: yes).</p>
</li>
<li><p>What gets included in the user feed (answer: tweets from everyone whom you are following).</p>
</li>
<li><p>Is feed a list of tweets in chronological order? (answer: for now, yes).</p>
</li>
<li><p>Can a user search for tweets (answer: yes).</p>
</li>
<li><p>Are we designing the client/server interaction or backend architecture or both (answer: we want to understand the interaction between client/server but we will focus on how to scale the backend).</p>
</li>
<li><p>How many total users are there (answer: we expect to reach 200 Million users in the first year).</p>
</li>
<li><p>How many daily active users are there (100 million users sign-in everyday)</p>
</li>
</ul>
<p>If you notice, some of these answers are not exactly similar to the real Twitter, and that’s ok. It’s a hypothetical problem geared towards evaluating your approach. You are just asking these questions to scope the problem that you are going to solve today. (e.g. You now don’t have to worry about handling videos or generating a timeline using algorithms etc.)</p>
<br>

<h2 id="System-interface-definition"><a href="#System-interface-definition" class="headerlink" title="System interface definition"></a>System interface definition</h2><p><strong>Define what APIs are expected from the system</strong>. This would not only establish the exact contract expected from the system but would also ensure if you haven’t gotten any requirements wrong. Some examples for our Twitter-like service would be:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">postTweet(user_id,</span> <span class="string">tweet_text,</span> <span class="string">image_url,</span> <span class="string">user_location,</span> <span class="string">timestamp,</span> <span class="string">…)</span> </span><br><span class="line"></span><br><span class="line"><span class="string">generateTimeline(user_id,</span> <span class="string">current_time)</span> </span><br><span class="line"></span><br><span class="line"><span class="string">recordUserTweetLike(user_id,</span> <span class="string">tweet_id,</span> <span class="string">timestamp,</span> <span class="string">…)</span></span><br></pre></td></tr></table></figure>


<p>If you have gathered the requirements and can identify the APIs exposed by the system, you are 50% done.</p>
<br>

<h2 id="Back-of-the-envelope-capacity-estimation"><a href="#Back-of-the-envelope-capacity-estimation" class="headerlink" title="Back-of-the-envelope capacity estimation"></a>Back-of-the-envelope capacity estimation</h2><p>It’s always a good idea to <strong>estimate the scale</strong> of the system you’re going to design. This would also help later when you’ll be focusing on scaling, partitioning, load balancing and caching.</p>
<ul>
<li><p>What <strong>scale</strong> is expected from the system (e.g., number of new tweets, number of tweet views, how many timeline generations per sec., etc.)</p>
</li>
<li><p>How much <strong>storage</strong> would we need? (This will depend on whether users can upload photos and videos in their tweets)</p>
</li>
<li><p>What <strong>network bandwidth</strong> usage are we expecting? This would be <strong>crucial in deciding how would we manage traffic and balance load between servers</strong>.</p>
</li>
</ul>
<br>

<h2 id="Defining-the-data-model"><a href="#Defining-the-data-model" class="headerlink" title="Defining the data model"></a>Defining the data model</h2><p>Defining the data model early will clarify how data will flow among different components of the system. Later, it will guide you towards better data partitioning and management. Candidate should be able to identify various entities of the system, how they will interact with each other and different aspect of data management like storage, transfer, encryption, etc. Here are some entities for our Twitter-like service:</p>
<ul>
<li>User: UserID, Name, Email, DoB, CreationData, LastLogin, etc.</li>
<li>Tweet: TweetID, Content, TweetLocation, NumberOfLikes, TimeStamp, etc.</li>
<li>UserFollows: UserdID1, UserID2</li>
<li>FavoriteTweets: UserID, TweetID, TimeStamp</li>
</ul>
<p>Which database system should we use? Would <strong>NoSQL like Cassandra</strong> best fits our needs, or we should use MySQL-like solution. What kind of blob storage should we use to store photos and videos?</p>
<br>

<h2 id="High-level-design"><a href="#High-level-design" class="headerlink" title="High-level design"></a>High-level design</h2><p>Draw a <strong>block diagram</strong> with 5–6 boxes representing core components of your system. You should identify enough components that are needed to solve the actual problem from end-to-end.</p>
<p>For Twitter, at a high level, we would need multiple application servers to serve all the read/write requests with load balancers in front of them for traffic distributions. If we’re assuming that we’ll have a lot more read traffic (as compared to write), we can decide to <strong>have separate servers for handling reads v.s writes</strong>. On the backend, we need an efficient database that can store all the tweets and can support a huge number of reads. We would also need a <strong>distributed file storage system for storing photos &amp; videos</strong> and a <strong>search index</strong> and infrastructure to enable searching of tweets.</p>
<br>

<h2 id="Detailed-design-for-selected-components"><a href="#Detailed-design-for-selected-components" class="headerlink" title="Detailed design for selected components"></a>Detailed design for selected components</h2><p>Dig deeper into 2–3 components; interviewers feedback should always guide you towards which parts of the system she wants you to explain further. You should be able to provide different approaches, their pros and cons, and why would you choose one? Remember there is no single answer, the only thing important is to <strong>consider tradeoffs between different options</strong> while keeping system constraints in mind. For instance:</p>
<ul>
<li><p>Since we’ll be storing a huge amount of data, how should we <strong>partition our data to distribute it to multiple databases</strong>? Should we try to store all the data of a user on the same database? What issues can it cause?</p>
</li>
<li><p>How would we handle <strong>high-traffic users</strong>, e.g. celebrities who have millions of followers?</p>
</li>
<li><p>Since user’s timeline will contain the most recent (and relevant) tweets, should we try to store our data in a way that is optimized to scan latest tweets?</p>
</li>
<li><p>How much and at which <strong>layer</strong> should we introduce cache to speed things up?</p>
</li>
<li><p>What components need better load balancing?</p>
</li>
</ul>
<br>

<h2 id="Identify-amp-resolve-bottlenecks"><a href="#Identify-amp-resolve-bottlenecks" class="headerlink" title="Identify &amp; resolve bottlenecks"></a>Identify &amp; resolve bottlenecks</h2><p>Try to discuss as many bottlenecks as possible and different approaches to mitigate them.</p>
<ul>
<li><p>Is there any single point of failure in our system? What are we doing to mitigate it?</p>
</li>
<li><p>Do we’ve enough replicas of the data so that if we lose a few servers, we can still serve our users? <strong>(High Availability)</strong></p>
</li>
<li><p>Similarly, do we’ve enough copies of different services running, such that a few failures will not cause total system shutdown?</p>
</li>
<li><p>How are we monitoring the performance of our service? Do we get alerts whenever critical components fail or their performance degrades?</p>
</li>
</ul>
<br>

<br>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>High Availability</title>
    <url>/2018/High-Availability/</url>
    <content><![CDATA[<p>High availability is an important subset of <strong>reliability engineering</strong>, focused towards assuring that a system or component has a high level of operational performance in a given period of time. HA can bring tremendous benefits for systems that require increased reliability.</p>
<blockquote>
<p>  High Availability: <strong>Implement a cluster of load balancers behind a Floating IP.</strong> </p>
<p>  Use Corosync  or Pacemaker.</p>
</blockquote>
<span id="more"></span> 

<br>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>With an increased demand for reliable and high-performance infrastructures designed to serve critical systems, the terms <strong>scalability</strong> and <strong>high availability</strong> couldn’t be more popular. While handling increased system load is a common concern, <strong>decreasing downtime and eliminating single points of failure</strong> are just as important. High availability is a quality of infrastructure design at scale that addresses these latter considerations.</p>
<p>In this post, we will discuss what exactly high availability means and how it can improve the infrastructure’s reliability.</p>
<br>

<h2 id="High-Availability-HA"><a href="#High-Availability-HA" class="headerlink" title="High Availability (HA)"></a>High Availability (HA)</h2><p>In computing, the term availability is used to describe the period of time when a service is available, as well as the time required by a system to respond to a request made by a user. High availability is a quality of a system or component that assures a high level of operational performance for a given period of time.</p>
<br>

<h3 id="Measuring-Availability"><a href="#Measuring-Availability" class="headerlink" title="Measuring Availability"></a>Measuring Availability</h3><p>Availability is often expressed as a percentage indicating how much uptime is expected from a particular system or component in a given period of time, where a value of 100% would indicate that the system never fails. For instance, a system that guarantees 99% of availability in a period of one year can have up to 3.65 days of downtime (1%).</p>
<p>These values are calculated based on several factors, including both scheduled and unscheduled maintenance periods, as well as the time to recover from a possible system failure.</p>
<br>

<h3 id="How-HA-Works"><a href="#How-HA-Works" class="headerlink" title="How HA Works"></a>How HA Works</h3><p>High availability functions as a <strong>failure response mechanism for infrastructure</strong>. The way that it works is quite simple conceptually but typically requires some specialized software and configuration.</p>
<br>

<h3 id="When-Is-HA-Important"><a href="#When-Is-HA-Important" class="headerlink" title="When Is HA Important"></a>When Is HA Important</h3><p>When setting up robust production systems, minimizing downtime and service interruptions is often a high priority. Regardless of how reliable your systems and software are, problems can occur that can bring down your applications or your servers.</p>
<p>Implementing high availability for your infrastructure is a useful strategy to reduce the impact of these types of events. <strong>Highly available systems can recover from server or component failure automatically</strong>.</p>
<br>

<h2 id="What-Makes-a-System-HA"><a href="#What-Makes-a-System-HA" class="headerlink" title="What Makes a System HA"></a>What Makes a System HA</h2><p>One of the goals of high availability is to <strong>eliminate single points of failure</strong> in your infrastructure. A single point of failure is a component of your technology stack that would cause a service interruption if it became unavailable. As such, any component that is a requisite for the proper functionality of your application that does not have redundancy is considered to be a single point of failure.</p>
<p>To eliminate single points of failure, each layer of your stack must be prepared for redundancy. For instance, imagine you have an infrastructure consisting of two identical, redundant web servers behind a load balancer. The traffic coming from clients will be equally distributed between the web servers, but if one of the servers goes down, the load balancer will redirect all traffic to the remaining online server.</p>
<p>The web server layer in this scenario is not a single point of failure because:</p>
<ul>
<li><p>Redundant components for the same task are in place</p>
</li>
<li><p>The mechanism on top of this layer (the load balancer) is able to detect failures in the components and adapt its behavior for a timely recovery</p>
</li>
</ul>
<p>But what happens if the load balancer goes offline?</p>
<p>With the described scenario, which is not uncommon in real life, the load balancing layer itself remains a single point of failure. Eliminating this remaining single point of failure, however, can be challenging; even though you can easily configure an additional load balancer to achieve redundancy, there isn’t an obvious point above the load balancers to implement failure detection and recovery.</p>
<p><strong>Redundancy alone cannot guarantee high availability</strong>. A mechanism must be in place for <strong>detecting failures and taking action</strong> when one of the components of your stack becomes unavailable.</p>
<p>Failure detection and recovery for redundant systems can be implemented using a <strong>top-to-bottom approach</strong>: the layer on top becomes responsible for monitoring the layer immediately beneath it for failures. In our previous example scenario, the load balancer is the top layer. If one of the web servers (bottom layer) becomes unavailable, the load balancer will stop redirecting requests for that specific server.</p>
<p><img data-src="/images/posts/180918-1.png" alt="01"></p>
<p>This approach tends to be simpler, but it has limitations: <strong>there will be a point in your infrastructure where a top layer is either nonexistent or out of reach, which is the case with the load balancer layer</strong>. Creating a failure detection service for the load balancer in an external server would simply create a new single point of failure.</p>
<p>With such a scenario, a <strong>distributed approach</strong> is necessary. <strong>Multiple redundant nodes must be connected together as a cluster</strong> where each node should be equally capable of failure detection and recovery.</p>
<p><img data-src="/images/posts/180918-2.png" alt="02"></p>
<p>For the load balancer case, however, there’s an additional complication, due to the way nameservers work. Recovering from a load balancer failure typically means a failover to a redundant load balancer, which implies that a DNS change must be made in order to point a domain name to the redundant load balancer’s IP address. A change like this can take a considerable amount of time to be propagated on the Internet, which would cause a serious downtime to this system.</p>
<p>A possible solution is to use <strong><a href="https://www.digitalocean.com/community/tutorials/how-to-configure-dns-round-robin-load-balancing-for-high-availability">DNS round-robin load balancing</a></strong>. However, this approach is <strong>not reliable</strong> as it leaves failover the client-side application.</p>
<p>A more robust and reliable solution is to use <strong>systems that allow for flexible IP address remapping</strong>, such as <strong>floating IPs</strong>. On demand IP address remapping eliminates the propagation and caching issues inherent in DNS changes by providing a <strong>static IP address that can be easily remapped</strong> when needed. The domain name can remain associated with the same IP address, while the <strong>IP address itself is moved between servers</strong>.</p>
<p>This is how a highly available infrastructure using <a href="https://www.digitalocean.com/docs/networking/floating-ips/">Floating IPs</a> looks like:</p>
<p><img data-src="/images/posts/180918-3.png" alt="03"></p>
<br>

<h2 id="What-System-Components-Are-Required-for-HA"><a href="#What-System-Components-Are-Required-for-HA" class="headerlink" title="What System Components Are Required for HA"></a>What System Components Are Required for HA</h2><p>There are several components that must be carefully taken into consideration for implementing high availability in practice. Much more than a software implementation, high availability depends on factors such as:</p>
<ul>
<li><p><strong>Environment</strong>: if all your servers are located in the same geographical area, an environmental condition such as an earthquake or flooding could take your whole system down. Having <strong>redundant servers in different datacenters</strong> and geographical areas will increase reliability.</p>
</li>
<li><p><strong>Hardware</strong>: highly available servers should be resilient to power outages and hardware failures, including hard disks and network interfaces.</p>
</li>
<li><p><strong>Software</strong>: the whole software stack, including the operating system and the application itself, must be prepared for handling unexpected failure that could potentially require a system restart, for instance.</p>
</li>
<li><p><strong>Data</strong>: data loss and inconsistency can be caused by several factors, and it’s not restricted to hard disk failures. Highly available systems must account for data safety in the event of a failure.</p>
</li>
<li><p><strong>Network</strong>: unplanned network outages represent another possible point of failure for highly available systems. It is important that a redundant network strategy is in place for possible failures.</p>
</li>
</ul>
<br>

<h2 id="What-Software-Can-Be-Used-to-Configure-HA"><a href="#What-Software-Can-Be-Used-to-Configure-HA" class="headerlink" title="What Software Can Be Used to Configure HA"></a>What Software Can Be Used to Configure HA</h2><p>Each layer of a highly available system will have different needs in terms of software and configuration. However, at the application level, load balancers represent an essential piece of software for creating any high availability setup.</p>
<p><a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts">HAProxy</a> is a common choice for <strong>load balancing</strong>, as it can handle load balancing at multiple layers, and for different kinds of servers, including database servers.</p>
<p>Moving up in the system stack, it is important to <strong>implement a reliable redundant solution for your application entry point, normally the load balancer</strong>. To remove this single point of failure, as mentioned before, we need to <em><strong>implement a cluster of load balancers behind a Floating IP</strong></em>. <strong>Corosync</strong> and <strong>Pacemaker</strong> are popular choices for creating such a setup, on both Ubuntu and CentOS servers.</p>
<br>

<br>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Notes on System Design</title>
    <url>/2018/Notes-On-System-Design/</url>
    <content><![CDATA[<p>In this post, we will cover a few notes on scaling the system, including Load Balancer &amp; Reverse Proxy, Vertical &amp; Horizontal scaling, and links to some architectures.</p>
<span id="more"></span> 

<br>

<h2 id="Load-Balancer-amp-Reverse-Proxy"><a href="#Load-Balancer-amp-Reverse-Proxy" class="headerlink" title="Load Balancer &amp; Reverse Proxy"></a><a href="https://serverfault.com/questions/127021/what-is-the-difference-between-load-balancer-and-reverse-proxy">Load Balancer &amp; Reverse Proxy</a></h2><p><strong>A reverse proxy</strong> accepts a request from a client, forwards it to a server that can fulfill it, and returns the server’s response to the client (which means a server behind the Reverse Proxy can communicate with somewhat different features of a protocol or a different protocol).</p>
<p><strong>A load balancer</strong> distributes incoming client requests among a group of servers, in each case returning the response from the selected server to the appropriate client.</p>
<br>

<p>When you refer to a <strong>load balancer</strong> you are referring to a very specific thing - a server or device that balances inbound requests across two or more web servers to spread the load. A <strong>reverse proxy</strong>, however, typically has any number of features:</p>
<ul>
<li><p><strong>load balancing</strong>: as discussed above</p>
</li>
<li><p><strong>caching</strong>: it can cache content from the web server(s) behind it and thereby reduce the load on the web server(s) and return some static content back to the requester without having to get the data from the web server(s)</p>
</li>
<li><p><strong>security</strong>: it can protect the web server(s) by preventing direct access from the internet; it might do this through simple means by just obfuscating the web server(s) or it may have some more active components that actually review inbound requests looking for malicious code</p>
</li>
<li><p><strong>SSL acceleration</strong>: when SSL is used; it may serve as a termination point for those SSL sessions so that the workload of dealing with the encryption is offloaded from the web server(s)</p>
</li>
</ul>
<p>Also, a reverse proxy is specific to web servers. Load balancers however can deal with a lot of other protocols. While the web (HTTP) is the big idea nowadays, things like DNS, mail (SMTP, IMAP), etc. can be load balanced as well. It’s just nowadays when most people think “Internet” or “IP network” they think of the web. There’s a bunch more stuff out there that may be more obscure, or more of a niche.</p>
<br>

<h2 id="Vertical-amp-Horizontal-Scaling"><a href="#Vertical-amp-Horizontal-Scaling" class="headerlink" title="Vertical &amp; Horizontal Scaling"></a>Vertical &amp; Horizontal Scaling</h2><p><strong>Vertical Scaling</strong></p>
<p>Vertical scaling, or improving the capabilities of a node/server, gives greater capacity to the node but does not decrease the overall load on existing members of the cluster. That is, the ability for the improved node to handle existing load is increased, but the load itself is unchanged. Reasons to scale vertically include increasing IOPS, increasing CPU/RAM capacity, and increasing disk capacity.</p>
<br>

<p><strong>Horizontal Scaling</strong></p>
<p>Horizontal scaling, or increasing the number of nodes in the cluster, reduces the responsibilities of each member node by spreading the keyspace wider and providing additional endpoints for client connections. That is, the capacity of each individual node does not change, but its load is decreased. Reasons to scale horizontally include increasing I/O concurrency, reducing the load on existing nodes, and increasing disk capacity.</p>
<br>

<h2 id="Architectures"><a href="#Architectures" class="headerlink" title="Architectures"></a>Architectures</h2><ul>
<li><a href="https://blog.cloudflare.com/a-brief-anycast-primer/">A Brief Primer on Anycast</a></li>
<li><a href="https://blog.imgur.com/2015/09/15/tech-tuesday-engineering-at-imgur/">imgur</a></li>
<li><a href="http://highscalability.com/blog/2013/8/26/reddit-lessons-learned-from-mistakes-made-scaling-to-1-billi.html">Reddit</a></li>
<li><a href="https://nickcraver.com/blog/2016/02/17/stack-overflow-the-architecture-2016-edition/">Stack Overflow</a></li>
<li><a href="https://edx.readthedocs.io/projects/edx-developer-docs/en/latest/">Open edx</a></li>
<li><a href="https://hackernoon.com/how-not-to-design-netflix-in-your-45-minute-system-design-interview-64953391a054">Netflix</a></li>
</ul>
<br>

<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Scaling with AWS - From 1 to 11 Million+ Users</title>
    <url>/2018/Scaling-with-AWS/</url>
    <content><![CDATA[<p>In this post, we will talk about scaling with AWS.</p>
<blockquote>
<p>  Reference:</p>
<p>  <a href="https://aws.amazon.com/architecture">AWS Architecture</a></p>
<p>  <a href="http://highscalability.com/blog/2016/1/11/a-beginners-guide-to-scaling-to-11-million-users-on-amazons.html">A Beginner’s Guide To Scaling To 11 Million+ Users On Amazon’s AWS</a></p>
<p>  <a href="https://expeditedsecurity.com/aws-in-plain-english/">AWS in plain English</a></p>
</blockquote>
<span id="more"></span> 

<br>

<p>How do you scale a system from one user to more than 11 million users? Joel Williams, Amazon Web Services Solutions Architect, gives an excellent talk on just that subject: <a href="https://www.youtube.com/watch?v=vg5onp8TU6Q&list=PLhr1KZpdzukdRxs_pGJm-qSy5LayL6W_Y">AWS re:Invent 2015 Scaling Up to Your First 10 Million Users</a>.</p>
<p>As you might expect since this is a talk by Amazon, then Amazon services are always front and center as the solution to any problem. Their platform play is impressive and instructive. It’s obvious by how the pieces all fit together Amazon has done a great job of mapping out what users need and then making sure they have a product in that space. </p>
<br>

<p><strong>Some of the interesting takeaways:</strong></p>
<ul>
<li><p>Start with SQL and only move to NoSQL when necessary.</p>
</li>
<li><p>A consistent theme is take components and separate them out. This allows those components to scale and fail independently. It applies to breaking up tiers and creating microservices.</p>
</li>
<li><p>Only invest in tasks that differentiate you as a business, don’t reinvent the wheel.</p>
</li>
<li><p>Scalability and redundancy are not two separate concepts, you can often do both at the same time.</p>
</li>
</ul>
<br>

<h2 id="The-Basics"><a href="#The-Basics" class="headerlink" title="The Basics"></a>The Basics</h2><h3 id="12-Regions"><a href="#12-Regions" class="headerlink" title="12 Regions"></a>12 Regions</h3><ul>
<li><p>A Region is a physical location in the world where Amazon has multiple Availability Zones. There are regions in: North America; South America; Europe; Middle East; Africa; Asia Pacific.</p>
</li>
<li><p>An Availability Zone (AZ) is generally a single datacenter, though they can be constructed out of multiple datacenters.</p>
</li>
<li><p>Each AZ is separate enough that they have separate power and Internet connectivity.</p>
</li>
<li><p>The only connection between AZs is a low latency network. AZs can be 5 or 15 miles apart, for example. The network is fast enough that your application can act like all AZs are in the same datacenter.</p>
</li>
<li><p>Each Region has at least two Availability Zones. There are 32 AZs total.</p>
</li>
<li><p>Using AZs it’s possible to create a high availability architecture for your application.</p>
</li>
<li><p>At least 9 more Availability Zones and 4 more Regions are coming in 2016.</p>
</li>
</ul>
<br>

<h3 id="53-Edge-Locations"><a href="#53-Edge-Locations" class="headerlink" title="53 Edge Locations"></a>53 Edge Locations</h3><ul>
<li><p>Edge locations are used by CloudFront, Amazon’s Content Distribution Network (CDN) and Route53, Amazon’s managed DNS server.</p>
</li>
<li><p>Edge locations enable users to access content with a very low latency no matter where they are in the world.</p>
</li>
</ul>
<br>

<h3 id="Building-Block-Services"><a href="#Building-Block-Services" class="headerlink" title="Building Block Services"></a><a href="https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/">Building Block Services</a></h3><ul>
<li><p>AWS has created a number of services that use multiple AZs internally to be highly available and fault tolerant. </p>
</li>
<li><p>You can use these services in your application, for a fee, without having to worry about making them highly available yourself.</p>
</li>
<li><p>Some services that exist within an AZ: CloudFront, Route 53, S3, DynamoDB, Elastic Load Balancing, EFS, Lambda, SQS, SNS, SES, SWF.</p>
</li>
<li><p>A highly available architecture can be created using services even though they exist within a single AZ.</p>
</li>
</ul>
<br>

<h2 id="1-User"><a href="#1-User" class="headerlink" title="1 User"></a>1 User</h2><p>In this scenario you are the only user and you want to get a website running. Your architecture will look something like:</p>
<ul>
<li><p>Run on a single instance, maybe a type t2.micro. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity and give you the flexibility to choose the appropriate mix of resources for your applications.</p>
</li>
<li><p>The one instance would run the entire web stack, for example: web app, database, management, etc.</p>
</li>
<li><p>Use <a href="https://aws.amazon.com/route53/">Amazon Route 53</a> for the DNS.</p>
</li>
<li><p>Attach a single Elastic IP address to the instance.</p>
</li>
<li><p>Works great, for a while.</p>
</li>
</ul>
<br>

<h3 id="Vertical-Scaling"><a href="#Vertical-Scaling" class="headerlink" title="Vertical Scaling"></a>Vertical Scaling</h3><p>You need a bigger box (more resources). Simplest approach to scaling is choose a larger instance type. Maybe a c4.8xlarge or m3.2xlarge, for example.</p>
<ul>
<li><p>Just stop your instance and choose a new instance type and you’re running with more power.</p>
</li>
<li><p>There is a wide mix of different hardware configurations to choose from. You can have a system with 244 gigs of RAM (2TB of RAM types are coming soon). Or one with 40 cores. There are High I/O instances, High CPU Instances, High storage instances.</p>
</li>
<li><p>Some Amazon services come with a Provisioned IOPS option to guarantee performance. The idea is you can perhaps use a smaller instance type for your service and make use of Amazon services like DynamoDB that can deliver scalable services so you don’t have to.</p>
</li>
<li><p>Vertical scaling has a big problem: there’s <strong>no failover, no redundancy</strong>. If the instance has a problem your website will die. All your eggs are in one basket.</p>
</li>
<li><p>Eventually a single instances can only get so big. You need to do something else.</p>
</li>
</ul>
<br>

<h2 id="10-Users"><a href="#10-Users" class="headerlink" title="10 Users"></a>10 Users</h2><p>Separate out a single host into multiple hosts</p>
<ul>
<li><p>One host for the web site.</p>
</li>
<li><p>One host for the database. Run any database you want, but you are on the hook for the database administration.</p>
</li>
<li><p>Using separate hosts allows the web site and the database to be scaled independently of each other. Perhaps your database will need a bigger machine than your web site, for example.</p>
</li>
</ul>
<p>Or instead of running your own database you could use a database service.</p>
<ul>
<li><p>Are you a database admin? Do your really want to worry about backups? High availability? Patches? Operating systems?</p>
</li>
<li><p>A big advantage of using a service is you can have a multi Availability Zone database setup with a single click. You won’t have to worry about replication or any of that sort of thing. Your database will be highly available and reliable.</p>
</li>
</ul>
<p>As you might imagine Amazon has several  fully managed database services to sell you:</p>
<ul>
<li><p>Amazon RDS (Relational Database Service). There are many options: Microsoft SQL Server, Oracle, MySQL, PostgreSQL, MariaDB, Amazon Aurora.</p>
</li>
<li><p>Amazon DynamoDB. A NoSQL managed database.</p>
</li>
<li><p>Amazon Redshift. A petabyte scale data warehouse system.</p>
</li>
</ul>
<p>More on Amazon Aurora:</p>
<ul>
<li><p>Automatic storage scaling up to 64TB. You no longer have to provision the storage for your data.</p>
</li>
<li><p>Up to 15 read read-replicas</p>
</li>
<li><p>Continuous (incremental) backups to S3.</p>
</li>
<li><p>6-way replication across 3 AZs. This helps you handle failure.</p>
</li>
<li><p>MySQL compatible.</p>
</li>
</ul>
<p>Start with a SQL database instead of a NoSQL database.</p>
<ul>
<li><p>The technology is established.</p>
</li>
<li><p>There’s lots of existing code, communities, support groups, books, and tools.</p>
</li>
<li><p>You aren’t going to break a SQL database with your first 10 million users. Not even close. (unless your data is huge).</p>
</li>
<li><p>Clear patterns to scalability.</p>
</li>
</ul>
<p>When might you need start with a NoSQL database?</p>
<ul>
<li><p>If you need to store &gt; 5 TB of data in year one or you have an incredibly data intensive workload.</p>
</li>
<li><p>Your application has super low-latency requirements.</p>
</li>
<li><p>You need really high throughput. You need to really tweak the IOs you are getting both on the reads and the writes.</p>
</li>
<li><p>You don’t have any relational data.</p>
</li>
</ul>
<br>

<h2 id="100-Users"><a href="#100-Users" class="headerlink" title="100 Users"></a>100 Users</h2><ul>
<li><p>Use a separate host for the web tier.</p>
</li>
<li><p>Store the database on Amazon RDS. It takes care of everything.</p>
</li>
</ul>
<br>

<h2 id="1k-Users"><a href="#1k-Users" class="headerlink" title="1k Users"></a>1k Users</h2><p>As architected your application has availability issues. If the host for your web service fails then your web site goes down.</p>
<p>So you need another web instance in another Availability Zone. That’s OK because the latency between the AZs is in the low single digit milliseconds, almost like they right next to each other.</p>
<p>You also need to a slave database to RDS that runs in another AZ. If there’s a problem with the master your application will automatically switch over to the slave. There are no application changes necessary on the failover because your application always uses the same endpoint.</p>
<p>An <strong>Elastic Load Balancer (ELB)</strong> is added to the configuration to load balance users between your two web host instances in the two AZs.</p>
<ul>
<li><p>ELB is a highly available managed load balancer. The ELB exists in all AZs. It’s a single DNS endpoint for your application. Just put it in Route 53 and it will load balance across your web host instances.</p>
</li>
<li><p>The ELB has Health Checks that make sure traffic doesn’t flow to failed hosts.</p>
</li>
<li><p>It scales without your doing anything. If it sees additional traffic it scales behind the scenes both horizontally and vertically. You don’t have to manage it. As your applications scales so is the ELB.</p>
</li>
</ul>
<br>

<h2 id="10k-100k"><a href="#10k-100k" class="headerlink" title="10k - 100k"></a>10k - 100k</h2><p>The previous configuration has 2 instances behind the ELB, in practice you can have 1000s of instances behind the ELB. This is horizontal scaling.</p>
<p>You’ll need to add more read replicas to the database, to RDS. This will take load off the write master.</p>
<p>Consider performance and efficiency by lightening the load off your web tier servers by moving some of the traffic elsewhere. Move static content in your web app to Amazon S3 and Amazon CloudFront. CloudFront is the Amazon’s CDN that stores your data in the 53 edge locations across the world.</p>
<p><strong>Amazon S3</strong> is an object base store.</p>
<ul>
<li><p>It’s not like EBS, it’s not storage that’s attached to an EC2 instance, it’s an object store, not a block store.</p>
</li>
<li><p>It’s a great place to store static content, like javascript, css, images, videos. This sort of content does not need to sit on an EC2 instance.</p>
</li>
<li><p>Highly durable, 11 9’s of reliability.</p>
</li>
<li><p>Infinitely scalable, throw as much data as it as you want. Customers store multiple petabytes of data in S3.</p>
</li>
<li><p>Objects of up to 5TB in size are supported.</p>
</li>
<li><p>Encryption is supported. You can use Amazon’s encryption, your encryption, or an encryption service.</p>
</li>
</ul>
<p>Amazon CloudFront is cache for your content.</p>
<ul>
<li><p>It caches content at the edge locations to provide your users the lowest latency access possible.</p>
</li>
<li><p>Without a CDN your users will experience higher latency access to your content. Your servers will also be under higher load as they are serving the content as well as handling the web requests.</p>
</li>
<li><p>One customer needed to serve content at 60 Gbps. The web tier didn’t even know that was going on, CloudFront handled it all.</p>
</li>
</ul>
<p>You can also lighten the load by shifting session state off your web tier: <strong>Store the session state in ElastiCache or DynamoDB</strong>. This approach also sets your system up to support auto scaling in the future.</p>
<p>You can also lighten the load by <strong>caching data</strong> from your database into ElastiCache. Your database doesn’t need to handle all the gets for data. A cache can handle a lot of that work and leaves the database to handle more important traffic.</p>
<p>Amazon DynamoDB - A managed NoSQL database</p>
<ul>
<li><p>You provision the throughput you want. You dial up the read and write performance you want to pay for.</p>
</li>
<li><p>Supports fast, predictable performance.</p>
</li>
<li><p>Fully distributed and fault tolerant. It exists in multiple Availability Zones.</p>
</li>
<li><p>It’s a key-value store. JSON is supported.</p>
</li>
<li><p>Documents up to 400KB in size are supported.</p>
</li>
</ul>
<p>Amazon Elasticache - a managed Memcached or Redis</p>
<ul>
<li><p>Managing a memcached cluster isn’t making you more money so let Amazon do that for you. That’s the pitch.</p>
</li>
<li><p>The clusters are automatically scaled for you. It’s a self-healing infrastructure, if nodes fail new nodes are started automatically.</p>
</li>
</ul>
<p>You can also lighten the load by shifting dynamic content to CloudFront. A lot of people know CloudFront can handle static content, like files, but it can also <a href="https://aws.amazon.com/cloudfront/dynamic-content/">handle some dynamic content</a>. </p>
<br>

<h3 id="Auto-Scaling"><a href="#Auto-Scaling" class="headerlink" title="Auto Scaling"></a><a href="https://aws.amazon.com/autoscaling/">Auto Scaling</a></h3><p>If you provision enough capacity to always handle your peak traffic load, Black Friday, for example, you are wasting money. It would be better to match compute power with demand. That’s what Auto Scaling let’s you do, the automatic resizing of compute clusters.</p>
<p>You can define the minimum and maximum size of your pools. As a user you decide what’s the smallest number of instances in your cluster and the largest number of instances.</p>
<p><strong>CloudWatch</strong> is a management service that’s embedded into all applications.</p>
<ul>
<li><p>CloudWatch events drive scaling.</p>
</li>
<li><p>Are you going to scale on CPU utilization? Are you going to scale on latency? On network traffic?</p>
</li>
<li><p>You can also push your own custom metrics into CloudWatch. If you want to scale on something application specific you can push that metric into CloudWatch and then tell Auto Scaling you want to scale on that metric.</p>
</li>
</ul>
<br>

<h2 id="500K"><a href="#500K" class="headerlink" title="500K +"></a>500K +</h2><p>The addition from the previous configuration is auto scaling groups are added to the web tier. The auto scaling group includes the two AZs, but can expand to 3 AZs, up to as many as are in the same region. Instances can pop up in multiple AZs not just for scalability, but for availability.</p>
<p>The example has 3 web tier instances in each AZ, but it could be thousands of instances. You could say you want a minimum of 10 instances and a maximum of a 1000.</p>
<ul>
<li><p>ElastiCache is used to offload popular reads from the database.</p>
</li>
<li><p>DynamoDB is used to offload Session data.</p>
</li>
<li><p>You need to add monitoring, metrics and logging.</p>
<ul>
<li><p>Host level metrics. Look at a single CPU instance within an autoscaling group and figure out what’s going wrong.</p>
</li>
<li><p>Aggregate level metrics. Look at metrics on the Elastic Load Balancer to get feel for performance of the entire set of instances.</p>
</li>
<li><p>Log analysis. Look at what the application is telling you using CloudWatch logs. CloudTrail helps you analyze and manage logs.</p>
</li>
<li><p>External Site Performance. Know what your customers are seeing as end users. Use a service like New Relic or Pingdom.</p>
</li>
</ul>
</li>
</ul>
<p>You need to know what your customers are saying. Is their latency bad? Are they getting an error when they go to your web page?</p>
<p>Squeeze as much performance as you can from your configuration. Auto Scaling can help with that. You don’t want systems that are at 20% CPU utilization.</p>
<br>

<h3 id="Automation"><a href="#Automation" class="headerlink" title="Automation"></a>Automation</h3><p>The infrastructure is getting big, it can scale to 1000s of instances. We have read replicas, we have horizontal scaling, but we need some automation to help manage it all, we don’t want to manage each individual instance.</p>
<p>There’s a hierarchy of automation tools.</p>
<ul>
<li><p>Do it yourself: Amazon EC2, AWS CloudFormation.</p>
</li>
<li><p>Higher-level services: AWS Elastic Beanstalk, AWS OpsWorks</p>
<ul>
<li><p><strong>AWS Elastic Beanstalk</strong>: manages the infrastructure for your application automatically. It’s convenient but there’s not a lot of control.</p>
</li>
<li><p><strong>AWS OpsWorks</strong>: an environment where you build your application in layers, you use Chef recipes to manage the layers of your application.</p>
</li>
<li><p>Also enables the ability to do Continuous Integration and deployment.</p>
</li>
</ul>
</li>
</ul>
<p>AWS CloudFormation: been around the longest.</p>
<ul>
<li><p>Offers the most flexibility because it offers a templatized view of your stack. It can be used to build your entire stack or just components of the stack.</p>
</li>
<li><p>If you want to update your stack you update the Cloud Formation template it will update just that one piece of your application.</p>
</li>
<li><p>Lots of control, but less convenient.</p>
</li>
</ul>
<p>AWS CodeDeploy: Deploys your code to a fleet of EC2 instances.</p>
<ul>
<li><p>Can deploy to one or thousands of instances.</p>
</li>
<li><p>Code Deploy can point to an auto scaling configuration so code is deployed to a group of instances.</p>
</li>
<li><p>Can also be used in conjunction with Chef and Puppet.</p>
</li>
</ul>
<br>

<h3 id="Decouple-Infrastructure"><a href="#Decouple-Infrastructure" class="headerlink" title="Decouple Infrastructure"></a>Decouple Infrastructure</h3><ul>
<li><p><strong>Use SOA/microservices</strong>.  Take components from your tiers and separate them out. Create separate services like when you separated the web tier from the database tier.</p>
</li>
<li><p>The individual services can then be scaled independently. This gives you a lot of flexibility for scaling and high availability.</p>
</li>
<li><p>SOA is a key component of the architectures built by Amazon.</p>
</li>
<li><p>Loose coupling sets you free.</p>
<ul>
<li><p>You can scale and fail components independently.</p>
</li>
<li><p>If a worker node fails in pulling work from SQS does it matter? No, just start another one. Things are going to fail, let’s build an architecture that handles failure.</p>
</li>
<li><p>Design everything as a black box.</p>
</li>
<li><p>Decouple interactions.</p>
</li>
<li><p>Favor services with built-in redundancy and scalability rather than building your own.</p>
</li>
</ul>
</li>
</ul>
<br>

<h3 id="Don’t-Reinvent-The-Wheel"><a href="#Don’t-Reinvent-The-Wheel" class="headerlink" title="Don’t Reinvent The Wheel"></a>Don’t Reinvent The Wheel</h3><p>Only invest in tasks that differentiate you as a business.</p>
<p>Amazon has a lot of services that are inherently fault tolerant because they span multiple AZs. For example: queuing, email, transcoding, search, databases, monitoring, metrics, logging, compute. You don’t have to build these yourself.</p>
<ul>
<li><p>SQS: queueing service.</p>
<ul>
<li>The first Amazon service offered.</li>
</ul>
</li>
<li><p>It spans multiple AZs so it’s fault tolerant.</p>
<ul>
<li>It’s scalable, secure, and simple.</li>
</ul>
</li>
<li><p>Queuing can help your infrastructure by helping you pass messages between different components of your infrastructure.</p>
<ul>
<li>Take for example a Photo CMS. The systems that collects the photos and processes them should be two different systems. They should be able to scale independently. They should be loosely coupled. Ingest a photo, put it in queue, and workers can pull photos off the queue and do something with them.</li>
</ul>
  <br></li>
<li><p>AWS Lambda: lets you run code without provisioning or managing servers.</p>
<ul>
<li><p>Great tool for allowing you to decouple your application.</p>
</li>
<li><p>In the Photo CMS example Lambda can respond to S3 events so when a S3 file is added the Lambda function to process is automatically triggered.</p>
</li>
<li><p>We’ve done away with EC2. It scales out for you and there’s no OS to manage.</p>
</li>
</ul>
</li>
</ul>
<br>

<h2 id="1-Million"><a href="#1-Million" class="headerlink" title="1 Million +"></a>1 Million +</h2><p>Reaching a million users and above requires bits of all the previous points:</p>
<ul>
<li>Multi-AZ</li>
<li>Elastic Load Balancing between tiers. Not just on the web tier, but also on the application tier, data tier, and any other tier you have.</li>
<li>Auto Scaling</li>
<li>Service Oriented Architecture</li>
<li>Serve Content Smartly with S3 and CloudFront</li>
<li>Put caching in front of the DB</li>
<li>Move state off the web tier.</li>
</ul>
<br>

<p>New to add:</p>
<ul>
<li><p>Use Amazon SES to send email.</p>
</li>
<li><p>Use CloudWatch for monitoring.</p>
</li>
</ul>
<br>

<h2 id="10-Million"><a href="#10-Million" class="headerlink" title="10 Million +"></a>10 Million +</h2><p>As we get bigger we’ll hit issues in the data tier. You will potentially start to run into issues with your database around contention with the write master, which basically means you can only send so much write traffic to one server. How do you solve it?</p>
<ul>
<li><p><strong>Federation</strong> - splitting into multiple DBs based on function. </p>
</li>
<li><p>For example, create a Forums Database, a User Database, a Products Database. You might have had these in a single database before, now spread them out.</p>
</li>
<li><p>The different databases can be scaled independently of each other.</p>
</li>
<li><p>The downsides: you can’t do cross database queries; it delays getting to the next strategy, which is sharding.</p>
</li>
<li><p><strong>Sharding</strong> -  splitting one dataset across multiple hosts</p>
</li>
<li><p>More complex at the application layer, but there’s no practical limit on scalability.</p>
</li>
<li><p>For example, in a Users Database ⅓ of the users might be sent to one shard, and the last third to another shard, and another shard to another third.</p>
</li>
<li><p>Moving some functionality to other types of DBs</p>
<ul>
<li><p>Start thinking about a NoSQL database.</p>
</li>
<li><p>If you have data that doesn’t require complex joins, like say a leaderboard, rapid ingest of clickstream/log data, temporary data, hot tables, metadata/lookup tables, then consider moving it to a NoSQL database.</p>
</li>
<li><p>This means they can be scaled independently of each other.</p>
</li>
</ul>
</li>
</ul>
<br>

<h2 id="11-Million"><a href="#11-Million" class="headerlink" title="11 Million +"></a>11 Million +</h2><p>Scaling is an iterative process. As you get bigger there’s always more you can do.</p>
<ul>
<li><p>Fine tune your application.</p>
</li>
<li><p>More SOA of features/functionality.</p>
</li>
<li><p>Go from Multi-AZ to multi-region.</p>
</li>
<li><p>Start to build custom solutions to solve your particular problem that nobody has ever done before. If you need to serve a billion customers you may need custom solutions.</p>
</li>
<li><p>Deep analysis of your entire stack.</p>
</li>
</ul>
<br>

<h2 id="In-Review"><a href="#In-Review" class="headerlink" title="In Review"></a>In Review</h2><ul>
<li><p>Use a multi-AZ infrastructure for reliability.</p>
</li>
<li><p>Make use of self-scaling services like ELB, S3, SQS, SNS, DynamoDB, etc.</p>
</li>
<li><p>Build in redundancy at every level. Scalability and redundancy are not two separate concepts, you can often do both at the same time.</p>
</li>
<li><p>Start with a traditional relational SQL database.</p>
</li>
<li><p>Cache data both inside and outside your infrastructure.</p>
</li>
<li><p>Use automation tools in your infrastructure.</p>
</li>
<li><p>Make sure you have good metrics/monitoring/logging in place. Make sure you are finding out what your customers experience with your application.</p>
</li>
<li><p>Split tiers into individual services (SOA) so they can scale and fail independently of each other.</p>
</li>
<li><p>Use Auto Scaling once you’re ready for it.</p>
</li>
<li><p>Don’t reinvent the wheel, use a managed service instead of coding your own, unless it’s absolutely necessary.</p>
</li>
<li><p>Move to NoSQL if and when it makes sense.</p>
</li>
</ul>
<br>

<br>
]]></content>
      <categories>
        <category>Resources</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>AWS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Five Common Server Setups</title>
    <url>/2018/Common-Server-Setups/</url>
    <content><![CDATA[<p>When deciding which server architecture to use for your environment, there are many factors to consider, such as performance, scalability, availability, reliability, cost, and ease of management.</p>
<p>Here is a list of commonly used server setups, with a short description of each, including pros and cons. Keep in mind that all of the concepts covered here can be used in various combinations with one another, and that every environment has different requirements, so there is no single, correct configuration.</p>
<span id="more"></span> 

<br>

<h2 id="Everything-On-One-Server"><a href="#Everything-On-One-Server" class="headerlink" title="Everything On One Server"></a>Everything On One Server</h2><blockquote>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-on-ubuntu-14-04">LAMP</a>: Linux, Apache, MySQL, PHP</p>
</blockquote>
<p>The entire environment resides on a single server. For a typical web application, that would include the <strong>web server, application server, and database server</strong>. A common variation of this setup is a LAMP stack, which stands for Linux, Apache, MySQL, and PHP, on a single server.</p>
<p><strong>Use Case</strong>: Good for setting up an application quickly, as it is the simplest setup possible, but it offers little in the way of <strong>scalability</strong> and <strong>component isolation</strong>.</p>
<p><img data-src="/images/posts/180809-1.png" alt="01"></p>
<p><strong>Pros:</strong></p>
<ul>
<li>Simple</li>
</ul>
<br>

<p><strong>Cons:</strong></p>
<ul>
<li><p>Application and database contend for the same server resources (CPU, Memory, I/O, etc.) which, aside from possible poor performance, can make it difficult to determine the source (application or database) of poor performance</p>
</li>
<li><p>Not readily horizontally scalable</p>
</li>
</ul>
<br>

<h2 id="Separate-Database-Server"><a href="#Separate-Database-Server" class="headerlink" title="Separate Database Server"></a>Separate Database Server</h2><p>The database management system (DBMS) can be separated from the rest of the environment to eliminate the resource contention between the application and the database, and to increase security by removing the database from the <a href="https://searchsecurity.techtarget.com/definition/DMZ">DMZ (Demilitarized Zone)</a>, or public internet.</p>
<p><strong>Use Case</strong>: Good for setting up an application quickly, but keeps application and database from fighting over the same system resources.</p>
<p><img data-src="/images/posts/180809-2.png" alt="02"></p>
<p><strong>Pros:</strong></p>
<ul>
<li>Application and database tiers do not contend for the same server resources (CPU, Memory, I/O, etc.)</li>
<li>You may vertically scale each tier separately, by adding more resources to whichever server needs increased capacity</li>
<li>Depending on your setup, it may <strong>increase security</strong> by removing your database from the DMZ</li>
</ul>
<br>

<p><strong>Cons:</strong></p>
<ul>
<li><p>Slightly more complex setup than single server</p>
</li>
<li><p>Performance issues can arise if the network connection between the two servers has <strong>high-latency</strong> (i.e. the servers are geographically distant from each other), or the bandwidth is too low for the amount of data being transferred</p>
</li>
</ul>
<br>

<h2 id="Load-Balancer-Reverse-Proxy"><a href="#Load-Balancer-Reverse-Proxy" class="headerlink" title="Load Balancer (Reverse Proxy)"></a>Load Balancer (Reverse Proxy)</h2><p>Load balancers can be added to a server environment to improve performance and reliability by distributing the workload across multiple servers. If one of the servers that is load balanced fails, the other servers will handle the incoming traffic until the failed server becomes healthy again. It can also be used to serve multiple applications through the same domain and port, by using a <strong>layer 7 (application layer) reverse proxy</strong>.</p>
<p>Examples of software capable of reverse proxy load balancing: <strong>HAProxy, Nginx, Varnish</strong>.</p>
<p><strong>Use Case</strong>: <strong>Useful in horizontal scaling</strong> (an environment that requires scaling by adding more servers).</p>
<p><img data-src="/images/posts/180809-3.png" alt="03"></p>
<p><strong>Pros:</strong></p>
<ul>
<li>Enables horizontal scaling</li>
<li>Can protect against DDOS attacks by limiting client connections to a sensible amount and frequency</li>
</ul>
<br>

<p><strong>Cons:</strong></p>
<ul>
<li><p>The load balancer can become a performance bottleneck if it does not have enough resources, or if it is configured poorly</p>
</li>
<li><p>Can introduce complexities that require additional consideration, such as where to perform SSL termination and how to handle applications that require sticky sessions</p>
</li>
<li><p>The load balancer is a single point of failure; if it goes down, your whole service can go down. A high availability (HA) setup is an infrastructure without a single point of failure (add more LBs). </p>
</li>
</ul>
<br>

<h2 id="4-HTTP-Accelerator-Caching-Reverse-Proxy"><a href="#4-HTTP-Accelerator-Caching-Reverse-Proxy" class="headerlink" title="4. HTTP Accelerator (Caching Reverse Proxy)"></a>4. HTTP Accelerator (Caching Reverse Proxy)</h2><p>An HTTP accelerator, or caching HTTP reverse proxy, can be used to reduce the time it takes to serve content to a user through a variety of techniques. The main technique employed with an HTTP accelerator is caching responses from a web or application server in memory, so future requests for the same content can be served quickly, with less unnecessary interaction with the web or application servers.</p>
<p>Examples of software capable of HTTP acceleration: <strong>Nginx, Varnish, Squid</strong>.</p>
<p><strong>Use Case:</strong> Useful in an environment with <strong>content-heavy dynamic web applications</strong>, or with many commonly accessed files.</p>
<p><img data-src="/images/posts/180809-4.png" alt="04"></p>
<p><strong>Pros:</strong></p>
<ul>
<li>Increase site performance by reducing CPU load on web server, through caching and compression, thereby increasing user capacity</li>
<li>Can be used as a reverse proxy load balancer</li>
<li>Some caching software can protect against DDoS attacks</li>
</ul>
<br>

<p><strong>Cons:</strong></p>
<ul>
<li>Requires tuning to get best performance out of it</li>
<li>If the cache-hit rate is low, it could reduce performance</li>
</ul>
<br>

<h2 id="Primary-replica-Database-Replication"><a href="#Primary-replica-Database-Replication" class="headerlink" title="Primary-replica Database Replication"></a>Primary-replica Database Replication</h2><p>One way to improve performance of a database system that performs many reads compared to writes, such as a CMS, is to use primary-replica database replication. Replication requires one primary node and one or more replica nodes. In this setup, all updates are sent to the primary node and reads can be distributed across all nodes.</p>
<p><strong>Use Case:</strong> Good for increasing the <strong>read performance</strong> for the database tier of an application.</p>
<p>Here is an example of a primary-replica replication setup, with a single replica node:</p>
<p><img data-src="/images/posts/180809-5.png" alt="05"></p>
<p><strong>Pros:</strong></p>
<ul>
<li>Improves database read performance by spreading reads across replicas</li>
<li>Can improve write performance by using primary exclusively for updates (it spends no time serving read requests)</li>
</ul>
<br>

<p><strong>Cons:</strong></p>
<ul>
<li><p>The application accessing the database must have a mechanism to determine which database nodes it should send update and read requests to</p>
</li>
<li><p>Updates to replicas are asynchronous, so there is a chance that their contents could be out of date</p>
</li>
<li><p>If the primary fails, no updates can be performed on the database until the issue is corrected</p>
</li>
<li><p>Does not have built-in failover in case of failure of primary node</p>
</li>
</ul>
<br>

<h2 id="Example-Combining-the-Concepts"><a href="#Example-Combining-the-Concepts" class="headerlink" title="Example: Combining the Concepts"></a>Example: Combining the Concepts</h2><hr>
<p>It is possible to load balance the caching servers, in addition to the application servers, and use database replication in a single environment. The purpose of combining these techniques is to reap the benefits of each without introducing too many issues or complexity. Here is an example diagram of what a server environment could look like:</p>
<p><img data-src="/images/posts/180809-6.png" alt="06"></p>
<p>Let’s assume that the load balancer is configured to recognize static requests (like images, css, javascript, etc.) and send those requests directly to the caching servers, and send other requests to the application servers.</p>
<br>

<p>Here is a description of what would happen when a user sends a requests dynamic content:</p>
<ul>
<li>The user requests dynamic content from <a href="http://example.com/">http://example.com/</a> (load balancer)</li>
<li>The load balancer sends request to app-backend</li>
<li>App-backend reads from the database and returns requested content to load balancer</li>
<li>The load balancer returns requested data to the user</li>
</ul>
<br>

<p>If the user requests static content:</p>
<ul>
<li><p>The load balancer checks cache-backend to see if the requested content is cached (cache-hit) or not (cache-miss)</p>
</li>
<li><p>If cache-hit: return the requested content to the load balancer and jump to Step 7. If cache-miss: the cache server forwards the request to app-backend, through the load balancer</p>
</li>
<li><p>The load balancer forwards the request through to app-backend</p>
</li>
<li><p>app-backend reads from the database then returns requested content to the load balancer</p>
</li>
<li><p>The load balancer forwards the response to cache-backend</p>
</li>
<li><p>cache-backend caches the content then returns it to the load balancer</p>
</li>
<li><p>The load balancer returns requested data to the user</p>
</li>
</ul>
<p>This environment still has two single points of failure (load balancer and primary database server), but it provides the all of the other reliability and performance benefits that were described in each section above.</p>
<br>



<blockquote>
<p>Reference:</p>
<p><a href="https://www.digitalocean.com/community/tutorials/5-common-server-setups-for-your-web-application">5 Common Server Setups For Your Web Application</a></p>
<p><a href="https://searchsecurity.techtarget.com/definition/DMZ">Demilitarized Zone / Perimeter Network</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-remote-database-to-optimize-site-performance-with-mysql">How To Set Up a Remote Database to Optimize Site Performance with MySQL</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-migrate-a-mysql-database-to-a-new-server-on-ubuntu-14-04">How to Migrate A MySQL Database To A New Server On Ubuntu</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-haproxy-as-a-layer-4-load-balancer-for-wordpress-application-servers-on-ubuntu-14-04">How To Use HAProxy As A Layer 4 Load Balancer for WordPress Application Servers</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-haproxy-as-a-layer-7-load-balancer-for-wordpress-and-nginx-on-ubuntu-14-04">How To Use HAProxy As A Layer 7 Load Balancer For WordPress and Nginx</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-configure-a-clustered-web-server-with-varnish-and-nginx-on-ubuntu-13-10">How To Configure a Clustered Web Server with Varnish and Nginx</a></p>
</blockquote>
<br>

<br>]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Database Resources &amp; Knowledge</title>
    <url>/2018/Database-Resources/</url>
    <content><![CDATA[<p>Some scattered resources and knowledge regarding databases.</p>
<blockquote>
<p>  Reference:</p>
<p>  <a href="https://sites.google.com/site/cs186spring2015/home/schedule-and-notes">Databse System</a></p>
</blockquote>
<span id="more"></span> 

<br> 

<h2 id="ORM"><a href="#ORM" class="headerlink" title="ORM"></a>ORM</h2><blockquote>
<p>Python: the Django ORM or <a href="https://en.wikipedia.org/wiki/SQLAlchemy">SQLAlchemy</a></p>
<p><strong>ORM can prevent SQL injection</strong>. </p>
</blockquote>
<p><a href="https://stackoverflow.com/questions/1279613/what-is-an-orm-how-does-it-work-and-how-should-i-use-one">ORM (Object-Relational-Mapping)</a> is a technique that lets you query and manipulate data from a database using an object-oriented paradigm.</p>
<ul>
<li><p>The <strong>Object</strong> part is the one you use with your programming language (e.g. Python)</p>
</li>
<li><p>The <strong>Relational</strong> part is a Relational Database Manager System. There are other types of databases but the most popular is relational (e.g. MySQL)</p>
</li>
<li><p>The <strong>Mapping</strong> part is where you do a bridge between your objects and your tables.</p>
</li>
</ul>
<p>An ORM library is a completely ordinary library written in your language of choice that encapsulates the code needed to manipulate the data, so you don’t use SQL anymore; you interact directly with an object in the same language you’re using. </p>
<p>Using an ORM framework would allow you to map that object with a database record automatically. For instance, retrieve a list of books from author name “Linus”:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">book_list = BookTable.query(author=<span class="string">&quot;Linus&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>The mechanical part is taken care of automatically via the ORM library.</p>
<br>

<p><strong>Pros and Cons</strong>:</p>
<ul>
<li><p><strong>ORM saves a lot of time</strong>:</p>
<ul>
<li>DRY: You write your data model in only one place, and it’s easier to update, maintain, and reuse the code.</li>
<li>A lot of stuff is done automatically, from database handling to I18N.</li>
<li>It forces you to write MVC code, which, in the end, makes your code a little cleaner.</li>
<li>You don’t have to write poorly-formed SQL (most Web programmers really suck at it, because SQL is treated like a “sub” language, when in reality it’s a very powerful and complex one).</li>
<li>Sanitizing; using prepared statements or transactions are as easy as calling a method.</li>
</ul>
<br></li>
<li><p><strong>ORM library is more flexible</strong>:</p>
<ul>
<li>It fits in your natural way of coding (it’s your language!).</li>
<li>It abstracts the DB system, so you can change it whenever you want.</li>
<li>The model is weakly bound to the rest of the application, so you can change it or use it anywhere else.</li>
<li>It lets you use OOP goodness like data inheritance without a headache.</li>
</ul>
<br></li>
<li><p><strong>Disadvantages of ORM</strong>:</p>
<ul>
<li>You have to learn it, and ORM libraries are not lightweight tools;</li>
<li>You have to set it up. Same problem.</li>
<li>Performance is OK for usual queries, but a SQL master will always do better with his own SQL for big projects.</li>
<li>It abstracts the DB. While it’s OK if you know what’s happening behind the scene, it’s a trap for new programmers that can write very greedy statements, like a heavy hit in a for loop.</li>
</ul>
</li>
</ul>
<br> 

<h2 id="NoSQL-amp-My-SQL"><a href="#NoSQL-amp-My-SQL" class="headerlink" title="NoSQL &amp; My SQL"></a>NoSQL &amp; My SQL</h2><blockquote>
<p>General points about NoSQL:</p>
</blockquote>
<ul>
<li><p>NoSQL is typically good for unstructured/“schemaless” data - usually, you don’t need to explicitly define your schema up front and can just include new fields without any ceremony</p>
</li>
<li><p>NoSQL typically favours a <strong>denormalised schema</strong> due to no support for JOINs per the RDBMS world. So you would usually have a flattened, denormalized representation of your data.</p>
</li>
<li><p>Using NoSQL doesn’t mean you could lose data. Different DBs have different strategies. e.g. MongoDB - you can essentially choose what level to trade off performance vs potential for data loss - best performance = greater scope for data loss.</p>
</li>
<li><p>It’s often very easy to scale out NoSQL solutions. Adding more nodes to replicate data to is one way to a) offer more scalability and b) offer more protection against data loss if one node goes down. But again, depends on the NoSQL DB/configuration. NoSQL does not necessarily mean “data loss” like you infer.</p>
</li>
<li><p><strong>Complex/dynamic queries/reporting</strong> are best served from an <strong>Relational Database</strong>. Often the query functionality for a NoSQL DB is limited (NoSQL DBs often lack the ability to perform atomic operations across multiple “tables”).</p>
</li>
<li><p>It doesn’t have to be a 1 or the other choice. My experience has been using RDBMS in conjunction with NoSQL for certain use cases.</p>
</li>
</ul>
<br>

<blockquote>
<p>NoSQL is more suitable for:</p>
</blockquote>
<ul>
<li><p><strong>Easy to scale</strong> by just adding more nodes.</p>
</li>
<li><p><strong>Query on large data set</strong></p>
<blockquote>
<p>   Imagine tons of tweets posted on twitter every day. In RDMS, there could be tables with billions of rows, and you don’t want to do query on those tables directly, not even mentioning, most of time, table joins are also needed for complex queries (MySQL breaks when it gets to billions).</p>
</blockquote>
</li>
<li><p><strong>Disk I/O bottleneck</strong></p>
<blockquote>
<p>   If a website needs to send results to different users based on users’ real-time info, we are probably talking about tens or hundreds of thousands of SQL read/write requests per second. Then disk i/o will be a serious bottleneck.</p>
</blockquote>
</li>
</ul>
<br> 

<h2 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h2><p><a href="https://www.postgresql.org/docs/9.4/using-explain.html">Using <code>explain</code></a></p>
<p><a href="http://postgresguide.com/performance/explain.html">Query Planning</a></p>
<br>

<br>]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Database Indices - How They Work</title>
    <url>/2018/Database-Indices/</url>
    <content><![CDATA[<p>A database index is an <strong>auxiliary data structure</strong>, which allows for <strong>faster retrieval of data</strong> stored in the database. They are keyed off of a specific column so that queries like “Give me all people with a last name of ‘Smith’” are fast.</p>
<blockquote>
<p>Reference:</p>
<p><a href="http://20bits.com/article/interview-questions-database-indexes">Database Indices</a></p>
<p><a href="https://www.tutorialcup.com/dbms/b-tree.htm">B+ Trees</a></p>
<p><a href="https://stackoverflow.com/questions/795031/how-do-composite-indexes-work">Composite Indices</a></p>
</blockquote>
<span id="more"></span> 

<br>

<div class="note info"><p>Technically the size of an index is going to be proportional to the cardinality of the column being indexed.</p>
</div>

<br>

<p>Database tables, at least conceptually, look something like this:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">id	age	last_name	hometown</span><br><span class="line">--	--	--		--</span><br><span class="line">1	10	Johnson		San Francisco, CA</span><br><span class="line">2	27	Smith		San Joe, CA</span><br><span class="line">3	15	Rose		Palo Alto, CA</span><br><span class="line">4	64	Farmer		Mill Valley, CA</span><br><span class="line">5	55	Pauling		San Francisco, CA</span><br><span class="line">6	17	Smith		Oakland, CA</span><br><span class="line">...	...	...		...</span><br><span class="line">100	49	Meyer		Berkeley, CA</span><br><span class="line">101	30	Wayne		Monterey, CA</span><br><span class="line">102	18	Schwartz	San Francisco, CA</span><br><span class="line">104	6	Johnson		San Francisco, CA</span><br><span class="line">...	...	...		...</span><br><span class="line">10000	41	Fetterman	Mountain View, CA</span><br><span class="line">10001	25	Breyer		Redwood City, CA</span><br></pre></td></tr></table></figure>

<p>That is, a table is a collection of tuples. If we have a file like this sitting on disk how do we get all records that have a last name of ‘Smith?’</p>
<p>The code would wind up looking something like this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    <span class="keyword">if</span> row[<span class="number">2</span>] == <span class="string">&#x27;Smith&#x27;</span>:</span><br><span class="line">        results.append[row]</span><br></pre></td></tr></table></figure>

<p>Finding the appropriate records requires checking the conditions for each row. This is linear in the number of rows which, for many databases, could be millions or billions of rows. Bad news.</p>
<p>How can we make it faster?</p>
<br>

<h2 id="Database-Indexes"><a href="#Database-Indexes" class="headerlink" title="Database Indexes"></a>Database Indexes</h2><div class="note primary"><p><strong>Any type of data structure that allows for faster access can be considered an <ins>index</ins></strong>. </p>
</div>

<br>

<h3 id="Hash-Indexes"><a href="#Hash-Indexes" class="headerlink" title="Hash Indexes"></a>Hash Indexes</h3><p>Take the same example from above, finding all people with a last name of ‘Smith.’ One solution would be to <strong>create a hash table</strong>. The keys of the hash would be based off of the <code>last_name</code> field and the values would be pointers to the database row.</p>
<p>This type of index is called, unsurprisingly, a “<strong>hash index</strong>“. Most databases support them but they’re generally not the default type. Why?</p>
<p>Well, consider a query like this: “Find all people who are younger than 45.” <strong>Hashes can deal with equality but not inequality</strong>. That is, given the hashes of two fields, there’s just no way for me to tell which is greater than the other, only whether they’re equal or not.</p>
<br>

<h3 id="B-tree-Indexes"><a href="#B-tree-Indexes" class="headerlink" title="B-tree Indexes"></a><a href="http://btechsmartclass.com/data_structures/b-trees.html">B-tree</a> Indexes</h3><p>The data structure most commonly used for database indexes are <strong>B-trees</strong>, a specific kind of self-balancing tree. </p>
<p><img data-src="/images/posts/180710-1.png" alt="01"></p>
<p>The main benefit of a B-tree is that it <strong>allows logarithmic selections, insertions, and deletions in the worst case</strong> scenario. And unlike hash indexes it stores the data in an <strong>ordered way</strong>, allowing for faster row retrieval when the selection conditions include things like inequalities or prefixes.</p>
<p>For example, using the tree above, to get the records for all people younger than 13 requires looking at only the left branch of the tree root.</p>
<br>

<h3 id="Other-Indexes"><a href="#Other-Indexes" class="headerlink" title="Other Indexes"></a>Other Indexes</h3><p>Hash indexes and B-tree indexes are the most common types of database indexes, but there are others, too. MySQL supports <strong>R-tree indexes</strong>, which are used to query spatial data, e.g., “Show me all cities within ten miles of San Francisco, CA.”</p>
<p>There are also <strong>bitmap indexes</strong>, which allow for almost instantaneous read operations but are expensive to change and take up a lot of space. They are best for columns which have only a few possible values.</p>
<br>

<h2 id="Nuances"><a href="#Nuances" class="headerlink" title="Nuances"></a>Nuances</h2><h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h3><p>Indexes don’t come for free. What you gain for in retrieval speed you lose in insertion and deletion speed because every time you alter a table the indexes must be updated accordingly. If your table is updating frequently it’s possible that having indexes will cause overall performance of your database to suffer.</p>
<p>There is also a space penalty, as the indexes take up space in memory or on disk. A single index is smaller than the table because it doesn’t contain all the data, only pointers to the data, but in general the larger the table the larger the index.</p>
<br>

<h3 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h3><p>Nodes in a B-tree contain a value and a number of pointers to children nodes. For database indexes the “value” is really a pair of values: <strong>the indexed field</strong> and <strong>a pointer to a database row</strong>. That is, rather than storing the row data right in the index, you store a pointer to the row on disk.</p>
<p>For example, if we have an index on an age column, the value in the B-tree might be something like <code>(34, 0x875900)</code>. 34 is the age and <code>0x875900</code> is a reference to the location of the data, rather than the data itself.</p>
<p>This often allows indexes to be stored in memory even for tables that are so large they can only be stored on disk.</p>
<p>Furthermore, B-tree indexes are typically designed so that each node takes up one disk block. This allows each node to be read in with a single disk operation.</p>
<p>Many databases use <strong>B+ trees</strong> rather than classic B-trees for generic database indexes. InnoDB’s BTREE index type is closer to a B+ tree than a B-tree, for example.</p>
<br>

<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Database indexes are auxiliary data structures that allow for quicker retrieval of data. The most common type of index is a <strong>B-tree index because it has very good general performance characteristics and allows a wide range of comparisons</strong>, including both equality and inequalities.</p>
<p>The penalty for having a database index is the cost required to update the index, which must happen any time the table is altered. There is also a certain amount of space overhead, although indexes will be smaller than the table they index.</p>
<p>For specific data types, different indexes might be better suited than a B-tree. For example, <strong>R-trees allow quicker retrieval of spatial data</strong>. For fields with only a few possible values, bitmap indexes might be appropriate.</p>
<br>

<br>]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Web Caching</title>
    <url>/2018/Web-Caching/</url>
    <content><![CDATA[<p>Intelligent content caching is one of the most effective ways to improve the site experience. <u>Caching is part of the core content delivery strategy implemented within the HTTP protocol</u>. Components throughout the delivery path can all cache items to speed up subsequent requests, subject to the caching policies declared for the content.</p>
<p>In this post, we will go through how to select caching policies, pros and cons of caching, and different strategies to provide the best mixture of <u>performance and flexibility</u>.</p>
<span id="more"></span> 

<br>

<h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><p>Caching is the term for storing reusable responses in order to make subsequent requests faster. There are many different types of caching available, each of which has its own characteristics. Application caches and memory caches are both popular for their ability to speed up certain responses.</p>
<p>Web caching is a core design feature of the HTTP protocol meant to minimize network traffic while improving the perceived responsiveness of the system as a whole. Caches are found at every level of a content’s journey from the original server to the browser. </p>
<p>Web caching works by caching the HTTP responses for requests according to certain rules. Subsequent requests for cached content can then be fulfilled from a cache closer to the user instead of sending the request all the way back to the web server.</p>
<p>Caching allows us to <u>cut down on the bandwidth costs associated with serving the same content repeatedly</u>. Your server will also be able to handle a greater amount of traffic with the same hardware. </p>
<br>



<p>Effective caching aids both content consumers and content providers. Some of the <strong>benefits</strong> that caching brings to content delivery are:</p>
<ul>
<li><p><strong>Decreased network costs</strong>: Content can be cached at various points in the network path between the content consumer and content origin. When the content is cached closer to the consumer, requests will not cause much additional network activity beyond the cache.</p>
</li>
<li><p><strong>Improved responsiveness</strong>: Caching enables content to be retrieved faster because an entire network round trip is not necessary. Caches maintained close to the user, like the browser cache, can make this retrieval nearly instantaneous.</p>
</li>
<li><p><strong>Increased performance on the same hardware</strong>: For the server where the content originated, more performance can be squeezed from the same hardware by allowing aggressive caching. The content owner can leverage the powerful servers along the delivery path to take the brunt of certain content loads.</p>
</li>
<li><p><strong>Availability of content during network interruptions</strong>: With certain policies, caching can be used to serve content to end users even when it may be unavailable for short periods of time from the origin servers.</p>
</li>
</ul>
<br>

<h2 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h2><p>When dealing with caching, there are a few terms that you are likely to come across that might be unfamiliar. Some of the more common ones are below:</p>
<ul>
<li><p><strong>Origin server</strong>: The origin server is the original location of the content. If you are acting as the web server administrator, this is the machine that you control. It is responsible for serving any content that could not be retrieved from a cache along the request route and for setting the caching policy for all content.</p>
</li>
<li><p><strong>Cache hit ratio</strong>: A cache’s effectiveness is measured in terms of its cache hit ratio or hit rate. This is a ratio of the requests able to be retrieved from a cache to the total requests made. A high cache hit ratio means that a high percentage of the content was able to be retrieved from the cache. This is usually the desired outcome for most administrators.</p>
</li>
<li><p><strong>Freshness</strong>: Freshness is a term used to describe whether an item within a cache is still considered a candidate to serve to a client. Content in a cache will only be used to respond if it is within the freshness time frame specified by the caching policy.</p>
</li>
<li><p><strong>Stale content</strong>: Items in the cache expire according to the cache freshness settings in the caching policy. Expired content is “stale”. In general, expired content cannot be used to respond to client requests. The origin server must be re-contacted to retrieve the new content or at least verify that the cached content is still accurate.</p>
</li>
<li><p><strong>Validation</strong>: Stale items in the cache can be validated in order to refresh their expiration time. Validation involves checking in with the origin server to see if the cached content still represents the most recent version of item.</p>
</li>
<li><p><strong>Invalidation</strong>: Invalidation is the process of removing content from the cache before its specified expiration date. This is necessary if the item has been changed on the origin server and having an outdated item in cache would cause significant issues for the client.</p>
</li>
</ul>
<p>There are plenty of other caching terms, but the ones above should help you get started.</p>
<br>

<h2 id="What-Can-be-Cached"><a href="#What-Can-be-Cached" class="headerlink" title="What Can be Cached?"></a>What Can be Cached?</h2><p>Certain content lends itself more readily to caching than others. Some very cache-friendly content for most sites are:</p>
<ul>
<li><p>Logos and brand images</p>
</li>
<li><p>Non-rotating images in general (navigation icons, for example)</p>
</li>
<li><p>CSS Style sheets</p>
</li>
<li><p>General JS files</p>
</li>
<li><p>Downloadable Content</p>
</li>
<li><p>Media Files</p>
</li>
</ul>
<p>These tend to change infrequently, so they can benefit from being cached for longer periods of time.</p>
<p>Some items that you have to be careful in caching are:</p>
<ul>
<li>HTML pages</li>
<li>Rotating images</li>
<li>Frequently modified Javascript and CSS</li>
<li>Content requested with authentication cookies</li>
</ul>
<p>Some items that should almost never be cached are:</p>
<ul>
<li>Assets related to sensitive data (banking info, etc.)</li>
<li>Content that is user-specific and frequently changed</li>
</ul>
<p>In addition to the above general rules, it’s possible to specify policies that allow you to cache different types of content appropriately. For instance, if authenticated users all see the same view of your site, it may be possible to cache that view anywhere. If authenticated users see a user-sensitive view of the site that will be valid for some time, you may tell the user’s browser to cache, but tell any intermediary caches not to store the view.</p>
<br>

<h2 id="Location-of-Caches"><a href="#Location-of-Caches" class="headerlink" title="Location of Caches"></a>Location of Caches</h2><p>Content can be cached at many different points throughout the delivery chain:</p>
<ul>
<li><p><strong>Browser cache</strong>: Web browsers themselves maintain a small cache. Typically, the browser sets a policy that dictates the most important items to cache. This may be user-specific content or content deemed expensive to download and likely to be requested again.</p>
</li>
<li><p><strong>Intermediary caching proxies</strong>: Any server in between the client and your infrastructure can cache certain content as desired. These caches may be maintained by ISPs or other independent parties.</p>
</li>
<li><p><strong>Reverse Cache</strong>: Your server infrastructure can implement its own cache for backend services. This way, content can be served from the point-of-contact instead of hitting backend servers on each request.<br>Each of these locations can and often do cache items according to their own caching policies and the policies set at the content origin.</p>
</li>
</ul>
<br>

<h2 id="Caching-Headers"><a href="#Caching-Headers" class="headerlink" title="Caching Headers"></a>Caching Headers</h2><p>Caching policy is dependent upon two different factors. The caching entity itself gets to decide whether or not to cache acceptable content. It can decide to cache less than it is allowed to cache, but never more.</p>
<p>The majority of caching behavior is determined by the caching policy, which is set by the content owner. These policies are mainly articulated through the use of specific HTTP headers.</p>
<p>Through various iterations of the HTTP protocol, a few different cache-focused headers have arisen with varying levels of sophistication. The ones you probably still need to pay attention to are below:</p>
<ul>
<li><p><strong><code>Expires</code></strong>: The Expires header is very straight-forward, although fairly limited in scope. Basically, it sets a time in the future when the content will expire. At this point, any requests for the same content will have to go back to the origin server. This header is probably best used only as a fall back.</p>
</li>
<li><p><strong><code>Cache-Control</code></strong>: This is the more modern replacement for the Expires header. It is well supported and implements a much more flexible design. In almost all cases, this is preferable to Expires, but it may not hurt to set both values. We will discuss the specifics of the options you can set with Cache-Control a bit later.</p>
</li>
<li><p><strong><code>Etag</code></strong>: The Etag header is used with cache validation. The origin can provide a unique Etag for an item when it initially serves the content. When a cache needs to validate the content it has on-hand upon expiration, it can send back the Etag it has for the content. The origin will either tell the cache that the content is the same, or send the updated content (with the new Etag).</p>
</li>
<li><p><strong><code>Last-Modified</code></strong>: This header specifies the last time that the item was modified. This may be used as part of the validation strategy to ensure fresh content.</p>
</li>
<li><p><strong><code>Content-Length</code></strong>: While not specifically involved in caching, the Content-Length header is important to set when defining caching policies. Certain software will refuse to cache content if it does not know in advanced the size of the content it will need to reserve space for.</p>
</li>
<li><p><strong><code>Vary</code></strong>: A cache typically uses the requested host and the path to the resource as the key with which to store the cache item. The Vary header can be used to tell caches to pay attention to an additional header when deciding whether a request is for the same item. This is most commonly used to tell caches to key by the Accept-Encoding header as well, so that the cache will know to differentiate between compressed and uncompressed content.</p>
</li>
</ul>
<br>

<h3 id="The-Vary-Header"><a href="#The-Vary-Header" class="headerlink" title="The Vary Header"></a>The Vary Header</h3><p>The Vary header provides you with the ability to store different versions of the same content at the expense of diluting the entries in the cache.</p>
<p>In the case of Accept-Encoding, setting the Vary header allows for a critical distinction to take place between compressed and uncompressed content. This is needed to correctly serve these items to browsers that cannot handle compressed content and is necessary in order to provide basic usability. One characteristic that tells you that Accept-Encoding may be a good candidate for Vary is that it only has two or three possible values.</p>
<p>Items like User-Agent might at first glance seem to be a good way to differentiate between mobile and desktop browsers to serve different versions of your site. However, since User-Agent strings are non-standard, the result will likely be many versions of the same content on intermediary caches, with a very low cache hit ratio. The Vary header should be used sparingly, especially if you do not have the ability to normalize the requests in intermediate caches that you control (which may be possible, for instance, if you leverage a content delivery network).</p>
<br>

<h2 id="How-Cache-Control-Flags-Impact-Caching"><a href="#How-Cache-Control-Flags-Impact-Caching" class="headerlink" title="How Cache-Control Flags Impact Caching"></a>How Cache-Control Flags Impact Caching</h2><p>Above, we mentioned how the Cache-Control header is used for modern cache policy specification. A number of different policy instructions can be set using this header, with multiple instructions being separated by commas.</p>
<p>Some of the Cache-Control options you can use to dictate your content’s caching policy are:</p>
<ul>
<li><p><strong><code>no-cache</code></strong>: This instruction specifies that any cached content must be re-validated on each request before being served to a client. This, in effect, marks the content as stale immediately, but allows it to use revalidation techniques to avoid re-downloading the entire item again.</p>
</li>
<li><p><strong><code>no-store</code></strong>: This instruction indicates that the content cannot be cached in any way. This is appropriate to set if the response represents sensitive data.</p>
</li>
<li><p><strong><code>public</code></strong>: This marks the content as public, which means that it can be cached by the browser and any intermediate caches. For requests that utilized HTTP authentication, responses are marked private by default. This header overrides that setting.</p>
</li>
<li><p><strong><code>private</code></strong>: This marks the content as private. Private content may be stored by the user’s browser, but must not be cached by any intermediate parties. This is often used for user-specific data.</p>
</li>
<li><p><strong><code>max-age</code></strong>: This setting configures the maximum age that the content may be cached before it must revalidate or re-download the content from the origin server. In essence, this replaces the Expires header for modern browsing and is the basis for determining a piece of content’s freshness. This option takes its value in seconds with a maximum valid freshness time of one year (31536000 seconds).</p>
</li>
<li><p><strong><code>s-maxage</code></strong>: This is very similar to the max-age setting, in that it indicates the amount of time that the content can be cached. The difference is that this option is applied only to intermediary caches. Combining this with the above allows for more flexible policy construction.</p>
</li>
<li><p><strong><code>must-revalidate</code></strong>: This indicates that the freshness information indicated by max-age, s-maxage or the Expires header must be obeyed strictly. Stale content cannot be served under any circumstance. This prevents cached content from being used in case of network interruptions and similar scenarios.</p>
</li>
<li><p><strong><code>proxy-revalidate</code></strong>: This operates the same as the above setting, but only applies to intermediary proxies. In this case, the user’s browser can potentially be used to serve stale content in the event of a network interruption, but intermediate caches cannot be used for this purpose.</p>
</li>
<li><p><strong><code>no-transform</code></strong>: This option tells caches that they are not allowed to modify the received content for performance reasons under any circumstances. This means, for instance, that the cache is not able to send compressed versions of content it did not receive from the origin server compressed and is not allowed.</p>
<br></li>
</ul>
<p>These can be combined in different ways to achieve various caching behavior. Some mutually exclusive values are:</p>
<ul>
<li><p><strong><code>no-cache</code>, <code>no-store</code></strong>, and the regular caching behavior indicated by absence of either</p>
</li>
<li><p><strong><code>public</code></strong> and <strong><code>private</code></strong></p>
</li>
</ul>
<p>The <code>no-store</code> option supersedes <code>the no-cache</code> if both are present. For responses to unauthenticated requests, public is implied. For responses to authenticated requests, private is implied. These can be overridden by including the opposite option in the Cache-Control header.</p>
<br>

<h2 id="Developing-a-Caching-Strategy"><a href="#Developing-a-Caching-Strategy" class="headerlink" title="Developing a Caching Strategy"></a>Developing a Caching Strategy</h2><p>In a perfect world, everything could be cached aggressively and your servers would only be contacted to validate content occasionally. This doesn’t often happen in practice though, so you should try to set some sane caching policies that aim to balance between implementing long-term caching and responding to the demands of a changing site.</p>
<br>

<h3 id="Common-Issues"><a href="#Common-Issues" class="headerlink" title="Common Issues"></a>Common Issues</h3><p>There are many situations where caching cannot or should not be implemented due to how the content is produced (dynamically generated per user) or the nature of the content (sensitive banking information, for example). Another problem that many administrators face when setting up caching is the situation where older versions of your content are out in the wild, not yet stale, even though new versions have been published.</p>
<p>These are both frequently encountered issues that can have serious impacts on cache performance and the accuracy of content you are serving. However, we can mitigate these issues by developing caching policies that anticipate these problems.</p>
<br>

<h3 id="General-Recommendations"><a href="#General-Recommendations" class="headerlink" title="General Recommendations"></a>General Recommendations</h3><p>While your situation will dictate the caching strategy you use, the following recommendations can help guide you towards some reasonable decisions.</p>
<p>There are certain steps that you can take to increase your cache hit ratio before worrying about the specific headers you use. Some ideas are:</p>
<ul>
<li><strong>Establish specific directories for images, CSS, and shared content</strong>: Placing content into dedicated directories will allow you to easily refer to them from any page on your site.</li>
<li><strong>Use the same URL to refer to the same items</strong>: Since caches key off of both the host and the path to the content requested, ensure that you refer to your content in the same way on all of your pages. The previous recommendation makes this significantly easier.</li>
<li><strong>Use CSS image sprites where possible</strong>: CSS image sprites for items like icons and navigation decrease the number of round trips needed to render your site and allow your site to cache that single sprite for a long time.</li>
<li><strong>Host scripts and external resources locally where possible</strong>: If you utilize javascript scripts and other external resources, consider hosting those resources on your own servers if the correct headers are not being provided upstream. Note that you will have to be aware of any updates made to the resource upstream so that you can update your local copy.</li>
<li><strong>Fingerprint cache items</strong>: For static content like CSS and Javascript files, it may be appropriate to fingerprint each item. This means adding a unique identifier to the filename (often a hash of the file) so that if the resource is modified, the new resource name can be requested, causing the requests to correctly bypass the cache. There are a variety of tools that can assist in creating fingerprints and modifying the references to them within HTML documents.</li>
</ul>
<br>

<p>In terms of selecting the correct headers for different items, the following can serve as a general reference:</p>
<ul>
<li><p><strong>Allow all caches to store generic assets</strong>: Static content and content that is not user-specific can and should be cached at all points in the delivery chain. This will allow intermediary caches to respond with the content for multiple users.</p>
</li>
<li><p><strong>Allow browsers to cache user-specific assets</strong>: For per-user content, it is often acceptable and useful to allow caching within the user’s browser. While this content would not be appropriate to cache on any intermediary caching proxies, caching in the browser will allow for instant retrieval for users during subsequent visits.</p>
</li>
<li><p><strong>Make exceptions for essential time-sensitive content</strong>: If you have content that is time-sensitive, make an exception to the above rules so that the out-dated content is not served in critical situations. For instance, if your site has a shopping cart, it should reflect the items in the cart immediately. Depending on the nature of the content, the no-cache or no-store options can be set in the Cache-Control header to achieve this.</p>
</li>
<li><p><strong>Always provide validators</strong>: Validators allow stale content to be refreshed without having to download the entire resource again. Setting the Etag and the Last-Modified headers allow caches to validate their content and re-serve it if it has not been modified at the origin, further reducing load.</p>
</li>
<li><p><strong>Set long freshness times for supporting content</strong>: In order to leverage caching effectively, elements that are requested as supporting content to fulfill a request should often have a long freshness setting. This is generally appropriate for items like images and CSS that are pulled in to render the HTML page requested by the user. Setting extended freshness times, combined with fingerprinting, allows caches to store these resources for long periods of time. If the assets change, the modified fingerprint will invalidate the cached item and will trigger a download of the new content. Until then, the supporting items can be cached far into the future.</p>
</li>
<li><p><strong>Set short freshness times for parent content</strong>: In order to make the above scheme work, the containing item must have relatively short freshness times or may not be cached at all. This is typically the HTML page that calls in the other assisting content. The HTML itself will be downloaded frequently, allowing it to respond to changes rapidly. The supporting content can then be cached aggressively.</p>
</li>
</ul>
<br>

<p>The key is to strike a <strong>balance</strong> that favors aggressive caching where possible while leaving opportunities to invalidate entries in the future when changes are made. The site will likely have a combination of:</p>
<ul>
<li><strong>Aggressively cached items</strong></li>
<li>Cached items with a <strong>short freshness</strong> time and the ability to <strong>re-validate</strong></li>
<li>Items that <strong>should not be cached</strong> at all</li>
</ul>
<p>The goal is to move content into the first categories when possible while maintaining an acceptable level of accuracy.</p>
<br>

<br>

]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Writing Cache-Friendly Code</title>
    <url>/2018/Cache-Friendly-Code/</url>
    <content><![CDATA[<blockquote>
<p>  Reference:</p>
<p>  <a href="https://stackoverflow.com/questions/9936132/why-does-the-order-of-the-loops-affect-performance-when-iterating-over-a-2d-arra">Why does the order of the loops affect performance when iterating over a 2D array?</a></p>
<p>  <a href="https://stackoverflow.com/questions/16699247/what-is-a-cache-friendly-code">What is a “cache-friendly” code?</a></p>
<p>  <a href="https://lwn.net/Articles/255364/">Memory part 5: What programmers can do</a></p>
</blockquote>
<span id="more"></span> 

<br>

<hr>
<h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><p>On modern computers, only the lowest level memory structures (<strong>the registers</strong>) can move data around in single clock cycles. However, registers are very expensive and most computer cores have less than a few dozen registers (few hundred to maybe a thousand bytes total). At the other end of the memory spectrum (<strong>DRAM</strong>), the memory is very cheap (i.e. literally millions of times cheaper) but takes hundreds of cycles after a request to receive the data. To bridge this gap between super fast and expensive and super slow and cheap are the cache memories, named L1, L2, L3 in decreasing speed and cost. The idea is that most of the executing code will be hitting a small set of variables often, and the rest (a much larger set of variables) infrequently. If the processor can’t find the data in L1 cache, then it looks in L2 cache. If not there, then L3 cache, and if not there, main memory. Each of these “misses” is expensive in time.</p>
<p>Caching is one of the main methods to reduce the impact of latency. To paraphrase Herb Sutter (cfr. links below): <strong>increasing bandwidth is easy, but we can’t buy our way out of latency</strong>.</p>
<p>Data is always retrieved through the memory hierarchy (smallest == fastest to slowest). A cache hit/miss usually refers to a hit/miss in the highest level of cache in the CPU – by highest level I mean the largest == slowest. The cache hit rate is crucial for performance since every cache miss results in fetching data from RAM (or worse …) which takes a lot of time (hundreds of cycles for RAM, tens of millions of cycles for HDD). In comparison, reading data from the (highest level) cache typically takes only a handful of cycles.</p>
<p>In modern computer architectures, the performance bottleneck is leaving the CPU die (e.g. accessing RAM or higher). This will only get worse over time. The increase in processor frequency is currently no longer relevant to increase performance. The problem is memory access. Hardware design efforts in CPUs therefore currently focus heavily on optimizing caches, prefetching, pipelines and concurrency. For instance, modern CPUs spend around 85% of die on caches and up to 99% for storing/moving data!</p>
<br>

<p>There is quite a lot to be said on the subject. Here are a few great references about caches, memory hierarchies and proper programming:</p>
<ul>
<li><p><a href="https://www.agner.org/optimize/">Agner Fog’s page</a>. In his excellent documents, you can find detailed examples covering languages ranging from assembly to C++.</p>
</li>
<li><p><a href="https://www.youtube.com/watch?v=L7zSU9HI-6I">Herb Sutter’s talk on machine architecture</a> (specifically check 12:00 and onwards).</p>
</li>
<li><p><a href="https://gist.github.com/ocornut/cb980ea183e848685a36">Slides about memory optimization by Christer Ericson</a> (director of technology @ Sony)</p>
</li>
</ul>
<br>

<h2 id="Main-concepts-for-cache-friendly-code"><a href="#Main-concepts-for-cache-friendly-code" class="headerlink" title="Main concepts for cache-friendly code"></a>Main concepts for cache-friendly code</h2><p>A very important aspect of cache-friendly code is all about the <a href="https://en.wikipedia.org/wiki/Locality_of_reference">principle of locality</a>, the goal of which is to place related data close in memory to allow efficient caching. In terms of the CPU cache, it’s important to be aware of cache lines to understand how this works: <a href="https://stackoverflow.com/questions/3928995/how-do-cache-lines-work">How do cache lines work</a>?</p>
<p>The following particular aspects are of high importance to optimize caching:</p>
<ul>
<li><p><strong>Temporal locality</strong>: when a given memory location was accessed, it is likely that the same location is accessed again in the near future. Ideally, this information will still be cached at that point.</p>
</li>
<li><p><strong>Spatial locality</strong>: this refers to placing related data close to each other. Caching happens on many levels, not just in the CPU. For example, when you read from RAM, typically a larger chunk of memory is fetched than what was specifically asked for because very often the program will require that data soon. HDD caches follow the same line of thought. Specifically for CPU caches, the notion of cache lines is important.</p>
</li>
</ul>
<br>

<h3 id="Use-appropriate-c-containers"><a href="#Use-appropriate-c-containers" class="headerlink" title="Use appropriate c++ containers"></a>Use appropriate c++ containers</h3><p>A simple example of cache-friendly versus cache-unfriendly is c++’s std::vector versus std::list. Elements of a std::vector are stored in contiguous memory, and as such accessing them is much more cache-friendly than accessing elements in a std::list, which stores its content all over the place. This is due to spatial locality.</p>
<p>A very nice illustration of this is given by <a href="https://www.youtube.com/watch?v=YQs6IC-vgmo">Bjarne Stroustrup</a>.</p>
<br>

<h3 id="Don’t-neglect-the-cache-in-data-structure-and-algorithm-design"><a href="#Don’t-neglect-the-cache-in-data-structure-and-algorithm-design" class="headerlink" title="Don’t neglect the cache in data structure and algorithm design"></a>Don’t neglect the cache in data structure and algorithm design</h3><p>Whenever possible, try to adapt your data structures and order of computations in a way that allows maximum use of the cache. A common technique in this regard is <strong><a href="https://web.archive.org/web/20140113145619/http://www.cs.berkeley.edu/~richie/cs267/mg/report/node35.html">cache blocking</a></strong>, which is of extreme importance in high-performance computing (cfr. for example ATLAS).</p>
<br>

<h3 id="Know-and-exploit-the-implicit-structure-of-data"><a href="#Know-and-exploit-the-implicit-structure-of-data" class="headerlink" title="Know and exploit the implicit structure of data"></a>Know and exploit the implicit structure of data</h3><p>Another simple example, which many people in the field sometimes forget is column-major (ex. fortran,matlab) vs. row-major ordering (ex. c,c++) for storing two dimensional arrays. For example, consider the following matrix:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> <span class="number">2</span></span><br><span class="line"><span class="number">3</span> <span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>In row-major ordering, this is stored in memory as 1 2 3 4; in column-major ordering, this would be stored as 1 3 2 4. It is easy to see that implementations which do not exploit this ordering will quickly run into (easily avoidable!) cache issues. Unfortunately, I see stuff like this very often in my domain (machine learning). @MatteoItalia showed this example in more detail in his answer.</p>
<p>When fetching a certain element of a matrix from memory, elements near it will be fetched as well and stored in a cache line. If the ordering is exploited, this will result in fewer memory accesses (because the next few values which are needed for subsequent computations are already in a cache line).</p>
<p>For simplicity, assume the cache comprises a single cache line which can contain 2 matrix elements and that when a given element is fetched from memory, the next one is too. Say we want to take the sum over all elements in the example 2x2 matrix above (lets call it M):</p>
<p>Exploiting the ordering (e.g. changing column index first in c++):</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">M[<span class="number">0</span>][<span class="number">0</span>] (memory) + M[<span class="number">0</span>][<span class="number">1</span>] (cached) + M[<span class="number">1</span>][<span class="number">0</span>] (memory) + M[<span class="number">1</span>][<span class="number">1</span>] (cached)</span><br><span class="line">= <span class="number">1</span> + <span class="number">2</span> + <span class="number">3</span> + <span class="number">4</span></span><br><span class="line">--&gt; <span class="number">2</span> cache hits, <span class="number">2</span> memory accesses</span><br></pre></td></tr></table></figure>

<p>Not exploiting the ordering (e.g. changing row index first in c++):</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">M[<span class="number">0</span>][<span class="number">0</span>] (memory) + M[<span class="number">1</span>][<span class="number">0</span>] (memory) + M[<span class="number">0</span>][<span class="number">1</span>] (memory) + M[<span class="number">1</span>][<span class="number">1</span>] (memory)</span><br><span class="line">= <span class="number">1</span> + <span class="number">3</span> + <span class="number">2</span> + <span class="number">4</span></span><br><span class="line">--&gt; <span class="number">0</span> cache hits, <span class="number">4</span> memory accesses</span><br></pre></td></tr></table></figure>

<p>In this simple example, exploiting the ordering approximately doubles execution speed (since memory access requires much more cycles than computing the sums). In practice, the performance difference can be much larger.</p>
<br>

<h3 id="Another-Example-in-C"><a href="#Another-Example-in-C" class="headerlink" title="Another Example in C"></a>Another Example in C</h3><p><strong>An instructive classic example of cache-unfriendly code</strong> is code that scans a C bi-dimensional array (e.g. a bitmap image) column-wise instead of row-wise.</p>
<p>Elements that are adjacent in a row are also adjacent in memory, thus accessing them in sequence means accessing them in ascending memory order; this is cache-friendly, since the cache tends to prefetch contiguous blocks of memory.</p>
<p>Instead, accessing such elements column-wise is cache-unfriendly, since elements on the same column are distant in memory from each other (in particular, their distance is equal to the size of the row), so when you use this access pattern you are jumping around in memory, potentially wasting the effort of the cache of retrieving the elements nearby in memory.</p>
<p>And all that it takes to ruin the performance is to go from</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Cache-friendly version - processes pixels which are adjacent in memory</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> y=<span class="number">0</span>; y&lt;height; ++y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> x=<span class="number">0</span>; x&lt;width; ++x)</span><br><span class="line">    &#123;</span><br><span class="line">        ... image[y][x] ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>to</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Cache-unfriendly version - jumps around in memory for no good reason</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> x=<span class="number">0</span>; x&lt;width; ++x)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> y=<span class="number">0</span>; y&lt;height; ++y)</span><br><span class="line">    &#123;</span><br><span class="line">        ... image[y][x] ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>This effect can be quite dramatic (several order of magnitudes in speed) in systems with small caches and/or working with big arrays (e.g. 10+ megapixels 24 bpp images on current machines); for this reason, if you have to do many vertical scans, often it’s better to rotate the image of 90 degrees first and perform the various analysis later, limiting the cache-unfriendly code just to the rotation.</p>
<br>

<h3 id="Avoid-unpredictable-branches"><a href="#Avoid-unpredictable-branches" class="headerlink" title="Avoid unpredictable branches"></a>Avoid unpredictable branches</h3><p>Modern architectures feature pipelines and compilers are becoming very good at reordering code to minimize delays due to memory access. When your critical code contains (unpredictable) branches, it is hard or impossible to prefetch data. This will indirectly lead to more cache misses.</p>
<p>This is explained very well here: <a href="https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array">Why is processing a sorted array faster than processing an unsorted array?</a></p>
<br>

<h3 id="Avoid-virtual-functions"><a href="#Avoid-virtual-functions" class="headerlink" title="Avoid virtual functions"></a>Avoid virtual functions</h3><p>In the context of c++, virtual methods represent a controversial issue with regard to cache misses (a general consensus exists that they should be avoided when possible in terms of performance). Virtual functions can induce cache misses during look up, but this only happens if the specific function is not called often (otherwise it would likely be cached), so this is regarded as a non-issue by some. For reference about this issue, check out: <a href="https://stackoverflow.com/questions/667634/what-is-the-performance-cost-of-having-a-virtual-method-in-a-c-class">What is the performance cost of having a virtual method in a C++ class?</a></p>
<br>

<hr>
<h2 id="Common-problems"><a href="#Common-problems" class="headerlink" title="Common problems"></a>Common problems</h2><p>A common problem in modern architectures with multiprocessor caches is called <strong>false sharing</strong>. This occurs when each individual processor is attempting to use data in another memory region and attempts to store it in the same cache line. This causes the cache line – which contains data another processor can use – to be overwritten again and again. Effectively, different threads make each other wait by inducing cache misses in this situation. See also: <a href="https://stackoverflow.com/questions/8469427/how-and-when-to-align-to-cache-line-size">How and when to align to cache line size?</a></p>
<p>An extreme symptom of poor caching in RAM memory (which is probably not what you mean in this context) is so-called <strong>thrashing</strong>. This occurs when the process continuously generates page faults (e.g. accesses memory which is not in the current page) which require disk access.</p>
<br>

<br>]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Low Level System</tag>
      </tags>
  </entry>
  <entry>
    <title>Understanding Buses</title>
    <url>/2018/The-Bus/</url>
    <content><![CDATA[<p>Think of a bus as the electronic highway on which data travels within a computer, from one component to another. This bus connects the CPU to the main memory (RAM) on the motherboard.</p>
<span id="more"></span> 

<br>



<h2 id="Key-Terms-To-Understanding-Buses"><a href="#Key-Terms-To-Understanding-Buses" class="headerlink" title="Key Terms To Understanding Buses"></a>Key Terms To Understanding Buses</h2><p><a href="https://www.webopedia.com/TERM/B/bus.html">1. Bus</a></p>
<ul>
<li>A collection of wires through which data is transmitted from one part of a computer to another.</li>
</ul>
<p><a href="https://www.webopedia.com/TERM/S/system_bus.html">2. System Bus</a></p>
<ul>
<li>The bus that connects the CPU to main memory on the motherboard.</li>
</ul>
<p><a href="https://www.webopedia.com/TERM/I/I_O.html">3. I/O</a></p>
<ul>
<li>The term I/O is used to describe any program, operation or device that transfers data to or from a computer and to or from a peripheral device.</li>
</ul>
<p><a href="https://www.webopedia.com/TERM/P/PCI.html">4. PCI</a></p>
<ul>
<li>Short for Peripheral Component Interconnect, a local bus standard developed by Intel Corp.</li>
</ul>
<br>

<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Basically, it’s the conduit used by your entire system to communicate with your CPU. A bus is a collection of wires and connectors through which the data is transmitted. When used in reference to personal computers, the term bus usually refers to what is commonly called the local bus (on older systems) or system bus (on newer systems). This bus is considered the first bus on the electronic highway and it connects the CPU to the main memory (RAM) on the motherboard. All buses consist of two parts – an address bus and a data bus.</p>
<p>The data bus transfers actual data whereas the address bus transfers information about the data and where it should go. The address bus is used to identify particular locations (addresses) in main memory. The width of the address bus (that is, the number of wires) determines how many unique memory locations can be addressed. Modern PCs and Macs have as many as 36 address lines, which enables them theoretically to access 64 GB of main memory. However, the actual amount of memory that can be accessed is usually much less than this theoretical limit due to chipset and motherboard limitations.</p>
<p>The size of a bus, known as its width, is important because it determines how much data can be transmitted at one time. The bus size actually indicates the number of wires in the bus. For example, a 32-bit bus has 32 wires or connectors that transmit 32 bits simultaneously (referred to as  in parallel). It would be considered “32-bits wide.” A 16-bit bus has 16 wires or connectors that can transmit 16 bits of data in parallel. You would say it is “16-bits wide.”</p>
<br>

<h2 id="System-Bus-amp-I-O-Bus"><a href="#System-Bus-amp-I-O-Bus" class="headerlink" title="System Bus &amp; I/O Bus"></a>System Bus &amp; I/O Bus</h2><p>On older computers, the local bus, which was the only bus, was used for the CPU, RAM and I/O (input/output) components. All components on the local bus used the same clock speed. In the late 80s we saw the separation of the system bus from the I/O bus allowing them to run at different speeds.</p>
<p>The system bus (also called the frontside bus, memory bus, local bus or host bus) is what connects the CPU to main memory on the motherboard. I/O buses are those that connect the CPU and RAM with all other components, and the I/O buses branch off of the system bus. I/O buses operate on a speed which is lower than the system bus speed. PCs offer several types of I/O buses which include the ISA bus, PCI bus, AGP bus and USB bus.</p>
<br>

<h2 id="ISA-Bus-amp-PCI-Bus"><a href="#ISA-Bus-amp-PCI-Bus" class="headerlink" title="ISA Bus &amp; PCI Bus"></a>ISA Bus &amp; PCI Bus</h2><p>Short for Industry Standard Architecture bus, the ISA bus architecture was used in the IBM PC/XT and PC/AT. The AT version of the bus is called the AT bus and became a de facto industry standard. Starting in the early 90s, ISA began to be replaced by the PCI (Peripheral Component Interconnect) local bus architecture. The PCI standard was developed by Intel Corp. On modern PCs, the PCI bus is the central (or main) I/O bus. It’s used for connecting adapters such as hard disks, sound cards, network cards and graphics cards (although now AGP is more common for 3-D graphics). PCI is a 64-bit bus, though it is usually implemented as a 32-bit bus, and it can run at clock speeds of 33 or 66 MHz. At 32-bits and 33 MHz, it yields a throughput rate of 133 MBps (at 66 MHz 266 MBps). The vast majority of today’s PCs implement a PCI bus that runs at a maximum speed of 33 MHz.</p>
<br>

<h3 id="PCI-2-1"><a href="#PCI-2-1" class="headerlink" title="PCI 2.1"></a>PCI 2.1</h3><p>Also called PCI-X 2.0, the PCI bus specification version 2.1 calls for expandability to 64-bits and 66 MHz speed, yielding a throughput rate of 532 MBps.</p>
<br>

<h2 id="AGP-Bus"><a href="#AGP-Bus" class="headerlink" title="AGP Bus"></a>AGP Bus</h2><p>Short for <strong>Accelerated Graphics Port</strong> (AGP), an interface specification developed by Intel Corporation. AGP is based on PCI, but is designed especially for the throughput demands of 3-D graphics. Rather than using the PCI bus for graphics data, AGP introduces a dedicated point-to-point channel so that the graphics controller can directly access main memory. The AGP channel is 32-bits wide and runs at 66 MHz. This translates into a total bandwidth of 266 MBps, as opposed to the PCI bandwidth of 133 MBps. AGP also supports optional faster modes and allows 3-D textures to be stored in main memory rather than video memory.</p>
<br>

<h2 id="USB-Bus"><a href="#USB-Bus" class="headerlink" title="USB Bus"></a>USB Bus</h2><p>Short for Universal Serial Bus, an external bus standard that supports data transfer rates of 12 Mbps. A single USB port can be used to connect up to 127 peripheral devices, such as mice, modems, and keyboards. USB also supports Plug-and-Play installation and hot plugging.</p>
<br>

<h3 id="USB-2-0"><a href="#USB-2-0" class="headerlink" title="USB 2.0"></a>USB 2.0</h3><p>Also referred to as Hi-Speed USB, USB 2.0 is an external bus that supports data rates up to 480Mbps. USB 2.0 is an extension of USB 1.1. USB 2.0 is fully compatible with USB 1.1 and uses the same cables and connectors.</p>
<br>

<h2 id="Bus-Speed"><a href="#Bus-Speed" class="headerlink" title="Bus Speed"></a>Bus Speed</h2><p>Every bus has a clock speed measured in MHz. This measurement represents the speed in which information and data can move across the bus on the motherboard. A fast bus allows data to be transferred faster, which makes applications run faster. Bus speed is one of the factors which determines the speed of your CPU.</p>
<br>

<h2 id="Backside-Bus"><a href="#Backside-Bus" class="headerlink" title="Backside Bus"></a>Backside Bus</h2><p>The backside bus is the microprocessor bus that connects the CPU to a Level 2 cache. Typically, a backside bus runs at a faster clock speed than the frontside bus that connects the CPU to main memory. For example, the Pentium Pro microprocessor actually consists of two chips — one contains the CPU and the primary cache, and the second contains the secondary cache. A backside bus connects the two chips at the same clock rate as the CPU itself (at least 200 MHz). In contrast, the frontside bus runs at only a fraction of the CPU clock speed.</p>
<br>

<br>]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Low Level System</tag>
      </tags>
  </entry>
  <entry>
    <title>Assembly - Structures &amp; How</title>
    <url>/2018/Assembly/</url>
    <content><![CDATA[<p>目前很多的汇编语言教材大多都是上来先讲一大堆CPU、总线、寄存器、标志位 … 再讲汇编语言程序设计。这种字典式的编写方法对入门是很不利的，因为在不知道这些东西都是用来干什么的情况下，全部记忆往往很难。然而这些概念在编程中还不得不用到，于是又得重新往前翻书，这就陷入了一个循环。</p>
<p>实际上，汇编语言的学习完全可以和高级语言一样。只不过因为汇编语言是根据CPU的工作原理进行操作，所以一切代码都要从CPU和内存的角度考虑问题。理解了指令在内存层面的执行过程，编程就水到渠成了。</p>
<span id="more"></span> 

<blockquote>
<p>  Reference:</p>
<p>  <a href="https://zhuanlan.zhihu.com/p/23969549">汇编语言程序设计</a></p>
<p>  <a href="https://www.zhihu.com/question/43608287/answer/96163327">为何不能直接写 <code>MOV DS,DATA</code></a></p>
</blockquote>
<br>

<h2 id="An-Example"><a href="#An-Example" class="headerlink" title="An Example"></a>An Example</h2><p>先从最简单的开始：给定两个数a和b，让CPU做一次加法，结果储存在c中。输出c。</p>
<p>用C语言编写这个程序：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a=<span class="number">3</span>;</span><br><span class="line"><span class="keyword">int</span> b=<span class="number">4</span>;</span><br><span class="line"><span class="keyword">int</span> c;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    c=a+b;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>,c);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：如果写int c=3+4，一行就可以搞定。但是这里没这样做，而是先统一声明所有的变量，然后再在进行运算的主函数中执行相加操作。后面可以看到，这种编程习惯是符合二进制数据在内存中的存放规律的。</p>
</blockquote>
<p>如果用汇编语言编写，该怎样写呢？</p>
<p>再重复一下题目：给定两个数a和b，让CPU做一次加法，结果储存在c中。输出c。</p>
<br>

<h2 id="Principles"><a href="#Principles" class="headerlink" title="Principles"></a>Principles</h2><p>要从原理上写这个过程，就要解决以下问题：</p>
<ul>
<li><strong>数据a和b怎么存储</strong></li>
<li><strong>怎么做加法</strong> </li>
<li><strong>怎么储存结果</strong> </li>
<li><strong>怎么输出结果</strong></li>
</ul>
<p>下面将分别解决这四个问题。</p>
<br>

<h3 id="汇编语言程序结构"><a href="#汇编语言程序结构" class="headerlink" title="汇编语言程序结构"></a>汇编语言程序结构</h3><p>首先，我们要知道二进制信号在内存中的存放规律。众所周知，计算机能直接处理的只能是二进制信号，这些信号以高低电平的方式存放在内存中，既可以作为指令，也可以作为程序使用的数据。一块内存区域所存放的二进制信号到底是指令还是数据，是由相应的命令说了算的。</p>
<p>CPU在读取指令/数据时，每读取一条指令/数据，内存位置指针就加1，指向下一条指令/数据的内存地址。这样就产生了一个问题：数据和指令在内存中应该分块，并且要连续存放。否则如果内存位置指针不知道下一个位置是数据还是代码，将会给内存位置指针的寻址带来极大的不便。所以，在汇编程序中，要人工将内存分为:</p>
<ul>
<li>数据段(Data Segment)</li>
<li>代码段(Code Segment)</li>
<li>堆栈段(Stack Segment)</li>
<li>附加段(Extra Segment)</li>
</ul>
<br>

<p>这样划分好以后，我们只需要告诉内存位置指针每个段在内存中的起始地址，内存位置指针就可以顺利寻址了。怎样告诉呢？在CPU中，有一组专门的段寄存器用来存放各个段的起始地址。它们是：DS（用来存放数据段的起始地址），CS（用来存放代码段的起始地址），SS（用来存放堆栈段的起始地址），ES（用来存放附加段的起始地址）。程序员在编程时，需要人工指定这些段寄存器对应于程序中的哪个段。</p>
<p>有了段的概念，我们就可以写出一个汇编程序的基本框架如下：</p>
<ul>
<li><p><code>DATA SEGMENT</code> : 定义一个叫DATA的段。DATA既是这个段的名称，也指代这个段的地址。但这里并未规定这个段是数据段、代码段还是其他段</p>
</li>
<li><p><code>SEGMENT ENDS</code> :  表示段结束。ENDS是END SEGMENT的缩写。</p>
</li>
<li><p><code>STACK SEGMENT</code> :  定义一个叫STACK的段，这个段的地址用STACK表示。</p>
</li>
<li><p><code>SEGMENT ENDS</code> :  段结束</p>
</li>
</ul>
<ul>
<li><code>CODE SEGMENT</code> :  定义一个叫CODE的段，，这个段的地址用CODE表示。</li>
</ul>
<ul>
<li><p><code>ASSUME:CS:CODE,DS:DATA,SS:SEGMENT</code> : 告诉编译器，将代码中写的各段分别对应上各个段寄存器。这句话要放在准备用作代码段的段开头</p>
</li>
<li><p><code>SEGMENT ENDS</code> : 段结束</p>
</li>
</ul>
<br>

<p>好了。回到我们的问题：怎样存储a和b呢？在数据段中声明变量如下：</p>
<p><code>DATA SEGMENT</code></p>
<p><code>A DW 03H</code> : 定义一个名为A的双字节(即1个字)的数据，DW是Define Word 的缩写。末尾加H表示十六进制。</p>
<p>这相当于C语言中的 <code>int A=3</code>，只不过int表示的范围远大于 <code>DW</code> 而已。</p>
<p><code>B DW 04H</code> : 定义一个名为B的双字节数据。由于B是紧挨着A之后定义的，根据 数据段的连续性，B在数据段的偏移地址就是A在数据段的偏移地址 + A的长度。由于 A是双字节数据，所以A的长度是2个字。</p>
<p><code>SEGMENT ENDS</code></p>
<br>

<h3 id="CPU的运算方式及运算结果的判定"><a href="#CPU的运算方式及运算结果的判定" class="headerlink" title="CPU的运算方式及运算结果的判定"></a>CPU的运算方式及运算结果的判定</h3><blockquote>
<p>第二个问题：怎样做一次加法？</p>
</blockquote>
<p>CPU只能处理电平信号。学过模电的都知道，有一种东西叫“加法器”，输入2个电压信号，经过运算放大器后，就会得到这两个信号的和。所以CPU做加法的方式就是：把输入的两个二进制信号输入加法器，得到结果。</p>
<p>问题似乎解决了。但是我们突然发现，这样的结果几乎没有任何意义，因为我们无法知道结果的性质。比如，如果结果超出了能容许的最大位数（溢出），会怎么样？CPU没有任何提示。又或者，我们要比较两个数的大小，这就要将两个数相减。然而结果是正是负？我们无从知晓。</p>
<br>

<p>为了获知运算结果的性质，在CPU中设置了一个<strong>“标志寄存器”</strong>，专门用于存放运算结果的各种标志。它们都是用电路实现的。比如：</p>
<ul>
<li><p><strong>CF(Carry Flag)</strong> 就是用来标志无符号数运算是否产生进位。产生进位时，CF=1，反之CF=0。特别指出，CF标志位的值对有符号数的运算没有意义。</p>
</li>
<li><p><strong>OF(Overflow Flag)</strong> 则是用来标志有符号数运算是否产生溢出。产生溢出时，OF=1，反之OF=0。同理，OF标志位的值对无符号数的运算没有意义。</p>
</li>
<li><p><strong>SF(Sign Flag)</strong> 用来标志结果的正负。当结果是负(SF)时，SF=1。反之SF=0。</p>
</li>
</ul>
<blockquote>
<p>回到我们的问题：怎么做一次加法？或者更一般地，怎样做一次运算？</p>
</blockquote>
<p>我们不必关心具体的电路实现细节，只需要执行相应的运算指令，运算完成后，不仅会得到结果，各个标志位的值也可能发生相应的改变，从而有利于我们对结果的判断。例如：</p>
<p><code>ADD AX,BX</code> : 把AX和BX中的内容相加，结果存放在AX中。若AX,BX为有符号数，当产生溢出时,<code>OF=1</code>。 CF的值不确定。当结果为负时，SF=1。</p>
<br>

<h3 id="内存与寄存器的关系"><a href="#内存与寄存器的关系" class="headerlink" title="内存与寄存器的关系"></a>内存与寄存器的关系</h3><p>内存（RAM）是存放各种数据、指令的地方。根据用途的不同，又可以把它分成不同的段。而寄存器(Register)则是CPU内部<strong>临时存放运算结果</strong>的地方。与容量较大的内存相比，寄存器的<strong>容量极小</strong>（每个寄存器只有16位），<strong>数量有限</strong>（只有少数几个），<strong>用途专一</strong>（各个寄存器有不同的用途，用来存放不同方面的结果）。例如，前面所述的段寄存器(DS,CS,SS,ES)就是用来存放段的起始地址的。除了段寄存器之外，CPU中还设有通用寄存器(AX,BX,CX,DX …)。它们各自有其专门的用途，在不致于产生冲突的情况下，也可以用来存放数据或运算结果。</p>
<br>


<p>通用寄存器的用途简述如下：（通用寄存器容量都是16位的）</p>
<p><strong>1) AX</strong>：</p>
<ul>
<li>用来存放数据或运算结果</li>
<li>AX的高8位AH用于与DOS操作系统通信。向AH中装入DOS系统的指令码并执行，可以利用DOS系统完成一些操作，如在屏幕上输出字符。</li>
</ul>
<br>

<p><strong>2) DX</strong>：</p>
<ul>
<li>用来存放数据或运算结果</li>
<li>与AH的DOS屏幕输出指令码配合使用，存放准备输出到屏幕上的数据</li>
</ul>
<br>

<p><strong>3) CX</strong>：</p>
<ul>
<li>在有循环的程序中，用来存放循环次数。相当于for循环中的计数变量i。</li>
</ul>
<br>

<p><strong>4) BX、SI、DI</strong>：</p>
<ul>
<li>用来存放数据或运算结果</li>
<li>用来存放数据段中的数据在段中的偏移地址</li>
</ul>
<br>


<p>一般而言，需要运算的数据存放在内存中。CPU在程序的指令下，通过指针确定它们的位置，将它们读入寄存器。进行运算后，再将结果返回到内存预留的结果位置中。</p>
<br>

<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>回到我们的问题，在内存的DATA SEGMENT中存放有两个双字节数据A=3和B=4。要将它们读入寄存器进行相加运算，再将结果写入到内存中。为了读入寄存器，首先需要获取A和B在内存数据段中的偏移地址。确定它们的地址后，按地址将它们读入寄存器（这里可以任选两个寄存器），然后执行运算指令。运算完成后，将储存在寄存器中的结果写入到内存 <code>DATA SEGMENT</code> 中事先预留的位置。使用 <code>MOV 目标，源</code> 指令完成源对目标的赋值。代码如下：</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">DATA <span class="meta">SEGMENT</span>	<span class="comment">; Data</span></span><br><span class="line">A <span class="built_in">DW</span> <span class="number">03H</span></span><br><span class="line">B <span class="built_in">DW</span> <span class="number">04H</span></span><br><span class="line">C <span class="built_in">DW</span> ? 		<span class="comment">; ? 表示声明时不赋值。相当于 int c;</span></span><br><span class="line"><span class="meta">SEGMENT</span> ENDS</span><br><span class="line"></span><br><span class="line">STACK <span class="meta">SEGMENT</span>	<span class="comment">; Stack</span></span><br><span class="line"><span class="meta">SEGMENT</span> ENDS</span><br><span class="line"></span><br><span class="line">CODE <span class="meta">SEGMENT</span>	<span class="comment">; Code</span></span><br><span class="line"><span class="symbol">ASSUME:</span><span class="built_in">CS</span>:CODE,<span class="built_in">DS</span>:DATA,<span class="built_in">SS</span>:<span class="meta">SEGMENT</span></span><br><span class="line">        <span class="comment">; 注意：ASSUME是一个伪代码，它只是告诉了编译器各个段与段寄存器的对应关系，并未存入各段的地址。</span></span><br><span class="line"><span class="symbol">START:</span> 		<span class="comment">; 指定程序的入口位置（这个位置当然要在代码段中），并命名为START。</span></span><br><span class="line"><span class="keyword">MOV</span> <span class="built_in">AX</span>,DATA</span><br><span class="line"><span class="keyword">MOV</span> <span class="built_in">DS</span>,<span class="built_in">AX</span> 	<span class="comment">; 这两行的意思是，以通用寄存器AX为中介，将数据段DATA的起始地址（用句柄DATA表示）送入数据段寄存器DS中。</span></span><br><span class="line">        <span class="comment">; 在需要使用数据段的程序中，这一步是必须的，否则CPU无法确定数据段的位置。</span></span><br><span class="line">        <span class="comment">;（由于电路结构的原因，DS不支持直接寻址。不能直接写 MOV DS,DATA。）</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">LEA</span> <span class="built_in">SI</span>,A 	<span class="comment">; 注意：与DATA SEGMENT中DATA的含义不同，数据段中A DW 03H中的A仅表示变量名，不表示变量的地址。</span></span><br><span class="line">        <span class="comment">; 类似于int a=3，a只是名称，取地址要用 &amp;a。在汇编中，取地址用LEA BX/SI/DI,A的格式。</span></span><br><span class="line">        <span class="comment">; 注：通常用BX、SI、DI这三个寄存器存数据的偏移地址。</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">MOV</span> <span class="built_in">AX</span>,[<span class="built_in">SI</span>] 	<span class="comment">; 将 [内存数据段中以SI为偏移地址的内容] 送入通用寄存器 AX中。这里AX也可以换成BX,CX等。</span></span><br><span class="line"><span class="keyword">INC</span> <span class="built_in">SI</span> 		<span class="comment">; SI的值加1。即SI++。</span></span><br><span class="line"><span class="keyword">INC</span> <span class="built_in">SI</span> 		<span class="comment">; 因为A是双字节数据，所以要来2次才能指向下一个数据B的偏移地址。当然，这两条也可用 LEA SI,B替代。</span></span><br><span class="line"><span class="keyword">MOV</span> <span class="built_in">BX</span>,[<span class="built_in">SI</span>] 	<span class="comment">; 将 [内存数据段中以SI为偏移地址的内容] ——就是B，送入通用寄存器 BX中。</span></span><br><span class="line"><span class="keyword">ADD</span> <span class="built_in">BX</span>,<span class="built_in">AX</span> 	<span class="comment">; BX与AX相加，结果存放在BX中。当然也可以写ADD AX,BX。</span></span><br><span class="line">        <span class="comment">; 但之所以不存放在AX中，是因为一会输出要用到AH，避免冲突。</span></span><br><span class="line"><span class="keyword">LEA</span> <span class="built_in">DI</span>,C</span><br><span class="line"><span class="keyword">MOV</span> [<span class="built_in">DI</span>],<span class="built_in">BX</span> 	<span class="comment">; 这两条是将存放在BX中的结果写回数据段中C所在位置</span></span><br><span class="line"><span class="keyword">MOV</span> <span class="built_in">DX</span>,<span class="built_in">BX</span> 	<span class="comment">; 准备在屏幕上输出结果。屏幕输出的是寄存器DX中的内容。</span></span><br><span class="line"><span class="keyword">ADD</span> <span class="built_in">DX</span>,<span class="number">30H</span> 	<span class="comment">; 由于屏幕上输出的是文字，因此必须将数字+30H转换为对应的ASCII码</span></span><br><span class="line"><span class="keyword">MOV</span> <span class="number">AH</span>,<span class="number">02H</span> 	<span class="comment">; 将控制DOS系统输出数值的代码02H装入AH。这步可理解为printf()中的&quot;%d&quot;</span></span><br><span class="line"><span class="keyword">INT</span> <span class="number">21H</span> 	<span class="comment">; INT = Interrupt，中断，执行DOS命令。执行后返回程序。</span></span><br><span class="line"><span class="keyword">MOV</span> <span class="number">AH</span>,<span class="number">4CH</span> 	<span class="comment">; 4CH是程序结束，返回DOS系统的命令。将此命令装入AH，等待执行。</span></span><br><span class="line"><span class="keyword">INT</span> <span class="number">21H</span> 	<span class="comment">; 中断，DOS系统执行4CH命令。程序结束。这两步类似于 &quot;return 0&quot;</span></span><br><span class="line"><span class="meta">SEGMENT</span> ENDS</span><br><span class="line"></span><br><span class="line">END START 	<span class="comment">; 在程序的尾部，告诉编译器程序的入口位置在标号START处</span></span><br></pre></td></tr></table></figure>


<p>输出结果为7。</p>
<br>

<br>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Low Level System</tag>
        <tag>Assembly</tag>
      </tags>
  </entry>
  <entry>
    <title>Design a URL Shortener</title>
    <url>/2018/URL-Shortener/</url>
    <content><![CDATA[<p>Design a URL shortener, like <code>bit.ly.</code> </p>
<p><strong>Step 1 is to scope the project</strong>. System design questions like this are usually intentionally left open-ended, so you have to ask some questions and make some decisions about exactly what you’re building to get on the same page as your interviewer.</p>
<span id="more"></span> 

<p>So, what are we building? What features might we need?</p>
<br>

<h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><p>Is this a full web app, with a web interface? No, let’s just build an API to start.</p>
<p><strong>Since it’s an API, do we need authentication or user accounts or developer keys?</strong> No, let’s just make it open to start.</p>
<p><strong>Can people modify or delete links?</strong> Let’s leave that out for now.</p>
<p><strong>If people can’t delete links…do they persist forever? Or do we automatically remove old ones?</strong> First, it’s worth considering what policies we could use for removing old ones:</p>
<ul>
<li>(1) We could remove links that were created some length of time ago…like 6 months.</li>
</ul>
<ul>
<li>(2) We could remove links that haven’t been visited in some length of time…like 6 months.</li>
</ul>
<p>(2) seems less frustrating than (1). </p>
<br>

<p>Are there cases where (2) could still frustrate users? If a link is on the public web, it’s likely to get hit somewhat regularly, at least by spiders. But what if it’s on the private web (e.g. an internal “resources” page on a private university intranet)? Or…what if someone printed a bunch of pamphlets that had the URL on it, didn’t give out any pamphlets for a few months, then started giving them out again? That seems like a pretty reasonable thing that might happen (putting a URL on a printed piece of paper is a great reason to use a link shortener!) and having the link suddenly stop working would be quite frustrating for the user. Worse, what if a book already had the shortlink printed in a million copies? So let’s let links exist forever.</p>
<p><strong>Should we let people choose their shortlink, or just always auto-generate it?</strong> For example, say they want ca.ke/parkers-resume. Let’s definitely support that.</p>
<p><strong>Do we need analytics, so people can see how many people are clicking on a link, etc?</strong> Hmmm, good idea. But let’s leave it out to start.</p>
<p>It’s okay if your list of features was different from ours. Let’s proceed with these requirements so we’re working on the same problem.</p>
<p><strong>Next step: Design goals.</strong> If we’re designing something, we should know what we’re optimizing for! What are we optimizing for?</p>
<br>

<h2 id="Design-Goals"><a href="#Design-Goals" class="headerlink" title="Design Goals"></a>Design Goals</h2><p>Here’s what we came up with:</p>
<ul>
<li><p>We should be able to store a lot of links, since we’re not automatically expiring them.</p>
</li>
<li><p>Our shortlinks should be as short as possible. The whole point of a link shortener is to make short links! Having shorter links than our competition could be a business advantage.</p>
</li>
<li><p>Following a shortlink should be fast.</p>
</li>
<li><p>The shortlink follower should be resilient to load spikes. One of our links might be the top story on Reddit, for example.</p>
</li>
</ul>
<blockquote>
<p>It’s worth taking a moment to really think about the order of our goals. Sometimes design goals are at odds with each other (to do a better job of one, we need to do a worse job of another). So it’s helpful to know which goals are more important than others.</p>
</blockquote>
<p>It’s okay if your list wasn’t just like ours. But to get on the same page, let’s move forward with these design goals.</p>
<p><strong>Next step: building the data model</strong>. Think about the database schema or the models we’ll want. What things do we need to store, and how should they relate to each other? This is the part where we answer questions like “is this a many-to-many or a one-to-many?” or “should these be in the same table or different tables?”</p>
<br>

<h2 id="Data-Model"><a href="#Data-Model" class="headerlink" title="Data Model"></a>Data Model</h2><p>It’s worthwhile to be careful about how we name things. This’ll help us communicate clearly with our interviewer, and it’ll show that we care about using descriptive and consistent names! Many interviewers look for this.</p>
<p>Let’s call our main entity a Link. A Link is a mapping between a short_link on our site, and a long_link, where we redirect people when they visit the short_link.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">  <span class="string">Link</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">short_link</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">long_link</span></span><br></pre></td></tr></table></figure>
<p>The short_link could be one we’ve randomly generated, or one a user chose.</p>
<p>Of course, we don’t need to store the full ShortLink URL (e.g. ca.ke/mysite), we just need to store the “slug”—the part at the end (e.g. “mysite”).</p>
<p>So let’s rename the short_link field to “slug.”</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">  <span class="string">Link</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">slug</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">long_link</span></span><br></pre></td></tr></table></figure>

<p>Now the name long_link doesn’t make as much sense without short_link. So let’s change it to destination.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">  <span class="string">Link</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">slug</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">destination</span></span><br></pre></td></tr></table></figure>

<p>And let’s call this whole model/table ShortLink, to be a bit more specific.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">  <span class="string">ShortLink</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">slug</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">destination</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Investing time in carefully naming things from the beginning is always impressive in an interview. A big part of code readability is how well things are named!</p>
</blockquote>
<br>

<p><strong>Next: sketching the code</strong>. Don’t get hung up on the details here—pseudocode is fine.</p>
<p>Think of this part as sprinting to a naive first draft design, so you and your interviewer can get on the same page and have a starting point for optimizing. There may be things that come up as you go that are clearly “tricky issues” that need to be thought through. Feel free to skip these as you go—just jot down a note to come back to them later.</p>
<p>Our main goal here is to come up with a skeleton to start building things out from. Think about what endpoints/views we’ll need, and what each one will have to do.</p>
<br>

<h2 id="Views-Pages-Endpoints"><a href="#Views-Pages-Endpoints" class="headerlink" title="Views/Pages/Endpoints"></a>Views/Pages/Endpoints</h2><p><strong>First, let’s make a way to create a ShortLink.</strong></p>
<p>Since we’re making an API, let’s make it <a href="https://www.restapitutorial.com/lessons/restquicktips.html">REST-style</a>. In normal REST style, our endpoint for creating a ShortLink should be named after the entity we’re creating. Versioning apis is also a reasonable thing to do. So let’s put our creation endpoint at <code>ca.ke/api/v1/shortlink</code>.</p>
<p>To create a new ShortLink, we’ll send a POST request there. Our POST request will include one required argument: the destination where our ShortLink will point. It’ll also optionally take a slug argument. If no slug is provided, we’ll generate one. The response will contain the newly-created ShortLink, including its slug and destination.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">curl</span> <span class="string">--data</span> <span class="string">&#x27;&#123;&quot;destination&quot;: &quot;interviewcake.com&quot;&#125;&#x27;</span> <span class="string">https://ca.ke/api/v1/shortlink</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;slug&quot;:</span> <span class="string">&quot;ae8uFt&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;destination&quot;:</span> <span class="string">&quot;interviewcake.com&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In usual REST style, we should allow GET, PUT, PATCH, and DELETE requests as well to read, modify, and delete links. But since that’s not a requirement yet, we’ll just reject non-POST requests with an error 501 (“not implemented”) for now.</p>
<br>

<p>So our endpoint might look something like this (pseudocode):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shortlink</span>(<span class="params">request</span>):</span></span><br><span class="line">    <span class="keyword">if</span> request[<span class="string">&#x27;method&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="string">&#x27;POST&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> Response(<span class="number">501</span>)  <span class="comment"># HTTP 501 NOT IMPLEMENTED</span></span><br><span class="line"></span><br><span class="line">    destination = request[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;destination&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;slug&#x27;</span> <span class="keyword">in</span> request[<span class="string">&#x27;data&#x27;</span>]:</span><br><span class="line">        <span class="comment"># If they included a slug, use that</span></span><br><span class="line">        slug = request[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;slug&#x27;</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Else, make them one</span></span><br><span class="line">        slug = generate_random_slug()</span><br><span class="line"></span><br><span class="line">    DB.insert(&#123;<span class="string">&#x27;slug&#x27;</span>: slug, <span class="string">&#x27;destination&#x27;</span>: destination&#125;)</span><br><span class="line"></span><br><span class="line">    response_body = &#123; <span class="string">&#x27;slug&#x27;</span>: slug &#125;</span><br><span class="line">    <span class="keyword">return</span> Response(<span class="number">200</span>, json.dumps(response_body))  <span class="comment"># HTTP 200 OK</span></span><br></pre></td></tr></table></figure>

<p>Of course, we haven’t defined exactly how generate_random_slug() works. Considering it a bit, it quickly becomes clear this is a pretty tangled issue. We’ll have to figure out:</p>
<ul>
<li><p>What characters can we use in randomly generated slugs? More possible characters means more possible random slugs without making our shortlinks longer. But what characters are allowed in URLs?</p>
</li>
<li><p>How do we ensure a randomly generated slug hasn’t already been used? Or if there is such a collision, how do we handle it?</p>
</li>
</ul>
<p>So let’s jot down these questions, put them aside, and come back to them after we’re done sketching our general app structure.</p>
<br>

<p><strong>Second, let’s make a way to follow a ShortLink</strong>. That’s the whole point, after all!</p>
<p>Our shortened URLs should be as short as possible. So as mentioned before, we’ll give them this format: <code>ca.ke/$slug</code>.</p>
<p>Where <code>$slug</code> is the slug (either auto-generated by us or specified by the user). We could make it clearer that this is a redirect endpoint, by using a format like <code>ca.ke/r/$slug</code>, for example. But that adds 2 precious characters of length to our shortlink URLs!</p>
<blockquote>
<p>One potential challenge here: if/when we build a web app for our service, we’ll need some way of differentiating our own pages from shortlinks. For example, if we want an about page at ca.ke/about, our back-end will need to know “about” isn’t just a shortlink slug. In fact, we might want to “reserve” or “block” shortlinks for pages we think we might need, so users don’t grab URLs we might want for our own site. Alternately we could just say our pages have paths that’re always prefixed with something, like /w/. For example, ca.ke/w/about.</p>
</blockquote>
<p>The code for the redirection endpoint is pretty simple:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">redirect</span>(<span class="params">request</span>):</span></span><br><span class="line">    destination = DB.get(&#123;<span class="string">&#x27;slug&#x27;</span>: request[<span class="string">&#x27;path&#x27;</span>]&#125;)[<span class="string">&#x27;destination&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> Response(<span class="number">302</span>, destination)</span><br></pre></td></tr></table></figure>

<p><strong>Next: slug generation</strong>. Let’s return to those questions we came up with about slugs. How long should they be, what characters should we allow, and how should we handle random slug collisions?</p>
<br>

<h2 id="Slug-generation"><a href="#Slug-generation" class="headerlink" title="Slug generation"></a>Slug generation</h2><blockquote>
<p>A note about methodology: Our default process for answering questions like this is often “make a reasonable guess, brainstorm potential issues, and revise.” That’s fine, but sometimes it feels more organized and impressive to do something more like “brainstorm design goals, then design around those goals.” So we’ll do that.</p>
</blockquote>
<p>Let’s look back up at the design goals we came up with earlier. The first two are immediately relevant to this problem:</p>
<ul>
<li>We should be able to store a lot of links.</li>
<li>Our shortlinks should be as short as possible.</li>
</ul>
<br>

<p>Looking at a few examples, we can quickly notice that the more characters we allow in our shortlinks, the more different ShortLinks we can have without making our ShortLinks longer. Specifically, if we allow cc different characters, for nn-character-long slugs we have c<sup>n</sup>  distinct possibilities.</p>
<br>

<p>So if we’re trying to accommodate as many slugs as possible, we should allow as many characters as we can! So let’s do this:</p>
<ul>
<li><p>Figure out the max set of characters we can allow in our random shortlinks.</p>
</li>
<li><p>Figure out how many distinct shortlinks we want to accommodate.</p>
</li>
<li><p>Figure out how long our shortlinks must be to accommodate that many distinct possibilities.<br>Sketching a process like this before jumping in is hugely impressive. It shows organized, methodical thinking. Whenever you’re not sure how to proceed, take a step back and try to write out a process for getting to the bottom of things. It’s fine if you end up straying from your plan—it’ll still help you organize your thinking.</p>
</li>
</ul>
<br>

<h2 id="What-characters-can-we-allow-in-our-randomly-generated-slugs"><a href="#What-characters-can-we-allow-in-our-randomly-generated-slugs" class="headerlink" title="What characters can we allow in our randomly-generated slugs?"></a>What characters can we allow in our randomly-generated slugs?</h2><p>What are the constraints on cc? Let’s think about it:</p>
<ul>
<li><p>We should only use characters that are actually allowed in URLs.</p>
</li>
<li><p>We should probably only pick characters that are relatively easy to type on a keyboard. Remember the use case we talked about where people are typing in a ShortLink that they’re reading off a piece of paper?</p>
</li>
</ul>
<p>So, what characters are allowed in URLs? It’s okay to not know the answer off the top of your head. But you should be able to tell your interviewer that you know how to figure it out! Googling or searching on Stack Overflow is a fine answer.</p>
<br>

<p>It turns out the answer is “only alphanumerics, the special characters <code>$-_.+!*&#39;(),</code>, and reserved characters used for their reserved purposes may be used unencoded within a URL” (RFC 1738). “Reserved characters” with “reserved purposes” are characters like ‘?’, which marks the beginning of a query string, and ‘#’, which marks the beginning of a fragment/anchor. We definitely shouldn’t use any of those. If we allowed ‘?’ in the beginning of our slug, the characters after it would be interpreted as part of the query string and not part of the slug!</p>
<p>So just alphanumerics and the “special characters” <code>$-_.+!*&#39;(),</code>. Are accented alphabetical characters allowed? No, according to RFC 3986.</p>
<p>What about uppercase and lowercase? Domains aren’t case-sensitive (so google.com and Google.com will always go to the same place), but the path portion of a URL is case-sensitive. If I query parker.com/foo and parker.com/Foo, I’m requesting different documents (although, as a site owner, I may choose to return the same document in response to both requests). So yes, lowercase and capital versions of the same letter can be treated as different characters in our slugs.</p>
<p><br>Okay, so it seems like the set of allowed characters is A-Z, a-z, 0-9, and <code>$-_.+!*&#39;(),</code>. The apostrophe character seems a little iffy, since sometimes URLs are surrounded by single quotes in HTML documents. So let’s pull that one.</p>
<p>In fact, in keeping with point (2) above about ease of typing, let’s pull all the “special characters” from our list. It seems like a small loss on character count (8 characters) in exchange for a big win on readability and typeability. If we find ourselves wanting those extra characters, we can add add ‘em back in.</p>
<p>Ah, but what if a user is specifying her own slug? She might want to use underscores, or dashes, or parentheses…so let’s say for user-specified slugs, we allow <code>$-_.+!*&#39;(),</code> (still no apostrophe).</p>
<blockquote>
<p>While we’re on the topic of making URLs easy to type, we might want to consider constraining our character set to clear up common ambiguities. For example, not allowing both uppercase letter O and number 0. Or lowercase letter l and number 1. Font choice can help reduce these ambiguities, but we don’t have any control over the fonts people use to display our shortlinks. This is a worthwhile consideration, but at the moment it’s adding complexity to a question we’re still trying to figure out. So let’s just mention it and say, “This is something we want to keep an eye on for later, but let’s put it aside for now.” Your interviewer understands that you can’t accommodate everything in your initial design, but she’ll appreciate you showing an ability to anticipate what problems may come up in the user experience.</p>
</blockquote>
<p>Okay, so with a-z, A-Z, and 0-9, we have 26 + 26 + 10 = 62 possible characters in our randomly-generated slugs. And for user-generated slugs, we have another 10 characters <code>$-_.+!*&#39;(),</code>, for 72 total.</p>
<br>

<h2 id="How-many-distinct-slugs-do-we-need"><a href="#How-many-distinct-slugs-do-we-need" class="headerlink" title="How many distinct slugs do we need?"></a>How many distinct slugs do we need?</h2><p>About how many slugs do we need to be able to accommodate? This is a good question to ask your interviewer. She may want you to make a reasonable choice yourself. There’s no one right answer; the important thing is to show some organized thinking.</p>
<p>Here’s one way to come up with a ballpark estimate: about how many new slugs might we create on a busy day? Maybe 100,000 per minute? Hard to imagine more than that. That’s 100,000 * 60 * 24 ≈ 145100,000∗60∗24≈145 million new links a day. 52.5 billion a year. What’s a number of years that feels like “almost forever”? I’d say 100. So that’s 5.2 trillion slugs. That seems sufficiently large. It’s pretty dependent on the accuracy of our estimate of 100,000 per minute. But it seems to be a pretty reasonable ceiling, and a purposefully high one. If we can accommodate that many slugs, we expect we’ll be able to keep handing out random slugs effectively indefinitely.</p>
<br>

<h2 id="How-short-can-we-make-our-slugs-while-still-getting-enough-distinct-possibilities"><a href="#How-short-can-we-make-our-slugs-while-still-getting-enough-distinct-possibilities" class="headerlink" title="How short can we make our slugs while still getting enough distinct possibilities?"></a>How short can we make our slugs while still getting enough distinct possibilities?</h2><p>Let’s return to the formula we came up with before: with a c-character-long alphabet and slugs of length nn, we get c^n possible slugs. We want ~5 trillion possible slugs. And we decided on a 62-character alphabet. So 62^n ≈ 5 trillion. We just have to solve for nn.</p>
<p>We might know that we need to take a logarithm to solve for nn. But even if we know that, this is a tricky thing to eyeball. If we’re in front of a computer or phone, we can just plug it in to wolfram alpha. Turns out the answer is ≈7.09≈7.09. So 7 characters gets us most of the way to our target number of distinct possibilities.</p>
<p>It’s worth checking how many characters we could save by allowing <code>$-_.+!*&#39;()</code>, as well. So 72^n 5.2 trillion. We get n≈6.8. Including the special characters would save us something like .3.3 characters on our slug length.</p>
<br>

<p>Is it worth it? Of course, there’s no such thing as a fraction of a character. If we really had to accommodate at least 5.2 trillion random slugs, we’d have to round up, which would mean 7.09 would round up to 8-character slugs for our 62-character alphabet (not including special characters) and 6.8 would round up to 7-character slugs for our 72-character alphabet (including special characters).</p>
<p>But we don’t really have to accommodate 5.2 trillion or more slugs. 5.2 trillion was just a ballpark estimate—and it was intended to be a high ceiling on how many slugs we expect to get. So let’s stick with our first instinct to remove those special characters for readability purposes, and let’s choose 7 characters for our slugs.</p>
<blockquote>
<p>At a glance, looks like bit.ly agrees with our choices! They seem to use the same alphabet as us (A-Z, a-z, and 0-9) and use 7 characters for each randomly-generated slug.</p>
<p>For some added potential brevity, and some added possible random slugs, we could also allow for random slugs with fewer than 7 characters. How many additional random slugs would that get us?</p>
<p>Since this doesn’t win us much, let’s skip it for now and only use exactly-7-character random slugs.</p>
<p>One interesting lesson here: going from 6 characters to 7 characters gave us a two orders of magnitude leap in our number of possible slugs. Going from 7 characters to 8 will give us another two orders of magnitude. So if and when we do start running out of 7-character random slugs, allowing just 1 more character will dramatically push back the point where we run out of random slugs.</p>
</blockquote>
<br>

<p>Okay, we know the characters we’ll use for slugs. And we know how many characters we’ll use. <strong>Next: how do we generate a random slug?</strong></p>
<p>We could just make a random choice for each character:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_random_slug</span>():</span></span><br><span class="line">    alphabet = <span class="string">&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789&quot;</span></span><br><span class="line">    num_chars = <span class="number">7</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join([random.choice(alphabet) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_chars)])</span><br></pre></td></tr></table></figure>

<p><strong>But how do we ensure slugs are unique?</strong> Two general strategies:</p>
<ul>
<li><p>“Re-roll” when we hit an already-used slug</p>
</li>
<li><p>Adjust our slug generation strategy to only ever give us un-claimed slugs.</p>
</li>
</ul>
<p>If we’re serious about our first 2 design goals (short slugs, and accommodating many different slugs), option (2) is clearly better than option (1). Why? As we have more and more slugs in our database, we’ll get more and more collisions. For example, when we’re 3/4 of the way through our set of possible 7-character slugs, we’d expect to have to make four “rolls” before arriving at a slug that isn’t taken already. And it’ll just keep going up from there.</p>
<p>So let’s try to come up with a strategy for option (2). How could we do it?</p>
<p>The answer is base conversion.</p>
<br>

<h2 id="Using-base-conversion-to-generate-slugs"><a href="#Using-base-conversion-to-generate-slugs" class="headerlink" title="Using base conversion to generate slugs"></a>Using base conversion to generate slugs</h2><p>We usually use base-10 numbers, which allow 10 possible numerals: 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9.</p>
<p>Binary is base-2 and has 2 possible numerals: 0 and 1.</p>
<p>Our random slug alphabet has 62 possible numerals (A-Z, a-z, and 0-9). So we can think of each of our possible “random” slugs as a unique number, expressed in base-62.</p>
<br>

<p>So let’s keep track of a global current_random_slug_id. When a request for a new random slug comes in, we simply convert that number to base-62 (using our custom numeral set) and return it. Oh, and we increment the current_random_slug_id, in preparation for the next request for a random slug.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_random_slug</span>():</span></span><br><span class="line">    <span class="keyword">global</span> current_random_slug_id</span><br><span class="line">    slug = base_conversion(current_random_slug_id, base_62_alphabet)</span><br><span class="line">    current_random_slug_id += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> slug</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Where should we store our current_random_slug_id? We can keep it in memory on our web server, perhaps with a regular writethrough to the database, to make it persistent even if the web server crashes. But what if we have multiple front-end web servers?</p>
</blockquote>
<p>How do we do the base conversion? This is easiest to show by example.</p>
<p>Take the number 125 in base 10. So to convert 125 to base-62, the answer is 21. Another example, 7,912 is the three-digit number <code>2 3 38</code>.</p>
<br>

<p><strong>One potential issue</strong>: the current_random_slug_id could be shorter than 7 digits in base-62. We could pad the generate slug with zeros to force it to be exactly 7 characters. Or we could simply accept shorter random slugs—we’d just need to make sure our function that converts slugs back to numbers doesn’t choke when the slug is fewer than 7 characters.</p>
<p><strong>Another issue</strong> is that the current_random_slug_id could give us something that a user has already claimed as a user-generated slug. We’ll need to check for that, and if it happens we’ll just increment the current_random_slug_id and try again (and again, potentially, until we hit a “random” slug that hasn’t been used yet).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_random_slug</span>():</span></span><br><span class="line">    <span class="keyword">global</span> current_random_slug_id</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        slug = base_conversion(current_random_slug_id, base_62_alphabet)</span><br><span class="line">        current_random_slug_id += <span class="number">1</span></span><br><span class="line">        <span class="comment"># Make sure the slug isn&#x27;t already used</span></span><br><span class="line">        existing = DB.get(&#123;<span class="string">&#x27;slug&#x27;</span>: slug&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> existing:</span><br><span class="line">            <span class="keyword">return</span> slug</span><br></pre></td></tr></table></figure>

<p>Okay, this’ll work! What’s next? </p>
<br>
## Database Choice


<p>Let’s look back at our design goals!</p>
<ul>
<li><p>We should be able to store a lot of links.</p>
</li>
<li><p>Our shortlinks should be as short as possible.</p>
</li>
<li><p>Following a shortlink should be fast.</p>
</li>
<li><p>The shortlink follower should be resilient to load spikes.</p>
</li>
</ul>
<p>We’re all set on (1) and (2)! Let’s start tackling (3) and (4). How do we scale our link follower to be fast and resilient to load spikes?</p>
<blockquote>
<p>Beware of premature optimization! That always looks bad. Don’t just jump around random ideas for optimizations. Instead, focus on asking yourself which thing is likely to bottleneck first and optimizing around that.</p>
</blockquote>
<br>

<p>The database read to get the destination for the given slug is certainly going to be our first bottleneck. In general, database operations usually bottleneck before business logic.</p>
<p>To figure out how to get these reads nice and fast, we should get specific about how we’re storing our shortlinks. To start, what kind of database should we use?</p>
<p>Database choice is a very broad issue. And it’s a contentious one. There are lots of different opinions about how to approach this. Here’s how we’ll do it:</p>
<br>

<p>Broadly (this is definitely a simplification), there are two main types of databases these days:</p>
<ul>
<li><p>Relational databases (RDBMs) like MySQL and Postgres.</p>
</li>
<li><p>“NoSQL”-style databases like BigTable and Cassandra.</p>
</li>
</ul>
<p>In general (again, this is a simplification), relational databases are great for systems where you expect to make lots of complex queries involving joins and such—in other words, they’re good if you’re planning to look at the relationships between things a lot. NoSQL databases don’t handle these things quite as well, but in exchange they’re faster for writes and simple key-value reads.</p>
<p>Looking at our app, it seems like relational queries aren’t likely to be a big part of our app’s functionality, even if we added a few of the obvious next features we might want. So let’s go with <strong>NoSQL</strong> for this.</p>
<br>

<p>Which NoSQL database do we use? Lots of options, each with their own pros and cons. Let’s keep our discussion and pseudocode generic for now.</p>
<blockquote>
<p>We might consider adding an abstraction layer between our application and the database, so that we can change over to a new one if our needs change or if some new hotness comes out.</p>
</blockquote>
<p>Okay, so we have our data in a NoSQL-type database. How do we un-bottleneck database reads?</p>
<p>The first step is to make sure we’re indexing the right way. In a NoSQL context, that means carefully designing our keys. In this case, the obvious choice is right: making the key for each row in the ShortLink table be the slug.</p>
<blockquote>
<p>If we used a SQL-type database like MySQL or Postgres, we usually default to having our key field be a standard auto-incrementing integer called “id” or “index.” But in this case, because we know that slugs will be unique, there’s no need for an integer id—the slug is enough of a unique identifier.</p>
<p>BUT here’s where it gets clever: what if we represented the slug as an auto-incrementing integer field? We’d just have to use our base conversion function to convert them to slugs! This would also give us tracking of our global current_random_slug_id for free—MySQL would keep track of the highest current id in the table when it auto increments. Careful though: user-generated slugs throw a pretty huge monkey wrench into things with this strategy! How can you maintain uniqueness across user-generated and randomly-generated slugs without breaking the auto-incrementing ids for randomly-generated slugs?</p>
</blockquote>
<br>

<p>How else can we <strong>speed up database reads</strong>?</p>
<p>We could put as much of the data in memory as possible, to avoid disc seeks.</p>
<p>This becomes especially important when we start getting a heavy load of requests to a single link, like if one of our links is on the front page of Reddit. If we have the redirect URL right there in memory, we can process those redirects quickly.</p>
<p>Depending on the database we use, it might already have an in-memory cache system. To get more links in memory, we may be able to configure our database to use more space for its cache.</p>
<p>If reads are still slow, we could research adding a caching layer, like memcached. Importantly, this might not save us time on reads, if the cache on the database is already pretty robust. It adds complexity—we now have two sources of truth, and we need to be careful to keep them in sync. For example, if we let users edit their links, we need to push those edits to both the database and the cache. It could also slow down reads if we have lots of cache misses.</p>
<p><strong>If we did add a caching layer</strong>, there are a few things we could talk about:</p>
<ul>
<li><p><strong>The eviction strategy</strong>. If the cache is full, what do we remove to make space? The most common answer is an LRU (“least recently used”) strategy.</p>
</li>
<li><p><strong>Sharding strategy</strong>. Sharding our cache lets us store more stuff in memory, because we can use more machines. But how do we decide which things go on which shard? The common answer is a “hash and mod strategy”—hash the key, mod the result by the number of shards, and you get a shard number to send your request to. But then how do you add or remove a shard without causing an unmanageable spike in cache misses?</p>
</li>
</ul>
<p>Of course, we could shard our underlying database instead of, or in addition to caching. If the database has a built-in in-memory cache, sharding the data would allow us to keep more of our data in working memory without an additional caching layer! Database sharding has some of the same challenges as cache sharding. Adding and removing shards can be painful, as can migrating the schema without site downtime. That said, some NoSQL databases have great sharding systems built right in, like <strong>Cassandra</strong>.</p>
<br>

<p>This should get our database reads nice and fast.</p>
<p>The next bottleneck might be processing the actual web requests. To remedy this, we should set up multiple web server workers. We can put them all behind a load balancer that distributes incoming requests across the workers. Having multiple web servers adds some complexity to our database (and caching layers) that we’ll need to consider. They’ll need to handle more simultaneous connections, for example. Most databases are pretty good at this by default.</p>
<p>Okay, now our redirects should go pretty quick, and should be resilient to load spikes. We have a solid system that fits all of our design goals!</p>
<ul>
<li><p>We can store a lot of links.</p>
</li>
<li><p>Our shortlinks are as short as possible.</p>
</li>
<li><p>Following a shortlink is fast.</p>
</li>
<li><p>The shortlink follower is resilient to load spikes.</p>
</li>
</ul>
<br>

<h2 id="Bonus"><a href="#Bonus" class="headerlink" title="Bonus"></a>Bonus</h2><p>As with all system design questions, there are a bunch more directions to go into with this one. A few ideas:</p>
<ul>
<li><p>At some point we’d probably want to consider splitting our link creation endpoint across multiple workers as well. This adds some complexity: how do they stay in sync about what the current_random_slug_id is?</p>
</li>
<li><p>Uptime and “single point of failure” (SPOF) are common concerns in system design. Are there any SPOFs in our current architecture? How can we ensure that an individual machine failure won’t bring down our whole system?</p>
</li>
<li><p>Analytics. What if we wanted to show users some analytics about the links they’ve created? What analytics could we show, and how would we store and display them?</p>
</li>
<li><p>Editing and deleting. How would we add edit and delete features?</p>
</li>
<li><p>Optimizing for implementation time. We built something optimized for scale. How would our system design be different if we were just trying to get an MVP off the ground as quickly as possible?</p>
</li>
</ul>
<br>

<br>


]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>LC Linked List (Java)</title>
    <url>/2018/LC-Java-List/</url>
    <content><![CDATA[<p>LC 链表经典题目总结，此篇包含五题：</p>
<ul>
<li>  021 - Merge 2 Sorted Lists</li>
<li>  083 - Remove Duplicates from Sorted List</li>
<li>  206 - Reverse Linked List</li>
<li>  234 - Palindrome Linked List</li>
<li>  141 - Linked List Cycle</li>
</ul>
<span id="more"></span> 

<br>

<h2 id="Merge-2-Sorted-Lists"><a href="#Merge-2-Sorted-Lists" class="headerlink" title="Merge 2 Sorted Lists"></a>Merge 2 Sorted Lists</h2><blockquote>
<p>  Singly linked list.   用题中给的 class 就行，不需要用 Java 的 LinkedList.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ListNode <span class="title">merge</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 用了 dummy，就不需要判断 l1, l2 是否为空</span></span><br><span class="line">    <span class="comment">// 因为 dummy 始终指向一个哨兵节点</span></span><br><span class="line">    ListNode dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);			</span><br><span class="line">    ListNode cur = dummy;						</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (l1 != <span class="keyword">null</span> &amp;&amp; l2 != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (l1.val &lt; l2.val) &#123;</span><br><span class="line">            cur.next = l1;</span><br><span class="line">            l1 = l1.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            cur.next = l2;</span><br><span class="line">            l2 = l2.next;</span><br><span class="line">        &#125;</span><br><span class="line">        cur = cur.next;</span><br><span class="line">    &#125;</span><br><span class="line">    cur.next = (l1 == <span class="keyword">null</span>) ? l2 : l1;		<span class="comment">// 三目运算符</span></span><br><span class="line">    <span class="keyword">return</span> dummy.next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<br>

<h2 id="Remove-Duplicates-from-Sorted-List"><a href="#Remove-Duplicates-from-Sorted-List" class="headerlink" title="Remove Duplicates from Sorted List"></a>Remove Duplicates from Sorted List</h2><blockquote>
<p>  模板题</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ListNode <span class="title">deleteDuplicates</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    ListNode cur = head;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (cur != <span class="keyword">null</span> &amp;&amp; cur.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cur.val == cur.next.val)</span><br><span class="line">            cur.next = cur.next.next;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// else 不要忘了，否则： [1, 1, 1] -&gt; [1, 1]</span></span><br><span class="line">        <span class="keyword">else</span> cur = cur.next;										</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<br>



<h2 id="Reverse-Linked-List"><a href="#Reverse-Linked-List" class="headerlink" title="Reverse Linked List"></a>Reverse Linked List</h2><blockquote>
<p>  经典模板题</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ListNode <span class="title">reverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(head == <span class="keyword">null</span> || head.next == <span class="keyword">null</span>)  <span class="keyword">return</span> head;						</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// pre 这个相当于 New Head</span></span><br><span class="line">    ListNode pre = <span class="keyword">null</span>;		</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 如果 head == null，那就说明链表到头了</span></span><br><span class="line">    <span class="keyword">while</span> (head != <span class="keyword">null</span>) &#123;		</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 先用 tmp 储存 next，然后让 next 指向之前的 node</span></span><br><span class="line">        ListNode tmp = head.next;	</span><br><span class="line">        head.next = pre;   </span><br><span class="line">        pre = head;</span><br><span class="line">        head = tmp;		</span><br><span class="line">    &#125;					   </span><br><span class="line">    <span class="keyword">return</span> pre;			   </span><br><span class="line">&#125;						</span><br></pre></td></tr></table></figure>

<br>

<br>

<h2 id="Palindrome-Linked-List"><a href="#Palindrome-Linked-List" class="headerlink" title="Palindrome Linked List"></a>Palindrome Linked List</h2><blockquote>
<p>  画图。此题要在熟练 reverse linked list 的基础之上</p>
<p>  分为三块：reverse，一行判断奇偶， slow &amp; pre 遍历</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (head == <span class="keyword">null</span> || head.next == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核心在于，用两个指针，slow 一边走，一边 reverse</span></span><br><span class="line">    ListNode fast = head;			</span><br><span class="line">    ListNode slow = head;		</span><br><span class="line">    ListNode pre = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (fast != <span class="keyword">null</span> &amp;&amp; fast.next != <span class="keyword">null</span>) &#123;		<span class="comment">// fast 的判断</span></span><br><span class="line"></span><br><span class="line">        fast = fast.next.next;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 下面四行为 reverse link 的基本操作</span></span><br><span class="line">        ListNode tmp = slow.next;					</span><br><span class="line">        slow.next = pre;							</span><br><span class="line">        pre = slow;</span><br><span class="line">        slow = tmp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果长度为奇数 （那么slow再移一格，跳过中间的那个点）</span></span><br><span class="line">    <span class="keyword">if</span> (fast != <span class="keyword">null</span>)   slow = slow.next;			</span><br><span class="line"></span><br><span class="line">    <span class="comment">// pre is the New Head</span></span><br><span class="line">    <span class="keyword">while</span> (pre != <span class="keyword">null</span>) &#123;	<span class="comment">// 用 (slow != null) 一样的      						</span></span><br><span class="line">        <span class="keyword">if</span> (slow.val != pre.val) <span class="keyword">return</span> <span class="keyword">false</span>;		</span><br><span class="line">        slow = slow.next;</span><br><span class="line">        pre = pre.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  拓展： <strong>链表找倒数第k个节点</strong></p>
<p>  创建两个指针，第一个先走k-1步然后两个在一同走。第一个走到最后时则第二个指针指向倒数第k位置。</p>
</blockquote>
<br>

<br>





<h2 id="Linked-List-Cycle"><a href="#Linked-List-Cycle" class="headerlink" title="Linked List Cycle"></a>Linked List Cycle</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasCycle</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (head == <span class="keyword">null</span> || head.next == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 直接用 head 也可以，但用 cur 指代好一点</span></span><br><span class="line">    <span class="comment">// 经典思想： 两个指针，如果有循环，那么总会碰面的</span></span><br><span class="line">    ListNode cur = head;			</span><br><span class="line">    ListNode fast = cur;			</span><br><span class="line">    ListNode slow = cur;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注意这里的条件判断，fast.next 必须不是 null 才能进行下去</span></span><br><span class="line">    <span class="comment">// fast.next.next 可以是 null （到了链尾）	</span></span><br><span class="line">    <span class="keyword">while</span> (fast != <span class="keyword">null</span> &amp;&amp; fast.next != <span class="keyword">null</span>) &#123;										</span><br><span class="line">        fast = fast.next.next;</span><br><span class="line">        slow = slow.next;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 先移动指针，再判断，顺序不可颠倒</span></span><br><span class="line">        <span class="keyword">if</span> (fast == slow) <span class="keyword">return</span> <span class="keyword">true</span>;				</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;    </span><br><span class="line">        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<br>

<br>
]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>中文</tag>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>Trees &amp; Graphs 不完全模板总结</title>
    <url>/2018/LC-Java-Summary/</url>
    <content><![CDATA[<p>今天来总结一下树和图的解题套路。此篇包括：</p>
<ul>
<li>  构造树</li>
<li>  树的遍历 （递归 &amp; 迭代）</li>
<li>  网格遍历</li>
<li>  并查集 (Union Find)</li>
<li>  递归</li>
<li>  回溯 （治理分支污染）</li>
</ul>
<span id="more"></span> 

<br>



<h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><br>

<h3 id="构造树"><a href="#构造树" class="headerlink" title="构造树"></a><u>构造树</u></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TreeNode root = <span class="keyword">new</span> TreeNode(value);</span><br><span class="line"></span><br><span class="line">root.left  = recursion(left);</span><br><span class="line">root.right = recursion(right);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> root;</span><br></pre></td></tr></table></figure>



<br>

<h3 id="树的遍历-（递归-amp-迭代）"><a href="#树的遍历-（递归-amp-迭代）" class="headerlink" title="树的遍历 （递归 &amp; 迭代）"></a><u>树的遍历 （递归 &amp; 迭代）</u></h3><blockquote>
<p>  <a href="https://mp.weixin.qq.com/s?__biz=MzU0ODMyNDk0Mw==&mid=2247487028&idx=1&sn=e06a0cd5760e62890e60e43a279a472b&chksm=fb419d14cc36140257eb220aaeac182287b10c3cab5c803ebd54013ee3fc120d693067c2e960&scene=21#wechat_redirect">遍历所有节点， 打印输出 (Link)</a></p>
</blockquote>
<br>

<p>总结：</p>
<ul>
<li>  **<u>BFS 节省时间</u>**， DFS 节省空间</li>
<li>  <strong>剪枝</strong>： 不符合条件的直接结束，以免 TLE</li>
<li>  <strong>BFS 解决最短路</strong>，DFS 解决连通性</li>
</ul>
<br>



<h4 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h4><p>每层遍历。本质还是和 DFS-前序 很像，都是遵循 root - left - right 的顺序。</p>
<br>

<blockquote>
<p>  迭代</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bfs</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    </span><br><span class="line">    Queue&lt;TreeNode&gt; q = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    q.offer(root);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!q.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = q.size(); i &gt; <span class="number">0</span>; ++i) &#123;</span><br><span class="line">            TreeNode node = q.poll();</span><br><span class="line">            System.out.print(node.val);		<span class="comment">// 打印输出</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (node.left != <span class="keyword">null</span>)  q.offer(node.left);</span><br><span class="line">            <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) q.offer(node.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> 	<span class="keyword">return</span>;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>



<blockquote>
<p>  递归</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bfs</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> d = depth(root);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> level = <span class="number">0</span>; level &lt; d; ++level)</span><br><span class="line">        printPath(root, level);	</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 递归打印，顺序： root - left - right</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">printPath</span><span class="params">(TreeNode root, <span class="keyword">int</span> level)</span> </span>&#123;		</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    <span class="keyword">if</span> (level == <span class="number">0</span>) System.out.print(root.val);</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        printPath(root.left,  level - <span class="number">1</span>);</span><br><span class="line">        printPath(root.right, level - <span class="number">1</span>);</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用 DFS-前序 找一共有几层 (maxDepth)</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">depth</span><span class="params">(TreeNode root)</span> </span>&#123;			</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> l = depth(root.left);</span><br><span class="line">    <span class="keyword">int</span> r = depth(root.right);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Math.max(l, r) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>



<h4 id="DFS-（前序）"><a href="#DFS-（前序）" class="headerlink" title="DFS （前序）"></a>DFS （前序）</h4><p>顺序： root - left - right</p>
<br>

<blockquote>
<p>  递归</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    </span><br><span class="line">    System.out.print(root.val);		<span class="comment">// DFS 的变形，条件判断写在这一行</span></span><br><span class="line">    dfs(root.left);</span><br><span class="line">    dfs(root.right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<blockquote>
<p>  迭代</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span> <span class="keyword">return</span> root);</span><br><span class="line">    </span><br><span class="line">    Stack&lt;TreeNode&gt; s = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">    s.push(root);</span><br><span class="line"> <span class="comment">// Stack&lt;Integer&gt;  n = new Stack&lt;&gt;();</span></span><br><span class="line"> <span class="comment">// n.push(1);</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!s.isEmpty()) &#123;</span><br><span class="line">     <span class="comment">// int tmp = n.pop();</span></span><br><span class="line">        TreeNode node = s.pop();</span><br><span class="line">        System.out.print(node.val);		<span class="comment">// 打印输出</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// right 先压栈才是 preorder，因为栈是 LIFO</span></span><br><span class="line">        <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) s.push(node.right);		</span><br><span class="line">        <span class="keyword">if</span> (node.left != <span class="keyword">null</span>)  s.push(node.left);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>



<h4 id="后序"><a href="#后序" class="headerlink" title="后序"></a>后序</h4><p>顺序： left - right - root</p>
<br>

<blockquote>
<p>  递归</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postorder</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    </span><br><span class="line">    postorder(root.left);</span><br><span class="line">    postorder(root.right);</span><br><span class="line">    System.out.print(root.val);		<span class="comment">// Postorder 的变形，条件判断写在这一行</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>



<blockquote>
<p>  迭代</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postorder</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 需要用两个 stack，一个记录 node， 一个记录打印顺序</span></span><br><span class="line">    Stack&lt;TreeNode&gt; path = <span class="keyword">new</span> Stack&lt;&gt;();	</span><br><span class="line">    Stack&lt;TreeNode&gt; s = <span class="keyword">new</span> Stack&lt;&gt;();		</span><br><span class="line">    s.push(root);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!s.isEmpty()) &#123;</span><br><span class="line">        TreeNode node = s.pop();</span><br><span class="line">        path.push(node);	<span class="comment">// 这里。DFS前序是直接打印，后序是放进 path stack			</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// left 先压栈才是 postorder，因为这里用了两个栈</span></span><br><span class="line">        <span class="keyword">if</span> (node.left != <span class="keyword">null</span>)  s.push(node.left);			</span><br><span class="line">        <span class="keyword">if</span> (node.right != <span class="keyword">null</span>) s.push(node.right);		</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// LIFO，左边最后进，最先出</span></span><br><span class="line">    <span class="keyword">while</span> (!path.isEmpty())  System.out.print(path.pop());			</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br>

<h4 id="中序"><a href="#中序" class="headerlink" title="中序"></a>中序</h4><p>顺序： left - root - right</p>
<br>

<blockquote>
<p>  递归</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inorder</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    </span><br><span class="line">    inorder(root.left);</span><br><span class="line">    System.out.print(root.val);		<span class="comment">// Inorder 的变形，条件判断写在这一行</span></span><br><span class="line">    inorder(root.right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<blockquote>
<p>  迭代</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inorder</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 不用放 root，因为不是从 root 开始的</span></span><br><span class="line">    Stack&lt;TreeNode&gt; s = <span class="keyword">new</span> Stack&lt;&gt;();		</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!s.isEmpty() || root != <span class="keyword">null</span>) &#123;	<span class="comment">// 注意条件</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;		<span class="comment">// 注意判断</span></span><br><span class="line">            s.push(root);</span><br><span class="line">            root = root.left;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            root = s.pop();		<span class="comment">// 这里直接用 root，不需要用 TreeNode node</span></span><br><span class="line">            System.out.print(root.val);		<span class="comment">// 逻辑判断替换此行</span></span><br><span class="line">            root = root.right;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> 	<span class="keyword">return</span>;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><br>

<h3 id="网格遍历"><a href="#网格遍历" class="headerlink" title="网格遍历"></a><u>网格遍历</u></h3><blockquote>
<p>  <a href="https://leetcode-cn.com/problems/number-of-islands/solution/dao-yu-lei-wen-ti-de-tong-yong-jie-fa-dfs-bian-li-/">网格类问题 DFS 通用思路</a></p>
</blockquote>
<p>和二叉树的 DFS 类比。</p>
<p>首先，网格结构中的格子有多少相邻结点？答案是上下左右四个。对于格子 (r, c) 来说（r 和 c 分别代表行坐标和列坐标），四个相邻的格子分别是 (r-1, c)、(r+1, c)、(r, c-1)、(r, c+1)。换句话说，**<u>网格结构是「四叉」的</u>**。</p>
<img data-src="https://pic.leetcode-cn.com/63f5803e9452ccecf92fa64f54c887ed0e4e4c3434b9fb246bf2b410e4424555.jpg" style="zoom:70%;" />



<br>

<p>网格 DFS 中的 base case : </p>
<p>不需要继续遍历、<code>grid[r][c]</code> 会出现数组下标越界异常的格子，也就是那些超出网格范围的格子。</p>
<img data-src="https://pic.leetcode-cn.com/5a91ec351bcbe8e631e7e3e44e062794d6e53af95f6a5c778de369365b9d994e.jpg" style="zoom:70%;" />





<br>

<p>网格结构的 DFS 与二叉树的 DFS 最大的不同之处在于，遍历中可能遇到遍历过的结点。 (因为图是连通的)</p>
<p>避免重复遍历: <u><strong>标记已经遍历过的格子</strong></u></p>
<p>每走过一个陆地格子，就把格子的值改为 2，这样当我们遇到 2 的时候，就知道这是遍历过的格子了。<br>也就是说，每个格子可能取三个值：</p>
<ul>
<li>  0 —— 海洋格子</li>
<li>  1 —— 陆地格子（未遍历过）</li>
<li>  <strong>2 —— 陆地格子（已遍历过）</strong></li>
</ul>
<br>

<p>框架代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span>[][] grid, <span class="keyword">int</span> r, <span class="keyword">int</span> c)</span> </span>&#123;</span><br><span class="line">    		</span><br><span class="line">    <span class="comment">// 判断 base case： 如果坐标 (r, c) 超出了网格范围，直接返回</span></span><br><span class="line">    <span class="keyword">if</span> (!inArea(grid, r, c))  <span class="keyword">return</span>;	</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 如果这个格子不是岛屿，直接返回</span></span><br><span class="line">    <span class="keyword">if</span> (grid[r][c] != <span class="number">1</span>)  <span class="keyword">return</span>;		</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 将格子标记为「已遍历过」</span></span><br><span class="line">    grid[r][c] = <span class="number">2</span>; 			</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 访问上、下、左、右四个相邻结点</span></span><br><span class="line">    dfs(grid, r - <span class="number">1</span>, c);		</span><br><span class="line">    dfs(grid, r + <span class="number">1</span>, c);</span><br><span class="line">    dfs(grid, r, c - <span class="number">1</span>);</span><br><span class="line">    dfs(grid, r, c + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断坐标 (r, c) 是否在网格中</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">inArea</span><span class="params">(<span class="keyword">int</span>[][] grid, <span class="keyword">int</span> r, <span class="keyword">int</span> c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span> &lt;= r &amp;&amp; r &lt; grid.length;		<span class="comment">// r 的左右区间</span></span><br><span class="line">        &amp;&amp; <span class="number">0</span> &lt;= c &amp;&amp; c &lt; grid[<span class="number">0</span>].length;	<span class="comment">// c 的左右区间</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<div class="note success"><p><strong>实战： <a href="https://leetcode.com/problems/number-of-islands/">Number of Islands (LC 200)</a></strong></p>
</div>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numIslands</span><span class="params">(<span class="keyword">char</span>[][] grid)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; grid.length; ++i) &#123;		<span class="comment">// i - r: row</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; grid[<span class="number">0</span>].length; j++) &#123;	<span class="comment">// j - c: column</span></span><br><span class="line">            <span class="keyword">if</span>(grid[i][j] == <span class="string">&#x27;1&#x27;</span>) &#123;</span><br><span class="line">                count++;</span><br><span class="line">                dfs(grid, i, j);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">char</span>[][] grid, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (i &lt; <span class="number">0</span> || j &lt; <span class="number">0</span> || i &gt;= grid.length || j &gt;= grid[<span class="number">0</span>].length || grid[i][j] != <span class="string">&#x27;1&#x27;</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 已经遍历过的，保存为 2</span></span><br><span class="line">    grid[i][j] = <span class="number">2</span>; 		</span><br><span class="line"></span><br><span class="line">    dfs(grid, i + <span class="number">1</span>, j);</span><br><span class="line">    dfs(grid, i, j + <span class="number">1</span>);</span><br><span class="line">    dfs(grid, i - <span class="number">1</span>, j);</span><br><span class="line">    dfs(grid, i, j - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>









<br>

<h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a><u>并查集</u></h3><blockquote>
<p>  <a href="https://leetcode-cn.com/problems/number-of-provinces/solution/python-duo-tu-xiang-jie-bing-cha-ji-by-m-vjdr/">LC Link</a></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnionFind</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer,Integer&gt; father;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 定义</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UnionFind</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        father = <span class="keyword">new</span> HashMap&lt;Integer,Integer&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!father.containsKey(x))</span><br><span class="line">            father.put(x, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 合并</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> rootX = find(x);</span><br><span class="line">        <span class="keyword">int</span> rootY = find(y);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rootX != rootY)  father.put(rootX,rootY);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查找</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> root = x;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(father.get(root) != <span class="keyword">null</span>)</span><br><span class="line">            root = father.get(root);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(x != root)&#123;</span><br><span class="line">            <span class="keyword">int</span> original_father = father.get(x);</span><br><span class="line">            father.put(x,root);</span><br><span class="line">            x = original_father;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否连通</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isConnected</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> find(x) == find(y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<br>

<div class="note success"><p><strong>实战： <a href="https://leetcode.com/problems/number-of-provinces/">Gifting Groups / Friend Circle (LC 547)</a></strong></p>
</div>

<p>题目分析：</p>
<ol>
<li> 考察连通分量的数目，所以我们要在模板中<strong>额外添加一个变量去跟踪集合的数量</strong>（有多少棵树）。</li>
<li> <strong>添加的时候把集合数量加一</strong></li>
<li> <strong>合并的时候让集合数量减一</strong></li>
</ol>
<br>

<blockquote>
<p>  <strong>用并查集</strong></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findCircleNum</span><span class="params">(<span class="keyword">int</span>[][] isConnected)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// class instantiation</span></span><br><span class="line">        UnionFind uf = <span class="keyword">new</span> UnionFind();				</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; isConnected.length; ++i)&#123;</span><br><span class="line">            uf.add(i);</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; ++j)</span><br><span class="line">                <span class="keyword">if</span>(isConnected[i][j] == <span class="number">1</span>)  uf.merge(i,j);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> uf.getNumOfSets();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 模版 (模版以外，新添加的内容，注释写在每行后面)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnionFind</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer,Integer&gt; father;	<span class="comment">// 记录父节点</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//【新内容】（numOfSets 记录集合的数量）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> numOfSets;				</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 定义 Constructor</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UnionFind</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        father = <span class="keyword">new</span> HashMap&lt;Integer,Integer&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 【新内容】</span></span><br><span class="line">        numOfSets = <span class="number">0</span>					</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 【新内容】</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getNumOfSets</span><span class="params">()</span> </span>&#123;			</span><br><span class="line">        <span class="keyword">return</span> numOfSets;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 添加</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!father.containsKey(x)) &#123;</span><br><span class="line">            father.put(x, <span class="keyword">null</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 【新内容】</span></span><br><span class="line">            numOfSets++;				</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 合并</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> rootX = find(x);</span><br><span class="line">        <span class="keyword">int</span> rootY = find(y);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rootX != rootY)  &#123;</span><br><span class="line">            father.put(rootX,rootY);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 【新内容】</span></span><br><span class="line">            numOfSets--;				</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查找</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> root = x;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(father.get(root) != <span class="keyword">null</span>)</span><br><span class="line">            root = father.get(root);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(x != root)&#123;</span><br><span class="line">            <span class="keyword">int</span> original_father = father.get(x);</span><br><span class="line">            father.put(x,root);</span><br><span class="line">            x = original_father;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否连通</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isConnected</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> find(x) == find(y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h2 id="递归-amp-回溯"><a href="#递归-amp-回溯" class="headerlink" title="递归 &amp; 回溯"></a>递归 &amp; 回溯</h2><br>



<h3 id="递归"><a href="#递归" class="headerlink" title="递归"></a><u>递归</u></h3><blockquote>
<p>  两篇文章</p>
<p>  <a href="https://mp.weixin.qq.com/s?__biz=MzI5MTU1MzM3MQ==&mid=2247483813&idx=1&sn=423c8804cd708b8892763a41cfcc8886&scene=21#wechat_redirect">Link 1</a></p>
<p>  <a href="https://mp.weixin.qq.com/s?__biz=MzU0ODMyNDk0Mw==&mid=2247487910&idx=1&sn=2670aec7139c6b98e83ff66114ac1cf7&chksm=fb418286cc360b90741ed54fecd62fd45571b2caba3e41473a7ea0934f918d4b31537689c664&token=1327182919&lang=zh_CN#rd">Link 2</a></p>
</blockquote>
<div class="note success"><p>简单总结：</p>
<p>分析问题我们需要采用<strong>自上而下</strong>的思维，而解决问题有时候采用<strong>自下而上</strong>的方式能让算法性能得到极大提升</p>
</div>



<p>e.g.  Climbing Stairs</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">f</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">2</span>) <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> pre = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> next = <span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">3</span>; i &lt; n + <span class="number">1</span>; i ++) &#123;</span><br><span class="line">        result = pre + next;</span><br><span class="line">        pre = next;</span><br><span class="line">        next = result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>   改造后的时间复杂度是 O(n), 而由于我们在计算过程中只定义了两个变量（pre，next），所以空间复杂度是O(1)</p>
</blockquote>
<br>

<h3 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a><u>回溯</u></h3><br>

<h4 id="治理分支污染"><a href="#治理分支污染" class="headerlink" title="治理分支污染"></a>治理分支污染</h4><p>防止分支污染： ( e.g.  3 Sum )</p>
<br>

<ul>
<li>  <strong>1 ) 每个分支都创建一个新的list</strong></li>
</ul>
<img data-src="https://mmbiz.qpic.cn/mmbiz_png/PGmTibd8KQBHuEhtvVND5AXia9ibYqvPnrchd8iacx992on4RmJKcedPuoW224ia6JhgZnuAFrfp8vHGQN8Bmocicavg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style="zoom:50%;" />

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">combSum</span><span class="params">(List&lt;Integer&gt; cur, <span class="keyword">int</span> sums[], <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">     </span><br><span class="line">    <span class="comment">// 结束条件</span></span><br><span class="line">     <span class="keyword">if</span> (target == <span class="number">0</span>)  <span class="keyword">return</span>;		</span><br><span class="line"></span><br><span class="line">    <span class="comment">// n叉树，length就是分支数量</span></span><br><span class="line">     <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sums.length; i++) &#123;	</span><br><span class="line">         </span><br><span class="line">        <span class="comment">// 逻辑处理, 如果当前值大于target我们就不要选了</span></span><br><span class="line">        <span class="keyword">if</span> (target &lt; sums[i]) <span class="keyword">continue</span>;		</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 由于List是引用传递，所以这里要重新创建一个，拷贝 cur</span></span><br><span class="line">        List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;(cur);   </span><br><span class="line">        list.add(sums[i]);							 </span><br><span class="line">        </span><br><span class="line">        combSum(list, sums, target - sums[i]);	<span class="comment">// 递归调用</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但每次都重新创建数据，运行效率很差。第二种方法：</p>
<br>

<ul>
<li><p><strong>2) 回溯算法</strong>： 从分支1执行到分支2的时候，把分支1的数据给删除</p>
<blockquote>
<p>  动画： <a href="https://www.bilibili.com/video/av842019220/">Link</a></p>
</blockquote>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">combSum</span><span class="params">(List&lt;Integer&gt; cur, <span class="keyword">int</span> sums[], <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">if</span> (target == <span class="number">0</span>)  <span class="keyword">return</span>;			<span class="comment">// 结束条件</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sums.length; i++) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (target &lt; sums[i]) <span class="keyword">continue</span>;		</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// ** 路径添加，然后参与下一轮的递归</span></span><br><span class="line">        cur.add(sums[i]);				</span><br><span class="line">        combSum(list, sums, target - sums[i]);	</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// ** 路径回溯【最关键一步】  sum[i] 已经用完了</span></span><br><span class="line">        <span class="comment">// 为什么用完： 递归调用了结束条件，已经结束了； 或者开始下一轮分支选择</span></span><br><span class="line">        cur.remove(cur.size() - <span class="number">1</span>);		</span><br><span class="line">    &#125;									</span><br><span class="line">    <span class="keyword">return</span>;								</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p>回溯实质上是一种<strong>暴力算法</strong>，所以很多时候我们需要 <strong>剪枝操作</strong></p>
<ul>
<li>  去除不必要的分支，减少时间</li>
</ul>
<br>

<p><strong>关于N皇后：</strong></p>
<blockquote>
<p>  <a href="https://cloud.tencent.com/developer/article/1424758">https://cloud.tencent.com/developer/article/1424758</a></p>
</blockquote>
<br>

<br>]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>中文</tag>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Common Syntax</title>
    <url>/2018/Java-Syntax/</url>
    <content><![CDATA[<p>Java 常用操作的总结，主要用作个人备忘录，以后视情况会更新。</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a><u>Basic</u></h2><br>

<h3 id="三目运算符"><a href="#三目运算符" class="headerlink" title="三目运算符"></a>三目运算符</h3><blockquote>
<p>  If boolean expression is true, then return value of a;   Otherwise return value of b.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">s = Boolean Expression ? exp. a : exp. b;</span><br><span class="line"></span><br><span class="line"><span class="comment">// e.g.</span></span><br><span class="line">cur.next = (l1 == <span class="keyword">null</span>) ? l2 : l1;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 上面的相当于：</span></span><br><span class="line"><span class="keyword">if</span> (l1 == <span class="keyword">null</span>)</span><br><span class="line">    cur.next = l2;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    cur.next = l1;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="输入操作"><a href="#输入操作" class="headerlink" title="输入操作"></a>输入操作</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Scanner in = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line"></span><br><span class="line">String a = in.nextLine();	<span class="comment">// Next line</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> b = in.nextInt();		<span class="comment">// Next int</span></span><br></pre></td></tr></table></figure>

<br>

<br>

<h2 id="String-操作"><a href="#String-操作" class="headerlink" title="String 操作"></a><u>String 操作</u></h2><br>

<h3 id="String-初始化：（两种）"><a href="#String-初始化：（两种）" class="headerlink" title="String 初始化：（两种）"></a>String 初始化：（两种）</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String a = <span class="string">&quot;hello&quot;</span>;		<span class="comment">// 用这种就可以了，简单</span></span><br><span class="line"></span><br><span class="line">String b = <span class="keyword">new</span> String(<span class="string">&quot;world&quot;</span>);</span><br></pre></td></tr></table></figure>

<br>

<h3 id="String-相关方法"><a href="#String-相关方法" class="headerlink" title="String 相关方法"></a>String 相关方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">a.length();</span><br><span class="line"></span><br><span class="line">a.equalsIgnoreCase(b);		<span class="comment">// 忽略大小写</span></span><br><span class="line"></span><br><span class="line">a == b; 	<span class="comment">// String 比较是否相等，用 equal。</span></span><br><span class="line">            <span class="comment">// == 表示的是，内存地址是否一致</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 遍历 String 中元素 (不能像 arr 那样，直接 for 遍历元素)</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s.length(); ++i)</span><br><span class="line">    <span class="keyword">char</span> c = s.charAt(i);</span><br></pre></td></tr></table></figure>

<br>

<h3 id="String连接"><a href="#String连接" class="headerlink" title="String连接"></a>String连接</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String a = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">String b = <span class="string">&quot;world&quot;</span>;</span><br><span class="line"></span><br><span class="line">String s1 = a + b;			<span class="comment">// 直接相加</span></span><br><span class="line">String s2 = a.concat(b);	<span class="comment">// 或者concat</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="常用提取方法"><a href="#常用提取方法" class="headerlink" title="常用提取方法"></a>常用提取方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">s.charAt(i);		<span class="comment">// Python 中，s[i]</span></span><br><span class="line"></span><br><span class="line">s.indexOf(<span class="keyword">char</span> c);	<span class="comment">// c 第一次出现的index。相对应的，最后一次出现为 lastIndexOf</span></span><br><span class="line">s.lastIndexOf();</span><br><span class="line"></span><br><span class="line">s.indexOf(String s);	<span class="comment">// 整个 str 第一次出现的index （String首个char的位置）</span></span><br><span class="line"></span><br><span class="line">s.substring(<span class="keyword">int</span> i);			<span class="comment">// 区间 [i, end) 的 str</span></span><br><span class="line"></span><br><span class="line">s.substring(<span class="keyword">int</span> i, <span class="keyword">int</span> j);	<span class="comment">// 区间 [i, j) 的 str</span></span><br><span class="line"></span><br><span class="line">s.trim();			<span class="comment">// Python strip(). 去掉前后的空格</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="StringBuilder"><a href="#StringBuilder" class="headerlink" title="StringBuilder"></a>StringBuilder</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">StringBuilder s = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出</span></span><br><span class="line">s.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 反转</span></span><br><span class="line">s.reverse();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 末尾添加</span></span><br><span class="line">s.append();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 替换</span></span><br><span class="line">s.replace(i, j, str);</span><br><span class="line">s.setChatAt(index, <span class="keyword">char</span>);</span><br></pre></td></tr></table></figure>

<br>

<br>

<h2 id="Array-操作"><a href="#Array-操作" class="headerlink" title="Array 操作"></a><u>Array 操作</u></h2><br>

<h3 id="数组基本操作"><a href="#数组基本操作" class="headerlink" title="数组基本操作"></a>数组基本操作</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 声明</span></span><br><span class="line">String [] name = <span class="keyword">new</span> String[<span class="number">5</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> [] age = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>];		<span class="comment">// 分配 3 个</span></span><br><span class="line"><span class="keyword">int</span> [] age = &#123;<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>&#125;;		<span class="comment">// 或者直接写出 elements	</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 存放数据</span></span><br><span class="line">age[<span class="number">2</span>] = <span class="number">19</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加</span></span><br><span class="line">arr.add(val);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Print elements !!</span></span><br><span class="line">System.out.println( Arrays.toString(a) );</span><br></pre></td></tr></table></figure>



<br>

<h3 id="数组遍历"><a href="#数组遍历" class="headerlink" title="数组遍历"></a>数组遍历</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> n : age) &#123;			<span class="comment">// 遍历元素。仅适用于 Arr</span></span><br><span class="line">    <span class="comment">/* ... */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果 string 想用的话： 必须先转换成 CharArray</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">char</span> c : s.toCharArray())</span><br></pre></td></tr></table></figure>

<br>



<h3 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a>二维数组</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> [][] matrix = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][<span class="number">4</span>];		<span class="comment">// 3 row, 4 column</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> [] a = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];		<span class="comment">// 初始，全部为 0 !!</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 全部设为 1</span></span><br><span class="line">Arrays.fill(a, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Length</span></span><br><span class="line"><span class="keyword">int</span> n = Arrays.length;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 排序</span></span><br><span class="line">Arrays.sort(a);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 二分查找 20 的位置</span></span><br><span class="line">Arrays.binarySearch(a, <span class="number">20</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数组是否相等</span></span><br><span class="line">Arrays.equals(a, b);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Index of Array&#x27;s element: 必须先转换成 ArrayList</span></span><br><span class="line">Arrays.asList(arr).indexOf(element);</span><br><span class="line"></span><br><span class="line"><span class="comment">// List 转化  -- 结果： [[1, 2], [3, 4]]</span></span><br><span class="line">Arrays.asList(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>), Arrays.asList(<span class="number">3</span>, <span class="number">4</span>));</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br>

<br>

<h2 id="类型变换"><a href="#类型变换" class="headerlink" title="类型变换"></a><u>类型变换</u></h2><blockquote>
<p>  <strong>Base conversion</strong>: <a href="https://stackoverflow.com/a/19607058">https://stackoverflow.com/a/19607058</a></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// char to int</span></span><br><span class="line"><span class="keyword">char</span> c;</span><br><span class="line"><span class="keyword">int</span> n = c - <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Binary string to int</span></span><br><span class="line"><span class="keyword">int</span> n = Integer.parseInt(<span class="string">&quot;1001&quot;</span>, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// String to int (两种)</span></span><br><span class="line"><span class="keyword">int</span> n = Integer.parseInt(s);</span><br><span class="line"><span class="keyword">int</span> n = Integer.valueOf(s);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// int to String</span></span><br><span class="line">String s = Integer.toString(n);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// int to array of digits</span></span><br><span class="line"><span class="keyword">int</span>[] ans = Integer.toString(n).chars().map(c -&gt; c-<span class="string">&#x27;0&#x27;</span>).toArray();</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Sentence to Array of strings:</strong></p>
<p>This can be accomplished just with <code>split</code> as it takes regex:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;This is a sample sentence with []s.&quot;</span>;</span><br><span class="line">String[] words = s.split(<span class="string">&quot;\\W+&quot;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>   This will give words as: <code>&#123;&quot;this&quot;,&quot;is&quot;,&quot;a&quot;,&quot;sample&quot;,&quot;sentence&quot;, &quot;s&quot;&#125;</code></p>
</blockquote>
<p>The <code>\\W+</code> will match all non-alphabetic characters occurring one or more times. So there is no need to replace. </p>
<br>

<br>

<h2 id="其他操作"><a href="#其他操作" class="headerlink" title="其他操作"></a><u>其他操作</u></h2><br>

<h3 id="设置临界值"><a href="#设置临界值" class="headerlink" title="设置临界值"></a>设置临界值</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Min &amp; Max Int</span></span><br><span class="line"><span class="keyword">int</span> a = Integer.MIN_VALUE;</span><br><span class="line"><span class="keyword">int</span> b = Integer.MAX_VALUE;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Min &amp; Max Long</span></span><br><span class="line"><span class="keyword">long</span> a = Long.MIN_VALUE;</span><br><span class="line"><span class="keyword">long</span> b = Long.MAX_VALUE;</span><br></pre></td></tr></table></figure>

<br>



<h3 id="常用数学方法"><a href="#常用数学方法" class="headerlink" title="常用数学方法"></a>常用数学方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 绝对值</span></span><br><span class="line">Math.abs(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 最大</span></span><br><span class="line">Math.max();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 最小</span></span><br><span class="line">Math.min();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 平方</span></span><br><span class="line">Math.pow(<span class="number">2</span>, <span class="number">4</span>);   <span class="comment">// 2^4 = 16</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Array-List"><a href="#Array-List" class="headerlink" title="Array List"></a>Array List</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">ArrayList&lt;Integer&gt; a = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加</span></span><br><span class="line">a.add(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// ArrayList to Array:</span></span><br><span class="line">Object[] arr = a.toArray();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sort</span></span><br><span class="line">Collections.sort(a);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Reverse</span></span><br><span class="line">Collections.reverse(a);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Reversely add elements</span></span><br><span class="line">a.add(<span class="number">0</span>, element);			</span><br><span class="line"></span><br><span class="line"><span class="comment">// Return 空列表</span></span><br><span class="line"><span class="keyword">if</span>(n == <span class="number">0</span>)  <span class="keyword">return</span> <span class="keyword">new</span> ArrayList();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 大小</span></span><br><span class="line">len = a.size();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get value</span></span><br><span class="line">a.get(index);</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Linked-List"><a href="#Linked-List" class="headerlink" title="Linked List"></a>Linked List</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ListNode</span></span><br><span class="line">ListNode dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">ListNode cur = dummy;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 套娃初始化</span></span><br><span class="line">LinkedList&lt;List&lt;Integer&gt;&gt; l = <span class="keyword">new</span> LinkedList&lt;List&lt;Integer&gt;&gt;();</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br>

<h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">Queue&lt;TreeNode&gt; q = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入队</span></span><br><span class="line">q.offer(root);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出队</span></span><br><span class="line">q.poll();</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Deque"><a href="#Deque" class="headerlink" title="Deque"></a>Deque</h3><blockquote>
<p>  Deque =  <a href="https://stackabuse.com/java-collections-queue-and-deque-interfaces/">Double Ended Queue</a> (can be accessed by both ends), organizes element in <strong>LIFO</strong> style</p>
<p>  <em>The documentation advise us to use the <code>Deque</code> interface which offers a more consistent API</em></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">Deque&lt;Integer&gt; dq = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 队首添加</span></span><br><span class="line">dq.addFirst(<span class="number">1</span>);</span><br><span class="line">dq.offerFirst(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 队尾添加</span></span><br><span class="line">dq.addLast(<span class="number">1</span>);</span><br><span class="line">dq.offerLast(<span class="number">1</span>);</span><br><span class="line">dq.offer(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 队首出队</span></span><br><span class="line">dq.poll();</span><br><span class="line">dq.pollFirst();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 队尾出队</span></span><br><span class="line">dq.pollLast();</span><br></pre></td></tr></table></figure>



<br>

<h3 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">Map&lt;Integer, Integer&gt; d = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Put</span></span><br><span class="line">d.put(key, value);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get Key&#x27;s Value</span></span><br><span class="line">d.get(key);</span><br><span class="line"></span><br><span class="line"><span class="comment">// If has Key</span></span><br><span class="line">d.containsKey(key);</span><br><span class="line"></span><br><span class="line"><span class="comment">// If has Value</span></span><br><span class="line">d.containsValue(value);</span><br></pre></td></tr></table></figure>

<br>

<h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">Stack&lt;Character&gt; s = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入栈</span></span><br><span class="line">s.add(c);</span><br><span class="line">s.push(c);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出栈</span></span><br><span class="line">s.pop();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判空</span></span><br><span class="line">s.isEmpty();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数量</span></span><br><span class="line">s.size();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看最新添加的元素 (peek不删除元素)</span></span><br><span class="line">s.peek();</span><br></pre></td></tr></table></figure>





<br>

<br>]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Normalization &amp; Relational Database Design</title>
    <url>/2018/Normalization/</url>
    <content><![CDATA[<p>Database normalization is the process of structuring a relational database in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity.</p>
<blockquote>
<p>  Reference: <a href="https://techdifferences.com/difference-between-normalization-and-denormalization.html">Normalization &amp; Denormalization</a></p>
</blockquote>
<span id="more"></span> 

<br>


<p>It’s common for people new to relational databases to approach the design of the tables like they would a flat, Excel-like spreadsheet: <em>to design the tables as if they were isolated, with all the data needed for a particular functionality crammed into a single table</em>.</p>
<p>This is not how relational databases are meant to be used. Tables in a relational database are <strong>linked together</strong>, forming a web of sorts, where all the data needed for a single query can be <strong>spread over a great many tables</strong>, and a change in one table can have an affect on every other table in that database.</p>
<p>It is therefore extremely important that each an every table in the database be properly designed, not only in regards to the data that each table is mean to store, but also in respect to every other table in the “web”. If you ever find yourself in need to expand your database, or refactor it in order to fix or improve your existing applications, a proper design can save you an enormous amount of time and effort.</p>
<br>



<hr>
<h2 id="Key-concepts"><a href="#Key-concepts" class="headerlink" title="Key concepts"></a>Key concepts</h2><blockquote>
<p>Most important concepts in relational database design. </p>
</blockquote>
<h3 id="Primary-Key-PK"><a href="#Primary-Key-PK" class="headerlink" title="Primary Key (PK)"></a>Primary Key (PK)</h3><p>A column with a <strong>unique value for each row</strong>. Although not all database management systems (DBMS) require you to put a PK into each table, from a design perspective a PK is a requirement. No table should be without one.</p>
<br>

<h3 id="Foreign-Key-FK"><a href="#Foreign-Key-FK" class="headerlink" title="Foreign Key (FK)"></a>Foreign Key (FK)</h3><p>These define relationships between tables. When you want a row in one table to be linked to a row in another table, you place a <strong>FK column in the child table</strong> and use the <em>value of the parent row’s PK as the value of the FK field</em>.</p>
<br>

<h3 id="Composite-Key"><a href="#Composite-Key" class="headerlink" title="Composite Key"></a>Composite Key</h3><p>This is a key that is <strong>made up of more than one column</strong>, typically when you want to prevent a table from using the same combination of values twice. It is commonly used in <strong>many-to-many relationships</strong>. </p>
<p>For example, in a table that lists item price for shops, you would only want each shop to have a single price for each item. So, you <em>create a FK for the shop and a FK for the item, and then you create a composite PK out of those two columns</em>. This would cause the DBMS to forcefully restrict entries that would create rows where the combined values of these fields are duplicated.</p>
<br>

<h3 id="One-To-One-1-1"><a href="#One-To-One-1-1" class="headerlink" title="One-To-One (1:1)"></a>One-To-One (1:1)</h3><p>A relationship between two tables, where a single row in one table is linked to a single row in another table.</p>
<pre><code>+------------+     +----------------+
| person     |     | person_contact |
+------------+     +----------------+
| person_id  | 1:1 | person_id      |
| first_name |     | email          |
| last_name  |     | phone          |
+------------+     +----------------+
</code></pre>
<p>This type of relationship is practically <strong>non-existent in normalized relational designs</strong>. They exist mostly to get around limitations in databases like Access, where the number of column was limited, thus creating the need to split tables up. They are also sometimes used to optimize the performance of the database.</p>
<br>

<h3 id="One-To-Many-1-N"><a href="#One-To-Many-1-N" class="headerlink" title="One-To-Many (1:N)"></a>One-To-Many (1:N)</h3><p>A relationship between two tables, where <strong>multiple rows in a child table</strong> can be linked to a <strong>single row in a parent table</strong>. For example:</p>
<pre><code>+------------+     +------------+
| person     |     | country    |
+------------+     +------------+
| person_id  |  |-1| country_id |
| name       |  |  | name       |
| country_id |N-|  +------------+
+------------+
</code></pre>
<p>This is in fact the only “real” type of relationship in a relational database. </p>
<br>

<h3 id="Many-To-Many-N-M"><a href="#Many-To-Many-N-M" class="headerlink" title="Many-To-Many (N:M)"></a>Many-To-Many (N:M)</h3><p>A relationship between two tables, where multiple rows in one table can be linked to multiple rows in another table. This type is “artificial” in a way, because this kind of relationship can not be created directly between tables. To accomplish this type of relationship you need to <strong>create a third table</strong>; an <strong>intermediary table</strong> that contains FKs to both parents, linked via <strong>a set of 1:N relationships</strong>.</p>
<pre><code>+-----------+     +--------------+     +--------------+
| shop      |     | prices       |     | product      |
+-----------+     +--------------+     +--------------+
| shop_id   |1-|  | product_id   |N---1| product_id   |
| shop_name |  |-N| shop_id      |     | product_name |
+-----------+     | price        |     +--------------+
                  +--------------+
</code></pre>
<br>

<hr>
<h2 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h2><p>To help us properly design our tables we have a set of guidelines which, if followed properly, will help <strong>reduce the redundancy and chance of data corruption</strong>. We call this “Normalization”.</p>
<p>There are several steps involved in normalizing a database. The steps are referred to as <strong>“Normal Forms” (NF)</strong>. There are at least seven NF ranging from 1NF to 6NF. Each NF requires that the NF before it has also been satisfied. The spot between 3NF and 4NF is reserved for the <em>BCNF (Boyce-Codd normal form)</em>, which was developed later as a slightly stronger version of the 3NF, to address certain shortcomings.</p>
<p>Tables that have <strong>reached 3NF are generally considered “normalized”</strong>. Specifically aiming for a higher level is unusual, but a table that is designed to be in 3NF is very likely also in the 5NF.</p>
<br>

<h3 id="The-First-Normal-Form-1NF"><a href="#The-First-Normal-Form-1NF" class="headerlink" title="The First Normal Form (1NF)"></a>The First Normal Form (1NF)</h3><p>The first normal form is both the simplest and the most important of the three steps. It simply requires that <strong>tables must not contain repeating groups of data</strong>. This means that if you need to store multiple, identical pieces of data for a single entry (row) then you can not serialize them into a single field, or create multiple identical columns.</p>
<p>Consider the following example. It’s a simple list of persons, where each person is listed with his/her name and phone numbers.</p>
<pre><code>+----+------+--------------------+
| id | name | phone              |
+----+------+--------------------+
|  1 | Joe  | 588-5522,789-85522 |
|  2 | Anna | 589-4567,987-12354 |
+----+------+--------------------+
</code></pre>
<p>Note that both entries store <strong>multiple phone numbers in a single field</strong>, separated by a comma. There are two major problems with this approach:</p>
<ul>
<li><p>Your database management system (DBMS) regards <strong>each field as a single value</strong>, so it can not differentiate between the individual phone numbers. From your DBMS perspective, the phone field is just a normal string containing a single value. This complicates the use of that data, especially when you need to do things like search for or extract a single value, or filter a data-set based on a single value in the field.</p>
</li>
<li><p>It also means you need to manually manage the data; to write the code that separates the values when they are retrieved and constructs the string when they are inserted. This makes it FAR more likely that your data will become <strong>corrupt or incompatible between applications</strong>. The DBMS has NO control over how the data is stored. It simply considers it a single string, and stores it as such. The internal structure and integrity of the data is completely up to you.</p>
</li>
</ul>
<p>To remedy the situation, you would need to separate the data into individual fields. Your first instinct might be to simply create multiple “phone” columns, like so:</p>
<pre><code>+----+------+----------+-----------+
| id | name | phone1   | phone2    |
+----+------+----------+-----------+
|  1 | Joe  | 588-5522 | 789-85522 |
|  2 | Anna | 589-4567 | 987-12354 |
+----+------+----------+-----------+
</code></pre>
<p>But this is <strong>NOT an acceptable solution</strong>. It does solve both of the problems I listed above, but it creates a new problem.</p>
<p>Namely that now we have restricted each person to two phone numbers and ONLY two phone numbers. What if a person needs to store three numbers? Using this table, the only way would be to add a third “phone” column, which would also add a third number to ALL other persons in the table. (What if we need to store a hundred phone numbers? Or a thousand?)</p>
<p>What we want to do is allow each person to supply as many phones as that person needs. To allow for that, we need to <ins><em>extract the phone numbers from that table altogether and put it into a new table dedicated to listing phone numbers</em></ins>. The design for that may look something like this:</p>
<pre><code>+-----------+     +--------------+
| person    |     | phone_number |
+-----------+     +--------------+
| person_id |1-|  | phone_id     |
| name      |  |-*| person_id    |
+-----------+     | number       |
                  +--------------+
</code></pre>
<p>There each row in the <code>phone_number</code> table contains a column with the ID of a person. This column identifies the person who’s number this is. A relationship like this is referred to as a <strong>One-To-Many (1:N) relationship</strong>, because each row in the parent table (<code>person</code>) can be linked to multiple rows in the child table (<code>phone_number</code>), but not the other way around.</p>
<p>The <code>person_id</code> column in the <code>phone_number</code> table is what we call a <strong>Foreign Key (FK)</strong>. It is an indication that the value in the column is meant to reference the value of another table. In many cases the DBMS will enforce this link and reject <code>phone_number</code> entries that do not provide a <code>person_id</code> that exists in the <code>person</code> table.</p>
<br>

<h3 id="The-Second-Normal-Form-2NF"><a href="#The-Second-Normal-Form-2NF" class="headerlink" title="The Second Normal Form (2NF)"></a>The Second Normal Form (2NF)</h3><p>This requires that <strong>no field should only be partially dependent on any candidate key in the table</strong>. This does not only include the PK, but any fields combinations that would uniquely identify a row.</p>
<p>Consider this design:</p>
<pre><code>+---------------+
| prices        |
+---------------+
| price_id (PK) |
| product       |
| shop          |
| unit_price    |
| qty           |
| shop_address  |
| unit_weight   |
+---------------+
</code></pre>
<p>The <code>price_id</code> column is the PK there, but because the combined values of the product and shop columns could also act as a composite PK, together they are considered a “candidate key”.</p>
<p>Lets look at a few example entries into that table.</p>
<pre><code>+----------+---------+--------+---------+------+--------------+------------+
| price_id | product | shop   | u_price | qty  | shop_address |unit_weight |
+----------+---------+--------+---------+------+--------------+------------+
|        1 | Beer    | Bob    |    9.50 | 12.0 | Main Road 5  |      15.00 |
|        2 | Pepper  | Bob    |   19.50 |  2.5 | Side Road 10 |       2.00 |
|        3 | Beer    | Jill   |    3.50 |  6.0 | Main Steet 1 |       1.50 |
|        4 | Pepper  | Jill   |    8.50 | 30.0 | Main Road 1  |      20.00 |
|        5 | Salt    | Jill   |   27.50 | 3.14 | Main Road 10 |     250.00 |
+----------+---------+--------+---------+------+--------------+------------+
</code></pre>
<p>The problem becomes apparent when we examine the values of the <code>shop_address</code> and <code>unit_weight</code> fields against the above mentioned candidate key. The <code>shop_address</code> values should be identical in all rows with the same shop value, and the <code>unit_weight</code> should be identical for the same product values. However, this design allows us to specify different shop addresses and unit weights for the same shops and products, which in reality makes no sense.</p>
<p>So, to turn this into a 2NF design, you <ins>move these fields out of the table into their own tables, creating FKs to link the new tables to the main sale table</ins>.</p>
<pre><code>+-----------+     +--------------+     +--------------+
| shop      |     | prices       |     | product      |
+-----------+     +--------------+     +--------------+
| name (PK) |1-|  | price_id     |  |-1| name (PK)    |
| address   |  |  | product      |*-|  | weight       |
+-----------+  |-*| shop         |     +--------------+
                  | unit_price   |
                  | qty          |
                  +--------------+
</code></pre>
<p>This ensures that all prices entries will be linked to a proper address and weight values.</p>
<br>

<h3 id="The-Third-Normal-Form-3NF"><a href="#The-Third-Normal-Form-3NF" class="headerlink" title="The Third Normal Form (3NF)"></a>The Third Normal Form (3NF)</h3><p>The last of the forms needed for a database to be considered normalized. It requires that <strong>columns should depend only upon the primary key of the table</strong>. Basically what that means is that any column that is not solely dependent on the primary key of this table, or only partially, should be moved out of the table.</p>
<p>Lets look at two examples:</p>
<br>

<p><strong>1) First, if we add a “country” column to the “persons” table we created for the 1NF:</strong></p>
<pre><code>+-----------+------+----------+
| person_id | name | country  |
+-----------+------+----------+
|         1 | Joe  | France   |
|         2 | Anna | England  |
+-----------+------+----------+
</code></pre>
<p>This looks fine at first glance, but consider what happens if you are asked to list ALL possible countries. (E.g. for a drop-down box on a website.) The problem is, because the countries are dependent on a person to exist, <ins>the design will only allow us to list countries of people that exist in the database</ins>. No country that does not have a representative in the person table can exist in the database.</p>
<p>The solution for this is to move the country out of the table, into it’s own table, and add a Foreign Key to the person table that references the country the person belongs to:</p>
<pre><code>+------------+     +------------+
| person     |     | country    |
+------------+     +------------+
| person_id  |  |-1| country_id |
| name       |  |  | name       |
| country_id |*-|  +------------+
+------------+
</code></pre>
<p>Now you can list all the countries in the country table, and just link the persons to their respective countries.</p>
<br>


<p><strong>2) Second, to address another common 3NF conformity issue</strong>, if we wanted to add more than just the country name for each person. If we were to add the city and address info as well, it might looks something like:</p>
<pre><code>+-----------+------+----------+--------+------------------+
| person_id | name | country  | city   | address          |
+-----------+------+----------+--------+------------------+
|         1 | Joe  | France   | Paris  | Eiffel blwd. 101 |
|         2 | Anna | England  | London | English road 302 |
+-----------+------+----------+--------+------------------+
</code></pre>
<p>This is basically the same problem we had with the previous example, but we have added two more columns, <ins><em>neither of which should stay in this table either</em></ins>. So, lets try to apply the same solution as last time, but this time move all three location items into a location table, and link the location to the person:</p>
<pre><code>+-------------+     +-------------+
| person      |     | location    |
+-------------+     +-------------+
| person_id   |  |-1| location_id |
| name        |  |  | country     |
| location_id |*-|  | city        |
+-------------+     | address     |
                    +-------------+
</code></pre>
<p>This is better, but can you spot the problem?</p>
<p>As you remember, to reach 3NF no field can depend on anything but the PK of the table. But if you look at the location table, notice that “address” depends not only on the PK, but on the “city” field as well. (If the city field changes, so must the address field). The same applies to the city field; it depends on the country field.</p>
<p>This means that, in order to reach 3NF, you need to move country, city and address all into their own tables, each linked to each other. The address table should be linked to the person, the city table linked to the address table, and finally the country table linked to the city table.</p>
<pre><code>+-------------+     +------------
| person      |     | address    
+-------------+     +------------+
| person_id   |  |-1| address_id |
| location_id |*-|  | city_id    |*-|
| name        |     | name       |  |
+-------------+     +------------+  |
                                    |
+------------+     +------------+   |
| country    |     | city       |   |
+------------+     +------------+   |
| country_id |1-|  | city_id    |1--|
| name       |  |-*| country_id |
+------------+     | name       |
                   +------------+
</code></pre>
<p>Now this design is in 3NF, and could be considered “normalized”.</p>
<br>

<hr>
<h2 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h2><p>It’s should be mentioned that in some cases, putting your tables into <strong>3NF can have a negative effect on the performance and usability</strong> of the table. Before normalizing the table, you could query all the data from the single table with a simple SELECT query. After normalizing it, fetching the exact same result requires three JOINs.</p>
<p>Normalization is a design goal. It may not always be the practical solution. It may in fact be impractical in certain situations to design fully normalized tables. If performance and resource conservation matters a great deal more to you than data integrity, then you may well be better of aiming for a lower NF level. </p>
<p>ALWAYS make sure you tables are in 1NF, but beyond that you must judge the situation for yourself. In 99% of cases, you are be better of at least trying to go for the 3NF. It may spare you some otherwise wasted efforts later on.</p>
<br>


<br>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>Concurrency Concepts</title>
    <url>/2018/Concurrency/</url>
    <content><![CDATA[<blockquote>
<p>  Key Concepts:</p>
<ul>
<li>  Message passing &amp; shared memory</li>
<li>  Processes &amp; threads</li>
<li>  Time slicing</li>
<li>  Race conditions</li>
</ul>
</blockquote>
<span id="more"></span> 

<br>


<blockquote>
<p> <a href="https://web.mit.edu/6.005/www/fa14/classes/17-concurrency/">Software Construction Lecture 17</a></p>
</blockquote>
<br>


<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Concurrency means multiple computations are happening at the same time</strong>. Concurrency is everywhere in modern programming, whether we like it or not:</p>
<ul>
<li>  Multiple computers in a network</li>
<li>  Multiple applications running on one computer</li>
<li>  Multiple processor cores on a single chip</li>
</ul>
<p>In fact, concurrency is essential in modern programming:</p>
<ul>
<li>  Websites must handle multiple simultaneous users.</li>
<li>  Mobile apps need to do some of their processing on servers (“in the cloud”).</li>
<li>  Graphical user interfaces almost always require background work that does not interrupt the user. For example, Eclipse compiles your Java code while you’re still editing it.</li>
</ul>
<p>Being able to program with concurrency will still be important in the future. Processor clock speeds are no longer increasing. Instead, we’re getting more cores with each new generation of chips. So in the future, in order to get a computation to run faster, we’ll have to <strong>split up a computation into concurrent pieces</strong>.</p>
<br>

<h2 id="Two-Models-for-Concurrent-Programming"><a href="#Two-Models-for-Concurrent-Programming" class="headerlink" title="Two Models for Concurrent Programming"></a>Two Models for Concurrent Programming</h2><blockquote>
<p>  <strong>The message-passing and shared-memory models are about how concurrent modules communicate.</strong></p>
</blockquote>
<p><strong>Shared memory</strong></p>
<p>In the shared memory model, concurrent modules interact by <strong>reading and writing shared objects in memory</strong>.</p>
<p><img data-src="/images/posts/180113-1.png" alt="01"></p>
<p>Other examples of the shared-memory model:</p>
<ul>
<li>  A and B might be two processors (or processor cores) in the same computer, sharing the same physical memory.</li>
<li>  A and B might be two programs running on the same computer, sharing a common filesystem with files they can read and write.</li>
<li>  A and B might be two threads in the same Java program (we’ll explain what a thread is below), sharing the same Java objects.</li>
</ul>
<br>

<p><strong>Message passing</strong></p>
<p>In the message-passing model, concurrent modules interact by <strong>sending messages to each other through a communication channel</strong>. Modules send off messages, and incoming messages to each module are queued up for handling.</p>
<p><img data-src="/images/posts/180113-2.png" alt="02"></p>
<p>Examples include:</p>
<ul>
<li>  A and B might be two computers in a network, communicating by network connections.</li>
<li>  A and B might be a web browser and a web server – A opens a connection to B, asks for a web page, and B sends the web page data back to A.</li>
<li>  A and B might be an instant messaging client and server.</li>
<li>  A and B might be two programs running on the same computer whose input and output have been connected by a pipe, like <code>ls | grep</code> typed into a command prompt.</li>
</ul>
<br>


<h2 id="Processes-Threads-Time-slicing"><a href="#Processes-Threads-Time-slicing" class="headerlink" title="Processes, Threads, Time-slicing"></a>Processes, Threads, Time-slicing</h2><blockquote>
<p>  <strong>The concurrent modules themselves come in two different kinds: processes and threads.</strong></p>
</blockquote>
<p><strong>Process</strong></p>
<p>A process is an instance of a running program that is <strong>isolated</strong> from other processes on the same machine. In particular, it has its own private section of the machine’s memory.</p>
<p>The process abstraction is a virtual computer. It makes the program feel like it has the entire machine to itself – like a fresh computer has been created, with fresh memory, just to run that program.</p>
<p>Just like computers connected across a network, processes normally share no memory between them. A process can’t access another process’s memory or objects at all. Sharing memory between processes is possible on most operating system, but it needs special effort. By contrast, a new process is automatically ready for message passing, because it is created with standard input &amp; output streams, which are the <code>System.out</code> and <code>System.in</code> streams you’ve used in Java.</p>
<br>

<p><strong>Thread</strong><br>A thread is a locus of control inside a running program. Think of it as a place in the program that is being run, plus the stack of method calls that led to that place to which it will be necessary to return through.</p>
<p>Just as a process represents a virtual computer, the thread abstraction represents a virtual processor. Making a new thread simulates making a fresh processor inside the virtual computer represented by the process. This new virtual processor runs the same program and shares the same memory as other threads in process.</p>
<p>Threads are automatically ready for shared memory, because threads share all the memory in the process. It needs special effort to get “thread-local” memory that’s private to a single thread. It’s also necessary to set up message-passing explicitly, by creating and using queue data structures.</p>
<p><img data-src="/images/posts/180113-3.png" alt="03"></p>
<p>How can I have many concurrent threads with only one or two processors in my computer? When there are more threads than processors, concurrency is simulated by time slicing, which means that the processor switches between threads. The figure on the right shows how three threads T1, T2, and T3 might be time-sliced on a machine that has only two actual processors. In the figure, time proceeds downward, so at first one processor is running thread T1 and the other is running thread T2, and then the second processor switches to run thread T3. Thread T2 simply pauses, until its next time slice on the same processor or another processor.</p>
<p>On most systems, time slicing happens unpredictably and nondeterministically, meaning that a thread may be paused or resumed at any time.</p>
<br>



<h2 id="Shared-Memory-Example"><a href="#Shared-Memory-Example" class="headerlink" title="Shared Memory Example"></a>Shared Memory Example</h2><p>Let’s look at an example of a shared memory system. The point of this example is to show that concurrent programming is hard, because it can have subtle bugs. Below is a model for bank accounts:</p>
<p><img data-src="/images/posts/180113-4.png" alt="04"></p>
<p>Imagine that a bank has cash machines that use a shared memory model, so all the cash machines can read and write the same account objects in memory.</p>
<p>To illustrate what can go wrong, let’s simplify the bank down to a single account, with a dollar balance stored in the balance variable, and two operations deposit and withdraw that simply add or remove a dollar:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// suppose all the cash machines share a single bank account</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> balance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deposit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    balance = balance + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">withdraw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    balance = balance - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Customers use the cash machines to do transactions like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deposit(); // put a dollar in</span><br><span class="line">withdraw(); // take it back out</span><br></pre></td></tr></table></figure>

<p>In this simple example, every transaction is just a one dollar deposit followed by a one-dollar withdrawal, so it should leave the balance in the account unchanged. Throughout the day, each cash machine in our network is processing a sequence of deposit/withdraw transactions.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// each ATM does a bunch of transactions that</span></span><br><span class="line"><span class="comment">// modify balance, but leave it unchanged afterward</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">cashMachine</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; TRANSACTIONS_PER_MACHINE; ++i) &#123;</span><br><span class="line">        deposit(); <span class="comment">// put a dollar in</span></span><br><span class="line">        withdraw(); <span class="comment">// take it back out</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>So at the end of the day, regardless of how many cash machines were running, or how many transactions we processed, we should expect the account balance to still be 0.</p>
<p>But if we run this code, we discover frequently that the balance at the end of the day is not 0. If more than one <code>cashMachine()</code> call is running at the same time – say, on separate processors in the same computer – then balance may not be zero at the end of the day. Why not?</p>
<br>

<h2 id="Interleaving"><a href="#Interleaving" class="headerlink" title="Interleaving"></a>Interleaving</h2><p>Here’s one thing that can happen. Suppose two cash machines, A and B, are both working on a deposit at the same time. Here’s how the deposit() step typically breaks down into low-level processor instructions:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">get balance (balance=0)</span><br><span class="line">add 1                 </span><br><span class="line">write back the result (balance=1)</span><br></pre></td></tr></table></figure>

<p>When A and B are running concurrently, these low-level instructions interleave with each other (some might even be simultaneous in some sense, but let’s just worry about interleaving for now):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A get balance (balance=0)</span><br><span class="line">A add 1        </span><br><span class="line">A write back the result (balance=1)</span><br><span class="line">                                    B get balance (balance=1)</span><br><span class="line">                                    B add 1     </span><br><span class="line">                                    B write back the result (balance=2)</span><br></pre></td></tr></table></figure>

<p>This interleaving is fine – we end up with balance 2, so both A and B successfully put in a dollar. But what if the interleaving looked like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A get balance (balance=0)</span><br><span class="line">                                    B get balance (balance=0)</span><br><span class="line">A add 1         </span><br><span class="line">                                    B add 1     </span><br><span class="line">A write back the result (balance=1)</span><br><span class="line">                                    B write back the result (balance=1)</span><br></pre></td></tr></table></figure>

<p>The balance is now 1 – A’s dollar was lost! A and B both read the balance at the same time, computed separate final balances, and then raced to store back the new balance – which failed to take the other’s deposit into account.</p>
<br>


<h2 id="Race-Condition"><a href="#Race-Condition" class="headerlink" title="Race Condition"></a>Race Condition</h2><p>This is an example of a race condition. A race condition means that the correctness of the program (the satisfaction of postconditions and invariants) depends on the relative timing of events in concurrent computations A and B. When this happens, we say “A is in a race with B.”</p>
<p>Some interleavings of events may be OK, in the sense that they are consistent with what a single, nonconcurrent process would produce, but other interleavings produce wrong answers – violating postconditions or invariants.</p>
<br>

<h2 id="Tweaking-the-Code-Won’t-Help"><a href="#Tweaking-the-Code-Won’t-Help" class="headerlink" title="Tweaking the Code Won’t Help"></a>Tweaking the Code Won’t Help</h2><blockquote>
<p>  <strong><a href="https://docs.oracle.com/javase/tutorial/essential/concurrency/interfere.html">Thread Interference</a></strong></p>
</blockquote>
<p>All these versions of the bank-account code exhibit the same race condition:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// version 1</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deposit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    balance = balance + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">withdraw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    balance = balance - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// version 2</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deposit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    balance += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">withdraw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    balance -= <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// version 3</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deposit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ++balance;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">withdraw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    --balance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>You can’t tell just from looking at Java code how the processor is going to execute it. You can’t tell what the indivisible operations – the atomic operations – will be. It isn’t atomic just because it’s one line of Java. It doesn’t touch balance only once just because the balance identifier occurs only once in the line. The Java compiler, and in fact the processor itself, makes no commitments about what low-level operations it will generate from your code. In fact, a typical modern Java compiler produces exactly the same code for all three of these versions!</p>
<p>The key lesson is that you can’t tell by looking at an expression whether it will be safe from race conditions.</p>
<br>


<h2 id="Reordering"><a href="#Reordering" class="headerlink" title="Reordering"></a>Reordering</h2><p>It’s even worse than that, in fact. The race condition on the bank account balance can be explained in terms of different interleavings of sequential operations on different processors. But in fact, when you’re using multiple variables and multiple processors, you can’t even count on changes to those variables appearing in the same order.</p>
<p>Here’s an example:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> ready = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> answer = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// computeAnswer runs in one thread</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">computeAnswer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    answer = <span class="number">42</span>;</span><br><span class="line">    ready = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// useAnswer runs in a different thread</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">useAnswer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!ready) &#123;</span><br><span class="line">        Thread.yield();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (answer == <span class="number">0</span>) <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;answer wasn&#x27;t ready!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>We have two methods that are being run in different threads. <code>computeAnswer</code> does a long calculation, finally coming up with the answer 42, which it puts in the answer variable. Then it sets the ready variable to true, in order to signal to the method running in the other thread, useAnswer, that the answer is ready for it to use. Looking at the code, answer is set before ready is set, so once useAnswer sees ready as true, then it seems reasonable that it can assume that the answer will be 42, right? Not so.</p>
<p>The problem is that modern compilers and processors do a lot of things to make the code fast. One of those things is making temporary copies of variables like answer and ready in faster storage (registers or caches on a processor), and working with them temporarily before eventually storing them back to their official location in memory. The storeback may occur in a different order than the variables were manipulated in your code. Here’s what might be going on under the covers (but expressed in Java syntax to make it clear). The processor is effectively creating two temporary variables, tmpr and tmpa, to manipulate the fields ready and answer:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">computeAnswer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> tmpr = ready;</span><br><span class="line">    <span class="keyword">int</span> tmpa = answer;</span><br><span class="line"></span><br><span class="line">    tmpa = <span class="number">42</span>;</span><br><span class="line">    tmpr = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    ready = tmpr;</span><br><span class="line">                   <span class="comment">// &lt;-- what happens if useAnswer() interleaves here?</span></span><br><span class="line">                   <span class="comment">// ready is set, but answer isn&#x27;t.</span></span><br><span class="line">    answer = tmpa;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<br>



<h2 id="Message-Passing-Example"><a href="#Message-Passing-Example" class="headerlink" title="Message Passing Example"></a>Message Passing Example</h2><p>Now let’s look at the message-passing approach to our bank account example.</p>
<p><img data-src="/images/posts/180113-5.png" alt="05"></p>
<p>Now not only are the cash machine modules, but the accounts are modules, too. Modules interact by sending messages to each other. Incoming requests are placed in a queue to be handled one at a time. The sender doesn’t stop working while waiting for an answer to its request. It handles more requests from its own queue. The reply to its request eventually comes back as another message.</p>
<p>Unfortunately, message passing doesn’t eliminate the possibility of race conditions. Suppose each account supports get-balance and withdraw operations, with corresponding messages. Two users, at cash machine A and B, are both trying to withdraw a dollar from the same account. They check the balance first to make sure they never withdraw more than the account holds, because overdrafts trigger big bank penalties:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">get-balance</span><br><span class="line"><span class="keyword">if</span> balance &gt;= <span class="number">1</span> then withdraw <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>The problem is again interleaving, but this time interleaving of the messages sent to the bank account, rather than the instructions executed by A and B. If the account starts with a dollar in it, then what interleaving of messages will fool A and B into thinking they can both withdraw a dollar, thereby overdrawing the account?</p>
<p>One lesson here is that you need to carefully choose the operations of a message-passing model. withdraw-if-sufficient-funds would be a better operation than just withdraw.</p>
<br>


<h2 id="Concurrency-is-Hard-to-Test-and-Debug"><a href="#Concurrency-is-Hard-to-Test-and-Debug" class="headerlink" title="Concurrency is Hard to Test and Debug"></a>Concurrency is Hard to Test and Debug</h2><p>If we haven’t persuaded you that concurrency is tricky, here’s the worst of it. It’s very hard to discover race conditions using testing. And even once a test has found a bug, it may be very hard to localize it to the part of the program causing it.</p>
<p>Concurrency bugs exhibit very poor reproducibility. It’s hard to make them happen the same way twice. Interleaving of instructions or messages depends on the relative timing of events that are strongly influenced by the environment. Delays can be caused by other running programs, other network traffic, operating system scheduling decisions, variations in processor clock speed, etc. Each time you run a program containing a race condition, you may get different behavior.</p>
<p>These kinds of bugs are heisenbugs, which are nondeterministic and hard to reproduce, as opposed to a “bohrbug”, which shows up repeatedly whenever you look at it. Almost all bugs in sequential programming are bohrbugs.</p>
<p>A heisenbug may even disappear when you try to look at it with println or debugger! The reason is that printing and debugging are so much slower than other operations, often 100-1000x slower, that they dramatically change the timing of operations, and the interleaving. So inserting a simple print statement into the cashMachine():</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">cashMachine</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; TRANSACTIONS_PER_MACHINE; ++i) &#123;</span><br><span class="line">        deposit(); <span class="comment">// put a dollar in</span></span><br><span class="line">        withdraw(); <span class="comment">// take it back out</span></span><br><span class="line">        System.out.println(balance); <span class="comment">// makes the bug disappear!</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>And suddenly the balance is always 0, as desired, and the bug appears to disappear. But it’s only masked, not truly fixed. A change in timing somewhere else in the program may suddenly make the bug come back.</p>
<p>Concurrency is hard to get right. Part of the point of this reading is to scare you a bit. Over the next several readings, we’ll see principled ways to design concurrent programs so that they are safer from these kinds of bugs.</p>
<br>



<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>  <strong>Concurrency</strong>: multiple computations running simultaneously</li>
<li>  <strong>Shared-memory</strong> &amp; <strong>message-passing</strong> paradigms</li>
<li>Processes &amp; threads<ul>
<li>  Process is like a virtual computer; thread is like a virtual processor</li>
</ul>
</li>
<li>Race conditions<ul>
<li>  When correctness of result (postconditions and invariants) depends on the relative timing of events</li>
</ul>
</li>
</ul>
<p>These ideas connect to our three key properties of good software mostly in bad ways. Concurrency is necessary but it causes serious problems for correctness. We’ll work on fixing those problems in the next few readings.</p>
<ul>
<li>  <strong>Safe from bugs</strong>. Concurrency bugs are some of the hardest bugs to find and fix, and require careful design to avoid.</li>
<li>  <strong>Easy to understand</strong>. Predicting how concurrent code might interleave with other concurrent code is very hard for programmers to do. It’s best to design in such a way that programmers don’t have to think about that.</li>
<li>  <strong>Ready for change</strong>. Not particularly relevant here.</li>
</ul>
<br>

<blockquote>
<p>  Reference:</p>
<p>  <a href="https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python">Multithreading and Multiprocessing with Python</a></p>
<p>  <a href="https://hackernoon.com/concurrent-programming-in-python-is-not-what-you-think-it-is-b6439c3f3e6a">Concurrent Programming in Python</a></p>
</blockquote>
<br>


]]></content>
      <categories>
        <category>Resources</category>
      </categories>
      <tags>
        <tag>Low Level System</tag>
      </tags>
  </entry>
  <entry>
    <title>System Design Cheatsheet</title>
    <url>/2017/System-Design-Cheatsheet/</url>
    <content><![CDATA[<div class="note success"><p>Picking the right architecture = Picking the right battles + Managing trade-offs</p>
</div>

<p>Reference:</p>
<blockquote>
<p>   <a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f">System Design Cheatsheet</a></p>
</blockquote>
<span id="more"></span> 

<br>



<h2 id="Basic-Steps"><a href="#Basic-Steps" class="headerlink" title="Basic Steps"></a>Basic Steps</h2><h3 id="Clarify-and-agree-on-the-scope-of-the-system"><a href="#Clarify-and-agree-on-the-scope-of-the-system" class="headerlink" title="Clarify and agree on the scope of the system"></a>Clarify and agree on the scope of the system</h3><ul>
<li><strong>User cases</strong> (description of sequences of events that, taken together, lead to a system doing something useful)<ul>
<li>Who is going to use it?</li>
<li>How are they going to use it?</li>
</ul>
</li>
<li><strong>Constraints</strong> <ul>
<li>Mainly identify <strong>traffic and data handling</strong> constraints at scale.</li>
<li>Scale of the system such as requests per second, requests types, data written per second, data read per second)</li>
<li>Special system requirements such as multi-threading, read or write oriented.</li>
</ul>
</li>
</ul>
<br>

<h3 id="Abstract-design"><a href="#Abstract-design" class="headerlink" title="Abstract design"></a>Abstract design</h3><ul>
<li>High level architecture design</li>
<li>Sketch the important components and connections between them, but don’t go into some details.<ul>
<li>Application service layer (serves the requests)</li>
<li>List different services required.<ul>
<li>Data Storage layer</li>
<li>eg. Usually a scalable system includes webserver (load balancer), service (service partition), database (master/slave database cluster) and caching systems.</li>
</ul>
</li>
</ul>
</li>
</ul>
<br>

<h3 id="Component-Design"><a href="#Component-Design" class="headerlink" title="Component Design"></a>Component Design</h3><ul>
<li>Component + specific <strong>APIs</strong> required for each of them.</li>
<li><strong>Object oriented design</strong> for functionalities.<ul>
<li>Map features to modules: One scenario for one module.</li>
<li>Consider the relationships among modules: <ul>
<li>Certain functions must have unique instance (Singletons)</li>
<li>Core object can be made up of many other objects (composition).</li>
<li>One object is another object (inheritance)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Database schema design.</strong></li>
</ul>
<br>

<h3 id="Understanding-Bottlenecks"><a href="#Understanding-Bottlenecks" class="headerlink" title="Understanding Bottlenecks"></a>Understanding Bottlenecks</h3><ul>
<li>Perhaps your system needs a load balancer and many machines behind it to handle the user requests. * Or maybe the data is so huge that you need to distribute your database on multiple machines. What are some of the downsides that occur from doing that? </li>
<li>Is the database too slow and does it need some in-memory caching?    </li>
</ul>
<br>

<h3 id="Scaling-abstract-design"><a href="#Scaling-abstract-design" class="headerlink" title="Scaling abstract design"></a>Scaling abstract design</h3><ul>
<li><strong>Vertical scaling</strong><ul>
<li>You scale by adding more power (CPU, RAM) to your existing machine.</li>
</ul>
</li>
<li><strong>Horizontal scaling</strong><ul>
<li>You scale by adding more machines into your pool of resources. </li>
</ul>
</li>
<li><strong>Caching</strong><ul>
<li>Load balancing helps you scale horizontally across an ever-increasing number of servers, but caching will enable you to make vastly better use of the resources you already have, as well as making otherwise unattainable product requirements feasible. </li>
<li><strong>Application caching</strong> requires explicit integration in the application code itself. Usually it will check if a value is in the cache; if not, retrieve the value from the database.</li>
<li><strong>Database caching</strong> tends to be “free”. When you flip your database on, you’re going to get some level of default configuration which will provide some degree of caching and performance. Those initial settings will be optimized for a generic usecase, and by tweaking them to your system’s access patterns you can generally squeeze a great deal of performance improvement.</li>
<li><strong>In-memory caches</strong> are most potent in terms of raw performance. This is because they store their entire set of data in memory and accesses to RAM are orders of magnitude faster than those to disk. eg. Memcached or Redis.</li>
<li>eg. Precalculating results (e.g. the number of visits from each referring domain for the previous day), </li>
<li>eg. Pre-generating expensive indexes (e.g. suggested stories based on a user’s click history)</li>
<li>eg. Storing copies of frequently accessed data in a faster backend (e.g. Memcache instead of PostgreSQL.</li>
</ul>
</li>
<li><strong>Load balancing</strong><ul>
<li>Public servers of a scalable web service are hidden behind a load balancer.  This load balancer evenly distributes load (requests from your users) onto your group/cluster of  application servers.</li>
<li>Types: Smart client (hard to get it perfect), Hardware load balancers ($$$ but reliable), Software load balancers (hybrid - works for most systems)</li>
</ul>
</li>
</ul>
<p align="center">
  <img data-src="http://lethain.com/static/blog/intro_arch/load_balance.png" alt="Load Balancing"/>
</p>

<ul>
<li><strong>Database replication</strong><ul>
<li>Database replication is the frequent electronic copying data from a database in one computer or server to a database in another so that all users share the same level of information. The result is a distributed database in which users can access data relevant to their tasks without interfering with the work of others. The implementation of database replication for the purpose of eliminating data ambiguity or inconsistency among users is known as normalization.</li>
</ul>
</li>
<li><strong>Database partitioning</strong><ul>
<li>Partitioning of relational data usually refers to decomposing your tables either row-wise (horizontally) or column-wise (vertically).</li>
</ul>
</li>
<li><strong>Map-Reduce</strong><ul>
<li>For sufficiently small systems you can often get away with adhoc queries on a SQL database, but that approach may not scale up trivially once the quantity of data stored or write-load requires sharding your database, and will usually require dedicated slaves for the purpose of performing these queries (at which point, maybe you’d rather use a system designed for analyzing large quantities of data, rather than fighting your database). </li>
<li>Adding a map-reduce layer makes it possible to perform data and/or processing intensive operations in a reasonable amount of time. You might use it for calculating suggested users in a social graph, or for generating analytics reports. eg. Hadoop, and maybe Hive or HBase.</li>
</ul>
</li>
<li><strong>Platform Layer (Services)</strong><ul>
<li>Separating the platform and web application allow you to scale the pieces independently. If you add a new API, you can add platform servers without adding unnecessary capacity for your web application tier.</li>
<li>Adding a platform layer can be a way to reuse your infrastructure for multiple products or interfaces (a web application, an API, an iPhone app, etc) without writing too much redundant boilerplate code for dealing with caches, databases, etc.</li>
</ul>
</li>
</ul>
<p align="center">
  <img data-src="http://lethain.com/static/blog/intro_arch/platform_layer.png" alt="Platform Layer"/>
</p>

<br>

<h2 id="Key-topics-for-designing-a-system"><a href="#Key-topics-for-designing-a-system" class="headerlink" title="Key topics for designing a system"></a>Key topics for designing a system</h2><ol>
<li><strong>Concurrency</strong> </li>
</ol>
<ul>
<li><p>Do you understand threads, deadlock, and starvation? Do you know how to parallelize algorithms? Do you understand consistency and coherence?</p>
  <br></li>
</ul>
<ol start="2">
<li><strong>Networking</strong></li>
</ol>
<ul>
<li>Do you roughly understand IPC and TCP/IP? Do you know the difference between throughput and latency, and when each is the relevant factor?</li>
</ul>
<br>

<ol start="3">
<li><strong>Abstraction</strong></li>
</ol>
<ul>
<li>You should understand the systems you’re building upon. Do you know roughly how an OS, file system, and database work? Do you know about the various levels of caching in a modern OS?</li>
</ul>
<br>

<ol start="4">
<li><strong>Real-World Performance</strong></li>
</ol>
<ul>
<li>You should be familiar with the speed of everything your computer can do, including the relative performance of RAM, disk, SSD and your network.</li>
</ul>
<br>

<ol start="5">
<li><strong>Estimation</strong></li>
</ol>
<ul>
<li>Estimation, especially in the form of a back-of-the-envelope calculation, is important because it helps you narrow down the list of possible solutions to only the ones that are feasible. Then you have only a few prototypes or micro-benchmarks to write.    <br></li>
</ul>
<ol start="6">
<li><strong>Availability &amp; Reliability</strong></li>
</ol>
<ul>
<li> Are you thinking about how things can fail, especially in a distributed environment? Do know how to design a system to cope with network failures? Do you understand durability?</li>
</ul>
<br>

<h2 id="Web-App-System-design-considerations"><a href="#Web-App-System-design-considerations" class="headerlink" title="Web App System design considerations:"></a>Web App System design considerations:</h2><ul>
<li>Security (CORS)</li>
<li>Using CDN<ul>
<li>A content delivery network (CDN) is a system of distributed servers (network) that deliver webpages and other Web content to a user based on the geographic locations of the user, the origin of the webpage and a content delivery server.</li>
<li>This service is effective in speeding the delivery of content of websites with high traffic and websites that have global reach. The closer the CDN server is to the user geographically, the faster the content will be delivered to the user. </li>
<li>CDNs also provide protection from large surges in traffic.</li>
</ul>
</li>
<li>Full Text Search<ul>
<li>Using Sphinx/Lucene/Solr - which achieve fast search responses because, instead of searching the text directly, it searches an index instead.</li>
</ul>
</li>
<li>Offline support/Progressive enhancement<ul>
<li>Service Workers</li>
</ul>
</li>
<li>Web Workers</li>
<li>Server Side rendering</li>
<li>Asynchronous loading of assets (Lazy load items)</li>
<li>Minimizing netwrok requests (Http2 + bundling/sprites etc)</li>
<li>Developer productivity/Tooling</li>
<li>Accessibility</li>
<li>Internationalization</li>
<li>Responsive design</li>
<li>Browser compatibility</li>
</ul>
<br>

<h2 id="Working-Components-of-Front-end-Architecture"><a href="#Working-Components-of-Front-end-Architecture" class="headerlink" title="Working Components of Front-end Architecture"></a>Working Components of Front-end Architecture</h2><ul>
<li>Code<ul>
<li>HTML5/WAI-ARIA</li>
<li>CSS/Sass Code standards and organization</li>
<li>Object-Oriented approach (how do objects break down and get put together)</li>
<li>JS frameworks/organization/performance optimization techniques</li>
<li>Asset Delivery - Front-end Ops</li>
</ul>
</li>
<li>Documentation<ul>
<li>Onboarding Docs</li>
<li>Styleguide/Pattern Library</li>
<li>Architecture Diagrams (code flow, tool chain)</li>
</ul>
</li>
<li>Testing<ul>
<li>Performance Testing</li>
<li>Visual Regression</li>
<li>Unit Testing</li>
<li>End-to-End Testing</li>
</ul>
</li>
<li>Process<ul>
<li>Git Workflow</li>
<li>Dependency Management (npm, Bundler, Bower)</li>
<li>Build Systems (Grunt/Gulp)</li>
<li>Deploy Process</li>
<li>Continuous Integration (Travis CI, Jenkins)</li>
</ul>
</li>
</ul>
<br>



<h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><ul>
<li><p><a href="http://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/">How to rock a systems design interview</a></p>
</li>
<li><p><a href="http://www.hiredintech.com/system-design/">System Design Interviewing</a></p>
</li>
<li><p><a href="http://www.lecloud.net/tagged/scalability">Scalability for Dummies</a></p>
</li>
<li><p><a href="http://lethain.com/introduction-to-architecting-systems-for-scale/">Introduction to Architecting Systems for Scale</a></p>
</li>
<li><p><a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html">Scalable System Design Patterns</a></p>
</li>
<li><p><a href="http://www.aosabook.org/en/distsys.html">Scalable Web Architecture and Distributed Systems</a></p>
</li>
<li><p><a href="http://programmers.stackexchange.com/a/108679/62739">What is the best way to design a web site to be highly scalable?</a></p>
</li>
<li><p><a href="https://github.com/vasanthk/how-web-works">How web works?</a></p>
</li>
</ul>
<br>

<br>
]]></content>
      <categories>
        <category>Resources</category>
      </categories>
      <tags>
        <tag>System Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Modern CPUs - What Have Changed Since the &#39;80s</title>
    <url>/2017/Modern-CPU/</url>
    <content><![CDATA[<p>Everything below refers to x86 and Linux, unless otherwise indicated. Reference:</p>
<blockquote>
<p>  <a href="https://danluu.com/new-cpu-features/">What’s new in CPUs since the 80s?</a></p>
</blockquote>
<span id="more"></span> 

<br>

<hr>
<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><p>My mental model of CPUs is stuck in the 1980s: basically boxes that do arithmetic, logic, bit twiddling and shifting, and loading and storing things in memory. I’m vaguely aware of various newer developments like vector instructions (SIMD) and the idea that newer CPUs have support for virtualization (though I have no idea what that means in practice).</p>
<p>What cool developments have I been missing? </p>
<p>What can today’s CPU do that last year’s CPU couldn’t? </p>
<p>How about a CPU from two years ago, five years ago, or ten years ago? </p>
<p>The things I’m most interested in are things that programmers have to manually take advantage of (or programming environments have to be redesigned to take advantage of) in order to use and as a result might not be using yet. </p>
<p>I think this excludes things like Hyper-threading/SMT, but I’m not honestly sure. I’m also interested in things that CPUs can’t do yet but will be able to do in the near future.</p>
<br>

<hr>
<h2 id="The-Present"><a href="#The-Present" class="headerlink" title="The Present"></a>The Present</h2><h3 id="Miscellanea"><a href="#Miscellanea" class="headerlink" title="Miscellanea"></a>Miscellanea</h3><p>For one thing, chips have wider registers and can address more memory. In the 80s, you might have used an 8-bit CPU, but now you almost certainly have a <a href="https://courses.cs.washington.edu/courses/csep590/06au/projects/history-64-bit.pdf">64-bit CPU</a> in your machine. I’m not going to talk about this too much, since I assume you’re familiar with programming a 64-bit machine. In addition to providing more address space, 64-bit mode provides more registers and more consistent floating point results (via the avoidance of pseudo-randomly getting 80-bit precision for 32 and 64 bit operations via x867 floating point). Other things that you’re very likely to be using that were introduced to x86 since the early 80s include paging / virtual memory, pipelining, and floating point.</p>
<br>

<h3 id="Esoterica"><a href="#Esoterica" class="headerlink" title="Esoterica"></a>Esoterica</h3><p>I’m also going to avoid discussing things that are now irrelevant (like A20M) and things that will only affect your life if you’re writing drivers, BIOS code, doing security audits, or other unusually low-level stuff (like APIC/x2APIC, SMM, NX, or <a href="https://eprint.iacr.org/2016/086">SGX</a>).</p>
<br>

<h3 id="Memory-Caches"><a href="#Memory-Caches" class="headerlink" title="Memory / Caches"></a>Memory / Caches</h3><p>Of the remaining topics, the one that’s most likely to have a real effect on day-to-day programming is how memory works. My first computer was a 286. On that machine, a memory access might take a few cycles. A few years back, I used a Pentium 4 system where a memory access took more than 400 cycles. Processors have sped up a lot more than memory. The solution to the problem of having relatively slow memory has been to add caching, which provides fast access to frequently used data, and prefetching, which preloads data into caches if the access pattern is predictable.</p>
<p>A few cycles vs. 400+ cycles sounds really bad; that’s well over 100x slower. But if I write a dumb loop that reads and operates on a large block of 64-bit (8-byte) values, the CPU is smart enough to prefetch the correct data before I need it, which lets me process at about <a href="http://danluu.com/assembly-intrinsics/">22 GB/s</a> on my 3GHz processor. A calculation that can consume 8 bytes every cycle at 3GHz only works out to 24GB/s, so getting 22GB/s isn’t so bad. We’re losing something like 8% performance by having to go to main memory, not 100x.</p>
<p>As a first-order approximation, using predictable memory access patterns and operating on chunks of data that are smaller than your CPU cache will get you most of the benefit of modern caches. If you want to squeeze out as much performance as possible, <a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">this document</a> is a good starting point. After digesting that 100 page PDF, you’ll want to familiarize yourself with the microarchitecture and memory subsystem of the system you’re optimizing for, and learn how to profile the performance of your application with something like <a href="https://code.google.com/archive/p/likwid/">likwid</a>.</p>
<br>

<h3 id="TLBs"><a href="#TLBs" class="headerlink" title="TLBs"></a>TLBs</h3><p>There are lots of little caches on the chip for all sorts of things, not just main memory. You don’t need to know about the decoded instruction cache and other funny little caches unless you’re really going all out on micro-optimizations. The big exception is the TLBs, which are caches for virtual memory lookups (done via a 4-level page table structure on x86). Even if the page tables were in the l1-data cache, that would be 4 cycles per lookup, or 16 cycles to do an entire virtual address lookup each time around. That’s totally unacceptable for something that’s required for all user-mode memory accesses, so there are small, fast, caches for virtual address lookups.</p>
<p>Because the first level TLB cache has to be fast, it’s severely limited in size (perhaps 64 entries on a modern chip). If you use 4k pages, that limits the amount of memory you can address without incurring a TLB miss. x86 also supports 2MB and 1GB pages; some applications will benefit a lot from using larger page sizes. It’s something worth looking into if you’ve got a long-running application that uses a lot of memory.</p>
<p>Also, first-level caches are usually limited by the page size times <a href="http://danluu.com/3c-conflict/">the associativity of the cache</a>. If the cache is smaller than that, the bits used to index into the cache are the same regardless if whether you’re looking at the virtual address or the physical address, so you don’t have to do a virtual to physical translation before indexing into the cache. If the cache is larger than that, you have to first do a TLB lookup to index into the cache (which will cost at least one extra cycle), or build a virtually indexed cache (which is possible, but adds complexity and coupling to software). You can see this limit in modern chips. Haswell has an 8-way associative cache and 4kB pages. Its l1 data cache is <code>8 * 4kB = 32kB</code>.</p>
<br>


<h3 id="Out-of-Order-Execution-Serialization"><a href="#Out-of-Order-Execution-Serialization" class="headerlink" title="Out of Order Execution / Serialization"></a>Out of Order Execution / Serialization</h3><p>For a couple decades now, x86 chips have been able to speculatively execute and re-order execution (to avoid blocking on a single stalled resource). This sometimes results in <a href="https://docs.google.com/document/d/18gs0bkEwQ5cO8pMXT_MsOa8Xey4NEavXq-OvtdUXKck/pub">odd performance hiccups</a>. But x86 is pretty strict in requiring that, for a single CPU, externally visible state, like registers and memory, must be updated as if everything were executed in order. The implementation of this involves making sure that, for any pair of instructions with a dependency, those instructions execute in the correct order with respect to each other.</p>
<p>That restriction that things look like they executed in order means that, for the most part, you can ignore the existence of OoO execution unless you’re trying to eke out the best possible performance. The major exceptions are when you need to make sure something not only looks like it executed in order externally, but actually executed in order internally.</p>
<p>An example of when you might care would be if you’re trying to measure the execution time of a sequence of instructions using <code>rdtsc</code>, which reads a hidden internal counter and puts the result into <code>edx</code> and <code>eax</code>, externally visible registers.</p>
<p>Say we do something like</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">foo</span><br><span class="line"><span class="keyword">rdtsc</span></span><br><span class="line">bar</span><br><span class="line"><span class="keyword">mov</span> %eax, [%ebx]</span><br><span class="line">baz</span><br></pre></td></tr></table></figure>

<p>where foo, bar, and baz don’t touch <code>eax</code>, <code>edx</code>, or <code>[%ebx]</code>. The <code>mov</code> that follows the rdtsc will write the value of <code>eax</code> to some location in memory, and because eax is an externally visible register, the CPU will guarantee that the mov doesn’t execute until after <code>rdtsc</code> has executed, so that everything looks like it happened in order.</p>
<p>However, since there isn’t an explicit dependency between the <code>rdtsc</code> and either <code>foo</code> or <code>bar</code>, the <code>rdtsc</code> could execute before <code>foo</code>, between <code>foo</code> and <code>bar</code>, or after <code>bar</code>. It could even be the case that <code>baz</code> executes before the <code>rdtsc</code>, as long as <code>baz</code> doesn’t affect the move instruction in any way. There are some circumstances where that would be fine, but it’s not fine if the <code>rdtsc</code> is there to measure the execution time of <code>foo</code>.</p>
<p>To precisely order the <code>rdtsc</code> with respect to other instructions, we need to an instruction that serializes execution. Precise details on how exactly to do that are provided in <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/ia-32-ia-64-benchmark-code-execution-paper.pdf">this document by Intel</a>.</p>
<br>


<h3 id="Memory-Concurrency"><a href="#Memory-Concurrency" class="headerlink" title="Memory / Concurrency"></a>Memory / Concurrency</h3><p>In addition to the ordering restrictions above, which imply that loads and stores to the same location can’t be reordered with respect to each other, x86 loads and stores have some other restrictions. In particular, for a single CPU, stores are never reordered with other stores, and stores are never reordered with earlier loads, regardless of whether or not they’re to the same location.</p>
<p>However, loads can be reordered with earlier stores. For example, if you write</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mov</span> <span class="number">1</span>, [%esp]</span><br><span class="line"><span class="keyword">mov</span> [%ebx], %eax</span><br></pre></td></tr></table></figure>

<p>it can be executed as if you wrote</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mov</span> [%ebx], %eax</span><br><span class="line"><span class="keyword">mov</span> <span class="number">1</span>, [%esp]</span><br></pre></td></tr></table></figure>

<p>But the reverse isn’t true – if you write the latter, it can never be executed as if you wrote the former.</p>
<p>You could force the first example to execute as written by inserting a serializing instruction. But that requires the CPU to serialize all instructions. But that’s slow, since it effectively forces the CPU to wait until all instructions before the serializing instruction are done before executing anything after the serializing instruction. There’s also an mfence instruction that only serializes loads and stores, if you only care about load/store ordering.</p>
<p>I’m not going to discuss the other memory fences, lfence and sfence, <a href="https://stackoverflow.com/questions/20316124/does-it-make-any-sense-to-use-the-lfence-instruction-on-x86-x86-64-processors">but you can read more about them here</a>.</p>
<p>We’ve looked at single core ordering, where loads and stores are mostly ordered, but there’s also multi-core ordering. The above restrictions all apply; if core0 is observing core1, it will see that all of the single core rules apply to core1’s loads and stores. However, if core0 and core1 interact, there’s no guarantee that their interaction is ordered.</p>
<p>For example, say that core 0 and core 1 start with eax and edx set to 0, and core 0 executes</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mov</span> <span class="number">1</span>, [_foo]</span><br><span class="line"><span class="keyword">mov</span> [_foo], %eax</span><br><span class="line"><span class="keyword">mov</span> [_bar], %edx</span><br></pre></td></tr></table></figure>

<p>while core1 executes</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mov</span> <span class="number">1</span>, [_bar]</span><br><span class="line"><span class="keyword">mov</span> [_bar], %eax</span><br><span class="line"><span class="keyword">mov</span> [_foo], %edx</span><br></pre></td></tr></table></figure>

<p>For both cores, eax has to be 1 because of the within-core dependency between the first instruction and the second instruction. However, it’s possible for edx to be 0 in both cores because line 3 of core0 can execute before core0 sees anything from core1, and visa versa.</p>
<p>That covers memory barriers, which serialize memory accesses within a core. Since stores are required to be seen in a consistent order across cores, they can, they also have an effect on cross-core concurrency, but it’s pretty difficult to reason about that kind of thing correctly. <a href="https://yarchive.net/comp/linux/locking.html">Linus has this to say on using memory barriers instead of locking</a>:</p>
<blockquote>
<p>The real cost of not locking also often ends up being the inevitable bugs. Doing clever things with memory barriers is almost always a bug waiting to happen. It’s just really hard to wrap your head around all the things that can happen on ten different architectures with different memory ordering, and a single missing barrier. … The fact is, any time anybody makes up a new locking mechanism, THEY ALWAYS GET IT WRONG. Don’t do it.</p>
</blockquote>
<br>

<p>And it turns out that on modern x86 CPUs, using locking to implement concurrency primitives is <a href="https://blogs.oracle.com/dave/resource/NHM-Pipeline-Blog-V2.txt">often cheaper than using memory barriers</a>, so let’s look at locks.</p>
<p>If we set <code>_foo</code> to 0 and have two threads that both execute <code>incl (_foo)</code> 10000 times each, incrementing the same location with a single instruction 20000 times, is guaranteed not to exceed 20000, but it could (theoretically) be as low as 2. If it’s not obvious why the theoretical minimum is 2 and not 10000, figuring that out is a good exercise. If it is obvious, my bonus exercise for you is, can any reasonable CPU implementation get that result, or is that some silly thing the spec allows that will never happen? There isn’t enough information in this post to answer the bonus question, but I believe I’ve linked to enough information.</p>
<p>We can try this with a simple code snippet</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUM_ITERS 10000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUM_THREADS 2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> *p_counter = &amp;counter;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">asm_inc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> *p_counter = &amp;counter;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUM_ITERS; ++i) &#123;</span><br><span class="line">    __asm__(<span class="string">&quot;incl (%0) \n\t&quot;</span> : : <span class="string">&quot;r&quot;</span> (p_counter));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::thread t[NUM_THREADS];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i) &#123;</span><br><span class="line">    t[i] = <span class="built_in">std</span>::thread(asm_inc);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i) &#123;</span><br><span class="line">    t[i].join();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Counter value: %i\n&quot;</span>, counter);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Compiling the above with <code>clang++ -std=c++11 -pthread</code>, I get the following Different distributions of non-determinism on Haswell and Sandy Bridge:</p>
<p><img data-src="/images/posts/171122-1.png" alt="01"></p>
<p>Not only do the results vary between runs, the distribution of results is different on different machines. We never hit the theoretical minimum of 2, or for that matter, anything below 10000, but there’s some chance of getting a final result anywhere between 10000 and 20000.</p>
<p>Even though incl is a single instruction, it’s not guaranteed to be atomic. Internally, incl is implemented as a load followed by an add followed by an store. It’s possible for an increment on cpu0 to sneak in and execute between the load and the store on cpu1 and visa versa.</p>
<p>The solution Intel has for this is the lock prefix, which can be added to a handful of instructions to make them atomic. If we take the above code and turn incl into lock incl, the resulting output is always 20000.</p>
<p>So, that’s how we make a single instruction atomic. To make a sequence atomic, we can use xchg or cmpxchg, which are always locked as compare-and-swap primitives. I won’t go into detail about how that works, but see <a href="https://davidad.github.io/blog/2014/03/23/concurrency-primitives-in-intel-64-assembly/">this article</a> if you’re curious.</p>
<p>In addition to making a memory transaction atomic, locks are globally ordered with respect to each other, and loads and stores aren’t re-ordered with respect to locks.</p>
<p>For a rigorous model of memory ordering, see the <a href="https://www.cl.cam.ac.uk/~pes20/weakmemory/x86tso-paper.pdf">x86 TSO doc</a>.</p>
<p>All of this discussion has been how about how concurrency works in hardware. Although there are limitations on what x86 will re-order, compilers don’t necessarily have those same limitations. In C or C++, you’ll need to insert the appropriate primitives to make sure the compiler doesn’t re-order anything. <a href="https://yarchive.net/comp/linux/memory_barriers.html">As Linus points out here</a>, if you have code like</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">local_cpu_lock = <span class="number">1</span>;</span><br><span class="line"><span class="comment">// .. do something critical ..</span></span><br><span class="line">local_cpu_lock = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>the compiler has no idea that <code>local_cpu_lock = 0</code> can’t be pushed into the middle of the critical section. Compiler barriers are distinct from CPU memory barriers. Since the x86 memory model is relatively strict, some compiler barriers are no-ops at the hardware level that tell the compiler not to re-order things. If you’re using a language that’s higher level than microcode, assembly, C, or C++, your compiler probably handles this for you without any kind of annotation.</p>
<br>

<h3 id="Memory-Porting"><a href="#Memory-Porting" class="headerlink" title="Memory / Porting"></a>Memory / Porting</h3><p>If you’re porting code to other architectures, it’s important to note that x86 has one of the strongest memory models of any architecture you’re likely to encounter nowadays. If you write code that just works without thinking it through and port it to architectures that have weaker guarantees (PPC, ARM, or Alpha), you’ll almost certainly have bugs.</p>
<p>Consider this example:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Inital</span><br><span class="line">-----</span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line">y = <span class="number">0</span>;</span><br><span class="line">p = &amp;x;</span><br><span class="line"></span><br><span class="line">CPU1         CPU2</span><br><span class="line">----         ----</span><br><span class="line">i = *p;      y = <span class="number">1</span>;</span><br><span class="line">             MB;</span><br><span class="line">             p = &amp;y;</span><br></pre></td></tr></table></figure>

<p><code>MB</code> is a <strong>memory barrier</strong>. On an Alpha 21264 system, this can result in i = 0.</p>
<p>Kourosh Gharachorloo explains how:</p>
<blockquote>
<p>CPU2 does y=1 which causes an “invalidate y” to be sent to CPU1. This invalidate goes into the incoming “probe queue” of CPU1; as you will see, the problem arises because this invalidate could theoretically sit in the probe queue without doing an MB on CPU1. The invalidate is acknowledged right away at this point (i.e., you don’t wait for it to actually invalidate the copy in CPU1’s cache before sending the acknowledgment). Therefore, CPU2 can go through its MB. And it proceeds to do the write to p. Now CPU1 proceeds to read p. The reply for read p is allowed to bypass the probe queue on CPU1 on its incoming path (this allows replies/data to get back to the 21264 quickly without needing to wait for previous incoming probes to be serviced). Now, CPU1 can derefence p to read the old value of y that is sitting in its cache (the invalidate y in CPU1’s probe queue is still sitting there).</p>
</blockquote>
<blockquote>
<p>How does an MB on CPU1 fix this? The 21264 flushes its incoming probe queue (i.e., services any pending messages in there) at every MB. Hence, after the read of p, you do an MB which pulls in the invalidate to y for sure. And you can no longer see the old cached value for y.</p>
</blockquote>
<blockquote>
<p>Even though the above scenario is theoretically possible, the chances of observing a problem due to it are extremely minute. The reason is that even if you setup the caching properly, CPU1 will likely have ample opportunity to service the messages (i.e., invalidate) in its probe queue before it receives the data reply for “read p”. Nonetheless, if you get into a situation where you have placed many things in CPU1’s probe queue ahead of the invalidate to y, then it is possible that the reply to p comes back and bypasses this invalidate. It would be difficult for you to set up the scenario though and actually observe the anomaly.</p>
</blockquote>
<p>This is long enough without my talking about other architectures so I won’t go into detail, but if you’re wondering why anyone would create a spec that allows this kind of optimization, consider that before rising fab costs crushed DEC, their chips were so fast that they could <a href="https://www.usenix.org/legacy/publications/library/proceedings/usenix-nt97/full_papers/chernoff/chernoff.pdf">run industry standard x86 benchmarks</a> of real workloads in emulation faster than x86 chips could run the same benchmarks natively. For more explanation of why the most RISC-y architecture of the time made the decisions it did, see <a href="https://www.hpl.hp.com/hpjournal/dtj/vol4num4/vol4num4art1.pdf">this paper</a> on the motivations behind the Alpha architecture.</p>
<p>BTW, this is a major reason I’m skeptical of the Mill architecture. Putting aside arguments about whether or not they’ll live up to their performance claims, being technically excellent isn’t, in and of itself, a business model.</p>
<br>


<h3 id="Memory-Non-Temporal-Stores-Write-Combine-Memory"><a href="#Memory-Non-Temporal-Stores-Write-Combine-Memory" class="headerlink" title="Memory / Non-Temporal Stores / Write-Combine Memory"></a>Memory / Non-Temporal Stores / Write-Combine Memory</h3><p>The set of restrictions outlined in the previous section apply to cacheable (i.e., “write-back” or WB) memory. That, itself, was new at one time. Before that, there was only uncacheable (UC) memory.</p>
<p>One of the interesting things about UC memory is that all loads and stores are expected to go out to the bus. That’s perfectly reasonable in a processor with no cache and little to no on-board buffering. A result of that is that devices that have access to memory can rely on all accesses to UC memory regions creating separate bus transactions, in order (because some devices will use a memory read or write as as trigger to do something). That worked great in 1982, but it’s not so great if you have a video card that just wants to snarf down whatever the latest update is. If multiple writes happen to the same UC location (or different bytes of the same word), the CPU is required to issue a separate bus transaction for each write, even though a video card doesn’t really care about seeing each intervening result.</p>
<p>The solution to that was to create a memory type called write combine (WC). WC is a kind of eventually consistent UC. Writes have to eventually make it to memory, but they can be buffered internally. WC memory also has weaker ordering guarantees than UC.</p>
<p>For the most part, you don’t have to deal with this unless you’re talking directly with devices. The one exception are “non-temporal” load and store operations. These make particular loads and stores act like they’re to WC memory, even if the address is in a memory region that’s marked WB.</p>
<p>This is useful if you don’t want to pollute your caches with something. This is often useful if you’re doing <a href="https://blogs.fau.de/hager/archives/2103">some kind of streaming calculation</a> where you know you’re not going to use a particular piece of data more than once.</p>
<br>


<h3 id="Memory-NUMA"><a href="#Memory-NUMA" class="headerlink" title="Memory / NUMA"></a>Memory / NUMA</h3><p>Non-uniform memory access, where memory latencies and bandwidth are different for different processors, is so common that we mostly don’t talk about NUMA or ccNUMA anymore because they’re so common that it’s assumed to be the default.</p>
<p>The takeaway here is that threads that share memory should be on the same socket, and a memory-mapped I/O heavy thread should make sure it’s on the socket that’s closest to the I/O device it’s talking to.</p>
<p>I’ve mostly avoided explaining the why behind things because that would make this post at least an order of magnitude longer than it’s going to be. But I’ll give a vastly oversimplified explanation of why we have NUMA systems, partially because it’s a self-contained thing that’s relatively easy to explain and partially to demonstrate how long the why is compared to the what.</p>
<p>Once upon a time, there was just memory. Then CPUs got fast enough relative to memory that people wanted to add a cache. It’s bad news if the cache is inconsistent with the backing store (memory), so the cache has to keep some information about what it’s holding on to so it knows if/when it needs to write things to the backing store.</p>
<p>That’s not too bad, but once you get 2 cores with their own caches, it gets a little more complicated. To maintain the same programming model as the no-cache case, the caches have to be consistent with each other and with the backing store. Because existing load/store instructions have nothing in their API that allows them to say sorry! this load failed because some other CPU is holding onto the address you want, the simplest thing was to have every CPU send a message out onto the bus every time it wanted to load or store something. We’ve already got this memory bus that both CPUs are connected to, so we just require that other CPUs respond with the data (and invalidate the appropriate cache line) if they have a modified version of the data in their cache.</p>
<p>That works ok. Most of the time, each CPU only touches data the other CPU doesn’t care about, so there’s some wasted bus traffic. But it’s not too bad because once a CPU puts out a message saying Hi! I’m going to take this address and modify the data, it can assume it completely owns that address until some other CPU asks for it, which will probably won’t happen. And instead of doing things on a single memory address, we can operate on cache lines that have, say, 64 bytes. So, the overall overhead is pretty low.</p>
<p>It still works ok for 4 CPUs, although the overhead is a bit worse. But this thing where each CPU has to respond to every other CPU’s fails to scale much beyond 4 CPUs, both because the bus gets saturated and because the caches will get saturated (the physical size/cost of a cache is O(n^2) in the number of simultaneous reads and write supported, and the speed is inversely correlated to the size).</p>
<p>A “simple” solution to this problem is to have a single centralized directory that keeps track of all the information, instead of doing N-way peer-to-peer broadcast. Since we’re packing 2-16 cores on a chip now anyway, it’s pretty natural to have a single directory per chip (socket) that tracks the state of the caches for every core on a chip.</p>
<p>This only solves the problem for each chip, and we need some way for the chips to talk to each other. Unfortunately, while we were scaling these systems up the bus speeds got fast enough that it’s really difficult to drive a signal far enough to connect up a bunch of chips and memory all on one bus, even for small systems. The simplest solution to that is to have each socket own a region of memory, so every socket doesn’t need to be connected to every part of memory. This also avoids the complexity of needed a higher level directory of directories, since it’s clear which directory owns any particular piece of memory.</p>
<p>The disadvantage of this is that if you’re sitting in one socket and want some memory owned by another socket, you have a significant performance penalty. For simplicity, most “small” (&lt; 128 core) systems use ring-like busses, so the performance penalty isn’t just the direct latency/bandwidth penalty you pay for walking through a bunch of extra hops to get to memory, it also uses up a finite resource (the ring-like bus) and slows down other cross-socket accesses.</p>
<p>In theory, the OS handles this transparently, but it’s <a href="https://www.usenix.org/conference/atc14/technical-sessions/presentation/gaud">often inefficient</a>.</p>
<br>


<h3 id="Context-Switches-Syscalls"><a href="#Context-Switches-Syscalls" class="headerlink" title="Context Switches / Syscalls"></a>Context Switches / Syscalls</h3><p>Here, syscall refers to a linux system call, not the SYSCALL or SYSENTER x86 instructions.</p>
<p>A side effect of all the caching that modern cores have is that <a href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html">context switches are expensive</a>, which causes syscalls to be expensive. Livio Soares and Michael Stumm discuss the cost in great detail in their paper. I’m going to use a few of their figures, below. Here’s a graph of how many instructions per clock (IPC) a Core i7 achieves on Xalan, a sub-benchmark from SPEC CPU. </p>
<p><img data-src="/images/posts/171122-2.png" alt="02"></p>
<p>14,000 cycles after a syscall, code is still not quite running at full speed.</p>
<p>Here’s a table of the footprint of a few different syscalls, both the direct cost (in instructions and cycles), and the indirect cost (from the number of cache and TLB evictions).</p>
<p><img data-src="/images/posts/171122-3.png" alt="03"></p>
<p>Cost of stat, pread, pwrite, open+close, mmap+munmap, and open+write+close</p>
<p>Some of these syscalls cause 40+ TLB evictions! For a chip with a 64-entry d-TLB, that nearly wipes out the TLB. The cache evictions aren’t free, either.</p>
<p>The high cost of syscalls is the reason people have switched to using batched versions of syscalls for high-performance code (e.g., epoll, or recvmmsg) and the reason that people who need <a href="http://danluu.com/clwb-pcommit/">very high performance I/O</a> often use user space I/O stacks. More generally, the cost of context switches is why high-performance code is often thread-per-core (or even single threaded on a pinned thread) and not thread-per-logical-task.</p>
<p>This high cost was also the driver behind <strong><a href="https://www.linuxjournal.com/content/creating-vdso-colonels-other-chicken">vDSO</a></strong>, which turns some simple syscalls that don’t require any kind of privilege escalation into simple user space library calls.</p>
<br>


<h3 id="SIMD"><a href="#SIMD" class="headerlink" title="SIMD"></a>SIMD</h3><p>Basically all modern x86 CPUs support SSE, 128-bit wide vector registers and instructions. Since it’s common to want to do the same operation multiple times, Intel added instructions that will let you operate on a 128-bit chunk of data as 2 64-bit chunks, 4 32-bit chunks, 8 16-bit chunks, etc. ARM supports the same thing with a different name (NEON), and the instructions supported are pretty similar.</p>
<p>It’s pretty common to get a 2x-4x speedup from using SIMD instructions; it’s definitely worth looking into if you’ve got a computationally heavy workload.</p>
<p>Compilers are good enough at recognizing common patterns that can be vectorized that simple code, like the following, will automatically use vector instructions with modern compilers</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">  sum += a[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>But <strong>compilers will often produce <a href="http://danluu.com/assembly-intrinsics/">non-optimal code</a> if you don’t write the assembly by hand</strong>, especially for SIMD code, so you’ll want to look at the disassembly and check for compiler optimization bugs if you really care about getting the best possible performance.</p>
<br>


<h3 id="Power-Management"><a href="#Power-Management" class="headerlink" title="Power Management"></a>Power Management</h3><p>There are a lot of fancy power management feature on modern CPUs that <a href="http://danluu.com/datacenter-power/">optimize power usage</a> in different scenarios. The result of these is that “race to idle”, completing work as fast as possible and then letting the CPU go back to sleep is the most power efficient way to work.</p>
<p>There’s been a lot of work that’s shown that specific micro-optmizations can benefit power consumption, but <a href="http://arcade.cs.columbia.edu/energy-oopsla14.pdf">applying those microoptimizations</a> on real workloads often results in smaller than expected benefits.</p>
<br>


<h3 id="GPU-GPGPU"><a href="#GPU-GPGPU" class="headerlink" title="GPU / GPGPU"></a>GPU / GPGPU</h3><p>I’m even less qualified to talk about this than I am about the rest of this stuff. Luckily, Cliff Burdick volunteered to write a section on GPUs, so here it is.</p>
<p>Prior to the mid-2000’s, Graphical Processing Units (GPUs) were restricted to an API that allowed only a very limited amount of control of the hardware. As the libraries became more flexible, programmers began using the processors for more general-purpose tasks, such as linear algebra routines. The parallel architecture of the GPU could work on large chunks of a matrix by launching hundreds of simultaneous threads. However, the code had to use traditional graphics APIs and was still limited in how much of the hardware it could control. Nvidia and ATI took notice and released frameworks that allowed the user to access more of the hardware with an API familiar with people outside of the graphics industry. The libraries gained popularity, and today GPUs are widely used for high-performance computing (HPC) alongside CPUs.</p>
<p>Compared to CPUs, the hardware on GPUs have a few major differences, outlined below:</p>
<br>

<h4 id="Processors"><a href="#Processors" class="headerlink" title="Processors"></a>Processors</h4><p>At the top level, a GPU processor contains one or many streaming multiprocessors (SMs). Each streaming multiprocessor on a modern GPU typically contains over 100 floating point units, or what are typically referred to as cores in the GPU world. Each core is typically clocked around 800MHz, although, like CPUs, processors with higher clock rates but fewer cores are also available. GPU processors lack many features of their CPU counterparts, including large caches and branch prediction. Between the layers of cores, SMs, and the overall processor, communicating becomes increasingly slower. For this reason, problems that perform well on GPUs are typically highly-parallel, but have some amount of data that can be shared between a small number of threads. We’ll get into why this is in the memory section below.</p>
<br>

<h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><p>Memory on modern GPU is broken up into 3 main categories: global memory, shared memory, and registers. Global memory is the GDDR memory that’s advertised on the box of the GPU and is typically around 2-12GB in size, and has a throughput of 300-400GB/s. Global memory can be accessed by all threads across all SMs on the processor, and is also the slowest type of memory on the card. Shared memory is, as the name says, memory that’s shared between all threads within the same SM. It is usually at least twice as fast as global memory, but is not accessible between threads on different SMs. Registers are much like registers on a CPU in that they are the fastest way to access data on a GPU, but they are local per thread and the data is not visible to any other running thread. Both shared memory and global memory have very strict rules on how they can be accessed, with severe performance penalties for not following them. To reach the throughputs mentioned above, memory accesses must be completely coalesced between threads within the same thread group. Similar to a CPU reading into a single cache line, GPUs have cache lines sized so that a single access can serve all threads in a group if aligned properly. However, in the worst case where all threads in a group access memory in a different cache line, a separate memory read will be required for each thread. This usually means that most of the data in the cache line is not used by the thread, and the usable throughput of the memory goes down. A similar rule applies to shared memory as well, with a couple exceptions that we won’t cover here.</p>
<br>

<h4 id="Threading-Model"><a href="#Threading-Model" class="headerlink" title="Threading Model"></a>Threading Model</h4><p>GPU threads run in a SIMT (Single Instruction Multiple Thread) fashion, and each thread runs in a group with a pre-defined size in the hardware (typically 32). That last part has many implications; every thread in that group must be working on the same instruction at the same time. If any of the threads in a group need to take a divergent path (an if statement, for example) of code from the others, all threads not part of the branch suspend execution until the branch is complete. As a trivial example:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (threadId &lt; <span class="number">5</span>) &#123;</span><br><span class="line">   <span class="comment">// Do something</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Do More</span></span><br></pre></td></tr></table></figure>

<p>In the code above, this branch would cause 27 of our 32 threads in the group to suspend execution until the branch is complete. You can imagine if many groups of threads all run this code, the overall performance will take a large hit while most of the cores sit idle. Only when an entire group of threads is stalled is the hardware allowed to swap in another group to run on those cores.</p>
<br>

<h4 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h4><p>Modern GPUs must have a CPU to copy data to and from CPU and GPU memory, and to launch and code on the GPU. At the highest throughput, a PCIe 3.0 bus with 16 lanes can achieves rates of about 13-14GB/s. This may sound high, but when compared to the memory speeds residing on the GPU itself, they’re over an order of magnitude slower. In fact, as GPUs get more powerful, the PCIe bus is increasingly becoming a bottleneck. To see any of the performance benefits the GPU has over a CPU, the GPU must be loaded with a large amount of work so that the time the GPU takes to run the job is significantly higher than the time it takes to copy the data to and from.</p>
<p>Newer GPUs have features to launch work dynamically in GPU code without returning to the CPU, but it’s fairly limited in its use at this point.</p>
<br>

<h4 id="GPU-Conclusion"><a href="#GPU-Conclusion" class="headerlink" title="GPU Conclusion"></a>GPU Conclusion</h4><p>Because of the major architectural differences between CPUs and GPUs, it’s hard to imagine either one replacing the other completely. In fact, a GPU complements a CPU well for parallel work and allows the CPU to work independently on other tasks as the GPU is running. AMD is attempting to merge the two technologies with their “Heterogeneous System Architecture” (HSA), but taking existing CPU code and determining how to split it between the CPU and GPU portion of the processor will be a big challenge not only for the processor, but for compilers as well.</p>
<br>

<h3 id="Virtualization"><a href="#Virtualization" class="headerlink" title="Virtualization"></a>Virtualization</h3><p>Since you mentioned virtualization, I’ll talk about it a bit, but Intel’s implementation of virtualization instructions generally isn’t something you need to think about unless you’re writing very low-level code that directly deals with virtualization.</p>
<p>Dealing with that stuff is pretty messy, as you can see <a href="https://github.com/vishmohan/vmlaunch">from this code</a>. Setting stuff up to use Intel’s VT instructions to launch a VM guest is about 1000 lines of low-level code, even for the very simple case shown there.</p>
<br>


<h3 id="Virtual-Memory"><a href="#Virtual-Memory" class="headerlink" title="Virtual Memory"></a>Virtual Memory</h3><p>If you look at Vish’s VT code, you’ll notice that there’s a decent chunk of code dedicated to page tables / virtual memory. That’s another “new” feature that you don’t have to worry about unless you’re writing an OS or other low-level systems code. Using virtual memory is much simpler than using segmented memory, but that’s not relevant nowadays so I’ll just leave it at that.</p>
<br>


<h3 id="SMT-Hyper-threading"><a href="#SMT-Hyper-threading" class="headerlink" title="SMT / Hyper-threading"></a>SMT / Hyper-threading</h3><p>Since you brought it up, I’ll also mention SMT. As you said, this is mostly transparent for programmers. A typical speedup for enabling SMT on a single core is around 25%. That’s good for overall throughput, but it means that each thread might only get 60% of its original performance. For applications where you care a lot about single-threaded performance, you might be better off disabling SMT. It depends a lot on the workload, though, and as with any other changes, you should run some benchmarks on your exact workload to see what works best.</p>
<p>One side effect of all this complexity that’s been added to chips (and software) is that performance is a lot less predictable than it used to be; the relative importance of benchmarking your exact workload on the specific hardware it’s going to run on has gone up.</p>
<p>Just for example, people often point to benchmarks from the <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html">Computer Languages Benchmarks Game</a> as evidence that one language is faster than another. I’ve tried reproducing the results myself, and on my mobile Haswell (as opposed to the server Kentsfield that’s used in the results), I get results that are different by as much as 2x (in relative speed). Running the same benchmark on the same machine, Nathan Kurz recently pointed me to an example where gcc -O3 is 25% slower than gcc -O2. <a href="https://users.cs.northwestern.edu/~robby/courses/322-2013-spring/mytkowicz-wrong-data.pdf">Changing the linking order on C++ programs can cause a 15% performance change</a>. Benchmarking is a hard problem.</p>
<br>


<h3 id="Branches"><a href="#Branches" class="headerlink" title="Branches"></a>Branches</h3><p>Old school conventional wisdom is that branches are expensive, and should be avoided at all (or most) costs. On a Haswell, the branch misprediction penalty is 14 cycles. Branch mispredict rates depend on the workload. Using perf stat on a few different things (bzip2, top, mysqld, regenerating my blog), I get branch mispredict rates of between 0.5% and 4%. If we say that a correctly predicted branch costs 1 cycle, that’s an average cost of between <code>.995 * 1 + .005 * 14 = 1.065</code> cycles to <code>.96 * 1 + .04 * 14 = 1.52</code> cycles. That’s not so bad.</p>
<p>This actually overstates the penalty since about 1995, since Intel added conditional move instructions that allow you to conditionally move data without a branch. This instruction was memorably <a href="https://yarchive.net/comp/linux/cmov.html">panned by Linus</a>, which has given it a bad reputation, but it’s fairly common to get <a href="https://github.com/logicchains/LPATHBench/issues/53#issuecomment-68160081">significant speedups using cmov</a> compared to branches.</p>
<p>A real-world example of the cost of extra branches are enabling integer overflow checks. When using <a href="http://danluu.com/integer-overflow/">bzip2 to compress a particular file</a>, that increases the number of instructions by about 30% (with all of the increase coming from extra branch instructions), which results in a 1% performance hit.</p>
<p>Unpredictable branches are bad, but most branches are predictable. Ignoring the cost of branches until your profiler tells you that you have a hot spot is pretty reasonable nowadays. CPUs have gotten a lot better at executing poorly optimized code over the past decade, and compilers are getting better at optimizing code, which makes optimizing branches a poor use of time unless you’re trying to squeeze out the absolute best possible performance out of some code.</p>
<p>If it turns out that’s what you need to do, you’re likely to be better off using <a href="https://en.wikipedia.org/wiki/Profile-guided_optimization">profile-guided optimization</a> than trying to screw with this stuff by hand.</p>
<p>If you really must do this by hand, there are compiler directives you can use to say whether a particular branch is likely to be taken or not. Modern CPUs ignore branch hint instructions, but they can help the compiler lay out code better.</p>
<br>


<h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a>Alignment</h3><p>Old school conventional wisdom is that you should pad out structs and make sure things are aligned. But on a Haswell chip, the mis-alignment for almost any single-threaded thing you can think of that doesn’t cross a page boundary is zero. There are some cases where it can make a difference, but in general, this is another type of optimization that’s mostly irrelevant because CPUs have gotten so much better at executing bad code. It’s also mildly harmful in cases where it increases the memory footprint for no benefit.</p>
<p>Also, <a href="http://danluu.com/3c-conflict/">don’t make things page aligned</a> or otherwise aligned to large boundaries or you’ll destroy the performance of your caches.</p>
<br>


<h3 id="Self-modifying-code"><a href="#Self-modifying-code" class="headerlink" title="Self-modifying code"></a>Self-modifying code</h3><p>Here’s another optimization that doesn’t really make sense anymore. Using self-modifying code to decrease code size or increase performance used to make sense, but because modern caches tend to split up their l1 instruction and data caches, modifying running code requires expensive communication between a chip’s l1 caches.</p>
<br>

<hr>
<h2 id="The-Future"><a href="#The-Future" class="headerlink" title="The Future"></a>The Future</h2><p>Here are some possible changes, from least speculative to most speculative.</p>
<br>


<h3 id="Partitioning"><a href="#Partitioning" class="headerlink" title="Partitioning"></a>Partitioning</h3><p>It’s now obvious that more and more compute is moving into large datacenters. Sometimes this involves running on VMs, sometimes it involves running in some kind of container, and sometimes it involves running bare metal, but in any case, individual machines are often multiplexed to run a wide variety of workloads. Ideally, you’d be able to schedule best effort workloads to soak up stranded resources without effecting latency sensitive workloads with an SLA. It turns out that you can actually do this with some <a href="http://danluu.com/intel-cat/17">relatively straightforward hardware changes</a>. The picture below shows 90% overall machine utilization:</p>
<p><img data-src="/images/posts/171122-4.png" alt="04"></p>
<p><a href="http://csl.stanford.edu/~christos/publications/2015.heracles.isca.pdf">David Lo, et. al,</a> were able to show that you can get about 90% machine utilization without impacting latency SLAs if caches can be partitioned such that best effort workloads don’t impact latency sensitive workloads. The solid red line is the load on a normal Google web search cluster, and the dashed green line is what you get with the appropriate optimizations. From bar-room conversations, my impression is that the solid red line is actually already better (higher) than most of Google’s competitors are able to do. If you compare the 90% optimized utilization to typical server utilization of 10% to 90%, that results in a massive difference in cost per unit of work compared to running a naive, unoptimized, setup. With substantial hardware effort, Google was able to avoid interference, but additional isolation features could allow this to be done at higher efficiency with less effort.</p>
<br>


<h3 id="Transactional-Memory-and-Hardware-Lock-Elision"><a href="#Transactional-Memory-and-Hardware-Lock-Elision" class="headerlink" title="Transactional Memory and Hardware Lock Elision"></a>Transactional Memory and Hardware Lock Elision</h3><p>IBM already has these features in their POWER chips. Intel made an attempt to add these to Haswell, but they’re disabled because of a bug. In general, modern CPUs are quite complex and we should expect to see <a href="http://danluu.com/cpu-bugs/">many more bugs than we used to</a>.</p>
<p>Transactional memory support is what it sounds like: hardware support for transactions. This is through three new instructions, xbegin, xend, and xabort.</p>
<p>xbegin starts a new transaction. A conflict (or an xabort) causes the architectural state of the processor (including memory) to get rolled back to the state it was in just prior to the xbegin. If you’re using transactional memory via library or language support, this should be transparent to you. If you’re implementing the library support, you’ll have to figure out how to convert this hardware support, with its limited hardware buffer sizes, to something that will handle arbitrary transactions.</p>
<p>I’m not going to discuss Hardware Lock Elision except to say that, under the hood, it’s implemented with mechanisms that are really similar to the mechanisms used to implement transactional memory and that it’s designed to speed up lock-based code. If you want to take advantage of HLE, see <a href="http://mcg.cs.tau.ac.il/papers/amir-levy-msc.pdf">this doc</a>.</p>
<br>


<h3 id="Fast-I-O"><a href="#Fast-I-O" class="headerlink" title="Fast I/O"></a>Fast I/O</h3><p>I/O bandwidth is going up and I/O latencies are going down, both for storage and for networking. The problem is that I/O is normally done via syscalls. As we’ve seen, the relative overhead of syscalls has been going up. For both storage and networking, the answer is to move to <a href="https://www.microsoft.com/en-us/research/publication/providing-safe-user-space-access-to-fast-solid-state-disks">user mode I/O stacks</a> (putting everything in kernel mode would work, too, but that’s a harder sell). On the storage side, that’s mostly still a weirdo research thing, but HPC and HFT folks have been doing that in networking for a while. And by a while, I don’t mean a few months. Here’s a <a href="http://web.stanford.edu/group/comparch/papers/huggahalli05.pdf">paper from 2005</a> that talks about the networking stuff I’m going to discuss, as well as some stuff I’m not going to discuss (DCA).</p>
<p>This is finally trickling into the non-supercomputing world. MS has been advertising Azure with infiniband networking with virtualized RDMA for over a year, Cloudflare has talked about using <a href="https://blog.cloudflare.com/a-tour-inside-cloudflares-latest-generation-servers/">Solarflare NICs</a> to get the same capability, etc. Eventually, we’re going to see SoCs with fast Ethernet onboard, and unless that’s limited to Xeon-type devices, it’s going to trick down into all devices. The competition between ARM devices will probably cause at least one ARM device maker to put fast Ethernet on their commodity SoCs, which may force Intel’s hand.</p>
<p>That RDMA bit is significant; it lets you bypass the CPU completely and have the NIC respond to remote requests. A couple months ago, I worked through the Stanford/Coursera Mining Massive Data Sets class. During one of the first lectures, they provide an example of a “typical” datacenter setup with 1Gb top-of-rack switches. That’s not unreasonable for processing “massive” data if you’re doing kernel TCP through non-RDMA NICs, since you can floor an entire core trying to push 1Gb/s through linux’s TCP stack. But with Azure, MS talks about getting 40Gb out of a single machine; that’s one machine getting 40x the bandwidth of what you might expect out of an entire rack. They also mention sub 2 us latencies, which is multiple orders of magnitude lower than you can get out of kernel TCP. This isn’t exactly a new idea. <a href="http://www.scs.stanford.edu/~rumble/papers/latency_hotos11.pdf">This paper from 2011</a> predicts everything that’s happened on the network side so far, along with some things that are still a ways off.</p>
<p><a href="https://www.youtube.com/watch?v=8Kyoj3bKepY&feature=youtu.be&t=20m8s">This MS talk</a> discusses how you can take advantage of this kind of bandwidth and latency for network storage. A concrete example that doesn’t require clicking through to a link is Amazon’s EBS. It lets you use an “elastic” disk of arbitrary size on any of your AWS nodes. Since a spinning metal disk seek has higher latency than an RPC over kernel TCP, you can get infinite storage pretty much transparently. For example, say you can get <a href="http://www.scs.stanford.edu/~rumble/papers/latency_hotos11.pdf">100us (.1ms) latency out of your network</a>, and your disk seek time is 8ms. That makes a remote disk access 8.1ms instead of 8ms, which isn’t that much overhead. That doesn’t work so well with SSDs, though, since you can get 20 us (.02ms) <a href="https://www.anandtech.com/show/8104/intel-ssd-dc-p3700-review-the-pcie-ssd-transition-begins-with-nvme/3">out of an SSD</a>. But RDMA latency is low enough that a transparent EBS-like layer is possible for SSDs.</p>
<p>So that’s networked I/O. The performance benefit might be even bigger on the disk side, if/when next generation storage technologies that are faster than flash start getting deployed. The performance delta is so large that <a href="http://danluu.com/clwb-pcommit/">Intel is adding new instructions</a> to keep up with next generation low-latency storage technology. Depending on who you ask, that stuff has been a few years away for a decade or two; this is more iffy than the networking stuff. But even with flash, people are showing off devices that can get down into the single microsecond range for latency, which is a substantial improvement.</p>
<br>


<h3 id="Hardware-Acceleration"><a href="#Hardware-Acceleration" class="headerlink" title="Hardware Acceleration"></a>Hardware Acceleration</h3><p>Like fast networked I/O, this is already here in some niches. DESRES has been doing ASICs to get 100x-1000x speedup in computational chemistry for years. <a href="https://www.microsoft.com/en-us/research/publication/a-reconfigurable-fabric-for-accelerating-large-scale-datacenter-services">Microsoft</a> has talked about speeding up search with FPGAs. People have been looking into accelerating memcached and similar systems for a while, researchers from <a href="http://csl.stanford.edu/~christos/publications/2014.hwkvs.nvmw.slides.pdf">Toshiba and Stanford</a> demonstrated a real implementation a while back, and I recently saw a pre-print out of Berkeley on the same thing. There are multiple companies making Bitcoin mining ASICs. That’s also true for other application areas, such as <a href="http://www.artificiallearning.com/products/">Machine Learning</a>.</p>
<p>It seems like we should see more of this as it gets harder to get power/performance gains out of CPUs. You might consider this a dodge of your question, if you think of programming as being a software oriented endeavor, but another way to look at it is that what it means to program something will change. In the future, it might mean designing hardware like an FPGA or ASIC in combination with writing software.</p>
<br>

<h4 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h4><p>Now that it’s 2016, one year after this post was originally published, we can see that companies are investing in hardware accelerators. In addition to its previous work on FPGA accelerated search, <a href="https://www.youtube.com/watch?v=RffHFIhg5Sc&feature=youtu.be&t=23m30s">Microsoft has announced</a> that it’s using FPGAs to accelerate networking. Google has been closed mouthed about infrastructure, as is typical for them, but if you look at the initial release of Tensorflow, you can see snippets of code that clearly references FPGAs, such as:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="keyword">class</span> <span class="title">PlatformKind</span> &#123;</span></span><br><span class="line">  kInvalid,</span><br><span class="line">  kCuda,</span><br><span class="line">  kOpenCL,</span><br><span class="line">  kOpenCLAltera,  <span class="comment">// Altera FPGA OpenCL platform.</span></span><br><span class="line">                  <span class="comment">// See documentation: go/fpgaopencl</span></span><br><span class="line">                  <span class="comment">// (StreamExecutor integration)</span></span><br><span class="line">  kHost,</span><br><span class="line">  kMock,</span><br><span class="line">  kSize,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>and</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">PlatformKindString</span><span class="params">(PlatformKind kind)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span> (kind) &#123;</span><br><span class="line">    <span class="keyword">case</span> PlatformKind::kCuda:</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;CUDA&quot;</span>;</span><br><span class="line">    <span class="keyword">case</span> PlatformKind::kOpenCL:</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;OpenCL&quot;</span>;</span><br><span class="line">    <span class="keyword">case</span> PlatformKind::kOpenCLAltera:</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;OpenCL+Altera&quot;</span>;</span><br><span class="line">    <span class="keyword">case</span> PlatformKind::kHost:</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;Host&quot;</span>;</span><br><span class="line">    <span class="keyword">case</span> PlatformKind::kMock:</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;Mock&quot;</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">return</span> port::StrCat(<span class="string">&quot;InvalidPlatformKind(&quot;</span>, <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(kind), <span class="string">&quot;)&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>As of this writing, Google doesn’t return any results for <code>+google +kOpenClAltera</code>, so it doesn’t appear that this has been widely observed. If you’re not familiar with Altera OpenCL and you work at google, you can try the internal go link suggested in the comment, go/fpgaopencl. If, like me, you don’t work at Google, well, there’s <a href="https://www.intel.com/content/www/us/en/software/programmable/sdk-for-opencl/overview.html">Altera’s docs</a> here. The basic idea is that you can take OpenCL code, the same kind of thing you might run on a GPU, and run it on an FPGA instead, and from the comment, it seems like Google has some kind of setup that lets you stream data in and out of nodes with FPGAs.</p>
<p>That FPGA-specific code was removed in <code>ddd4aaf5286de24ba70402ee0ec8b836d3aed8c7</code>, which has a commit message that starts with “TensorFlow: upstream changes to git.” and then has a list of internal google commits that are being upstreamed, along with a description of each internal commit. Curiously, there’s nothing about removing FPGA support even though that seems like it’s a major enough thing that you’d expect it to be described, unless it was purposely redacted. Amazon has also been quite secretive about their infrastructure plans, but you can make reasonable guesses there by looking at the hardware people they’ve been vacuuming up. A couple other companies are also betting pretty heavily on hardware accelerators, but since I learned about that through private conversations (as opposed to accidentally published public source code or other public information), I’ll leave you to guess which companies.</p>
<br>


<h3 id="Dark-Silicon-SoCs"><a href="#Dark-Silicon-SoCs" class="headerlink" title="Dark Silicon / SoCs"></a>Dark Silicon / SoCs</h3><p>One funny side effect of the way transistor scaling has turned out is that we can pack a ton of transistors on a chip, but they generate so much heat that the average transistor can’t switch most of the time if you don’t want your chip to melt.</p>
<p>A result of this is that it makes more sense to include dedicated hardware that isn’t used a lot of the time. For one thing, this means we get all sorts of specialized instructions like the <a href="https://www.felixcloutier.com/x86/pcmpestri">PCMP</a> and <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/ia-large-integer-arithmetic-paper.pdf">ADX</a> instructions. But it also means that we’re getting chips with entire devices integrated that would have previously lived off-chip. That includes things like GPUs and (for mobile devices) radios.</p>
<p>In combination with the hardware acceleration trend, it also means that it makes more sense for companies to design their own chips, or at least parts of their own chips. Apple has gotten a lot of mileage out of acquiring PA Semi. First, by adding little custom accelerators to bog standard ARM architectures, and then by adding custom accelerators to their own custom architecture. Due to a combination of the right custom hardware plus well thought out benchmarking and system design, the iPhone 4 is slightly more responsive than my flagship Android phone, which is multiple years newer and has a much faster processor as well as more RAM.</p>
<p>Amazon has picked up a decent chunk of the old Calxeda team and are hiring enough to create a good-sized hardware design team. Facebook has picked up a small handful of ARM SoC folks and is partnering with Qualcomm on something-or-other. <a href="https://www.realworldtech.com/forum/?threadid=146066&curpostid=146227">Linus is on record</a> as saying we’re going to see more dedicated hardware all over the place. And so on and so forth.</p>
<br>

<hr>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>x86 chips have picked up a lot of new features and whiz-bang gadgets. For the most part, you don’t have to know what they are to take advantage of them. As a first-order approximation, making your code predictable and keeping memory locality in mind works pretty well. The really low-level stuff is usually hidden by libraries or drivers, and compilers will try to take care of the rest of it. The exceptions are if you’re writing really low-level code, in which case the world has gotten a lot messier, or if you’re trying to get the absolute best possible performance out of your code, in which case the world has gotten a lot weirder.</p>
<p>Also, things will happen in the future. But most predictions are wrong, so who knows?</p>
<br>

<hr>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a><a href="http://danluu.com/new-cpu-features/#Resources">Resources</a></h2><p><a href="https://www.youtube.com/watch?v=hgcNM-6wr34">This is a talk by Matt Godbolt</a> that covers a lot of the implementation details that I don’t get into. To down into one more level of detail, see <a href="https://www.amazon.com/gp/product/1478607831/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1478607831&linkCode=as2&tag=abroaview-20&linkId=HXBNFFJ3CIXMWUZP">Modern Processor Design</a>, the best book I’ve found on processor internals. It describes, in good detail, what you need to implement to make a P6-era high-performance CPU. It also derives theoretical performance limits given different sets of assumptions and talks about a lot of different engineering tradeoffs, with explanations of why for a lot of them.</p>
<p><strong>For one level deeper of “why”</strong>, you’ll probably need to look at a VLSI text, which will explain how devices and interconnect scale and how that affects circuit design, which in turn affects architecture. I really like <a href="https://www.amazon.com/gp/product/B008VIXPI2/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=B008VIXPI2&linkCode=as2&tag=abroaview-20&linkId=YOJVAWVH5XTIF6LN">Weste &amp; Harris</a> because they have clear explanations and good exercises with solutions that you can find online, but if you’re not going to work the problems pretty much any VLSI text will do. For one more level deeper of the “why” of things, you’ll want a solid state devices text and something that explains how transmission lines and interconnect can work. For devices, I really like Pierret’s books. I got introduced to the E-mag stuff through Ramo, Whinnery &amp; Van Duzer, but Ida is a better intro text.</p>
<p><strong>For specifics about current generation CPUs and optimization techniques</strong>, see Agner Fog’s site. For something on optimization tools from the future, see this post. What Every Programmer Should Know About Memory is also good background knowledge. Those docs cover a lot of important material, but if you’re writing in a higher level language there are a lot of other things you need to keep in mind. For more on Intel CPU history, Xao-Feng Li has a nice overview.</p>
<p><strong>For something a bit off the wall</strong>, see this post on the possibility of CPU backdoors. For something less off the wall, see this post on how complexity we have in modern CPUs enables all sorts of exciting bugs.</p>
<p><strong>For more benchmarks on locking</strong>, See this post by Aleksey Shipilev, this post by Paul Khuong, as well as their archives.</p>
<p><strong>For general benchmarking</strong>, last year’s Strange Loop benchmarking talk by Aysylu Greenberg is a nice intro to common gotchas. For something more advanced but more specific, Gil Tene’s talk on latency is great.</p>
<p><strong>For historical computing</strong> that predates everything I’ve mentioned by quite some time, see IBM’s Early Computers and Design of a Computer, which describes the design of the CDC 6600. Readings in Computer Architecture is also good for seeing where a lot of these ideas originally came from.</p>
<br>

<br>]]></content>
      <categories>
        <category>Resources</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Low Level System</tag>
        <tag>Assembly</tag>
      </tags>
  </entry>
  <entry>
    <title>Stack &amp; Heap Explained</title>
    <url>/2017/Stack-Heap/</url>
    <content><![CDATA[<p>We know that value types are created on the stack, and reference types are created on the heap. But what are stacks and heaps, really?</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h2><p><strong>The stack</strong> is the memory set aside <strong>as scratch space for a thread of execution</strong>. When a function is called, a block is reserved on the top of the stack for local variables and some bookkeeping data. When that function returns, the block becomes unused and can be used the next time a function is called. The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed. This makes it really simple to keep track of the stack; freeing a block from the stack is nothing more than adjusting one pointer.</p>
<p><ins><strong>The heap is memory set aside for dynamic allocation</strong></ins>. Unlike the stack, there’s no enforced pattern to the allocation and deallocation of blocks from the heap; you can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time; there are many custom heap allocators available to tune heap performance for different usage patterns.</p>
<p>Each thread gets a stack, while there’s typically only one heap for the application (although it isn’t uncommon to have multiple heaps for different types of allocation).</p>
<br>

<h3 id="The-Extent-of-the-OS-Control"><a href="#The-Extent-of-the-OS-Control" class="headerlink" title="The Extent of the OS Control"></a>The Extent of the OS Control</h3><blockquote>
<p>The OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.</p>
</blockquote>
<p>Computer programs typically have a stack called a <strong>call stack</strong> which stores information relevant to the current function such as a pointer to whichever function it was called from, and any local variables. Because functions call other functions and then return, the stack grows and shrinks to hold information from the functions further down the call stack. A program doesn’t really have runtime control over it; it’s determined by the programming language, OS and even the system architecture.</p>
<p><strong>A heap is a general term used for any memory that is allocated dynamically and randomly</strong>. The memory is typically allocated by the OS, with the application calling API functions to do this allocation. There is a fair bit of overhead required in managing dynamically allocated memory, which is usually handled by the OS.</p>
<br>



<h3 id="Scope"><a href="#Scope" class="headerlink" title="Scope"></a>Scope</h3><blockquote>
<p>The stack is attached to a thread, so when the thread exits the stack is reclaimed. The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.</p>
</blockquote>
<p>The call stack is such a low level concept that it doesn’t relate to ‘scope’ in the sense of programming. If you disassemble some code you’ll see relative pointer style references to portions of the stack, but as far as a higher level language is concerned, the language imposes its own rules of scope. One important aspect of a stack, however, is that once a function returns, anything local to that function is immediately freed from the stack. That works the way you’d expect it to work given how your programming languages work. In a heap, it’s also difficult to define. The scope is whatever is exposed by the OS, but your programming language probably adds its rules about what a “scope” is in your application. The processor architecture and the OS use virtual addressing, which the processor translates to physical addresses and there are page faults, etc. They keep track of what pages belong to which applications. You never really need to worry about this, though, because you just use whatever method your programming language uses to allocate and free memory, and check for errors (if the allocation/freeing fails for any reason).</p>
<br>

<h3 id="Size"><a href="#Size" class="headerlink" title="Size"></a>Size</h3><blockquote>
<p>The size of the stack is set when a thread is created. The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).</p>
</blockquote>
<p>A stack is usually pre-allocated, because by definition it must be contiguous memory (more on that in the last paragraph). The language compiler or the OS determine its size. You don’t store huge chunks of data on the stack, so it’ll be big enough that it should never be fully used, except in cases of unwanted endless recursion (hence, “stack overflow”) or other unusual programming decisions.</p>
<p>A heap is a general term for anything that can be dynamically allocated. Depending on which way you look at it, it is constantly changing size. In modern processors and operating systems the exact way it works is very abstracted anyway, so you don’t normally need to worry much about how it works deep down, except that (in languages where it lets you) you mustn’t use memory that you haven’t allocated yet or memory that you have freed.</p>
<br>

<h3 id="Speed"><a href="#Speed" class="headerlink" title="Speed"></a>Speed</h3><p><strong>The stack is faster</strong> because the access pattern makes it trivial to allocate and deallocate memory from it (a pointer/integer is simply incremented or decremented), while the heap has much more complex bookkeeping involved in an allocation or deallocation. Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor’s cache, making it very fast. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe, i.e. each allocation and deallocation needs to be - typically - synchronized with “all” other heap accesses in the program. </p>
<p>The stack is faster because <strong>all free memory is always contiguous</strong>. No list needs to be maintained of all the segments of free memory, just a single pointer to the current top of the stack. Compilers usually store this pointer in a special, fast register for this purpose. What’s more, subsequent operations on a stack are usually concentrated within very nearby areas of memory, which at a very low level is good for optimization by the processor on-die caches.</p>
<p><img data-src="/images/posts/171111-1.png" alt="01"></p>
<br>

<hr>
<h2 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h2><blockquote>
<p>The most important point is that <strong>heap and stack are generic terms for ways in which memory can be allocated.</strong></p>
</blockquote>
<br>


<h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><ul>
<li>Stored in computer RAM just like the heap.</li>
<li>Variables created on the stack will go out of scope and are automatically deallocated.</li>
<li>Much faster to allocate in comparison to variables on the heap.</li>
<li>Implemented with an actual stack data structure.</li>
<li>Stores local data, return addresses, used for parameter passing.</li>
<li>Can have a stack overflow when too much of the stack is used (mostly from infinite or too deep recursion, very large allocations).</li>
<li>Data created on the stack can be used without pointers.</li>
<li>A stack is used if you know exactly how much data you need to allocate before compile time and it is not too big.</li>
<li>Usually has a maximum size already determined when your program starts.</li>
</ul>
<br>

<h3 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h3><ul>
<li>Stored in computer RAM just like the stack.</li>
<li>In C++, variables on the heap must be destroyed manually and never fall out of scope. The data is freed with delete, delete[], or free.</li>
<li>Slower to allocate in comparison to variables on the stack.</li>
<li>Used on demand to allocate a block of data for use by the program.</li>
<li>Can have fragmentation when there are a lot of allocations and deallocations.</li>
<li>In C++ or C, data created on the heap will be pointed to by pointers and allocated with new or malloc respectively.</li>
<li>Can have allocation failures if too big of a buffer is requested to be allocated.</li>
<li>A heap is used if you don’t know exactly how much data you will need at run time or if you need to allocate a lot of data.</li>
<li>Responsible for memory leaks.</li>
</ul>
<br>

<hr>
<h2 id="More-Explanation"><a href="#More-Explanation" class="headerlink" title="More Explanation"></a>More Explanation</h2><p>Both the stack and the heap are memory areas allocated from the underlying operating system (often virtual memory that is mapped to physical memory on demand).</p>
<p>In a multi-threaded environment each thread will have its own completely independent stack but they will share the heap. Concurrent access has to be controlled on the heap and is not possible on the stack.</p>
<br>



<h3 id="Heap-1"><a href="#Heap-1" class="headerlink" title="Heap"></a>Heap</h3><ul>
<li><p>The heap contains a linked list of used and free blocks. New allocations on the heap (by new or <code>malloc</code>) are satisfied by creating a suitable block from one of the free blocks. This requires updating list of blocks on the heap. This meta information about the blocks on the heap is also stored on the heap often in a small area just in front of every block.</p>
</li>
<li><p>As the heap grows new blocks are often allocated from lower addresses towards higher addresses. Thus you can think of the heap as a heap of memory blocks that grows in size as memory is allocated. If the heap is too small for an allocation the size can often be increased by acquiring more memory from the underlying operating system.</p>
</li>
<li><p>Allocating and deallocating many small blocks may leave the heap in a state where there are a lot of small free blocks interspersed between the used blocks. A request to allocate a large block may fail because none of the free blocks are large enough to satisfy the allocation request even though the combined size of the free blocks may be large enough. This is called heap fragmentation.</p>
</li>
<li><p>When a used block that is adjacent to a free block is deallocated the new free block may be merged with the adjacent free block to create a larger free block effectively reducing the fragmentation of the heap.</p>
</li>
</ul>
<p><img data-src="/images/posts/171111-2.png" alt="02"></p>
<br>

<h3 id="Stack-1"><a href="#Stack-1" class="headerlink" title="Stack"></a>Stack</h3><ul>
<li><p>The stack often works in close tandem with a special register on the CPU named the stack pointer. Initially the stack pointer points to the top of the stack (the highest address on the stack).</p>
</li>
<li><p>The CPU has special instructions for pushing values onto the stack and popping them back from the stack. Each push stores the value at the current location of the stack pointer and decreases the stack pointer. A pop retrieves the value pointed to by the stack pointer and then increases the stack pointer (don’t be confused by the fact that adding a value to the stack decreases the stack pointer and removing a value increases it. Remember that the stack grows to the bottom). The values stored and retrieved are the values of the CPU registers.</p>
</li>
<li><p>When a function is called the CPU uses special instructions that push the current instruction pointer, i.e. the address of the code executing on the stack. The CPU then jumps to the function by setting the instruction pointer to the address of the function called. Later, when the function returns, the old instruction pointer is popped from the stack and execution resumes at the code just after the call to the function.</p>
</li>
<li><p>When a function is entered, the stack pointer is decreased to allocate more space on the stack for local (automatic) variables. If the function has one local 32 bit variable four bytes are set aside on the stack. When the function returns, the stack pointer is moved back to free the allocated area.</p>
</li>
<li><p>If a function has parameters, these are pushed onto the stack before the call to the function. The code in the function is then able to navigate up the stack from the current stack pointer to locate these values.</p>
</li>
<li><p>Nesting function calls work like a charm. Each new call will allocate function parameters, the return address and space for local variables and these activation records can be stacked for nested calls and will unwind in the correct way when the functions return.</p>
</li>
<li><p>As the stack is a limited block of memory, you can cause a stack overflow by calling too many nested functions and/or allocating too much space for local variables. Often the memory area used for the stack is set up in such a way that writing below the bottom (the lowest address) of the stack will trigger a trap or exception in the CPU. This exceptional condition can then be caught by the runtime and converted into some kind of stack overflow exception.</p>
</li>
</ul>
<p><img data-src="/images/posts/171111-3.png" alt="03"></p>
<br>

<h3 id="Clarification"><a href="#Clarification" class="headerlink" title="Clarification"></a>Clarification</h3><blockquote>
<p>Can a function be allocated on the heap instead of a stack?</p>
</blockquote>
<p>No.</p>
<p>Activation records for functions (i.e. local or automatic variables) are allocated on the stack that is used not only to store these variables, but also to keep track of nested function calls.</p>
<p>How the heap is managed is really up to the runtime environment. C uses malloc and C++ uses new, but many other languages have garbage collection.</p>
<p>However, the stack is a more low-level feature closely tied to the processor architecture. Growing the heap when there is not enough space isn’t too hard since it can be implemented in the library call that handles the heap. However, growing the stack is often impossible as the stack overflow only is discovered when it is too late; and shutting down the thread of execution is the only viable option.</p>
<br>

]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Low Level System</tag>
      </tags>
  </entry>
  <entry>
    <title>Memory Mapping</title>
    <url>/2017/Memory-Mapping/</url>
    <content><![CDATA[<p>More to read: <a href="https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/generalprogramming/understanding_mem_mapping.html">Understanding Memory Mapping</a></p>
<span id="more"></span> 

<br>


<h2 id="What-Is-Memory-Mapping"><a href="#What-Is-Memory-Mapping" class="headerlink" title="What Is Memory-Mapping?"></a>What Is Memory-Mapping?</h2><p>Memory-mapping is a mechanism that maps a portion of a file, or an entire file, on disk to a range of addresses within an application’s address space. The application can then access files on disk in the same way it accesses dynamic memory. This makes file reads and writes faster in comparison with using functions such as <code>fread</code> and <code>fwrite</code>.</p>
<br>

<h2 id="Benefits-of-Memory-Mapping"><a href="#Benefits-of-Memory-Mapping" class="headerlink" title="Benefits of Memory-Mapping"></a>Benefits of Memory-Mapping</h2><blockquote>
<p>The principal benefits of memory-mapping are efficiency, faster file access, the ability to share memory between applications, and more efficient coding.</p>
</blockquote>
<h3 id="Faster-File-Access"><a href="#Faster-File-Access" class="headerlink" title="Faster File Access"></a>Faster File Access</h3><p>Accessing files via memory map is faster than using I/O functions such as fread and fwrite. Data are read and written using the virtual memory capabilities that are built in to the operating system rather than having to allocate, copy into, and then deallocate data buffers owned by the process.</p>
<p>MATLAB does not access data from the disk when the map is first constructed. It only reads or writes the file on disk when a specified part of the memory map is accessed, and then it only reads that specific part. This provides faster random access to the mapped data.</p>
<br>


<h3 id="Efficiency"><a href="#Efficiency" class="headerlink" title="Efficiency"></a>Efficiency</h3><p>Mapping a file into memory allows access to data in the file as if that data had been read into an array in the application’s address space. Initially, MATLAB only allocates address space for the array; it does not actually read data from the file until you access the mapped region. As a result, memory-mapped files provide a mechanism by which applications can access data segments in an extremely large file without having to read the entire file into memory first.</p>
<br>


<h3 id="Efficient-Coding-Style"><a href="#Efficient-Coding-Style" class="headerlink" title="Efficient Coding Style"></a>Efficient Coding Style</h3><p>Memory-mapping in MATLAB application enables users to access file data using standard MATLAB indexing operations. Once you have mapped a file to memory, you can read the contents of that file using the same type of MATLAB statements used to read variables from the MATLAB workspace. The contents of the mapped file appear as if they were an array in the currently active workspace. You simply index into this array to read or write the desired data from the file. Therefore, you do not need explicit calls to the fread and fwrite functions.</p>
<p>In MATLAB, if x is a memory-mapped variable, and y is the data to be written to a file, then writing to the file is as simple as:</p>
<pre><code>x.Data = y;
</code></pre>
<br>


<h3 id="Sharing-Memory-Between-Applications"><a href="#Sharing-Memory-Between-Applications" class="headerlink" title="Sharing Memory Between Applications"></a>Sharing Memory Between Applications</h3><p>Memory-mapped files also provide a mechanism for sharing data between applications, as shown in the figure below. This is achieved by having each application map sections of the same file. You can use this feature to transfer large data sets between MATLAB and other applications.</p>
<p><img data-src="/images/posts/171026-1.gif" alt="graph"></p>
<p>Also, within a single application, you can map the same segment of a file more than once.</p>
<br>


<h2 id="When-to-Use-Memory-Mapping"><a href="#When-to-Use-Memory-Mapping" class="headerlink" title="When to Use Memory-Mapping"></a>When to Use Memory-Mapping</h2><p>Just how much advantage you get from mapping a file to memory depends mostly on the size and format of the file, the way in which data in the file is used, and the computer platform you are using.</p>
<br>


<h3 id="When-Memory-Mapping-Is-Most-Useful"><a href="#When-Memory-Mapping-Is-Most-Useful" class="headerlink" title="When Memory-Mapping Is Most Useful"></a>When Memory-Mapping Is Most Useful</h3><p>Memory-mapping works best with <strong>binary files</strong>, and in the following scenarios:</p>
<ul>
<li><p>For large files that you want to access randomly one or more times</p>
</li>
<li><p>For small files that you want to read into memory once and access frequently</p>
</li>
<li><p>For data that you want to share between applications</p>
</li>
<li><p>When you want to work with data in a file as if it were a MATLAB array</p>
</li>
</ul>
<br>


<h3 id="When-the-Advantage-Is-Less-Significant"><a href="#When-the-Advantage-Is-Less-Significant" class="headerlink" title="When the Advantage Is Less Significant"></a>When the Advantage Is Less Significant</h3><p>The following types of files do not fully use the benefits of memory-mapping:</p>
<ul>
<li><p>Formatted binary files like HDF or TIFF that require customized readers are not good for memory-mapping. Describing the data contained in these files can be a very complex task. Also, you cannot access data directly from the mapped segment, but must instead create arrays to hold the data.</p>
</li>
<li><p>Text or ASCII files require that you convert the text in the mapped region to an appropriate type for the data to be meaningful. This takes up additional address space.</p>
</li>
<li><p>Files that are larger than several hundred megabytes in size consume a significant amount of the virtual address space needed by MATLAB to process your program. Mapping files of this size may result in MATLAB reporting out-of-memory errors more often. This is more likely if MATLAB has been running for some time, or if the memory used by MATLAB becomes fragmented.</p>
</li>
</ul>
<br>


<h2 id="Maximum-Size-of-a-Memory-Map"><a href="#Maximum-Size-of-a-Memory-Map" class="headerlink" title="Maximum Size of a Memory Map"></a>Maximum Size of a Memory Map</h2><p>Due to limits set by the operating system and MATLAB, the maximum amount of data you can map with a single instance of a memory map is 2 gigabytes on 32-bit systems, and 256 terabytes on 64-bit systems. If you need to map more than this limit, you can either create separate maps for different regions of the file, or you can move the window of one map to different locations in the file.</p>
<br>


<h2 id="Byte-Ordering"><a href="#Byte-Ordering" class="headerlink" title="Byte Ordering"></a>Byte Ordering</h2><p>Memory-mapping works <strong>only with data that have the same byte ordering scheme as the native byte ordering of your operating system</strong>. For example, because both Linux and Windows use little-endian byte ordering, data created on a Linux system can be read on Windows systems. You can use the computer function to determine the native byte ordering of your current system.</p>
<br>


]]></content>
      <categories>
        <category>Resources</category>
      </categories>
      <tags>
        <tag>Low Level System</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Log System</title>
    <url>/2017/Linux-Log/</url>
    <content><![CDATA[<p>今天来简单总结一下 Linux 的 日志系统。参考：</p>
<blockquote>
<p><a href="https://www.rsyslog.com/">Rsyslog 官方文档</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.rsyslog.com/doc/v8-stable/configuration/index.html">Rsyslog 官方配置文件</a></p>
</blockquote>
<span id="more"></span> 

<br>



<hr>
<h2 id="日志文件"><a href="#日志文件" class="headerlink" title="日志文件"></a>日志文件</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><strong>位置</strong>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">service</span> <span class="string">rsyslog</span> <span class="string">start</span></span><br><span class="line"><span class="string">ll</span> <span class="string">/var/log</span> </span><br></pre></td></tr></table></figure>

<br>

<p><strong>常见日志文件</strong>：</p>
<table>
<thead>
<tr>
<th>日志名称</th>
<th>信息说明</th>
</tr>
</thead>
<tbody><tr>
<td>alternatives.log</td>
<td>系统的更新替代信息</td>
</tr>
<tr>
<td>apport.log</td>
<td>应用程序崩溃信息记录</td>
</tr>
<tr>
<td>apt/history.log</td>
<td>使用 apt-get 安装卸载软件的信息记录</td>
</tr>
<tr>
<td>apt/term.log</td>
<td>使用 apt-get 时的具体操作</td>
</tr>
<tr>
<td>auth.log</td>
<td>登录认证的 log 信息</td>
</tr>
<tr>
<td>boot.log</td>
<td>系统启动时的日志信息</td>
</tr>
<tr>
<td>btmp</td>
<td>记录所有失败启动信息</td>
</tr>
<tr>
<td>dmesg</td>
<td>内核缓冲信息，在系统启动时，显示屏幕上的与硬件有关的信息</td>
</tr>
<tr>
<td>dpkg.log</td>
<td>安装或 dpkg 命令清除软件包的日志</td>
</tr>
<tr>
<td>kern.log</td>
<td>内核产生的日志，有助于在定制内核时解决问题</td>
</tr>
<tr>
<td>lastlog</td>
<td>记录所有用户的最近信息。这不是一个 ASCII 文件，因此需要用 <code>lastlog</code> 命令查看内容</td>
</tr>
<tr>
<td>faillog</td>
<td>用户登录失败信息。此外，错误登录命令也会记录在本文件中</td>
</tr>
<tr>
<td>wtmp</td>
<td>包含登录信息。使用 wtmp 可以找出谁正在登陆进入系统，谁使用命令显示这个文件或信息等</td>
</tr>
<tr>
<td>syslog</td>
<td>系统信息记录</td>
</tr>
<tr>
<td>apport.log</td>
<td>读取内核信息来收集判断其他应用程序的信息，从而记录应用程序的崩溃信息。</td>
</tr>
</tbody></table>
<br>

<h3 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h3><p>一般格式：</p>
<ul>
<li>事件发生的时间</li>
<li>发生的主机名</li>
<li>启动的服务名称</li>
<li>实际信息内容</li>
</ul>
<br>

<p>e.g. cat 查看日志 （从 alternatives.log 中得到信息有程序作用，日期，命令，成功与否的返回码等信息）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">/var/log/alternatives.log</span></span><br></pre></td></tr></table></figure>

<p>显示结果：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">update-alternatives 2016-08-18 18:03:40: run with --quiet --install /usr/bin/c++ c++ /usr/bin/clang++ 10</span><br><span class="line">update-alternatives 2016-08-18 18:03:40: run with --quiet --install /usr/bin/cc cc /usr/bin/clang 10</span><br><span class="line">...</span><br></pre></td></tr></table></figure>


<p>一般日志的格式内容大部分都是时间，操作这样。不过还有两个比较特殊的日志，它们并不是 ASCII 文件，而是被编码成了<strong>二进制文件</strong>，所以不能直接使用 less、cat、more 这样的工具命令来查看，这两个日志文件是 <strong>wtmp</strong>，<strong>lastlog</strong>。</p>
<p>查看lastlog：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">last</span></span><br></pre></td></tr></table></figure>


<table>
<thead>
<tr>
<th>选项</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>-b</td>
<td>仅打印早于 DAYS 的最近登录记录</td>
</tr>
<tr>
<td>-h</td>
<td>显示此帮助信息并推出</td>
</tr>
<tr>
<td>-R</td>
<td>chroot 到的目录</td>
</tr>
<tr>
<td>-t</td>
<td>仅打印晚于 DAYS 的最近登录记录</td>
</tr>
<tr>
<td>-u</td>
<td>打印 LOGIN 用户的最近登录记录</td>
</tr>
</tbody></table>
<p>e.g.   </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">lastlog</span> <span class="string">-u</span> <span class="string">merikanto</span></span><br></pre></td></tr></table></figure>

<br>

<h2 id="rsyslog系统日志"><a href="#rsyslog系统日志" class="headerlink" title="rsyslog系统日志"></a>rsyslog系统日志</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p>日志产生的方式一般存在两种方式：</p>
<ul>
<li>由软件开发商自己来自定义日志格式，然后指定输出日志位置</li>
<li>Linux 提供的日志服务程序，而我们这里系统日志是通过 syslog 来实现，提供日志管理服务。</li>
</ul>
<p>syslog 是一个系统日志记录程序，在早期的大部分 Linux 发行版都是内置 syslog，让其作为系统的默认日志收集工具。因为syslog跟不上需求的发展，所以被 <strong>rsyslog</strong> 所替代。Ubuntu、Fedora 等等都是默认使用 rsyslog 作为系统的日志收集工具。</p>
<p>rsyslog 的全称是 <strong>rocket-fast system for log</strong>，它提供了高性能，高安全功能和模块化设计。rsyslog 能够接受从各种各样的来源，将其输入，输出的结果到不同的目的地。</p>
<p>默认的 rsyslog 配置文件是：</p>
<ul>
<li><code>/etc/rsyslog.conf</code>：该配置文件主要决定需要加载的模块、文件所属者等</li>
<li><code>/etc/rsyslog.d/50-default.conf</code>: 该文件主要是配置 Filter Conditions</li>
</ul>
<br>

<h3 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h3><p><img data-src="/images/posts/171012-1.png" alt="struct"></p>
<p>通过上面可以看出rsyslog 主要是由三个模块构成：</p>
<ul>
<li>Input</li>
<li>Output</li>
<li>Parser</li>
</ul>
<p>其流程是首先通过 Input module 来收集消息，然后将得到的消息传给Parser module，通过分析模块的层层处理，将真正需要的消息传给 Output module，然后便输出至日志文件中。</p>
<p>官方的 Rsyslog 架构如下图所示，rsyslog 还有一个核心的功能模块是 Queue，便是它的存在使得 rsyslog 高并发优势的突出：</p>
<p><img data-src="/images/posts/171012-2.jpg" alt="struct"></p>
<p><strong>Input 模块</strong>：主要功能就是从各种各样的来源收集 messages，通过这些接口实现：</p>
<table>
<thead>
<tr>
<th>接口名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>im3195</td>
<td>RFC3195 Input Module</td>
</tr>
<tr>
<td>imfile</td>
<td>Text File Input Module</td>
</tr>
<tr>
<td>imgssapi</td>
<td>GSSAPI Syslog Input Module</td>
</tr>
<tr>
<td>imjournal</td>
<td>Systemd Journal Input Module</td>
</tr>
<tr>
<td>imklog</td>
<td>Kernel Log Input Module</td>
</tr>
<tr>
<td>imkmsg</td>
<td>/dev/kmsg Log Input Module</td>
</tr>
<tr>
<td>impstats</td>
<td>Generate Periodic Statistics of Internal Counters</td>
</tr>
<tr>
<td>imrelp</td>
<td>RELP Input Module</td>
</tr>
<tr>
<td>imsolaris</td>
<td>Solaris Input Module</td>
</tr>
<tr>
<td>imptcp</td>
<td>Plain TCP Syslog</td>
</tr>
<tr>
<td>imtcp</td>
<td>TCP Syslog Input Module</td>
</tr>
<tr>
<td>imudp</td>
<td>UDP Syslog Input Module</td>
</tr>
<tr>
<td>imuxsock</td>
<td>Unix Socket Input</td>
</tr>
</tbody></table>
<br>

<p>Output 模块也有许多可用的接口来实现。Output 也被称为 actions。 一个组操作内容都是预先加载的（比如输出文件编写器，几乎在每个 <code>rsyslog.conf</code> 中都使用）, 通过 action（<code>type =“type”...</code>）对象调用一个动作。Type 是<strong>强制性</strong>的，并且必须包含要调用的插件的名称（例如 “omfile” 或 “ommongodb”）。 其他参数可能存在。 他们的类型和使用取决于问题的输出插件。</p>
<p>这些模块接口的都需要通过 <code>ModLoad</code> 指令来加载。</p>
<br>

<blockquote>
<p>在下文中会为大家展示 <code>/etc/rsyslog.conf</code> 的内容，大家可以注意前两行，其意思就是默认加载了 imklog、imuxsock 这两个模块。</p>
</blockquote>
<p>在配置中 rsyslog 支持三种配置语法格式：</p>
<ul>
<li>sysklogd</li>
<li>legacy rsyslog</li>
<li>RainerScript</li>
</ul>
<p>sysklogd 是比较老的简单格式，一些新的语法特性不支持。</p>
<p>legacy rsyslog 是以 <code>$</code> 开头的语法，指令是全局指令 （全局指令是 rsyslogd 守护进程的配置指令，每行只能有一个指令）。</p>
<p>RainnerScript 是最新的语法。在官网上 rsyslog 大多推荐这个语法格式来配置。</p>
<blockquote>
<p>注：老的语法格式（sysklogd &amp; legacy rsyslog）是以行为单位。新的语法格式（RainnerScript）可以分割多行。</p>
</blockquote>
<br>

<p>注释有两种语法:</p>
<ul>
<li>井号 #</li>
<li>C-style/* .. */</li>
</ul>
<br>

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>查看系统中的配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">/etc/rsyslog.d/50-default.conf</span> </span><br></pre></td></tr></table></figure>

<p><strong>配置文件格式说明</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">日志设备(类型).(连接符号)日志级别</span>  <span class="string">日志处理方式</span></span><br></pre></td></tr></table></figure>

<p><strong>日志设备(类型):</strong></p>
<table>
<thead>
<tr>
<th>设备</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>auth</td>
<td>pam 产生的日志</td>
</tr>
<tr>
<td>authpriv</td>
<td>ssh, ftp 等登录信息的验证信息，即权限系统</td>
</tr>
<tr>
<td>cron</td>
<td>时间任务相关，计划安排</td>
</tr>
<tr>
<td>kern</td>
<td>内核消息</td>
</tr>
<tr>
<td>lpr</td>
<td>打印</td>
</tr>
<tr>
<td>mail</td>
<td>邮件系统消息</td>
</tr>
<tr>
<td>mark(syslog)</td>
<td>rsyslog 服务内部的信息,时间标识</td>
</tr>
<tr>
<td>news</td>
<td>新闻组消息</td>
</tr>
<tr>
<td>user</td>
<td>用户程序产生的相关信息</td>
</tr>
<tr>
<td>uucp</td>
<td>unix 主机之间相关的通讯</td>
</tr>
<tr>
<td>local</td>
<td>1~7    自定义的日志设备</td>
</tr>
</tbody></table>
<br>

<p><strong>日志级别:</strong></p>
<blockquote>
<p>从上到下，日志级别由高到低，记录的信息越来越少。基本上，<strong>warning (4), notice (5), info (6)</strong> 这三个讯息都是在告知一些基本信息，应该还不至于造成一些系统运作困扰。</p>
</blockquote>
<table>
<thead>
<tr>
<th>priority 取值</th>
<th>值</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>emerge</td>
<td>0</td>
<td>发生严重事件，并有导致系统崩溃的潜在危险。报告软件或者硬件问题</td>
</tr>
<tr>
<td>alert</td>
<td>1</td>
<td>严重错误消息，会导致程序关闭并可能影响其他程序</td>
</tr>
<tr>
<td>crit</td>
<td>2</td>
<td>错误消息，可能会导致程序关闭的事件重</td>
</tr>
<tr>
<td>err</td>
<td>3</td>
<td>程序中存在错误的通告</td>
</tr>
<tr>
<td>warning</td>
<td>4</td>
<td>程序中存在潜在问题的警告信息</td>
</tr>
<tr>
<td>notice</td>
<td>5</td>
<td>程序运行中产生了值得注意的事件</td>
</tr>
<tr>
<td>info</td>
<td>6</td>
<td>关于程序当前状态的报告信息</td>
</tr>
<tr>
<td>debug</td>
<td>7</td>
<td>编程人员或测试人员使用的调试信息</td>
</tr>
</tbody></table>
<br>

<p><strong>连接符号:</strong></p>
<ul>
<li><p><code>.xx</code> : 表示大于等于 xx 级别的信息</p>
</li>
<li><p><code>.=xx</code>：表示等于 xx 级别的信息</p>
</li>
<li><p><code>.!xx</code>：表示在 xx 之外的等级的信息</p>
</li>
</ul>
<p>可以从上面的文件中看到几项系统配置：</p>
<ul>
<li><p><code>auth</code> 与 <code>authpriv</code> 的所有优先级的信息全都输出于 <code>/var/log/auth.log</code> 日志中</p>
 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">auth,authpriv.*</span> <span class="string">/var/log/auth.log</span></span><br></pre></td></tr></table></figure></li>
<li><p>kern 的所有优先级信息<strong>异步写入</strong> <code>/var/log/kern.log</code> 日志中</p>
 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kern.*</span> <span class="string">-/var/log/kern.log</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>   <code>-</code>代表<strong>异步写入</strong>，也就是说日志写入时不需要等待系统缓存的同步。通常写入数据比较大时使用。</p>
</blockquote>
</li>
</ul>
<br>

<p><strong>举例:</strong></p>
<p>syslog启动</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">rsyslog</span> <span class="string">start</span></span><br></pre></td></tr></table></figure>

<p>向 syslog 写入数据</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ping</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="string">|</span> <span class="string">logger</span> <span class="string">-it</span> <span class="string">logger_test</span> <span class="string">-p</span> <span class="string">local3.notice</span> <span class="string">&amp;</span></span><br></pre></td></tr></table></figure>

<p>查看：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/var/log/syslog</span></span><br></pre></td></tr></table></figure>

<p>退出：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Ctrl</span> <span class="string">+</span> <span class="string">C</span></span><br></pre></td></tr></table></figure>

<br>

<h2 id="日志的转储"><a href="#日志的转储" class="headerlink" title="日志的转储"></a>日志的转储</h2><h3 id="logrotate"><a href="#logrotate" class="headerlink" title="logrotate"></a>logrotate</h3><p>logrotate 程序是一个日志文件管理工具，用来把旧的日志文件删除，然后创建新的日志文件。可以根据日志文件的大小，也可以根据其天数来<strong>切割、管理</strong>日志，这个过程又叫做“<strong>转储</strong>”。</p>
<p>大多数 Linux 发行版使用 logrotate 或 newsyslog对日志进行管理。logrotate 程序不但可以压缩日志文件，减少存储空间，还可以将日志发送到指定 E-mail，方便管理员及时查看日志。</p>
<p>其中 logrotate 是基于 Cron 来运行的，脚本是 <code>/etc/cron.daily/logrotate</code>；同时配置文件在 <code>/etc/logrotate.conf</code> 和 <code>/etc/logrotate.d</code> 中。</p>
<p>查看 <code>/etc/logrotate.conf</code> 中的内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">/etc/logrotate.conf</span></span><br></pre></td></tr></table></figure>

<p>文件内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置每周转储一次(daily、weekly、monthly当然可以使用这些参数每天、星期，月 )</span></span><br><span class="line"><span class="string">weekly</span>      </span><br><span class="line"></span><br><span class="line"><span class="comment"># 最多转储4次</span></span><br><span class="line"><span class="string">rotate</span> <span class="number">4</span>            		</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当转储后文件不存在时创建它</span></span><br><span class="line"><span class="string">create</span>             		</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过gzip压缩方式转储（nocompress可以不压缩）</span></span><br><span class="line"><span class="string">compress</span>           		</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他日志文件的转储方式配置文件，包含在该目录下</span></span><br><span class="line"><span class="string">include</span> <span class="string">/etc/logrotate.d</span>    	</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置/var/log/wtmp日志文件的转储参数</span></span><br><span class="line"><span class="string">/var/log/wtmp</span> &#123;    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每月转储    </span></span><br><span class="line">    <span class="string">monthly</span>      </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转储后文件不存在时创建它，文件所有者为root，所属组为utmp，对应的权限为0664</span></span><br><span class="line">    <span class="string">create</span> <span class="number">0664 </span><span class="string">root</span> <span class="string">utmp</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 最多转储一次 </span></span><br><span class="line">    <span class="string">rotate</span> <span class="number">1</span>                  	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<h3 id="logrotate-日志转储"><a href="#logrotate-日志转储" class="headerlink" title="logrotate 日志转储"></a>logrotate 日志转储</h3><p>logrotate 的配置文件是 <code>/etc/logrotate.conf</code>，是一个<strong>只读文件</strong>，通常不需要对它进行修改。而日志文件的转储设置在独立的配置文件中，放在 <code>/etc/logrotate.d/</code> 目录下。</p>
<p>我们先简单查看一下实验环境中已经配置的一些文件:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ll /etc/logrotate.d/</span><br><span class="line"></span><br><span class="line">cat /etc/logrotate.d/apt</span><br><span class="line">cat /etc/logrotate.d/dpkg</span><br></pre></td></tr></table></figure>



<br>

<p><strong>举例说明日志如何转储：</strong></p>
<p>创建日志文件:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">touch</span> <span class="string">/var/log/log-file</span></span><br></pre></td></tr></table></figure>

<p>快速生成文件在其中填入一个 10MB 的随机比特流数据:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">chmod 777 /var/<span class="built_in">log</span>/log-file</span><br><span class="line">head -c 10M &lt;/dev/urandom &gt; /var/<span class="built_in">log</span>/log-file</span><br></pre></td></tr></table></figure>

<p>为这个文件创建一个配置文件:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">touch</span> <span class="string">/etc/logrotate.d/log-file</span></span><br><span class="line"><span class="string">vim</span> <span class="string">/etc/logrotate.d/log-file</span></span><br></pre></td></tr></table></figure>

<p>Vim中编辑：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">/var/<span class="built_in">log</span>/log-file &#123;</span><br><span class="line">    monthly</span><br><span class="line">    rotate 5</span><br><span class="line">    compress</span><br><span class="line">    delaycompress</span><br><span class="line">    missingok</span><br><span class="line">    notifempty</span><br><span class="line">    postrotate</span><br><span class="line">    /usr/bin/killall -HUP rsyslogd</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p><strong>说明</strong>：</p>
<ul>
<li><code>monthly</code> : 日志文件按月转储。可以换成 daily，weekly 或者 yearly 。</li>
<li><code>rotate 5</code> : 一次转储 最近的 5 个归档日志。</li>
<li><code>compress</code> : 在转储任务完成后，已转储的日志将使用 gzip 进行压缩。</li>
<li><code>delaycompress</code> : 和 compress 选项一起使用，delaycompress 表示 logrotate 不会将最近的压缩，压缩将在下一次转储周期进行。</li>
<li><code>missingok</code> : 在日志转储的时候，任何错误将被忽略，例如“文件无法找到”之类的错误。</li>
<li><code>notifempty</code> : 如果日志文件为空，转储不会进行。</li>
<li><code>create 644 root root</code> : 以指定的权限创建全新的日志文件，同时 logrotate 也会重命名原始日志文件。</li>
<li><code>postrotate/endscript</code> : 在所有其它指令完成后，<code>postrotate</code> 和 <code>endscript</code> 里面指定的命令将被执行。<code>rsyslogd</code> 进程将立即再次读取其配置并继续运行。</li>
</ul>
<br>


<p><strong>例如，当文件满足 10M 就转储一个日志文件</strong>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">vim /etc/logrotate.d/log-file</span><br><span class="line"></span><br><span class="line">/var/<span class="built_in">log</span>/log-file&#123;</span><br><span class="line">    su root root</span><br><span class="line">    size=10M</span><br><span class="line">    rotate    5</span><br><span class="line">    create 644 root root </span><br><span class="line">    postrotate</span><br><span class="line">    /usr/bin/killall   -HUP rsyslogd</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br>

<p>在配置文件的开始部分 <code>su root root</code> 来指定进行转储的用户，否则会报错 （parent directory has insecure permissions）。</p>
<blockquote>
<p>注：编写的配置文件的权限必须为：<code>-rw-r--r--</code> ，否则logrotate 就无法正常工作。执行时就会提示：Ignoring mosquitto because of bad filemode。</p>
</blockquote>
<p>使用 -d 选项是以预演方式运行 logrotate。不用实际转储任何日志文件，可以模拟演练日志轮循并显示其输出:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">su</span> <span class="string">root</span></span><br><span class="line"><span class="string">logrotate</span> <span class="string">-d</span> <span class="string">/etc/logrotate.d/log-file</span> </span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：即使轮循条件没有满足，也可以通过使用 -f 选项来强制 logrotate 轮循日志文件，-v参数提供了详细的输出。</p>
</blockquote>
<br>

<p>下面我们对所有配置文件进行转储操作。并且通过输出日志信息查看错误日志信息等。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">logrotate</span> <span class="string">/etc/logrotate.d/</span></span><br></pre></td></tr></table></figure>

<p>查看转储的情况:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ll</span> <span class="string">/var/log</span></span><br></pre></td></tr></table></figure>

<br>






]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Task Scheduling</title>
    <url>/2017/Linux-Task-Scheduling/</url>
    <content><![CDATA[<p>我们经常需要安排脚本在某个时间或周期性的运行。 今天介绍两个工具， <strong><code>crontab</code> （周期性）</strong> 与 <strong><code>at</code> （仅执行一次）</strong>。</p>
<span id="more"></span> 

<br>


<h2 id="at"><a href="#at" class="headerlink" title="at"></a>at</h2><p>所在目录： <code>/var/spool/at</code></p>
<p><strong>管理使用限制</strong>： <code>/etc/at.allow</code> 和  <code>/etc/at.deny</code>。 写在 <code>/etc/at.allow</code> 中的用户才能使用 <code>at</code>。若这两个文件不存在，则只有 root 用户可以使用。</p>
<br>

<h3 id="Service常用操作"><a href="#Service常用操作" class="headerlink" title="Service常用操作"></a>Service常用操作</h3><table>
<thead>
<tr>
<th>名称</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>start</td>
<td>启动</td>
</tr>
<tr>
<td>stop</td>
<td>关闭</td>
</tr>
<tr>
<td>restart</td>
<td>重启</td>
</tr>
<tr>
<td>reload</td>
<td>重新载入配置</td>
</tr>
<tr>
<td>status</td>
<td>查看状态</td>
</tr>
</tbody></table>
<p>e.g. 启动 <code>at</code> ：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">atd</span> <span class="string">start</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="基本格式"><a href="#基本格式" class="headerlink" title="基本格式"></a>基本格式</h3><blockquote>
<p>   格式： <code>at  选项  参数（时间）</code></p>
</blockquote>
<br>

<p><strong>选项</strong></p>
<table>
<thead>
<tr>
<th>选项</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>-f</td>
<td>指定包含具体指令的任务文件</td>
</tr>
<tr>
<td>-q</td>
<td>指定新任务的队列名称</td>
</tr>
<tr>
<td>-l</td>
<td>显示待执行任务的列表</td>
</tr>
<tr>
<td>-d</td>
<td>删除指定的待执行任务</td>
</tr>
<tr>
<td>-m</td>
<td>任务执行完成后向用户发送email</td>
</tr>
</tbody></table>
<br>



<p><strong>参数</strong></p>
<ul>
<li><p><strong>绝对计时</strong></p>
<ul>
<li>midnight（深夜），noon（中午），teatime（下午4点）</li>
<li>hh:mm today , hh:mm tomorrow 。例：14:30 today </li>
<li>12小时制 （am， pm）</li>
<li>日期的表示的方式有：mm/dd/yy（月/日/年）， dd.mm.yy（日.月.年）， yy-dd-mm（年-月-日）。</li>
</ul>
</li>
<li><p><strong>相对计时</strong></p>
<ul>
<li><code>at now + 时间数量 时间单位</code>。时间单位可以是 minutes，hours，days，weeks。e.g. <code>at now + 3 minutes</code>（3 分钟后）</li>
</ul>
</li>
</ul>
<br>

<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>查看：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">atq</span>   <span class="string">或者</span>   <span class="string">at</span> <span class="string">-l</span></span><br></pre></td></tr></table></figure>

<p>查看工作内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">at</span> <span class="string">-c</span> <span class="number">2</span>  		<span class="comment"># 2 代表第2项工作内容</span></span><br></pre></td></tr></table></figure>

<p>删除待执行队列中的指定任务：    </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">atrm</span>  <span class="string">&lt;jobnumber&gt;</span></span><br></pre></td></tr></table></figure>

<p>e.g. 两分钟后写 hello 到 my.txt 中 </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">at now + 2 minutes</span><br><span class="line"></span><br><span class="line">at&gt;  <span class="built_in">echo</span> <span class="string">&quot;hello&quot;</span> &gt; my.txt</span><br><span class="line">at&gt;  &lt;EOT&gt; 		<span class="comment"># 按 ctrl + D 自动出现&lt;EOT&gt;</span></span><br></pre></td></tr></table></figure>

<p>e.g. 今天 18:28 输出时间到 time.log 中</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">at 18:28 today                                     </span><br><span class="line"></span><br><span class="line">at&gt;  date &gt; time.log</span><br><span class="line">at&gt;  &lt;EOT&gt;</span><br></pre></td></tr></table></figure>

<p>e.g. 在2017年9月29日 18:00关机</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">at 18:00 2017-9-29                                  </span><br><span class="line"></span><br><span class="line">at&gt;  sudo /bin/sync</span><br><span class="line">at&gt;  sudo /bin/sync   	<span class="comment"># sync 两遍，同步数据。强迫症可以多 sync 几遍 </span></span><br><span class="line">at&gt;  sudo /sbin/shutdown -h now</span><br><span class="line">at&gt;  &lt;EOT&gt;</span><br></pre></td></tr></table></figure>

<p>e.g. <strong>batch</strong>：当系统负载小于 1.5 , 或调用 atq 时指定的值才执行任务。</p>
<p>当系统负载小于 1.5 时，执行备份操作。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">batch                                </span><br><span class="line">at&gt;  sudo /bin/sync</span><br><span class="line">at&gt;  &lt;EOT&gt;</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Crontab"><a href="#Crontab" class="headerlink" title="Crontab"></a>Crontab</h2><blockquote>
<p>参考我的另一篇文章： <a href="/2016/Crontab/">Crontab in Linux</a></p>
</blockquote>
<br>



<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><code>crontab</code> 常见于 Unix 和类 Unix 的操作系统之中（Linux 就属于类 Unix 操作系统）。它通过守护进程 cron 使得任务能够按照<strong>固定的时间间隔</strong>在后台自动运行。cron 利用的是一个被称为 cron table 的文件，这个文件中存储了需要执行的脚本或命令的调度列表以及执行时间。</p>
<p>和 at 相似，使用限制的配置文件在 <code>/etc/cron.allow</code> 和 <code>/etc/cron.deny</code> 中。当使用者使用 crontab 后，该项工作会被记录到 <code>/var/spool/cron/</code> 里。不同用户执行的任务记录在不同用户的文件中。</p>
<table>
<thead>
<tr>
<th>特殊字符</th>
<th>意义</th>
</tr>
</thead>
</table>
<ul>
<li>   | 任何时刻<br>,    | 分隔时段，例如 <code>0 7,9 * * *</code> 7:00 和 9:00</li>
</ul>
<ul>
<li>   | 时间范围，例如 <code>30 7-9 * * *</code> 7点到9点之间每小时的30分<br>/n    | 每隔n单位间隔，例如 <code>*/10 * * * *</code> 每10分钟</li>
</ul>
<br>

<h3 id="基本格式-1"><a href="#基本格式-1" class="headerlink" title="基本格式"></a>基本格式</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">crontab</span> [<span class="string">-u</span> <span class="string">username</span>] [<span class="string">-l|-e|-r</span>]</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>选项</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>-u</td>
<td>只有root才能进行这个任务，帮其他使用者创建/移除crontab工作调度</td>
</tr>
<tr>
<td>-e</td>
<td>编辑crontab工作内容</td>
</tr>
<tr>
<td>-l</td>
<td>列出crontab工作内容</td>
</tr>
<tr>
<td>-r</td>
<td>移除所有的crontab工作内容</td>
</tr>
</tbody></table>
<br>

<p><strong>注意</strong></p>
<p>“ % ” 在 crontab 文件中，有结束命令行、换行、重定向的作用。前面必须加 ” \ ” 符号转义</p>
<p><code>* * * * *</code>  代表： </p>
<ul>
<li>min   (0 - 59)</li>
<li>hour  (0 - 23)</li>
<li>day   (1 - 31)</li>
<li>month (1 - 12)</li>
<li>week  (0 - 6)</li>
</ul>
<br>

<h3 id="应用-1"><a href="#应用-1" class="headerlink" title="应用"></a>应用</h3><p>启动：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">service</span> <span class="string">rsyslog</span> <span class="string">start</span></span><br><span class="line"><span class="string">cron</span> <span class="string">-f</span> <span class="string">&amp;</span></span><br></pre></td></tr></table></figure>

<p>查看cron运行状态：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ps</span> <span class="string">aux</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">cron</span></span><br><span class="line"></span><br><span class="line"><span class="string">pgrep</span> <span class="string">cron</span>	 <span class="comment"># 或者用这个</span></span><br></pre></td></tr></table></figure>

<p>编辑任务：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">crontab</span> <span class="string">-e</span></span><br></pre></td></tr></table></figure>

<p>查看任务：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">crontab</span> <span class="string">-l</span></span><br></pre></td></tr></table></figure>

<p>清除所有任务：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">crontab</span> <span class="string">-r</span></span><br></pre></td></tr></table></figure>

<br>

<p>e.g. 每天每小时的第5分钟执行脚本 <code>test.sh</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">05</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">/home/test.sh</span></span><br></pre></td></tr></table></figure>

<p>e.g. 每天的凌晨的 3、4、5 点执行 <code>test.sh</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">00</span> <span class="number">3</span><span class="string">,4,5</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">/home/test.sh</span></span><br></pre></td></tr></table></figure>

<p>e.g. 周日每隔 3 小时执行 <code>test.sh</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">00</span> <span class="string">*/3</span> <span class="string">*</span> <span class="string">*</span> <span class="number">0</span> <span class="string">/home/test.sh</span></span><br></pre></td></tr></table></figure>

<p>e.g. 每天下午 7 点关机</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">00</span> <span class="number">19</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">/sbin/shutdown</span> <span class="string">-h</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>每个用户使用 <code>crontab -e</code> 添加计划任务，系统都会在 <code>/var/spool/cron/crontabs</code>中，添加一个<strong>该用户自己的任务文档</strong>，这样为了<strong>隔离</strong>。</p>
<p>如果是系统级别的定时任务，以 <code>sudo</code> 权限编辑 <code>/etc/crontab</code> 文件就可以。</p>
<p>cron 服务监测时间<strong>最小单位是分钟</strong>，所以 cron 会每分钟去读取一次 <code>/etc/crontab</code> 与 <code>/var/spool/cron/crontabs</code> 里面的內容。</p>
<br>



<p><code>/etc</code> 下，<strong>cron 相关目录</strong> (括号内为系统默认执行时间，可以根据需求修改)：</p>
<ul>
<li><code>/etc/cron.daily</code>，每天执行一次 （6:52）</li>
<li><code>/etc/cron.hourly</code>，每小时执行一次 （第17分钟）</li>
<li><code>/etc/cron.monthly</code>，每月执行一次 （1号，6:52）</li>
<li><code>/etc/cron.weekly</code>，每周执行一次 （每周第七天，6:47）</li>
</ul>
<br>



]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Boot Process</title>
    <url>/2017/Linux-Boot-Process/</url>
    <content><![CDATA[<p>今天来简单总结一下 Linux 的启动流程。<u>从主机设备加电开始一直到操作系统展开登录界面的过程</u>，称为<strong>操作系统启动过程</strong>。Linux 在启动过程中默默完成了许多初始化任务，包括<strong>装载 Linux 内核模块</strong>、<strong>启动网络服务</strong>、<strong>设定时钟</strong>等。相关链接：</p>
<blockquote>
<p><a href="http://blog.itpub.net/370491/viewspace-216955">Linux 之 /etc/inittab 文件</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.cnblogs.com/kayvan/p/4592568.html">关于 Ubuntu 修改默认运行级别</a></p>
</blockquote>
<span id="more"></span> 



<br>




<h2 id="启动顺序"><a href="#启动顺序" class="headerlink" title="启动顺序"></a>启动顺序</h2><p><strong>1. BIOS 自检</strong>：计算机加电后，系统将自动读取 BIOS 中的硬件信息（如：显卡、内存、主板、CPU 等）。然后查找启动设备并设置优先级。接着系统开始用 <strong>POST</strong> 自检 (Power On Self Test），若有问题会给出提示信息，没有问题就启动执行硬件初始化，并设置 <strong>PnP</strong> （Plug-and-Play）设备。最后启动驻留在硬盘主引导记录 <strong>MBR</strong> (MasterBoot Record，主引导分区)中的引导程序 GRUB 或 lilo。</p>
<p><strong>2. GRUB / lilo 引导启动程序</strong>：用户通过 GRUB 或 lilo 引导加载程序启动 Linux 系统。引导程序只是将控制权交给内核，此时操作系统并未装入内存。其中，ubuntu 默认 GRUB 为引导加载程序。</p>
<p><strong>3. 装载 Linux 内核</strong>：最初的引导过程完成后，引导程序开始加载 Linux 内核。ubuntu 的 Linux 内核在 <code>/boot</code> 目录下。</p>
<p><strong>4. 系统初始化</strong>：Ubuntu 采用的是基于事件的启动管理器 —— Upstart，主要包括 3 个程序（<strong>init, telinit, runlevel</strong>）和相应配置文件目录（<code>/etc/init</code>、<code>/etc/rcN.d</code>、<code>/etc/init.d</code>）组成。系统内核首先会启动 init 进程，读取并运行 <code>/etc/init</code> 目录下的启动配置文件，init 启动任务时会读取默认的运行等级（runlevel），然后将结果传递给 upstart 的下一个组件 telinit 中。telinit 通过比较当前 runlevel 与将要进入的 runlevel 之间运行服务的不同，关闭不需要的服务项，启动目前未运行的服务，从而实现系统状态的转换。</p>
<br>

<p>初始化阶段完成后，系统就可以准备接受用户登录。下面是补充说明：</p>
<ul>
<li><p><strong>bios</strong> ：接管主板所有自检工作，掌握系统的启动，部件之间的兼容和程序管理等多项任务。连接软件与硬件设备的“桥梁”。</p>
</li>
<li><p><strong>boot loader</strong> ：grub 实际上是一个 boot loader，开机管理程序可以指定使用哪个核心文件来开机，并实际载入核心（kernel）到内存当中解压缩与执行， 此时核心就能够开始在内存内活动，并侦测所有硬件信息与载入适当的驱动程序来使整部主机开始运行。</p>
</li>
<li><p><strong>init 进程</strong>：系统开始的第一个工作，它是其他所有进程的父进程，一直处在运行状态，并且进程 id 号永远是第一个。作用是读取初始化脚本，完成系统相关管理任务。</p>
</li>
</ul>
<br>

<h2 id="运行级别"><a href="#运行级别" class="headerlink" title="运行级别"></a>运行级别</h2><p>Linux 系统的运行级别由 init 启动的，可以通过 <code>ps aux</code> 看到 <code>PID=1</code> 的是 <strong>init 进程</strong>。init 是 Linux 内核启动的用户级别进程。ubuntu 的默认运行级别文件是 <strong><code>/etc/init/rc-sysinit.conf</code></strong> 。在 <code>/etc/rc.d</code> 目录中定义了各种运行级别的运行服务: </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cd</span> <span class="string">/etc</span></span><br><span class="line"><span class="string">ls</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">rc</span></span><br></pre></td></tr></table></figure>



<br>



<table>
<thead>
<tr>
<th>级别</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>关闭系统</td>
</tr>
<tr>
<td>1</td>
<td>让系统进入单用户（S，恢复）模式</td>
</tr>
<tr>
<td>2/3/4/5</td>
<td>多用户，图形界面，运行所有预定的系统服务。于系统定制而言，运行级别2-5的作用相同。</td>
</tr>
<tr>
<td>6</td>
<td>重启系统</td>
</tr>
<tr>
<td>S</td>
<td>单用户与（恢复）模式， 文本登录界面，只运行很少几项系统服务</td>
</tr>
</tbody></table>
<br>

<p>默认情况下，ubuntu 系统引导进入运行级别 2。查看定义为 2 级别的服务：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ls</span> <span class="string">rc2.d</span></span><br></pre></td></tr></table></figure>

<p>说明：</p>
<ul>
<li><p><code>rc.local</code> 可以写入任何想要开机时就进行的工作，在启动的最后阶段，系统会执行存于 rc.local 中的命令。</p>
</li>
<li><p>目录里面的服务以 K 开头的是系统将终止对应的服务，以 S 开头的是系统将启动对应的服务。</p>
</li>
<li><p>S 或者 K 后面跟的数字是程序优先级，数值越小，优先级越高。数字后面的是服务的名称。</p>
  <br></li>
</ul>
<p>查看 <code>/etc/init/rc-sysinit.conf</code> 的内容:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">/etc/init/rc-sysinit.conf</span></span><br></pre></td></tr></table></figure>

<p>可以看到 <code>default runlevel = 2</code>，即默认运行级别为 2。</p>
<br>




<h2 id="添加-移除开机启动项"><a href="#添加-移除开机启动项" class="headerlink" title="添加 / 移除开机启动项"></a>添加 / 移除开机启动项</h2><p><strong>1. 用 rc.local</strong></p>
<p><code>/rc.local</code> 脚本是 ubuntu 开机之后就会自动执行的一个脚本，位于 <code>/etc</code> 。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">/etc/rc.local</span> </span><br></pre></td></tr></table></figure>

<p>如果需要添加执行的操作，那么必须写在 exit 0 之前。</p>
<br>

<p><strong>2. 自定义脚本</strong></p>
<p>新建脚本，设置脚本权限：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">new.sh</span></span><br><span class="line"><span class="string">chmod</span> <span class="string">+x</span> <span class="string">new.sh</span> </span><br></pre></td></tr></table></figure>

<p>移动脚本到启动目录下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mv</span> <span class="string">new.sh</span> <span class="string">/etc/init.d/new_service.sh</span></span><br></pre></td></tr></table></figure>

<p>将自定义脚本添加至启动项中：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/init.d/</span><br><span class="line">update-rc.d new_service.sh defaults 95</span><br></pre></td></tr></table></figure>

<p>(其中，数值 95 表示一个优先级，<strong>越小表示执行的越早</strong>，可以按照需要修改。） 设置某些运行级别启动，某些运行级别不启动：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">update-rc.d</span> <span class="string">mysql</span> <span class="string">start</span> <span class="number">50</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="string">.</span> <span class="string">stop</span> <span class="number">51</span> <span class="number">0</span> <span class="number">1</span> <span class="number">5</span> <span class="number">6</span> <span class="string">.</span> </span><br></pre></td></tr></table></figure>

<p>优先级为 50 的在 2，3，4 上启动，优先级为 51 的在 0，1，5，6 上不启动。</p>
<br>

<p><strong>3. 使用 <code>sysv-rc-conf</code></strong></p>
<p>安装：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-get</span> <span class="string">install</span> <span class="string">sysv-rc-conf</span></span><br></pre></td></tr></table></figure>

<p>验证使用工具：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">su</span></span><br><span class="line"><span class="string">sysv-rc-conf</span></span><br></pre></td></tr></table></figure>

<p>用鼠标点击，或方向键定位；用空格键设置，X 表示开启该服务，q 退出。</p>
<br>

<p><strong>4. 举例：将 <code>mysql</code> 设置为自启动</strong></p>
<p>使用 <code>update-rc.d </code>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">update-rc.d</span> <span class="string">mysql</span> <span class="string">defaults</span></span><br></pre></td></tr></table></figure>

<p>用 　<code>ll</code> 查看 <code>mysql</code> 运行信息</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ll</span> <span class="string">/etc/rc?.d/*mysql</span></span><br></pre></td></tr></table></figure>

<p>移除自启动：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">update-rc.d</span> <span class="string">-f</span> <span class="string">mysql</span> <span class="string">remove</span></span><br></pre></td></tr></table></figure>


<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Processes</title>
    <url>/2017/Linux-Processes/</url>
    <content><![CDATA[<p>今天来谈一下 Linux 进程相关。 参考：</p>
<blockquote>
<p><a href="https://www.cnblogs.com/vamei/archive/2012/09/20/2694466.html">Linux 进程基础</a></p>
</blockquote>
<blockquote>
<p><a href="https://blog.csdn.net/a623891391/article/details/48263411">Linux 进程及进程控制</a></p>
</blockquote>
<span id="more"></span> 

<br>

<hr>
<h2 id="进程的关系"><a href="#进程的关系" class="headerlink" title="进程的关系"></a>进程的关系</h2><blockquote>
<p>为了能够在出现异常， 或者查看进程信息指标时对一个程序做更准确的控制，我们需要了解进程的用途与之间的关系。</p>
</blockquote>
<br>

<p>比如说，启动了终端就是启动了一个 zsh 进程，我们可以在 zsh 中再输入 zsh 则会再启动一个 zsh 的进程，此时第二个 zsh 进程就是由第一个 zsh 进程创建出来的。我们一般称呼第一个 zsh 进程是第二 zsh 进程的<strong>父进程</strong>，第二 bash 进程是第一个 bash 进程的<strong>子进程</strong>。</p>
<p>既然子进程是通过父进程而衍生出来的，那么子进程的退出与资源的回收定然与父进程有很大的相关性。当一个子进程要正常的终止运行时，或者该进程结束时它会向父进程传递一个 <code>SIGCHLD</code> 信号，父进程做最后的<strong>资源回收与收尾</strong>工作。</p>
<br>

<h3 id="特殊进程"><a href="#特殊进程" class="headerlink" title="特殊进程"></a>特殊进程</h3><p><strong>1. 僵尸进程</strong>：</p>
<p>若是父进程没有做最后的收尾工作，导致进程的进程控制块（PCB）仍驻留在内存中，而PCB 的存在代表这个进程没有消亡（因为 PCB 就是进程存在的唯一标志，里面有 PID 等消息），这样的进程称之为<strong>僵尸进程（Zombie）</strong>。</p>
<br>

<p><strong>2. 孤儿进程</strong>： </p>
<p>如果父进程结束（非正常的结束），未能及时收回子进程，子进程仍在运行，这样的子进程称之为<strong>孤儿进程</strong>。在 Linux 系统中，孤儿进程一般会被 init 进程所“收养”，成为 init 的子进程，由 <strong>init 来做善后处理</strong>。</p>
<br>

<p><strong>3. 内核初始化进程</strong>： </p>
<p><strong>进程 0</strong> 是系统引导时创建的一个特殊进程，也称之为<strong>内核初始化</strong>，其最后一个动作就是创建出一个子进程运行 /sbin/init 可执行文件，该子进程就是 PID=1 的进程 1，而进程 0 就转为交换进程（也被称为空闲进程），进程 1 （init 进程）是第一个用户态的进程，再由它不断创建系统里其他的进程，所以它是所有用户态进程的父进程或者祖先进程。同时它是一个守护程序，直到计算机关机才会停止。</p>
<br>

<h3 id="进程的查看与分类"><a href="#进程的查看与分类" class="headerlink" title="进程的查看与分类"></a>进程的查看与分类</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ps</span> <span class="string">－afxo</span> <span class="string">user,ppid,pid,pgid,command</span></span><br></pre></td></tr></table></figure>

<p><code>pid</code> 是该进程的一个唯一编号，<code>ppid</code> 就是该进程的父进程的 pid，<code>command</code> 表示的是该进程通过执行什么样的命令或者脚本而运行。</p>
<p>使用此命令我们也能清楚的看见， <em>init 是由进程 0 这个初始化进程来创建而出的子进程</em>, 而其他的进程基本是由 init 创建的子进程。所以 init 是用户进程的第一个进程也是所有用户进程的父进程或者祖先进程。</p>
<br>

<p>进程一般从两个角度分类：</p>
<p><strong>1. 进程的功能与服务的对象</strong></p>
<ul>
<li><strong>用户进程</strong>：执行用户程序、应用程序或者说内核之外的程序而产生的进程，此类进程可以在用户的控制下运行或关闭。</li>
<li><strong>系统进程</strong>：通过执行系统内核程序而产生的进程，比如可以执行内存资源分配和进程切换等相对底层的工作；而且该进程的运行不受用户的干预，即使是 root 用户也不能干预系统进程的运行。</li>
</ul>
<br>

<p><strong>2. 应用程序的服务类型</strong></p>
<ul>
<li><p><strong>交互进程</strong>：在执行过程中，需要与用户进行交互操作</p>
</li>
<li><p><strong>批处理进程</strong>：该进程是一个进程集合，负责按顺序启动其他的进程。</p>
</li>
<li><p><strong>守护进程</strong>：一直运行的一种进程，它们独立于控制终端并且周期性的执行某种任务或等待处理某些发生的事件。例如 httpd 进程，还有 crontab 的守护进程，可以周期性的执行用户设定的某些任务。</p>
</li>
</ul>
<br>

<hr>
<h2 id="工作管理"><a href="#工作管理" class="headerlink" title="工作管理"></a>工作管理</h2><p>进程直接的父子关系只能描述比较浅的关系，若是同父进程的进程，并不能很好的描述，所以引入了<strong>进程组</strong>的概念，<em>每一个进程都会是一个进程组的成员</em>，以 <strong>PGID（process group ID）</strong>字段来描述。每当一个进程被创建的时候，它便会成为其父进程所在 <strong>Session</strong> 中的一员，每一个进程组都会在一个 Session 中，并且这个 Session 是<strong>唯一存在</strong>的。</p>
<p>一般情况，进程组的 PGID 等同于进程组的第一个成员的 PID，并且这样的进程称为该进程组的领导者, 也就是<strong>领导进程</strong>。 领导进程可以先终结，此时进程组依然存在，并持有相同的 PGID，直到进程组中最后一个进程终结。</p>
<p>Session 主要是针对一个 <strong>tty</strong> 建立，Session 中的每个进程都称为一个工作(job)。每个会话可以连接一个终端(control terminal)。当控制终端有输入输出时，都传递给该会话的前台进程。Session 意义在于<strong>将多个 jobs 囊括在一个终端</strong>，并取其中的一个 job 作为前台，来直接接收该终端的输入输出以及终端信号，其他 jobs 在后台运行。</p>
<br>

<p><strong>前台 (foreground)</strong> 就是在终端中运行，能与用户有交互的进程。</p>
<p><strong>后台 (background)</strong> 就是在终端中运行，但是并不能与用户交互，也不会显示其执行的过程。</p>
<p><strong>若想将程序放入后台运行</strong>，常用此命令：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">bg</span> [<span class="string">%jobnumber</span>]</span><br></pre></td></tr></table></figure>

<p>其他可以用 <strong><code>Ctrl + z</code></strong>, 或加上 <code>&amp;</code>。 <code>[x] xxx</code> 分别是 job number, PID, 若最后一行显示 <code>done</code>, 表示已经在后台执行完毕。查看后台程序用 <code>jobs</code>。 <code>+</code> 表示最新放入的job， <code>-</code>表示倒数第二放入的job，没符号表示倒数第三以及之前放入的。</p>
<br>

<p><strong>若想将后台程序拉回前台</strong>，用此命令：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">fg</span> [<span class="string">%jobnumber</span>]</span><br></pre></td></tr></table></figure>

<br>

<h3 id="进程的控制"><a href="#进程的控制" class="headerlink" title="进程的控制"></a>进程的控制</h3><p>删除job：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">pkill</span> <span class="string">&lt;NAME&gt;</span></span><br></pre></td></tr></table></figure>

<p>或者用：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">kill</span> -signal %jobnumber    <span class="comment"># 控制进程</span></span><br></pre></td></tr></table></figure>

<p>比如说：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 1608		<span class="comment"># 强制终止1608号任务</span></span><br></pre></td></tr></table></figure>

<p>signal 有64个信号值可以选择，可以这样查看：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kill</span> <span class="string">－l</span></span><br></pre></td></tr></table></figure>

<br>

<p>常用的信号值：</p>
<table>
<thead>
<tr>
<th>信号值</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>-1</td>
<td>重新读取参数运行，类似restart</td>
</tr>
<tr>
<td>-2</td>
<td>如同 ctrl+c 退出</td>
</tr>
<tr>
<td>-9</td>
<td>强制终止该任务</td>
</tr>
<tr>
<td>-15</td>
<td>正常的方式终止该任务</td>
</tr>
</tbody></table>
<br>

<p><strong>注意：</strong></p>
<ul>
<li><p>若是 kill ＋ signal 然后直接加 pid，将会对 pid 对应的进程进行操作</p>
</li>
<li><p>若是 kill + signal 然后加 <code>％jobnumber</code>，这时所操作的对象是 job，这个数字就是就当前 bash 中后台的运行的 job 的 ID</p>
</li>
</ul>
<br>

<hr>
<h2 id="查看进程状态"><a href="#查看进程状态" class="headerlink" title="查看进程状态"></a>查看进程状态</h2><blockquote>
<p>接下来介绍一些常用的，查看进程状态的工具。</p>
</blockquote>
<br>

<h3 id="top"><a href="#top" class="headerlink" title="top"></a>top</h3><blockquote>
<p>前台程序，实时、动态的显示当前系统中进程信息。<strong>好好利用 top 能够很有效的帮助我们观察到系统的瓶颈或问题所在。</strong></p>
</blockquote>
<br>

<h4 id="Load-Average"><a href="#Load-Average" class="headerlink" title="Load Average"></a>Load Average</h4><p>对当前 CPU 工作量的度量（等待 CPU 的平均进程数），分别对应<strong>1、5、15分钟内 CPU 的平均负载</strong>。</p>
<p>假设系统是单 CPU、单内核</p>
<ul>
<li><strong>load = 0</strong>： CPU 没有任何任务</li>
<li><strong>load &lt; 1</strong>： CPU 的任务并不多，资源还很充足</li>
<li><strong>load = 1</strong>：CPU 已经在全力工作，系统资源用完；但还在能力范围之内，只是有点慢</li>
<li><strong>load &gt; 1</strong>： CPU 已经在全力工作，系统资源用完，但还有大量的进程在请求，在等待。若 &gt;5， 说明系统已经在超负荷运作了</li>
<li>load 的临界值为1， 但<strong>最佳临界值为0.7</strong>。先看 15 分钟的值来看大体趋势，再看 5 分钟的值对比是否有下降趋势。</li>
</ul>
<br>

<h4 id="查看-CPU-情况"><a href="#查看-CPU-情况" class="headerlink" title="查看 CPU 情况"></a>查看 CPU 情况</h4><p>查看 CPU 个数：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep <span class="string">&quot;physical id&quot;</span> | sort | uniq | wc -l</span><br></pre></td></tr></table></figure>



<p>每个 CPU 核心数：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep <span class="string">&quot;physical id&quot;</span> | grep <span class="string">&quot;0&quot;</span> | wc -l</span><br></pre></td></tr></table></figure>



<br>

<h4 id="CPU利用率-（Column-3）"><a href="#CPU利用率-（Column-3）" class="headerlink" title="CPU利用率 （Column 3）"></a>CPU利用率 （Column 3）</h4><p>CPU 利用率是一个时间段内 CPU 使用状况的统计，通过这个指标可以看出在某一个时间段内 CPU 被占用的情况，而 Load Average 是 CPU 的 Load，它所包含的信息不是 CPU 的使用率状况，而是在一段时间内 CPU 正在处理以及等待 CPU 处理的进程数情况统计信息，这两个指标并不一样。</p>
<ul>
<li><strong>us：</strong>     用户空间进程占用CPU百分比</li>
<li><strong>sy：</strong>     内核空间运行占用CPU百分比</li>
<li><strong>ni：</strong>     用户进程空间内，改变过优先级的进程占用CPU百分比</li>
<li><strong>id：</strong>     空闲CPU百分比</li>
<li><strong>wa：</strong>     等待输入输出的CPU时间百分比</li>
<li><strong>hi：</strong>     硬中断(Hardware IRQ)占用CPU的百分比</li>
<li><strong>si：</strong>     软中断(Software IRQ)占用CPU的百分比</li>
<li><strong>st：</strong>     (Steal time) 是 hypervisor 等虚拟服务中，虚拟 CPU 等待实际 CPU 的时间的百分比</li>
</ul>
<br>

<h4 id="内存-（Column-4）"><a href="#内存-（Column-4）" class="headerlink" title="内存 （Column 4）"></a>内存 （Column 4）</h4><p>系统的中可用的物理内存最大值并不是 free 这个单一的值，而是 free + buffers + swap 中的 cached 的和。</p>
<ul>
<li><strong>total：</strong> 物理内存总量</li>
<li><strong>used    ：</strong> 使用的物理内存总量</li>
<li><strong>free    ：</strong> 空闲内存总量</li>
<li><strong>buffers：</strong> 用作内核缓存的内存量</li>
</ul>
<br>

<h4 id="SWAP-（Column-5）"><a href="#SWAP-（Column-5）" class="headerlink" title="SWAP （Column 5）"></a>SWAP （Column 5）</h4><ul>
<li><strong>total：</strong>    交换区总量</li>
<li><strong>used    ：</strong> 使用的交换区总量</li>
<li><strong>free    ：</strong> 空闲交换区总量</li>
<li><strong>cached：</strong> 缓冲的交换区总量,内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖</li>
</ul>
<br>

<h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><table>
<thead>
<tr>
<th>名称</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>PID</td>
<td>进程id</td>
</tr>
<tr>
<td>USER</td>
<td>该进程的所属用户</td>
</tr>
<tr>
<td>PR</td>
<td>该进程执行的优先级 priority 值</td>
</tr>
<tr>
<td>NI</td>
<td>该进程的 <strong>nice 值</strong></td>
</tr>
<tr>
<td>VIRT</td>
<td>该进程任务所使用的虚拟内存的总数</td>
</tr>
<tr>
<td>RES</td>
<td>该进程所使用的物理内存数，也称之为驻留内存数</td>
</tr>
<tr>
<td>SHR</td>
<td>该进程共享内存的大小</td>
</tr>
<tr>
<td>S</td>
<td>该进程进程的状态: S=sleep R=running Z=zombie</td>
</tr>
<tr>
<td>%CPU</td>
<td>CPU的利用率</td>
</tr>
<tr>
<td>%MEM</td>
<td>内存的利用率</td>
</tr>
<tr>
<td>TIME+</td>
<td>活跃总时间</td>
</tr>
<tr>
<td>COMMAND</td>
<td>运行的名字</td>
</tr>
</tbody></table>
<br>


<ul>
<li><strong>NICE</strong> 值叫做<strong>静态优先级</strong>，是用户空间的一个优先级值，其取值范围是**-20至19**。这个值越小，表示进程”优先级”越高。 -20 优先级最高， 0 是默认的值，而 19 优先级最低。</li>
<li><strong>PR</strong> 值是<strong>动态优先级</strong>，是进程在内核中实际的优先级值，进程优先级的取值范围是通过一个宏定义的，这个宏的名称是 <strong>MAX_PRIO</strong>，它的值为 140。Linux 实际上实现了 140 个优先级范围，取值范围是从 0-139，这个值越小，优先级越高。而这其中的 0 - 99 是实时进程的值，而 100 - 139 是给用户的。</li>
<li>其中 PR 中的 100 to 139 值部分有这么一个对应 <code>PR = 20 + (-20 to +19)</code>，这里的 -20 to +19 便是nice值，所以说两个虽然都是优先级，但是他们的值和作用范围并不相同</li>
<li><strong>VIRT</strong> 任务所使用的虚拟内存的总数，其中包含所有的代码，数据，共享库和被换出 swap空间的页面等所占据空间的总数</li>
</ul>
<br>

<h4 id="常用交互命令"><a href="#常用交互命令" class="headerlink" title="常用交互命令"></a>常用交互命令</h4><ul>
<li><strong>q:</strong>     退出程序</li>
<li><strong>I:</strong>  Irix mode的开关 切换显示单核平均负载和CPU平均负载</li>
<li><strong>P:</strong>  根据CPU使用百分比大小进行排序</li>
<li><strong>M:</strong>      根据驻留内存大小进行排序</li>
<li><strong>i:</strong>  忽略闲置和僵死的进程，这是一个开关式命令</li>
<li><strong>k:</strong>  终止一个进程，系统提示输入 PID 及发送的信号值。一般终止进程用 15 信号，不能正常结束则使用 9 信号。安全模式下该命令被屏蔽。</li>
</ul>
<br>

<h3 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h3><h4 id="查看信息"><a href="#查看信息" class="headerlink" title="查看信息"></a>查看信息</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ps</span> <span class="string">aux</span></span><br><span class="line"></span><br><span class="line"><span class="string">ps</span> <span class="string">axjf</span></span><br></pre></td></tr></table></figure>

<br>
    

<h4 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h4><table>
<thead>
<tr>
<th>内容</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>F</td>
<td><strong>Process Flags</strong>， F = 1 表示此子程序只是 fork 但没有执行 exec，F = 4 表示此程序使用 root 权限</td>
</tr>
<tr>
<td>USER</td>
<td>进程的拥有用户</td>
</tr>
<tr>
<td>PID</td>
<td>进程 ID</td>
</tr>
<tr>
<td>PPID</td>
<td>父进程的 PID</td>
</tr>
<tr>
<td>SID</td>
<td>session 的 ID</td>
</tr>
<tr>
<td>TPGID</td>
<td>前台进程组的 ID， -1的是守护进程</td>
</tr>
<tr>
<td>%CPU</td>
<td>进程占用的 CPU 百分比</td>
</tr>
<tr>
<td>%MEM</td>
<td>占用内存的百分比</td>
</tr>
<tr>
<td>NI</td>
<td>进程的 NICE 值</td>
</tr>
<tr>
<td>VSZ</td>
<td>进程使用虚拟内存大小</td>
</tr>
<tr>
<td>RSS</td>
<td>驻留内存中页的大小</td>
</tr>
<tr>
<td>TTY</td>
<td>终端 ID</td>
</tr>
<tr>
<td>S / STAT</td>
<td>进程状态</td>
</tr>
<tr>
<td>WCHAN</td>
<td>正在等待的进程资源</td>
</tr>
<tr>
<td>START</td>
<td>启动进程的时间</td>
</tr>
<tr>
<td>TIME</td>
<td>进程消耗CPU的时间</td>
</tr>
<tr>
<td>COMMAND</td>
<td>命令的名称和参数</td>
</tr>
</tbody></table>
<br>

<h4 id="进程状态-（STAT）"><a href="#进程状态-（STAT）" class="headerlink" title="进程状态 （STAT）"></a>进程状态 （STAT）</h4><blockquote>
<p>处在 <strong>D状态</strong> 的进程不接受外来的任何 signal，所以无法使用 kill 命令杀掉。 一般处于这种状态可能是进程 I/O 的时候出问题了。</p>
</blockquote>
<br>

<table>
<thead>
<tr>
<th>状态</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>R</td>
<td>Running</td>
</tr>
<tr>
<td>S</td>
<td>Interruptible Sleep.  等待调用</td>
</tr>
<tr>
<td>D</td>
<td>Uninterruptible Sleep.  不可中断睡眠</td>
</tr>
<tr>
<td>T</td>
<td>Stoped.  暂停或者跟踪状态</td>
</tr>
<tr>
<td>X</td>
<td>Dead. 即将被撤销</td>
</tr>
<tr>
<td>Z</td>
<td>Zombie</td>
</tr>
<tr>
<td>W</td>
<td>Paging. 内存交换</td>
</tr>
<tr>
<td>N</td>
<td>优先级低的进程</td>
</tr>
<tr>
<td>&lt;</td>
<td>优先级高的进程</td>
</tr>
<tr>
<td>s</td>
<td>进程的领导者</td>
</tr>
<tr>
<td>L</td>
<td>锁定状态</td>
</tr>
<tr>
<td>l</td>
<td>多线程状态</td>
</tr>
</tbody></table>
<ul>
<li>   | 前台进程</li>
</ul>
 <br>

<h4 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h4><ul>
<li><p><code>-l</code>: 此次登陆 bash 相关的进程信息</p>
</li>
<li><p><code>ps aux</code>： 所有进程</p>
</li>
<li><p><code>ps axjf</code>：树状显示</p>
</li>
<li><p><code>ps -afxo user,ppid,pid,pgid,command</code>: 自定义需要显示的参数</p>
</li>
<li><p><code>pstree</code>:</p>
<ul>
<li><p><code>pstree -up -A</code>: 各程序树之间以 ASCII 字元來连接</p>
</li>
<li><p><code>pstree -up -p</code>: 同时列出每个 process 的 PID</p>
</li>
<li><p><code>pstree -up -u</code>: 同时列出每个 process 的所属账户名称</p>
</li>
</ul>
</li>
</ul>
<br>]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux System Backup &amp; Restore, Software Management</title>
    <url>/2017/Linux-System-Backup/</url>
    <content><![CDATA[<p>今天来了解一下 Linux 系统备份与恢复，还有软件管理的一些基础知识。</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="System-Backup-amp-Restore"><a href="#System-Backup-amp-Restore" class="headerlink" title="System Backup &amp; Restore"></a>System Backup &amp; Restore</h2><p>几乎所有的备份工具都支持两种不同的备份类型：<strong>完整备份</strong>和<strong>增量备份</strong>。</p>
<p>对于完整备份而言，包含的是一个文件系统的<strong>全部内容</strong>。而增量备份只包括相对于上一次备份之后，<strong>发生变化</strong>的文件。</p>
<br>

<h3 id="Dump"><a href="#Dump" class="headerlink" title="Dump"></a>Dump</h3><p><code>dump</code> 用于备份文件系统。对于 GNU 版本的 dump 来说，默认支持的是 <strong>ext2/3/4</strong> 文件系统的备份。如果需要备份其它文件系统，需要下载指定版本的 dump。</p>
<p>在使用 dump 命令的时候，需要指定一个备份级别。dump等级为0时，将会把整个文件系统进行备份，称为<strong>完整备份</strong>。而 1 则是相对与备份等级为 0 时所有修改的文件进行备份，这时备份方式被称为<strong>增量备份</strong>。下面介绍一些常用参数：</p>
<ul>
<li><code>-level#</code>: 指定备份等级， e.g. <code>-0</code> 备份整个文件系统</li>
<li><code>-f</code>: 指定备份设备</li>
<li><code>-n</code>: 当备份工作需要管理员介入时，向所有 “operator” 群组中的使用者发出通知</li>
<li><code>-T</code>: 指定备份的时间</li>
</ul>
<p>比如，将当前系统的整个文件系统（根目录），备份到 <code>/home/test.dump</code> 中：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">dump</span> <span class="number">-0</span> <span class="string">-f</span> <span class="string">/home/test.dump</span> </span><br></pre></td></tr></table></figure>

<p><em>注：如果是虚拟环境的 Docker 容器，缺乏必要的权限，dump 时会失败。</em></p>
<br>

<h3 id="Restore"><a href="#Restore" class="headerlink" title="Restore"></a>Restore</h3><p>从备份的文件中提取文件，我们称为<strong>恢复</strong>，而对于恢复而言，也可以指定仅恢复一小部分文件和恢复整个文件系统。</p>
<p>与 <code>dump</code> 命令对应的命令为 <code>restore</code>。下面介绍一些常用参数:</p>
<ul>
<li><code>-C</code>: 比较备份的内容与当前实际的内容的区别</li>
<li><code>-i</code>: 交互模式，可以仅还原部分内容</li>
<li><code>-r</code>: 还原整个文件系统</li>
<li><code>-t</code>: 查看备份的内容</li>
<li><code>-f</code>: 指定备份文件</li>
<li><code>-D</code>: 指定需要比较的文件系统</li>
<li><code>-T</code>: 指定需要恢复的路径</li>
</ul>
<p>举例。比较区别：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">restore</span> <span class="string">-C</span> <span class="string">-f</span> <span class="string">test.dump</span> <span class="string">-D</span> <span class="string">/</span> </span><br></pre></td></tr></table></figure>

<p>恢复备份内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">restore</span> <span class="string">-r</span> <span class="string">-f</span> <span class="string">test.dump</span> <span class="string">-T</span> <span class="string">/home</span></span><br></pre></td></tr></table></figure>

<p>我们还可以仅恢复<strong>部分文件</strong>。 在 <code>/home</code> 下创建文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">touch</span> <span class="string">hello.txt</span></span><br></pre></td></tr></table></figure>

<p>进行增量备份：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">dump</span> <span class="number">-1</span> <span class="string">-f</span> <span class="string">/test1.dump</span> <span class="string">/</span></span><br></pre></td></tr></table></figure>

<p>然后将其删除：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">rm</span> <span class="string">hello.txt</span></span><br></pre></td></tr></table></figure>

<p>再通过备份文件将其恢复：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">restore</span> <span class="string">-i</span> <span class="string">-f</span> <span class="string">test1.dump</span></span><br></pre></td></tr></table></figure>


<br>

<h3 id="Backup-Tools"><a href="#Backup-Tools" class="headerlink" title="Backup Tools"></a>Backup Tools</h3><blockquote>
<p><strong>只备份关键数据，不需要备份所有内容</strong></p>
</blockquote>
<h4 id="tar"><a href="#tar" class="headerlink" title="tar"></a>tar</h4><p><code>tar</code> 也可以进行增量备份。 进行增量备份时，使用 <code>-g</code> 或 <code>--listed-incremental</code> 指示 <code>tar</code> 进行<strong>增量归档操作</strong>，并且将额外的元数据存储在快照文件中 (此文件的作用是记录上次归档以来，哪些文件被更改，添加或者删除，以便下一次增量备份时将只包含已经修改的文件) 。</p>
<p>例如，将 <code>/home/test</code> 目录的内容进行增量备份：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">tar</span> <span class="string">-cvf</span> <span class="string">hello.tar</span> <span class="string">-g</span> <span class="string">file1</span> <span class="string">/home/test</span></span><br></pre></td></tr></table></figure>

<p>此处的 <code>-g</code> 指定快照文件为 <code>file1</code>。在快照文件创建时，为 <strong>0 级备份</strong>。对于一个完整的路径 <code>/home/test</code> 而言，保存时会删除开头的 <code>/</code> ，即为 <code>home/test</code>，为了在恢复文件时不会与根目录冲突。</p>
<p>还原文件即用：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">tar</span> <span class="string">-xvf</span> <span class="string">hello.tar</span></span><br></pre></td></tr></table></figure>

<br>

<h4 id="dd"><a href="#dd" class="headerlink" title="dd"></a>dd</h4><p>用于复制和转换文件（系统）。 <code>dd</code> 默认从 stdin<br>读取，输出到 stdout。但可以通过 <code>if</code> 和 <code>of</code> 重定向输入和输出。</p>
<p>比如，将 <code>/etc/hosts</code> 复制到当前目录下的 <code>hosts</code> 中，就可以使用：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">dd</span> <span class="string">if=/etc/hosts</span> <span class="string">of=hosts</span></span><br></pre></td></tr></table></figure>

<p>如果复制文件系统，只需要将 <code>if=</code> 的参数修改为 <code>dev</code> 下对应文件系统的设备即可。</p>
<figure class="highlight plaintext"><figcaption><span>还可以用于临时创建 swap 交换分区。下面的命令通过 ```/dev/zero``` ，复制创建一个文件大小为 1M * 1024 </span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```yaml</span><br><span class="line">dd if=/dev/zero of=swap1 bs=1M count=1024</span><br><span class="line"></span><br><span class="line">mkswap swap1</span><br><span class="line"></span><br><span class="line">swapon swap1  </span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>bs</code>: 设置输入输出块的大小</p>
</li>
<li><p><code>count</code>: 则是复制对应数目的块</p>
</li>
<li><p><code>/dev/zero</code>: 特殊文件，会不断输出 <code>of= 0</code>，即为空。 上面的命令。</p>
</li>
<li><p>对应的 <code>/dev/null</code>: 将所有重定向到 <code>/dev/null</code> 的输出全部抛弃。</p>
</li>
</ul>
<br>

<hr>
<h2 id="Software-Management"><a href="#Software-Management" class="headerlink" title="Software Management"></a>Software Management</h2><blockquote>
<p>常用的管理工具有：<strong>apt，dpkg，rpm，yum</strong> 等</p>
</blockquote>
<br>

<h3 id="dpkg"><a href="#dpkg" class="headerlink" title="dpkg"></a>dpkg</h3><p>最初软件的工具的安装只能依靠代码的下载，通过编译安装，随着 Debian 的诞生，出现了 <strong>dpkg</strong> (Debian Packager) 软件包管理工具。 Red Hat 系列受启发开发出了类似的管理工具 <strong>rpm</strong>。</p>
<p>但是有一些软件的实现依赖于其他软件已有的功能，这样我们就需要首先安装其依赖的软件，不然直接安装会提示依赖错误，而安装的人并不知道有哪些依赖的关系，这样使得安装、升级一个软件变得非常的痛苦。此时 Debian 提出了解决方案，创造了 <strong>apt</strong> 工具来解决这样的困境。 Red Hat 借鉴 apt 的方式创造了 <strong>yum</strong>。</p>
<p>在 Debian 系列的 Linux 操作系统（如 Debian、Ubuntu 等）中会使用 dpkg 与 apt 这样的包管理工具，在 Red Hat 系列的 Linux 操作系统（如 Red Hat、Centos、fe dora 等）会使用 rpm 与 yum 这样的包管理工具。apt 和 dpkg 的区别如下：</p>
<table>
<thead>
<tr>
<th>区别</th>
<th>dpkg</th>
<th>apt</th>
</tr>
</thead>
<tbody><tr>
<td>离线与在线</td>
<td>dpkg 就像 exe 安装包，属于离线方式，不需要依靠网络</td>
<td>apt 每次安装都需要从网络中获取相关资源，属于在线方式</td>
</tr>
<tr>
<td>依赖的处理</td>
<td>dpkg 没有处理依赖的能力，若是有依赖，必须了解依赖关系，按顺序手动安装相关软件包，否则安装失败</td>
<td>apt 能够获取安装软件的所有信息，并自动处理其依赖的关系，从而完成软件包的正确安装</td>
</tr>
<tr>
<td>工具的实现</td>
<td>dpkg 是用 C、perl 等开发语言实现的工具</td>
<td>apt 虽然也是使用 C++、shell 等开发语言实现的工具，但其底层会调用 dpkg 处理一些安装的工作</td>
</tr>
</tbody></table>
<br>

<p>一些常用参数：</p>
<ul>
<li><code>-i</code>:    安装指定 deb 包</li>
<li><code>-R</code>:    后面加上目录名，用于安装该目录下的所有 deb 安装包</li>
<li><code>-r</code>:    移除已安装的软件包 （保留原有配置文件）</li>
<li><code>-P</code>:    完全卸载</li>
<li><code>-I</code>:    显示 deb 包文件的信息</li>
<li><code>-s</code>:    显示已安装软件的信息</li>
<li><code>-S</code>:    搜索已安装的软件包</li>
<li><code>-L</code>:    显示已安装软件包的目录信息</li>
</ul>
<br>

<p>例如统计软件包个数：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">dpkg</span> <span class="string">-l</span> <span class="string">|</span> <span class="string">wc</span> <span class="string">-l</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="apt"><a href="#apt" class="headerlink" title="apt"></a>apt</h3><blockquote>
<p>apt 是 dpkg 的升级版本，主要解决软件包依赖关系</p>
</blockquote>
<br>

<p>一些常用参数：</p>
<ul>
<li><code>apt-get</code>: 管理软件包，包括安装，卸载，升级等</li>
<li><code>apt-cache</code>:    查询软件包信息</li>
<li><code>apt-proxy</code>:    搭建APT代理服务器</li>
<li><code>apt-show-versions</code>:    显示系统中软件包版本信息</li>
<li><code>apt-config</code>:    读取APT配置文件</li>
<li><code>apt-cdrom</code>:    将CD-ROM加入软件源配置文件</li>
</ul>
<br>

<p>APT 是一个<strong>客户 / 服务器结构</strong>的工具，客户端就是我们本地使用 apt 工具，而服务端的 apt 中管理着各种各样的 deb 包，通常我们将其称为<strong>镜像站</strong>或者是源，我们的 apt 客户端工具会根据我们的命令，去服务端中获取相关的软件包并自动为我们安装。工作流程如下：</p>
<ul>
<li>查看配置文件中所给的镜像站（源）地址</li>
<li>通过该地址下载一个资源列表，保存在 <code>/var/lib/apt/list</code>s 中(通常是一个类似于镜像站名-Packages.gz 的压缩包，该压缩包中就是一张资源列表，该列表包含着所有软件的信息，例如包名、优先级、版本号、依赖包、冲突信息、大小、服务器中的路径等等）</li>
<li>安装软件时，便通过读取该文件中的信息，到镜像站中下载相关的软件包，临时存储在 <code>/var/cache/apt/archives</code> 中</li>
<li>安装完毕之后会将安装的包信息写入 <code>/var/lib/dpkg/available</code> 文件中</li>
</ul>
<br>

<p>镜像站地址的配置文件就是 <code>/etc/apt/sources.list</code> ，里面列出了软件包的镜像站点地址。每次修改后，一定要运行 <code>apt-get update</code>，这样 apt 才会再次读取配置文件，获取站点中的包信息，从而更新本地的列表信息。使用 <code>apt-get install</code> 安装软件包时的执行步骤：</p>
<ul>
<li>读取本地存放的软件列表（从镜像站中获取的列表），找到软件包相关信息。</li>
<li>从信息中获取软件包依赖关系，获取其相关的软件包的信息。</li>
<li>根据信息中的软件包地址，下载所有软件包。</li>
<li>按照其依赖的顺序安装所有软件包。</li>
</ul>
<br>

<p>接下来举几个应用的例子。只下载不安装软件包：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-get</span> <span class="string">-d</span> <span class="string">file1</span></span><br></pre></td></tr></table></figure>

<p>统计所有可用的软件包数量：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-cache</span> <span class="string">pkgnames</span> <span class="string">|</span> <span class="string">wc</span> <span class="string">-l</span></span><br></pre></td></tr></table></figure>

<p>获取统计信息：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-cache</span> <span class="string">stats</span></span><br></pre></td></tr></table></figure>

<p>搜索名字 = git 的软件包：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-cache</span> <span class="string">search</span> <span class="string">^git$</span></span><br></pre></td></tr></table></figure>

<p>查询安装状态：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-cache</span> <span class="string">policy</span> <span class="string">git</span></span><br></pre></td></tr></table></figure>

<p>查询依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">apt-cache</span> <span class="string">depends</span> <span class="string">git</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="rpm"><a href="#rpm" class="headerlink" title="rpm"></a>rpm</h3><p>常用参数：</p>
<ul>
<li><p>安装： <code>rpm -i &lt;NAME&gt;.rpm</code></p>
</li>
<li><p>卸载： <code>rpm -e &lt;NAME&gt;.rpm</code></p>
</li>
<li><p>查看已安装的包： <code>rpm -qa</code></p>
</li>
</ul>
<br>

<h3 id="yum"><a href="#yum" class="headerlink" title="yum"></a>yum</h3><p>常用参数：</p>
<ul>
<li><p><code>yum install</code>：安装</p>
</li>
<li><p><code>yum groupinstall</code>：批量安装常用组合</p>
</li>
<li><p><code>yum deplist</code>：依赖关系</p>
</li>
<li><p><code>yum clean</code>：清除缓存</p>
</li>
<li><p><code>yum erase</code>：卸载</p>
</li>
<li><p><code>yum upgrade</code>：升级</p>
</li>
</ul>
<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Disk Management &amp; LVM</title>
    <url>/2017/Linux-Disk-Management/</url>
    <content><![CDATA[<p>今天来复习一下Linux的磁盘管理。<strong>注意此 Section 里, 所有命令都需要 sudo</strong>.</p>
<div class="note primary"><p><strong>Linux中，一切皆文件</strong></p>
</div>

<span id="more"></span> 

<br>

<hr>
<h2 id="查看设备信息"><a href="#查看设备信息" class="headerlink" title="查看设备信息"></a>查看设备信息</h2><p>用 <code>uname</code> 查看<strong>系统信息</strong></p>
<ul>
<li><p><code>-a</code>： 全部Info</p>
</li>
<li><p><code>-m</code>： 硬件类型</p>
</li>
<li><p><code>-n</code>： 网络节点的主机名</p>
</li>
<li><p><code>-o</code>： OS名称</p>
</li>
<li><p><code>-s</code>： (Default) 内核名称</p>
</li>
<li><p><code>-r</code>： 内核版本</p>
</li>
</ul>
<br>



<p>用 <code>lspci</code> 查看<strong>设备信息</strong>（安装 <strong>pciutils</strong>）</p>
<br>

<p>用 <code>lsmod</code> 查看<strong>系统模块</strong> （list modules）</p>
<br>

<hr>
<h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>硬盘分区：<strong>主分区，扩展分区，逻辑分区</strong>。这是属于 <strong>MBR</strong> (MasterBoot Record) 的分区方式。因为 MBR 最多只支持 4 个主分区，而对于想创建更多的分区，则必须创建一个<strong>扩展分区</strong>，再在扩展分区中创建逻辑分区。而扩展分区和主分区的数目加起来<strong>不能超过四个</strong>。</p>
<p>还有一种 <strong>GPT</strong> 的分区方式，可以创建多个分区，没有分区限制，解决了传统分区方式 MBR 的很多缺点。但是使用该方式会有很多限制。</p>
<br>

<h3 id="MBR-分区演示"><a href="#MBR-分区演示" class="headerlink" title="MBR 分区演示"></a>MBR 分区演示</h3><p><strong>假设新添加的磁盘是 vdb</strong>, 查看磁盘：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ls</span> <span class="string">/dev</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">db</span></span><br></pre></td></tr></table></figure>

<p>用 <strong>fdisk</strong> 对磁盘进行分区：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">fdisk</span> <span class="string">/dev/vdb</span>			</span><br></pre></td></tr></table></figure>

<p>输入 <code>m</code>获取帮助，使用 <code>n</code> 创建分区，用 <code>mkfs</code> 建立 Linux 文件系统。将此分区格式化为 <code>ext4</code>文件系统：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkfs.ext4</span> <span class="string">/dev/vdb1</span></span><br></pre></td></tr></table></figure>

<p>用 <code>mount</code> 临时挂载此文件系统，格式如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mount</span> <span class="string">&lt;-t</span> <span class="string">文件系统类型&gt;</span> <span class="string">&lt;待挂载项&gt;</span>  <span class="string">&lt;挂载位置&gt;</span></span><br></pre></td></tr></table></figure>

<p>在 Home 里创建 <strong>test</strong> 目录，作为挂载位置：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mount</span> <span class="string">/dev/vdb1</span> <span class="string">test</span></span><br></pre></td></tr></table></figure>

<br>

<p>对于当前挂载的 <code>/dev/vdb1</code> 而言，重启后分区不会消失，但<strong>并不会默认将其挂载到 test 中</strong>，即 mount 命令只是<strong>临时挂载</strong>。如果希望重启后能自动挂载，需要配置 <code>/etc/fstab</code> 文件，注意几个点：</p>
<ul>
<li><p>Filesystem</p>
</li>
<li><p>Mount point</p>
</li>
<li><p>Options</p>
</li>
<li><p>Dump: 备份</p>
</li>
<li><p>Pass num：一般根目录设为 <strong>0</strong></p>
</li>
</ul>
<p>因此挂载的 <code>/dev/vdb1</code> 在 <code>fstab</code>文件里可以写成：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">/dev/vdb1</span>    <span class="string">/home/test</span>    <span class="string">ext4</span>    <span class="string">defaults</span>    <span class="number">0</span>    <span class="number">2</span></span><br></pre></td></tr></table></figure>

 <br>

<hr>
<h2 id="LVM-Logical-Volume-Manager"><a href="#LVM-Logical-Volume-Manager" class="headerlink" title="LVM (Logical Volume Manager)"></a>LVM (Logical Volume Manager)</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><div class="note info"><p>LVM 是 Linux 管理磁盘分区的一种机制。</p>
</div>
<br>

<p>安装 Linux 操作系统时遇到的一个常见的难以决定的问题，就是<strong>如何正确地评估各分区大小</strong>，以分配合适的硬盘空间。<em>普通的磁盘分区管理方式在逻辑分区划分好之后就无法改变其大小</em>，当一个逻辑分区存放不下某个文件时，这个文件因为受上层文件系统的限制，也不能跨越多个分区来存放，所以也不能同时放到别的磁盘上。而遇到出现某个分区空间耗尽时，解决的方法通常是使用<strong>符号链接</strong>，或者使用调整分区大小的工具，但这只是暂时解决办法，没有从根本上解决问题。</p>
<p>随着 Linux 的逻辑卷管理功能的出现，这些问题都迎刃而解，用户在无需停机的情况下可以方便地调整各个分区大小。下面介绍一下 LVM 相关概念：</p>
<ul>
<li><p><strong>PV（Physical Volume）</strong>，物理卷处于 lvm 的最底层，是 lvm 的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与 LVM 相关的管理参数</p>
</li>
<li><p><strong>VG（Volume Group）</strong>，卷组一般由一个或多个物理卷组成，在卷组创建之后，可以扩展卷组空间</p>
</li>
<li><p><strong>LV（Logical Volume）</strong> ，逻辑卷建立在卷组之上。在逻辑卷上可以建立文件系统，逻辑卷也可以动态地调整空间</p>
</li>
<li><p><strong>PE（Physical Extent）</strong> 物理卷由<strong>物理区域</strong>组成。PE 的大小还可以在创建物理卷的时候指定。默认大小为 4MB</p>
</li>
<li><p><strong>LE（Logical Extent）</strong> 逻辑区域是给逻辑卷中可用于分配的<strong>最小单元</strong>，一般 LE 的大小为 PE 的倍数，默认为 （1 : 1）</p>
</li>
</ul>
<p><em><strong>下面简单演示一下 LVM 的使用过程。</strong></em></p>
<br>

<h3 id="PV-Physical-Volumn"><a href="#PV-Physical-Volumn" class="headerlink" title="PV (Physical Volumn)"></a>PV (Physical Volumn)</h3><blockquote>
<p>首先是 <strong>PV</strong>（<strong>apt</strong> 安装 <strong>lvm2</strong>）。</p>
</blockquote>
<p>物理卷类似于磁盘分区，但却包含有 lvm 相关的管理参数。这里我们使用刚刚添加的新磁盘进行操作。卸载刚刚挂载的文件系统，并且删除 /dev/vdb 中的分区，即 /dev/vdb1。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">umount</span> <span class="string">test</span></span><br></pre></td></tr></table></figure>

<p>接着创建四个主分区:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">fdisk</span> <span class="string">/dev/vdb</span></span><br></pre></td></tr></table></figure>
<p>此时，我们已经建立了四个分区，但是此时只是普通的分区，我们需要将其修改为 lvm 类型。 输入 <code>I</code> 查看系统 id 对应的分区类型。Linux LVM 对应的id是 <code>8e</code>，即把此四个分区 id 改为<code>8e</code>。</p>
<p>接下来创建物理卷：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">pvcreate</span> <span class="string">/dev/vdb1</span></span><br><span class="line"><span class="string">pvcreate</span> <span class="string">/dev/vdb2</span></span><br><span class="line"><span class="string">pvcreate</span> <span class="string">/dev/vdb3</span></span><br><span class="line"><span class="string">pvcreate</span> <span class="string">/dev/vdb4</span></span><br></pre></td></tr></table></figure>

<p>查看物理卷信息：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">pvdisplay</span> <span class="string">/dev/vdb1</span></span><br></pre></td></tr></table></figure>
<p>如果要修改物理卷，则用 <code>pvchange</code>.</p>
<br>

<h3 id="VG-Volume-Group"><a href="#VG-Volume-Group" class="headerlink" title="VG (Volume Group)"></a>VG (Volume Group)</h3><p>卷组需要在物理卷的基础上进行创建，使用 <code>vgcreate</code> 命令，例如我们使用物理卷 <code>/dev/vdb1</code> 和 <code>/dev/vdb2</code> 创建 名为 <strong>vg1</strong> 的卷组：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vgcreate</span> <span class="string">vg1</span> <span class="string">/dev/vdb1</span> <span class="string">/dev/vdb2</span></span><br></pre></td></tr></table></figure>

<p>同物理卷相关的命令类似，查看卷组信息的命令为 <code>vgdisplay</code>，修改卷组的命令为 <code>vgchange</code> 。我们先查看卷组 <strong>vg1</strong> 的信息：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vgdisplay</span> <span class="string">vg1</span></span><br></pre></td></tr></table></figure>

<p>再将默认的 <strong>PE</strong> 大小 (4MB) 修改为 8MB:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vgchange</span> <span class="string">-s</span> <span class="string">8MB</span> <span class="string">vg1</span></span><br></pre></td></tr></table></figure>

<p>接下来我们用 <code>vgextend</code> 扩展卷组 <strong>vg1</strong> ，将剩余的两个物理卷添加到卷组中。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vgextend</span> <span class="string">vg1</span> <span class="string">/dev/vdb3</span> <span class="string">/dev/vdb4</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="LV-Logical-Volume"><a href="#LV-Logical-Volume" class="headerlink" title="LV (Logical Volume)"></a>LV (Logical Volume)</h3><p>在创建卷组后，就可以从卷组中创建逻辑卷了，使用 <code>lvcreate</code> 命令。相关参数如下：</p>
<ul>
<li><strong><code>-n</code></strong> : 指定逻辑卷的名称</li>
<li><strong><code>-l</code></strong> : 通过指定 PE 的数量指定逻辑卷的大小</li>
<li><strong><code>-L</code></strong> : 直接指定逻辑卷的大小，单位有 <code>bBsSkKmMgGtTpPeE</code> 等</li>
<li><strong><code>-p</code></strong> : 设置权限，可以设为 r 只读，或者 rw 读写</li>
</ul>
<p>创建两个卷组 lv1, lv2。 一个使用 -l 参数，指定 100 个 PE ，即 100*8=800MB 的容量 （前面修改 PE 大小为 8MB）：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">lvcreate</span> <span class="string">-l</span> <span class="number">100</span> <span class="string">-n</span> <span class="string">lv1</span> <span class="string">vg1</span></span><br></pre></td></tr></table></figure>

<p>另一个通过 -L 参数，也指定为 800MB 大小:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">lvcreate</span> <span class="string">-L</span> <span class="string">800M</span> <span class="string">-n</span> <span class="string">lv2</span> <span class="string">vg1</span></span><br></pre></td></tr></table></figure>

<p>查看逻辑卷则通过 <code>lvdisplay</code> 命令实现，不同的是，这里查看的是卷组中的逻辑卷，所以需要指定卷组：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">lvdisplay</span> <span class="string">vg1</span></span><br></pre></td></tr></table></figure>

<p>创建 Lv 后，就可以通过 <code>mkfs</code> 建立文件系统，像使用普通的磁盘分区一样使用逻辑卷。此处需要说明的是，对于 lv1 和 lv2 而言，设备文件在 <code>/dev</code> 目录下的对应的卷组的子目录中，即 <code>/dev/vg1/</code> 。可使用 <code>ls</code>查看：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ls</span> <span class="string">/dev/vg1</span></span><br></pre></td></tr></table></figure>

<p>最后给创建的逻辑卷建立<strong>操作系统</strong>，创建对应的目录并<strong>挂载</strong>。</p>
<br>

<p>建立 ext4 文件系统：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkfs.ext4</span> <span class="string">/dev/vg1/lv1</span></span><br></pre></td></tr></table></figure>

<p>建立逻辑卷 lv1 的挂载目录：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">/home/merikanto/lv1</span></span><br></pre></td></tr></table></figure>

<p>挂载 lv1：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mount</span> <span class="string">/dev/vg1/lv1</span> <span class="string">/home/merikanto/lv1</span> </span><br></pre></td></tr></table></figure>

<br>

<h3 id="SWAP"><a href="#SWAP" class="headerlink" title="SWAP"></a>SWAP</h3><p>交换分区 SWAP 就是 Linux 下的虚拟内存分区,它的作用是在物理内存使用完之后，<strong>将磁盘空间 (也就是 SWAP 分区) 虚拟成内存来使用</strong>。</p>
<p>首先，我们需要将刚刚挂载的逻辑卷删除：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">lvremove</span> <span class="string">/dev/vg1/lv1</span></span><br><span class="line"><span class="string">lvremove</span> <span class="string">/dev/vg1/lv2</span></span><br><span class="line"><span class="string">vgremove</span> <span class="string">vg1</span></span><br></pre></td></tr></table></figure>

<p>再通过 <code>fdisk</code> 命令将 <code>/dev/vdb</code> 分区表的内容删除：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">fdisk</span> <span class="string">/dev/vdb</span></span><br></pre></td></tr></table></figure>

<p>通过下面指令创建 1G 的虚拟内存:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># if &amp; of</span></span><br><span class="line"><span class="string">dd</span> <span class="string">if=/dev/zero</span> <span class="string">of=/swap/swap</span> <span class="string">bs=1024</span> <span class="string">count=1024000</span></span><br></pre></td></tr></table></figure>

<p>创建交换文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkswap</span> <span class="string">/swap/swap</span></span><br></pre></td></tr></table></figure>


<p>最后我们用 <code>swapon</code> 启动交换分区，对应的关闭命令为 <code>swapoff</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">swapon</span> <span class="string">/swap/swap</span></span><br></pre></td></tr></table></figure>

<p>之后用 <code>top</code> 命令查看启动的 swap 分区。</p>
<p>跟 <code>mount</code> 一样，<code>swapon</code> 也只是<strong>临时启动交换分区</strong>，如果希望 swap 在下次重启后自动启动，需要配置 <code>/etc/fstab</code> 文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">&quot;/swap/swap swap swap defaults 0 0&quot;</span> <span class="string">&gt;&gt;</span> <span class="string">/etc/fstab</span></span><br></pre></td></tr></table></figure>


 <br>










]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux File System, FHS &amp; umask</title>
    <url>/2017/Linux-File-System/</url>
    <content><![CDATA[<p>今天来 <strong><a href="https://naotu.baidu.com/file/2837949e235138bfa65076f5f6aae62d?token=b9d8da8b83ad5b03">总结一下</a></strong> Linux 的文件系统，还有文件类型。</p>
<span id="more"></span> 

<br>

<hr>
<h2 id="File-System"><a href="#File-System" class="headerlink" title="File System"></a>File System</h2><h3 id="FHS"><a href="#FHS" class="headerlink" title="FHS"></a>FHS</h3><p>Linux 主要采用的是<strong>树形结构</strong>，它是单一的一棵树，无论有多少分区，都包含在以 <code>/</code> 为根节点的树结构上。其中<strong>分区</strong>是物理上的区分，<strong>目录</strong>则是逻辑上的区分。Linux 中每个分区都要挂载到目录树中一个具体的目录下才能访问，其中根目录必须挂载一个分区 (<strong>挂载</strong>是 Linux 文件系统与一个存储设备关联起来的过程）。 因为 Linux 是一个多用户系统，一个规范的目录有助于对系统文件和不同的用户文件进行统一管理。</p>
<p>在 Linux 的目录结构中，用户的主目录通常是保存在一个单独的文件系统上，然后挂载到根目录下的一个目录。<strong>FHS (Filesystem Hierarchy Standard)</strong> 定义了系统中每个区域的用途、所需要的最小构成的文件和目录，同时还给出了例外处理与矛盾处理。</p>
<img data-src="/images/posts/170707-1.png" style="zoom: 130%;" />

<br>

<h3 id="文件系统的组成"><a href="#文件系统的组成" class="headerlink" title="文件系统的组成"></a>文件系统的组成</h3><ol>
<li><p><strong>Namespace:</strong> 主要给事物对象命名，并按照一种层次结构来组织</p>
</li>
<li><p><strong>API:</strong> 主要用于查询和操作对象的一种系统调用</p>
</li>
<li><p><strong>安全模型:</strong> 主要用于保护、共享和隐藏对象</p>
</li>
<li><p><strong>实现:</strong> 主要用于逻辑模型和硬件系统连接起来</p>
</li>
</ol>
<br>

<h2 id="File-Types"><a href="#File-Types" class="headerlink" title="File Types"></a>File Types</h2><h3 id="7-Types"><a href="#7-Types" class="headerlink" title="7 Types"></a>7 Types</h3><ol>
<li><p><strong>普通文件 <code>-</code></strong></p>
<ul>
<li>文本文件、数据文件、可执行程序等等都可作为普通文件存储。</li>
</ul>
</li>
<li><p><strong>目录 <code>d</code></strong></p>
<ul>
<li>目录中按照名字来对其他文件进行引用，用户通过 <code>mkdir</code> 创建目录，用 <code>rmdir</code> 来删除空目录，用 <code>rm -r</code> 来删除非空目录。</li>
</ul>
</li>
<li><p><strong>字符设备文件 <code>c</code></strong></p>
<ul>
<li>字符设备文件让相关的驱动程序作为输入输出的缓冲。</li>
</ul>
</li>
<li><p><strong>块设备文件 <code>b</code></strong></p>
<ul>
<li>块设备文件有处理块数据的 I/O 的驱动程序使用，同时让内核提供缓冲。</li>
</ul>
</li>
<li><p><strong>本地域套接口 <code>s</code></strong></p>
<ul>
<li>实现进程间通信的连接，本地域套接口由系统调用 <code>socket</code> 创建，用 <code>rm</code> 或 <code>unlink</code> 删除。</li>
</ul>
</li>
<li><p><strong>有名管道（FIFO）<code>p</code></strong></p>
<ul>
<li>让运行在同一主机上的两个进程相互通信，和 socket 相似，用 <code>mknod</code> 创建，用 <code>rm</code> 来删除。</li>
</ul>
</li>
<li><p><strong>符号链接 <code>l</code></strong></p>
<ul>
<li>也叫做<strong>软链接</strong>，通过名字指向文件。用 <code>ln -s</code> 创建，用 <code>rm</code> 来删除。</li>
</ul>
</li>
</ol>
<br>

<h3 id="软链接-amp-硬链接"><a href="#软链接-amp-硬链接" class="headerlink" title="软链接 &amp; 硬链接"></a>软链接 &amp; 硬链接</h3><blockquote>
<p>在 Linux 中链接文件可以分为<strong>软链接</strong>和<strong>硬链接</strong>两种。创建方法：</p>
</blockquote>
<ul>
<li>软链接：<code>ln -s source target</code></li>
<li>硬链接：<code>ln source target</code></li>
</ul>
<br>

<ol>
<li><strong>软链接（符号链接）:</strong><br>软链接文件类似于<strong>快捷方式</strong>。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。</li>
</ol>
<br>


<ol start="2">
<li><strong>硬链接（实体链接）:</strong><br>硬连接是通过<strong>索引节点（inode）</strong>来进行的连接，其作用是允许一个文件拥有多个有效路径名，能够达到误删除的作用。在 Linux 中，多个文件名指向同一索引节点是存在的。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，<strong>文件真正删除的条件是与之相关的所有硬连接文件均被删除</strong>。</li>
</ol>
<br>


<ol start="3">
<li><p><code>ln</code> 命令：</p>
<ul>
<li><p>软链接(<code>ln -s</code>) 只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间</p>
</li>
<li><p>硬链接<code>ln</code>没有参数 <code>-s</code>, 在选定的位置上生成一个和源文件大小相同的文件</p>
</li>
<li><p>无论是软链接还是硬链接，文件都保持同步变化。 <code>ln</code> 会保持每一处链接文件的同步性。 不论改动哪一处，其它的文件都会发生相同的变化</p>
</li>
<li><p>e.g. </p>
  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">touch f</span><br><span class="line">ln -s f f2		<span class="comment"># Create softlink f2</span></span><br><span class="line">rm f</span><br><span class="line">cat f2   </span><br><span class="line">&gt;&gt;&gt; No such file or directory</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;hello&quot;</span> </span><br><span class="line">&gt;&gt;&gt; f2</span><br><span class="line"></span><br><span class="line">ls    </span><br><span class="line">&gt;&gt;&gt;  f  f1  f2		<span class="comment"># Original file f reappears</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<ul>
<li><img data-src="/images/posts/170707-2.jpeg" alt="img">  <br>
  </li>
</ul>
<ol start="4">
<li><p><strong>区别:</strong></p>
<ul>
<li><p><strong>硬链接缺点：</strong></p>
<ul>
<li>不允许给目录创建硬链接</li>
<li>只有在同一文件系统中的文件之间才能创建链接，而且只有 root 才有建立权限</li>
</ul>
</li>
<li><p><strong>软链接优点：</strong></p>
<ul>
<li>没有硬链接以上的两个限制，因而现在更为广泛使用，它具有更大的灵活性，甚至可以跨越不同机器、不同网络对文件进行链接。</li>
</ul>
</li>
<li><p><strong>软链接缺点：</strong></p>
<ul>
<li>因为软链接含有原文件的路径信息，所以当原文件被移到其他目录中，再访问链接文件，系统就找不到了。而硬链接就没有这个缺陷，想怎么移就怎么移。</li>
<li>要系统分配额外的空间用于建立新的索引节点和保存原文件的路径</li>
</ul>
</li>
<li><p><strong>一句话总结</strong>：</p>
<ul>
<li>软链接可以<strong>跨分区</strong>，但源文件不能删除。</li>
<li>硬链接不能跨分区，但可以<strong>删除源文件</strong>。</li>
</ul>
</li>
</ul>
</li>
</ol>
<br>

<h2 id="补充：umask"><a href="#补充：umask" class="headerlink" title="补充：umask"></a>补充：umask</h2><blockquote>
<p>umask 主要用来设置用户创建文件的<strong>默认权限</strong>，它与 <code>chmod</code> 的效果刚好相反。<code>umask</code> 设置的是<strong>权限“补码”</strong>，而 <code>chmod</code> 设置的是文件权限码。一般在 <code>/etc/profile</code>、<code>～/.bash_profile</code> 或 <code>～/.profile</code> 中设置 umask 值。</p>
</blockquote>
<br>

<p>计算 umask 值相应的文件，和目录缺省创建权限的步骤如下：</p>
<ul>
<li>先写下具有全部权限的模式，即 777 (所有用户都具有读、写和执行权限)。</li>
<li>在下面一行按照 umask 值写下相应的位。</li>
<li>在接下来的一行中记下上面两行中没有匹配的位。这就是目录的缺省创建权限。</li>
<li>对于文件来说，在创建时不能具有执行权限，只要拿掉相应的执行权限即可。</li>
</ul>
<br>

<p>e.g. 假设 umask 值为 <strong>022</strong>：</p>
<ul>
<li><p>文件的最大权限是: rwx rwx rwx (777)</p>
</li>
<li><p>umask 值为 <strong>022</strong> (<code>--- -w- -w-</code>)</p>
</li>
<li><p>目录权限就是 <strong>755</strong> (<code>rwx r-x r-x</code>)（这就是目录创建缺省权限）</p>
</li>
<li><p>文件权限 <strong>644</strong> (<code>rw- r-- r-- </code>) （这就是文件创建缺省权限）</p>
</li>
</ul>
<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Bash Programming - 03 Flow Control</title>
    <url>/2017/Bash-03/</url>
    <content><![CDATA[<p>This post is <strong>Part Three</strong> of Bash Programming. Today let’s look at <strong>flow control</strong>.</p>
<span id="more"></span> 

<br>



<hr>
<h2 id="Conditions"><a href="#Conditions" class="headerlink" title="Conditions"></a>Conditions</h2><h3 id="if"><a href="#if" class="headerlink" title="if"></a>if</h3><p>Format:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ ... ]]; <span class="keyword">then</span></span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">elif</span> [[ ... ]]; <span class="keyword">then</span></span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    ...	</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<br>

<p>e.g. Input number &amp; 7:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">read</span> -p <span class="string">&quot;Input: &quot;</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$a</span> &gt; 7 ]]; <span class="keyword">then</span>  </span><br><span class="line">    <span class="built_in">echo</span> Bigger</span><br><span class="line"><span class="keyword">elif</span> [[ <span class="variable">$a</span> = 7 ]]; <span class="keyword">then</span>  </span><br><span class="line">    <span class="built_in">echo</span> Equal </span><br><span class="line"><span class="keyword">else</span>  </span><br><span class="line">    <span class="built_in">echo</span> Smaller</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<br>
    
    
<h3 id="case"><a href="#case" class="headerlink" title="case"></a>case</h3><p>Format:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> &lt;VAR&gt; <span class="keyword">in</span> </span><br><span class="line">..1)			<span class="comment"># Can be digits or strings. </span></span><br><span class="line">...	;;</span><br><span class="line">..2)</span><br><span class="line">...	;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<p>e.g. Month &amp; Half-year:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">read</span> -p <span class="string">&quot;Input: &quot;</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$a</span> <span class="keyword">in</span> </span><br><span class="line">1 | 2 | 3 | 4 | 5 | 6)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;1st half of the year&quot;</span>;;</span><br><span class="line">7 | 8 | 9 | 10 | 11 | 12)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;2nd half of the year&quot;</span>;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input error&quot;</span>;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<br>



<hr>
<h2 id="Loops"><a href="#Loops" class="headerlink" title="Loops"></a>Loops</h2><h3 id="for"><a href="#for" class="headerlink" title="for"></a>for</h3><p>Bash-Type:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sum=0</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> &#123;1..5&#125;; <span class="keyword">do</span> </span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;sum += n&quot;</span></span><br><span class="line"><span class="keyword">done</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Total is: <span class="variable">$sum</span>&quot;</span></span><br></pre></td></tr></table></figure>

<br>

<p>C-Type:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sum=0</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (( n = 1; n &lt;=5; n++ )); <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;sum += n&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Total is: <span class="variable">$sum</span>&quot;</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="while"><a href="#while" class="headerlink" title="while"></a>while</h3><p>e.g. Calculate sum of 1 - 10:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">s=0</span><br><span class="line">n=1</span><br><span class="line"><span class="keyword">while</span> (( <span class="variable">$n</span> &lt;= 10 )); <span class="keyword">do</span>    // <span class="keyword">while</span> n ≤ 10</span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;s += n&quot;</span></span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;n++&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Total is: <span class="variable">$s</span>&quot;</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="until"><a href="#until" class="headerlink" title="until"></a>until</h3><p>e.g. Calculate sum of 1 - 10:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">s=0</span><br><span class="line">n=1</span><br><span class="line">until (( <span class="variable">$n</span> &gt; 10 )); <span class="keyword">do</span>    // until n &gt; 10</span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;s += n&quot;</span></span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;n++&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Total is: <span class="variable">$s</span>&quot;</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>e.g. Select words</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">PS3=<span class="string">&quot;Select: &quot;</span></span><br><span class="line">select w <span class="keyword">in</span> hello world; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;Result: \n  <span class="variable">$w</span>&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;  1) hello</span><br><span class="line">&gt;&gt;&gt;  2) world</span><br><span class="line">&gt;&gt;&gt;  Select: 1</span><br><span class="line">&gt;&gt;&gt;  Result:</span><br><span class="line">&gt;&gt;&gt;    hello</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note that <code>echo -e</code>: Recognize <code>\</code>, escape.</p>
</blockquote>
<blockquote>
<p><code>PS3</code> is the prompt. Default is <code>#?</code>.</p>
</blockquote>
<br>

<h3 id="Nested-Loop"><a href="#Nested-Loop" class="headerlink" title="Nested Loop"></a>Nested Loop</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">n=3</span><br><span class="line"><span class="keyword">while</span> [[ <span class="variable">$n</span> &gt; 0 ]]; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Outer <span class="variable">$n</span>&quot;</span></span><br><span class="line">    <span class="built_in">let</span> <span class="string">&quot;n--&quot;</span></span><br><span class="line">    <span class="keyword">for</span> (( i=2; i&gt;0; i-- )); <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Inner <span class="variable">$i</span>&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="break"><a href="#break" class="headerlink" title="break"></a>break</h3><blockquote>
<p>Out of <strong>all loops</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">n=0</span><br><span class="line"><span class="keyword">while</span> [[ <span class="variable">$n</span> &lt;= 4 ]]; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$n</span></span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">$n</span> == 2 ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">break</span>		   // <span class="built_in">break</span> AFTER <span class="built_in">echo</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">let</span> n++</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 0</span><br><span class="line">    1		</span><br><span class="line">    2</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: <code>break</code> after <code>echo</code></p>
</blockquote>
<br>

<h3 id="continue"><a href="#continue" class="headerlink" title="continue"></a>continue</h3><blockquote>
<p>Out of <strong>current loop</strong></p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> &#123;0..4&#125;; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">$n</span> == 2 ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">continue</span>	  // <span class="built_in">continue</span> BEFORE <span class="built_in">echo</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$n</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 0</span><br><span class="line">    1</span><br><span class="line">    3</span><br><span class="line">    4</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note: <code>continue</code> before <code>echo</code></p>
</blockquote>
<br>

<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Scripting</tag>
      </tags>
  </entry>
  <entry>
    <title>Bash Programming - 02 Arithmetics</title>
    <url>/2017/Bash-02/</url>
    <content><![CDATA[<p>This post is <strong>Part Two</strong> of Bash Programming. In this post, we will focus on doing arithmetics with Bash.</p>
<span id="more"></span> 

<br>



<h2 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h2><h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><ul>
<li><code>+</code></li>
<li><code>-</code></li>
<li><code>*</code>  (Use <code>\</code> to <strong>escape</strong>)</li>
<li><code>/</code>  (Result is integer, not float)</li>
<li><code>%</code>  </li>
</ul>
<p><strong><code>expr</code></strong>: Only among <strong>integers</strong>. e.g.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">expr 3 \* -2 / 5</span><br><span class="line">&gt;&gt;&gt;  -1</span><br></pre></td></tr></table></figure>

<br>



<h3 id="Logic"><a href="#Logic" class="headerlink" title="Logic"></a>Logic</h3><ul>
<li><code>!</code>  (Not used in shell’s arithmetics)</li>
<li><code>&amp;</code></li>
<li><code>|</code></li>
</ul>
<p>e.g. </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">expr 1 \&amp; 2</span><br><span class="line">&gt;&gt;&gt;  1</span><br><span class="line"></span><br><span class="line">expr 2 \&amp; 0</span><br><span class="line">&gt;&gt;&gt;  0</span><br><span class="line"></span><br><span class="line">expr 2 \| 0</span><br><span class="line">&gt;&gt;&gt; 2</span><br></pre></td></tr></table></figure>

<p>In commands: </p>
<ul>
<li><code>1 &amp;&amp; 2</code> </li>
<li><code>1 || 2</code> (exec. 2 only if 1 fails)</li>
</ul>
<br>

<h3 id="Relational"><a href="#Relational" class="headerlink" title="Relational"></a>Relational</h3><ul>
<li><code>=</code></li>
<li><code>&gt;</code></li>
<li><code>&lt;</code></li>
<li><code>&lt;=</code></li>
<li><code>&gt;=</code></li>
</ul>
<br>

<h2 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h2><p><code>expr</code></p>
<ul>
<li>No power or floats</li>
</ul>
<br>

<p><code>(( ))</code> （是 <code>[ ]</code> 的进化版）</p>
<ul>
<li><p>e.g. <code>echo $((2**3))</code></p>
</li>
<li><p>e.g.     </p>
<pre><code>  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a=0</span><br><span class="line">((a=a+3))</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$a</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;  3</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<br>

<p><code>let</code>: assignment &amp; simple arithmetics</p>
<ul>
<li><code>(( ))</code>‘s command version</li>
<li>e.g. <code>let 1+1</code></li>
</ul>
<p><br><code>declare</code>: calculations use <code>-i</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a=1+1</span><br><span class="line"><span class="built_in">declare</span> -i a</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$a</span></span><br><span class="line">    </span><br><span class="line">&gt;&gt;&gt;  2</span><br></pre></td></tr></table></figure>

<br>

<p><code>bc</code>: Linux calculator (<strong>ints &amp; floats</strong>)</p>
<ul>
<li>e.g. <code>echo &quot;1.1*3&quot; | bc</code></li>
</ul>
<br>

<h2 id="Conditions"><a href="#Conditions" class="headerlink" title="Conditions"></a>Conditions</h2><p><code>[[ ]]</code> equals to <code>test</code> command</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">test</span> 3 -gt 2  	-&gt;   [[ 3 &gt; 2 ]]</span><br><span class="line"><span class="built_in">echo</span> $?</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 0   	<span class="comment"># True</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>File type:</strong></p>
<ul>
<li><code>-d</code>: Is it a dir.</li>
<li><code>-e</code>: Does it contain this file</li>
<li><code>-r</code>: Is it read-only</li>
<li>e.g.  <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[ -d /home/<span class="built_in">test</span> ]</span><br><span class="line"><span class="built_in">echo</span> $?</span><br><span class="line"></span><br><span class="line">[[ -r /home/<span class="built_in">test</span> &amp;&amp; -e /<span class="built_in">test</span>/hello ]]</span><br><span class="line"><span class="built_in">echo</span> $?</span><br></pre></td></tr></table></figure></li>
</ul>
<br>

<h2 id="Special"><a href="#Special" class="headerlink" title="Special"></a>Special</h2><p>Convert decimal to binary:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;obase=2; ibase=10; 11&quot;</span> | bc -l</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;  1011</span><br></pre></td></tr></table></figure>

<br>

<p>Convert binary to decimal:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> $(( <span class="number">2#1011</span> ))	</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;  11</span><br></pre></td></tr></table></figure>

<br>

<p>Get random numbers (Default: 0 - 32767):</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$RANDOM</span></span><br></pre></td></tr></table></figure>

<br>

<p>Get random numbers (0 - 255):</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">expr <span class="variable">$RANDOM</span> / 128	</span><br></pre></td></tr></table></figure>

<br>

<p>More flexible way:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">shuf -i 100-300 -n 4</span><br></pre></td></tr></table></figure>

<ul>
<li>Range (<code>-i</code>)</li>
<li># of outputs (<code>-n</code>)</li>
</ul>
<br>
]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Scripting</tag>
      </tags>
  </entry>
  <entry>
    <title>Bash Programming - 01 Vars, Exps</title>
    <url>/2017/Bash-01/</url>
    <content><![CDATA[<p>This post is <strong>Part One</strong> of <a href="https://naotu.baidu.com/file/a48ef9a632491d12bcdf33632273c09a?token=378a7037a3818df5">Bash Programming</a>. </p>
<span id="more"></span> 

<br>


<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Common shell types:</p>
<ul>
<li>Bourne (sh)</li>
<li>Bourne-again (bash)</li>
<li>C (csh)</li>
<li>tcsh</li>
<li>Korn (ksh)</li>
<li>zsh</li>
</ul>
<br>

<p>Check current shell:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">$0</span></span><br></pre></td></tr></table></figure>

<p>Check default shell:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">$SHELL</span></span><br></pre></td></tr></table></figure>

<p>Check shell’s process:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ps</span> <span class="string">auxf</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">bash</span> <span class="string">-A</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Prompts</strong>:</p>
<ul>
<li><code>PS1</code>: <code>$</code> for normal user, <code>#</code> for root</li>
<li><code>PS2</code>: <code>&gt;</code></li>
</ul>
<br>

<p>Shell scripts always start with:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br></pre></td></tr></table></figure>

<p><strong>Check exit status</strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">echo</span> <span class="string">$?</span></span><br></pre></td></tr></table></figure>



<br>



<table>
<thead>
<tr>
<th>Number</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>Success</td>
</tr>
<tr>
<td>1</td>
<td>Unknown error</td>
</tr>
<tr>
<td>126</td>
<td>Command cannot be executed</td>
</tr>
<tr>
<td>127</td>
<td>Invalid command</td>
</tr>
<tr>
<td>130</td>
<td>Exit via <code>Ctrl + c</code></td>
</tr>
</tbody></table>
<br>

<h2 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h2><p>Variables in shell:</p>
<ul>
<li>All treated as <strong>chars</strong></li>
<li>Direct assignment</li>
</ul>
<br>

<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><blockquote>
<p><code>&lt;var&gt;=&lt;char&gt;</code> (Numbers, Letters, and <code>_</code>)</p>
</blockquote>
<p><strong>Assignment</strong>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">&lt;var&gt;=$(<span class="built_in">command</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># e.g.</span></span><br><span class="line">a=$(<span class="built_in">echo</span> hello)</span><br></pre></td></tr></table></figure>




<br>

<p><strong><code>read</code></strong>:</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td>-s</td>
<td>quiet mode (no echo)</td>
</tr>
<tr>
<td>-a</td>
<td>array</td>
</tr>
<tr>
<td>-n</td>
<td>read char</td>
</tr>
<tr>
<td>-p</td>
<td>prompt</td>
</tr>
<tr>
<td>-t</td>
<td>wait time</td>
</tr>
</tbody></table>
<p>e.g. Input with prompt:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">read</span> <span class="string">-p</span> <span class="string">&quot;Enter: &quot;</span> <span class="string">a</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong><code>declare</code></strong>:</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td>-r</td>
<td>read only</td>
</tr>
<tr>
<td>-l</td>
<td>upper -&gt; lower</td>
</tr>
<tr>
<td>-u</td>
<td>lower -&gt; upper</td>
</tr>
</tbody></table>
<p>e.g. Transform upper to lower:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">declare</span> <span class="string">-l</span> <span class="string">a=HELLO</span></span><br><span class="line"><span class="string">echo</span> <span class="string">$a</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Delete Vars</strong>:</p>
<ul>
<li><code>unset -f</code>: Only deletes function</li>
<li><code>unset -v</code>: Only deletes var.</li>
</ul>
<p>e.g. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">a=hello</span></span><br><span class="line"><span class="string">unset</span> <span class="string">a</span></span><br></pre></td></tr></table></figure>


<br>

<h3 id="Referencing"><a href="#Referencing" class="headerlink" title="Referencing"></a>Referencing</h3><blockquote>
<p>Remember the <code>$</code> sign. Otherwise, it’s not a var, but a string.</p>
</blockquote>
<p>e.g. Print “Hello World”</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a=World</span><br><span class="line">b=<span class="string">&quot;Hello <span class="variable">$a</span>&quot;</span>		<span class="comment"># Must use DOUBLE QUOTES!</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$b</span></span><br></pre></td></tr></table></figure>

<br>

<p><strong>Extension</strong>:</p>
<blockquote>
<p>Again, must be <strong>DOUBLE QUOTES</strong>!</p>
</blockquote>
<table>
<thead>
<tr>
<th>Expression</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><code>$&#123;var&#125;</code></td>
<td>== <code>$var</code></td>
</tr>
<tr>
<td><code>$&#123;var:-word&#125;</code></td>
<td>如果 $var 的变量值为空或未赋值，则返回 word 字符串，防止变量为空值或因未定义而导致异常</td>
</tr>
<tr>
<td><code>$&#123;var:=word&#125;</code></td>
<td>如果 <code>$var</code> 的变量值为空或未赋值，则设置这个变量值为 word，并返回其值。位置变量和特殊变量不适用。基本同上一个，但该变量又额外给 <code>$var</code> 变量赋值了</td>
</tr>
<tr>
<td><code>$&#123;var:?word&#125;</code></td>
<td>如果 <code>$var</code> 变量值为空或未赋值，那么 word 字符串将被作为标准错误输出，否则输出变量的值。用于捕捉由于变量未定义而导致的错误，并退出程序</td>
</tr>
<tr>
<td><code>$&#123;var:+word&#125;</code></td>
<td>如果 <code>$var</code> 变量值为空或未赋值，则什么都不做，否则返回 word 字符串的值，也就是整个表达式的值为 word</td>
</tr>
</tbody></table>
<br>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Since user2 isn&#x27;t defined, return the string 002</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$user1</span> <span class="variable">$&#123;user2:-002&#125;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Print user1&#x27;s value, and assign 002 to user2</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$user1</span> <span class="variable">$&#123;user2:=002&#125;</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="Special-Vars"><a href="#Special-Vars" class="headerlink" title="Special Vars"></a>Special Vars</h3><p><strong>Positional</strong>:</p>
<p><code>$n</code>: </p>
<ul>
<li><code>$0</code>: Current script’s name</li>
<li><code>$1</code>: 1st parameter</li>
<li><code>$&#123;10&#125;</code>: 10th parameter (Use <code>&#123; &#125;</code> when n ≥ 10)</li>
</ul>
<br>

<p><strong>Other</strong>:</p>
<table>
<thead>
<tr>
<th>Var.</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><code>$0</code></td>
<td>Current filename</td>
</tr>
<tr>
<td><code>$#</code></td>
<td># of parameters passed to scripts / functions</td>
</tr>
<tr>
<td><code>$_</code></td>
<td>Last parameter</td>
</tr>
<tr>
<td><code>$*</code></td>
<td>All parameters</td>
</tr>
<tr>
<td><code>$?    </code></td>
<td>Get returned value</td>
</tr>
<tr>
<td><code>$$    </code></td>
<td>Current shell’s PID</td>
</tr>
<tr>
<td><code>$!</code></td>
<td>Last background process’ PID</td>
</tr>
</tbody></table>
<br>



<br>

]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Scripting</tag>
      </tags>
  </entry>
  <entry>
    <title>Ueli Steck, R.I.P.</title>
    <url>/Notes/Ueli-Steck/</url>
    <content><![CDATA[<p>Rest in peace, Ueli Steck.</p>
<br>


<span id="more"></span> 


]]></content>
      <categories>
        <category>随记</category>
      </categories>
  </entry>
  <entry>
    <title>Introduction to Vim</title>
    <url>/2017/Vim/</url>
    <content><![CDATA[<p>In today’s post, we will review some basic operations in Vim. </p>
<span id="more"></span> 

<br>

<hr>
<h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p>Moving Around: <strong>h, j, k, l</strong></p>
<ul>
<li>To start: <code>gg</code></li>
<li>To end: <code>G</code></li>
<li>To start of line: <code>0</code></li>
<li>To end of line: <code>$</code></li>
<li>To previous location: <code>Ctrl + o</code></li>
</ul>
<br>

<p><strong>Number + Char:</strong></p>
<ul>
<li><code>5j</code>: Down 5 lines</li>
<li><code>6dd</code>: Delete 6 lines</li>
<li><code>7G</code>: Jump to line 7</li>
</ul>
<br>

<p>Other:</p>
<ul>
<li><p>Quit: <code>Shift + zz</code></p>
</li>
<li><p><strong>Repeat Same Command</strong>:  <code>.</code></p>
</li>
<li><p>Change cases (upper / lower): <code>-</code></p>
</li>
<li><p><strong>Quick switch with the line below</strong>: <code>ddp</code></p>
</li>
<li><p><strong>Tab</strong>: <code>&gt;&gt;</code>, and back: <code>&lt;&lt;</code></p>
</li>
</ul>
<br>

<hr>
<h2 id="Common-Options"><a href="#Common-Options" class="headerlink" title="Common Options"></a>Common Options</h2><br>


<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><ul>
<li><p><code>x</code>: Del the char</p>
</li>
<li><p><code>dw</code> &amp;  <code>de</code>: Del words</p>
</li>
<li><p><code>dgg</code>: Del till start of file</p>
</li>
<li><p><code>D</code>: Del till end of line</p>
</li>
</ul>
<br>

<h3 id="Undo"><a href="#Undo" class="headerlink" title="Undo"></a>Undo</h3><ul>
<li><p><code>u</code>: Undo</p>
</li>
<li><p><code>Ctrl + r</code>: Undo undo</p>
</li>
</ul>
<br>

<h3 id="Cut-Copy-amp-Paste"><a href="#Cut-Copy-amp-Paste" class="headerlink" title="Cut, Copy &amp; Paste"></a>Cut, Copy &amp; Paste</h3><p><strong>Cut:</strong></p>
<ul>
<li><code>dd</code>: Cut</li>
</ul>
<br>

<p><strong>Copy:</strong></p>
<ul>
<li><code>y</code>: Copy</li>
<li><code>yy</code>: Whole line</li>
<li>Other usage are the same with <strong>Delete</strong>.</li>
</ul>
<br>

<p><strong>Paste:</strong></p>
<ul>
<li><p><code>p</code>: After the cursor</p>
</li>
<li><p><code>P</code>: Before the cursor</p>
</li>
</ul>
<br>

<h3 id="Quick-Search"><a href="#Quick-Search" class="headerlink" title="Quick Search"></a>Quick Search</h3><ul>
<li><p><code>/&lt;STRING&gt;</code> &amp; <code>?&lt;STRING&gt;</code></p>
</li>
<li><p><code>n</code>: Next result</p>
</li>
<li><p><code>N</code>: Previous one</p>
  <br></li>
</ul>
<h3 id="Find-amp-Replace"><a href="#Find-amp-Replace" class="headerlink" title="Find &amp; Replace"></a>Find &amp; Replace</h3><p>Format: <strong><code>: &#123;range&#125; s/ &#123;target&#125; / &#123;replace&#125; / &#123;sign&#125;</code></strong></p>
<br>

<p><strong><code>:%s/hello/world/g</code></strong></p>
<ul>
<li><code>%</code>: Range is entire file (Without <code>%</code>: Only current line)</li>
<li><code>hello</code>: Found string</li>
<li><code>world</code>: Replace to this word</li>
<li><code>g</code>: Only replace first match of each line</li>
<li>Other choices of <code>&#123;sign&#125;</code>: Ignore the cases (<code>i</code>), Confirm at each replacement (<code>gc</code>)</li>
</ul>
<br>

<p><strong><code>:5,12s/hello/world</code></strong>: Between line 5 - 12</p>
<br>

<p><strong><code>:.,+2s/hello/world</code></strong>: </p>
<ul>
<li><code>.</code>: Current line</li>
<li><code>+2</code>: 2 lines after</li>
</ul>
<br>

<p><strong><code>:&#39;&lt;,&#39;&gt;s/hello/world</code></strong>: In <strong>Visual mode</strong>, <code>:&#39;&lt;,&#39;&gt;</code> is auto-complete in the selected area</p>
<br>

<hr>
<h2 id="Additional-Options"><a href="#Additional-Options" class="headerlink" title="Additional Options"></a>Additional Options</h2><br>

<h3 id="Edit-Multiple-Files"><a href="#Edit-Multiple-Files" class="headerlink" title="Edit Multiple Files"></a>Edit Multiple Files</h3><p><strong>Two Files</strong>: <code>vim file1 file2</code></p>
<ul>
<li><p><code>:n</code>: Switch to file 2 (changes unsaved)</p>
</li>
<li><p><code>:N</code>: Switch to file 1 (changes unsaved)</p>
</li>
</ul>
<br>

<p><strong>Multiple Files:</strong></p>
<ul>
<li><p>Open a 3rd file: <code>:e file3</code></p>
</li>
<li><p><code>:e! file4</code>: Abandon file3 (unsaved), open a new file</p>
</li>
<li><p>Back to previous: <code>:e#</code></p>
</li>
<li><p>List the files: <code>:ls</code></p>
</li>
<li><p>Go to file 1: <code>b file1</code></p>
</li>
<li><p>Change filename: <code>:f &lt;NEW NAME&gt;</code></p>
</li>
</ul>
<br>

<h3 id="Open-Multiple-Windows"><a href="#Open-Multiple-Windows" class="headerlink" title="Open Multiple Windows"></a>Open Multiple Windows</h3><ul>
<li><p>Open a new window: <code>:new</code> or <code>Ctrl + w</code></p>
</li>
<li><p>New horizontal window: <code>:sp file1</code></p>
</li>
<li><p>New vertical window: <code>:vsp file2</code></p>
</li>
<li><p>Move among windows: <code>Ctrl + w  h / j / k / l</code></p>
</li>
<li><p>Move windows around: <code>Ctrl + w  H / J / K / L</code></p>
</li>
<li><p>Reduce / Increase window’s height: <code>Ctrl + w  - / +</code></p>
</li>
</ul>
<br>

<h3 id="Command-Line-Mode"><a href="#Command-Line-Mode" class="headerlink" title="Command-Line Mode"></a>Command-Line Mode</h3><blockquote>
<p>Check vim’s settings (<code>:scriptname</code>). Create <code>.vimrc</code> under home directory.</p>
</blockquote>
<br>

<ul>
<li><p><code>:set nu</code>: Line numbers</p>
</li>
<li><p><code>:set tabstop=4</code>: Set to 4 (Default is 8)</p>
</li>
<li><p><code>:set autoindent</code>: Indent automatically</p>
</li>
<li><p><code>:ce</code>: <strong>Center the line</strong></p>
</li>
<li><p><code>:set readonly</code>: Read-only</p>
</li>
<li><p><code>:set encoding=utf-8</code>: UFT-8 coding</p>
</li>
<li><p><code>:set backup</code>: Backup file</p>
</li>
<li><p><code>:ver</code>: Show version</p>
</li>
</ul>
<br>

<h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h3><ul>
<li><p><strong>Visual mode</strong>: <code>v</code>, highlighting texts</p>
</li>
<li><p><strong>Select mode</strong>: <code>gvim</code></p>
<ul>
<li>Start: <code>:set selectmode+=mouse</code></li>
</ul>
</li>
<li><p>Replace mode: <code>R</code></p>
</li>
<li><p><strong>Encrypt file</strong>: <code>vim -x &lt;FILE&gt;</code></p>
</li>
<li><p>Help: <code>F1</code></p>
</li>
</ul>
<br>

<br>


]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Steganography with Python</title>
    <url>/2017/Python-LSB/</url>
    <content><![CDATA[<p><strong>LSB-Steganography</strong> is a technique in which we hide messages inside an image by replacing <strong>Least Significant Bit (LSB)</strong> of an image with the bits of messages to be hidden.  </p>
<img data-src="/images/posts/170411-1.png" style="zoom: 40%;" />

<span id="more"></span> 

<p>The Least Significant Bit (LSB) is the lowest bit of a binary number. For example, in the binary number <strong>10010010</strong>, “0”is the least significant bit (as shown in the image above).</p>
<p><img data-src="/images/posts/170411-2.png" alt="LSB"></p>
<p>By modifying only the first most right bit of an image, we can insert our secret message almost unnoticeably, but if our message is too large, we will need to start modifying the second rightmost bit and so on. </p>
<br>

<h2 id="Implementation-in-Python"><a href="#Implementation-in-Python" class="headerlink" title="Implementation in Python"></a>Implementation in Python</h2><p>We only need one module —— the <strong>PIL</strong> module. We first use the <code>constLenBin()</code> function to transform the strings of characters to binaries, making sure that the length is always 8. Then we use the <code>encodeDataInImage()</code> function to encode the binaries into images. </p>
<p>The <code>decodeImage()</code> is to return the hidden texts after the image is being decoded, and the <code>binaryToString()</code> function converts the binaries to strings of characters. If the code in the function <code>binaryToString()</code> seems confusing, please read about <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8 and code points here</a>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内置函数bin()的替代，返回固定长度的二进制字符串</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">constLenBin</span>(<span class="params"><span class="built_in">int</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 去掉bin()返回的二进制字符串中的&#x27;0b&#x27;，并在左边补足&#x27;0&#x27;直到字符串长度为8</span></span><br><span class="line">    binary = <span class="string">&quot;0&quot;</span>*(<span class="number">8</span>-(<span class="built_in">len</span>(<span class="built_in">bin</span>(<span class="built_in">int</span>))-<span class="number">2</span>))+<span class="built_in">bin</span>(<span class="built_in">int</span>).replace(<span class="string">&#x27;0b&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> binary</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字符串编码到图片中    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encodeDataInImage</span>(<span class="params">image, data</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得最低有效位为 0 的图片副本</span></span><br><span class="line">    evenImage = makeImageEven(image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将需要被隐藏的字符串转换成二进制字符串</span></span><br><span class="line">    binary = <span class="string">&#x27;&#x27;</span>.join(<span class="built_in">map</span>(constLenBin, <span class="built_in">bytearray</span>(data, <span class="string">&#x27;utf-8&#x27;</span>)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(binary) &gt; <span class="built_in">len</span>(image.getdata()) * <span class="number">4</span>:</span><br><span class="line">        <span class="comment"># 如果不可能编码全部数据，跑出异常</span></span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">&quot;Error: Can&#x27;t encode more than&quot;</span> + <span class="built_in">len</span>(evenImage.getdata()) * <span class="number">4</span> + <span class="string">&quot; bits in this image. &quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 将binary中的二进制字符串信息编码进像素里</span></span><br><span class="line">    encodedPixels = [(r+<span class="built_in">int</span>(binary[index*<span class="number">4</span>+<span class="number">0</span>]), g+<span class="built_in">int</span>(binary[index*<span class="number">4</span>+<span class="number">1</span>]), </span><br><span class="line">                      b+<span class="built_in">int</span>(binary[index*<span class="number">4</span>+<span class="number">2</span>]), t+<span class="built_in">int</span>(binary[index*<span class="number">4</span>+<span class="number">3</span>])) </span><br><span class="line">                     <span class="keyword">if</span> index*<span class="number">4</span> &lt; <span class="built_in">len</span>(binary) <span class="keyword">else</span> (r,g,b,t) </span><br><span class="line">                     <span class="keyword">for</span> index,(r,g,b,t) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">list</span>(evenImage.getdata()))]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建新图片以存放编码后的像素</span></span><br><span class="line">    encodedImage = Image.new(evenImage.mode, evenImage.size)</span><br><span class="line">    <span class="comment"># 添加编码后的数据</span></span><br><span class="line">    encodedImage.putdata(encodedPixels)</span><br><span class="line">    <span class="keyword">return</span> encodedImage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取得一个 PIL 图像并且更改所有值为偶数（使最低有效位为0）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeImageEven</span>(<span class="params">image</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 得到一个这样的列表：[(r,g,b,t),(r,g,b,t)...]</span></span><br><span class="line">    pixels = <span class="built_in">list</span>(image.getdata())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更改值为偶数（魔法般的移位）</span></span><br><span class="line">    evenPixels = [(r&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>,g&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>,b&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>,t&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>) <span class="keyword">for</span> [r,g,b,t] <span class="keyword">in</span> pixels]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建一个相同大小的图片副本</span></span><br><span class="line">    evenImage = Image.new(image.mode, image.size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 把上面的像素放入到图片副本</span></span><br><span class="line">    evenImage.putdata(evenPixels)</span><br><span class="line">    <span class="keyword">return</span> evenImage</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 解码隐藏数据    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decodeImage</span>(<span class="params">image</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得像素列表</span></span><br><span class="line">    pixels = <span class="built_in">list</span>(image.getdata()) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 提取图片中所有最低有效位中的数据</span></span><br><span class="line">    binary = <span class="string">&#x27;&#x27;</span>.join([<span class="built_in">str</span>(<span class="built_in">int</span>(r&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>!=r))+<span class="built_in">str</span>(<span class="built_in">int</span>(g&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>!=g))</span><br><span class="line">                      +<span class="built_in">str</span>(<span class="built_in">int</span>(b&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>!=b))+<span class="built_in">str</span>(<span class="built_in">int</span>(t&gt;&gt;<span class="number">1</span>&lt;&lt;<span class="number">1</span>!=t)) <span class="keyword">for</span> (r,g,b,t) <span class="keyword">in</span> pixels])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到数据截止处的索引</span></span><br><span class="line">    locationDoubleNull = binary.find(<span class="string">&#x27;0000000000000000&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    endIndex = locationDoubleNull+(<span class="number">8</span>-(locationDoubleNull %<span class="number">8</span>)) </span><br><span class="line">    	<span class="keyword">if</span> locationDoubleNull%<span class="number">8</span> != <span class="number">0</span> <span class="keyword">else</span> locationDoubleNull</span><br><span class="line">    </span><br><span class="line">    data = binaryToString(binary[<span class="number">0</span>:endIndex])</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从二进制字符串转为 UTF-8 字符串</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binaryToString</span>(<span class="params">binary</span>):</span></span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    string = []</span><br><span class="line">    rec = <span class="keyword">lambda</span> x, i: x[<span class="number">2</span>:<span class="number">8</span>] + (rec(x[<span class="number">8</span>:], i-<span class="number">1</span>) <span class="keyword">if</span> i &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span>) <span class="keyword">if</span> x <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    fun = <span class="keyword">lambda</span> x, i: x[i+<span class="number">1</span>:<span class="number">8</span>] + rec(x[<span class="number">8</span>:], i-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> index + <span class="number">1</span> &lt; <span class="built_in">len</span>(binary):</span><br><span class="line">        </span><br><span class="line">         <span class="comment"># 存放字符所占字节数，一个字节的字符会存为0</span></span><br><span class="line">        chartype = binary[index:].index(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">        length = chartype*<span class="number">8</span> <span class="keyword">if</span> chartype <span class="keyword">else</span> <span class="number">8</span></span><br><span class="line">        string.append(<span class="built_in">chr</span>(<span class="built_in">int</span>(fun(binary[index:index+length],chartype),<span class="number">2</span>)))</span><br><span class="line">        index += length</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(string)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    encodeDataInImage(Image.<span class="built_in">open</span>(<span class="string">&quot;coffee.png&quot;</span>), <span class="string">&#x27;Hello World!&#x27;</span>).save(<span class="string">&#x27;stega.png&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(decodeImage(Image.<span class="built_in">open</span>(<span class="string">&quot;stega.png&quot;</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br>

<p>The output will be a line of words – in our case, <code>Hello World!</code> – hidden in the new image <code>stega.png</code>.</p>
<br>





]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Convert an Image to ASCIIs in Python</title>
    <url>/2017/Python-Ascii/</url>
    <content><![CDATA[<p>Today we’re going to convert images to ASCII texts. We’ve all seen pictures like this before:</p>
<p><img data-src="/images/posts/170323-0.jpeg" alt="Example"></p>
<p>The transformed ASCII texts can be viewed as a collection of a bunch of characters, and each character represents a pixelated color. </p>
<span id="more"></span> 

<br>

<h2 id="Black-and-White-Output"><a href="#Black-and-White-Output" class="headerlink" title="Black-and-White Output"></a>Black-and-White Output</h2><p>Let us first try to convert images to black-and-white texts. We use a simple grayscale formula for conversion:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gray ＝ <span class="number">0.2126</span> * r + <span class="number">0.7152</span> * g + <span class="number">0.0722</span> * b</span><br></pre></td></tr></table></figure>
<br>

<p>We are also going to use two Python modules: <strong>PIL</strong> (Python Image Library) and <strong>argparse</strong>. The code is shown below:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">r = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line">r.add_argument(<span class="string">&#x27;file&#x27;</span>)</span><br><span class="line">r.add_argument(<span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;--output&#x27;</span>)</span><br><span class="line">r.add_argument(<span class="string">&#x27;--width&#x27;</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, default = <span class="number">100</span>)</span><br><span class="line">r.add_argument(<span class="string">&#x27;--height&#x27;</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, default = <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">a = r.parse_args()</span><br><span class="line"></span><br><span class="line">IMG = a.file</span><br><span class="line">W = a.width</span><br><span class="line">H = a.height</span><br><span class="line">OUTPUT = a.output</span><br><span class="line"></span><br><span class="line"><span class="built_in">ascii</span> = <span class="built_in">list</span>(<span class="string">&quot;$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1&#123;&#125;[]?-_+~&lt;&gt;i!lI;:,\&quot;^`&#x27;. &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span>(<span class="params">r, g, b, al = <span class="number">256</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> al == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span></span><br><span class="line">    gray = <span class="built_in">int</span>(<span class="number">0.2126</span> * r + <span class="number">0.7152</span> * g + <span class="number">0.0722</span> * b)</span><br><span class="line">    unit = (<span class="number">256.0</span> + <span class="number">1</span>) / <span class="built_in">len</span>(<span class="built_in">ascii</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">ascii</span>[<span class="built_in">int</span>(gray / unit)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    m = Image.<span class="built_in">open</span>(IMG)</span><br><span class="line">    m = m.resize((W, H), Image.NEAREST)</span><br><span class="line">    c = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(H):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(W):</span><br><span class="line">            p = m.getpixel((j, i))  <span class="comment"># p[0], p[1], p[2], p[3]</span></span><br><span class="line">            c += <span class="built_in">map</span>(*p)</span><br><span class="line">        c += <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(c)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> OUTPUT:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(OUTPUT, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(c)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;ascii.txt&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(c)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>We use the image below to test our code:</p>
<p><img data-src="/images/posts/170323-1.png" alt="Test"></p>
<p>And below is the screenshot of the output <code>ascii.txt</code>:</p>
<p><img data-src="/images/posts/170323-2.png" alt="Output1"></p>
<p>We noticed that the proportion of the output isn’t quite right. Moreover, it would better if the output is colored, but not just black-and-white. So let us make some improvements.</p>
<br>

<h2 id="Colored-Output"><a href="#Colored-Output" class="headerlink" title="Colored Output"></a>Colored Output</h2><p>In the previous case, the output format is in <strong>.txt</strong> form, and we get a black-and-white output. Now if we want to get a colored output, then the format cannot be .txt anymore, since plain text files do not display colored texts. To achieve this, we need the submodule <strong>ImageDraw</strong> from the <strong>PIL</strong> library.</p>
<p>As to the proportion of the output, we’re going to set the width and height of the output, and also adjust the font to get the optimum result. Hence one more submodule from <strong>PIL</strong> is needed: <strong>ImageFont</strong>.</p>
<p>Enough for the explanation. The code is shown below:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageFont, ImageDraw</span><br><span class="line"></span><br><span class="line">r = argparse.ArgumentParser()</span><br><span class="line">r.add_argument(<span class="string">&#x27;file&#x27;</span>)</span><br><span class="line">r.add_argument(<span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;--output&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ag = r.parse_args()</span><br><span class="line">Pic = ag.file</span><br><span class="line">OUTPUT = ag.output</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> = <span class="built_in">list</span>(<span class="string">&quot;$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1&#123;&#125;[]?-_+~&lt;&gt;i!lI;:,\&quot;^`&#x27;. &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span>(<span class="params">r, g, b, a = <span class="number">256</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> a == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span></span><br><span class="line">    gray = <span class="built_in">int</span>(<span class="number">0.2126</span> * r + <span class="number">0.7152</span> * g + <span class="number">0.0722</span> * b)</span><br><span class="line">    unit = (<span class="number">256.0</span> + <span class="number">1</span>) / <span class="built_in">len</span>(<span class="built_in">set</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>[<span class="built_in">int</span>(gray / unit)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    m = Image.<span class="built_in">open</span>(Pic)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Don&#x27;t forget to set the W &amp; H</span></span><br><span class="line">    W = <span class="built_in">int</span>(m.width / <span class="number">6</span>)</span><br><span class="line">    H = <span class="built_in">int</span>(m.height / <span class="number">15</span>)</span><br><span class="line">    m_txt = Image.new(<span class="string">&#x27;RGB&#x27;</span>, (m.width, m.height), (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br><span class="line">    m = m.resize((W, H))</span><br><span class="line">    t = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    color = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(H):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(W):</span><br><span class="line">            p = m.getpixel((j, i))</span><br><span class="line">            color.append((p[<span class="number">0</span>], p[<span class="number">1</span>], p[<span class="number">2</span>]))</span><br><span class="line">            t += <span class="built_in">map</span>(*p)</span><br><span class="line">        t += <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">        color.append((<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adjust the fonts</span></span><br><span class="line">    draw = ImageDraw.Draw(m_txt)</span><br><span class="line">    font = ImageFont.load_default().font</span><br><span class="line">    x = y = <span class="number">0</span></span><br><span class="line">    fw, fh = font.getsize(t[<span class="number">1</span>])</span><br><span class="line">    fh *= <span class="number">1.37</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Coloring the ASCIIs</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(t)):</span><br><span class="line">        <span class="keyword">if</span> t[i] == <span class="string">&#x27;\n&#x27;</span>:</span><br><span class="line">            x = x + fh</span><br><span class="line">            y = -fw    <span class="comment"># Note: -fw</span></span><br><span class="line">        draw.text([y, x], t[i], color[i])</span><br><span class="line">        y = y + fw</span><br><span class="line">    m_txt.save(<span class="string">&#x27;color.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<br>

<p>Using the same picture, and this time we got the output like this:</p>
<p><img data-src="/images/posts/170323-3.png" alt="Output2"></p>
<br>




]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Socket Cheatsheet</title>
    <url>/2017/Sockets/</url>
    <content><![CDATA[<p>When we need to use sockets (or netcat <code>nc</code>) to connect to a server, here are some snippets, in 4 different languages.</p>
<span id="more"></span> 

<br>

<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">from</span> telnetlib <span class="keyword">import</span> Telnet</span><br><span class="line"></span><br><span class="line">s = socket.socket()</span><br><span class="line">s.connect((<span class="string">&#x27;YOUR IP&#x27;</span>, PORT))</span><br><span class="line">s.send(<span class="string">&#x27;Hello world!\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;&gt; &quot;</span> + s.recv(<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#interactive mode</span></span><br><span class="line">t = new Telnet()</span><br><span class="line">t.s = s</span><br><span class="line">t.interact()</span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure>



<br>

<h2 id="Python-Pwntools"><a href="#Python-Pwntools" class="headerlink" title="Python Pwntools"></a><a href="https://github.com/Gallopsled/pwntools">Python Pwntools</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">r = remote(<span class="string">&#x27;YOUR IP&#x27;</span>, PORT)</span><br><span class="line">r.send(<span class="string">&quot;Hello world!\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;&gt; &quot;</span> + r.recv()</span><br><span class="line"><span class="built_in">print</span> r.recvuntil(<span class="string">&quot;END\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#interactive mode</span></span><br><span class="line">r.interactive()</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h2><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">&#x27;socket&#x27;</span></span><br><span class="line"></span><br><span class="line">a = TCPSocket.new(<span class="string">&#x27;YOUR IP&#x27;</span>, PORT)</span><br><span class="line">a.write <span class="string">&quot;Hello world!&quot;</span></span><br><span class="line">puts <span class="string">&quot;&gt; &quot;</span> + a.recv(<span class="number">1024</span>)</span><br><span class="line">a.close</span><br></pre></td></tr></table></figure>

<br>

<h2 id="NodeJS"><a href="#NodeJS" class="headerlink" title="NodeJS"></a>NodeJS</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> net = <span class="built_in">require</span>(<span class="string">&#x27;net&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> client = <span class="keyword">new</span> net.Socket();</span><br><span class="line">client.connect(<span class="number">3333</span>, <span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    client.write(<span class="string">&#x27;Hello world!&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">client.on(<span class="string">&#x27;data&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;&gt; &#x27;</span> + data);</span><br><span class="line">    client.destroy();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">client.on(<span class="string">&#x27;close&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>





<br>

]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>Scripting</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Shell Commands - 04 Pipes</title>
    <url>/2017/Linux-Shell-4/</url>
    <content><![CDATA[<p>This post is <strong>Part Four</strong> of the summary of some common Linux Shell Commands. </p>
<span id="more"></span> 



<br>

<h2 id="Pipes"><a href="#Pipes" class="headerlink" title="Pipes"></a>Pipes</h2><blockquote>
<p><strong>Pipes connect the output and input.</strong> </p>
</blockquote>
<br>



<h3 id="Three-I-O-Stream"><a href="#Three-I-O-Stream" class="headerlink" title="Three I/O Stream"></a>Three I/O Stream</h3><p><strong>stdin</strong>: Input stream. <strong>File descriptor (FD)</strong> is <strong>0</strong>. </p>
<ul>
<li>FD is an index.</li>
<li>Kernel uses FD to visit files.</li>
<li>FD are non-negative integers. Kernel returns a FD when open / create a new file. Read / write files also need FD.</li>
</ul>
<p><strong>stout</strong>: FD is <strong>1</strong></p>
<p><strong>stderr</strong>: FD is <strong>2</strong></p>
<br>

<h3 id="Redirection"><a href="#Redirection" class="headerlink" title="Redirection"></a>Redirection</h3><p><strong>Re. Input</strong>: <code>[n] &lt; file</code></p>
<br>

<p><strong>Re. Output</strong>: <code>[n] &gt; file</code></p>
<ul>
<li>Note: This creates new file if file doesn’t exist, overwrites original content if file exists.</li>
<li>e.g. <code>cat file1 | cat &gt; file2</code>: Stdin is file1’s content, redirected to file2.</li>
</ul>
<br>

<p><strong>Re. Error</strong>: <code>&lt;command 1&gt; |&amp; &lt;command 2&gt;</code></p>
<ul>
<li><p>e.g. <code>ls file1 |&amp; cat &gt; file2</code></p>
</li>
<li><p>e.g. <code>cat file 2 &gt; err.log 1 &gt; info.log</code>: Stderr (2), stdout (1), save output and error in 2 separate files.</p>
</li>
</ul>
<br>

<p><strong><code>tee</code></strong>: Read stdin, and write to stdout &amp; files.</p>
<ul>
<li><p><code>tee -a</code>: append, not overwrite</p>
</li>
<li><p><code>tee file1 file2</code>: Write file1 to file2</p>
</li>
<li><p><code>ls | tee file1</code>: Write result to file1</p>
</li>
<li><p><strong>Quit tee</strong>: <code>Ctrl + d</code></p>
</li>
</ul>
<br>

<h3 id="Text-Processing"><a href="#Text-Processing" class="headerlink" title="Text Processing"></a>Text Processing</h3><p><strong>Sort</strong></p>
<ul>
<li><p><code>sort -u</code>: Get rid of repated lines</p>
</li>
<li><p><code>sort -t</code>: Split chars. e.g. Whitespace</p>
</li>
<li><p><code>sort -o</code>: Output to file</p>
</li>
<li><p><code>sort -k</code>: Sort according to one column</p>
</li>
<li><p><code>sort -r</code>: Sort, <strong>desceding</strong> (Default is ascending)</p>
</li>
<li><p>e.g. <code>sort -k 3 -o res.txt file1</code>: Use file1’s data, sort according to 3rd column, output write to res.txt.</p>
</li>
</ul>
<br>

<p><strong>Combine</strong></p>
<ul>
<li><p><code>paste file1 file2</code>: Combine as one file</p>
</li>
<li><p><code>join file1 file2</code>: Find intersection (set)</p>
</li>
</ul>
<br>

<p><strong>Transform</strong></p>
<ul>
<li><p>Format: <code>tr [option] set1 set2</code></p>
</li>
<li><p>e.g. <code>echo &quot;hello world&quot; | tr a-z A-Z</code>: Transform to upper cases.</p>
</li>
</ul>
<br>

<p><strong><code>xargs</code></strong></p>
<ul>
<li><p>Pass parameters, and read data from stdin.</p>
</li>
<li><p>e.g. <code>tail -5 \etc\hosts | xargs</code>: Whitespace replaces <code>\n</code>.</p>
</li>
<li><p><code>xargs -a</code>: Read from file, not from stdin</p>
</li>
<li><p><code>xargs -d</code>: Self-defined <strong>delimiters</strong></p>
</li>
<li><p><code>xargs -n</code>: Max number of parameters per line</p>
</li>
</ul>
<br>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;f1xf2xf3&quot;</span> | xargs -n 2 -d x</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Delimiter is <code>x</code></p>
</li>
<li><p>2 parameters per line</p>
</li>
<li><p>Result: </p>
<pre><code>  f1 f2
  f3
</code></pre>
</li>
</ul>
<br>
    
            
            
            
            
            
    












]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Shell Commands - 03 Search &amp; Pack Files</title>
    <url>/2017/Linux-Shell-3/</url>
    <content><![CDATA[<p>This post is <strong>Part Three</strong> of the summary of some common Linux Shell Commands. The commands we are going to use today are: <code>find</code>, <code>locate</code>, <code>gzip</code>, <code>tar</code>. </p>
<span id="more"></span> 


 <br>

<hr>
<h2 id="Searching-Files-find"><a href="#Searching-Files-find" class="headerlink" title="Searching Files: find"></a>Searching Files: <code>find</code></h2> <br>

<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p><strong><code>find &lt;PATH&gt; &lt;Expression&gt;</code></strong></p>
<p>Here <code>&lt;Expression&gt;</code> contains 4 types:</p>
<ul>
<li>options</li>
<li>tests (T / F)</li>
<li>actions</li>
<li>operators</li>
</ul>
 <br>

<p>e.g.  <code>find /etc -size +100k</code></p>
<p>Find files that size &gt; 100k, under the directory <code>/etc</code>. Note that:</p>
<ul>
<li><p><code>+n</code>: ≥ n</p>
</li>
<li><p><code>n</code>: = n </p>
</li>
<li><p><code>-n</code>: ≤ n</p>
</li>
</ul>
<br>

<h3 id="Wildcard-Chars"><a href="#Wildcard-Chars" class="headerlink" title="Wildcard Chars"></a>Wildcard Chars</h3><p><strong>Four Common Types</strong></p>
<ul>
<li><p><code>*</code>: Match 0, or multiple chars</p>
</li>
<li><p><code>?</code>: Match any <strong>one</strong> char</p>
</li>
<li><p><code>[STRING]</code>: Match any char in the string. </p>
<ul>
<li>e.g. <code>[a-z0-9]</code> matches lowercase letters and digits</li>
<li>Note that <code>[! STRING]</code>means match any other chars <strong>except ones after <code>!</code></strong></li>
</ul>
</li>
<li><p><code>\</code>: escape </p>
</li>
</ul>
<br>

<p><strong>Using Wildcard with <code>find</code>:</strong></p>
<ul>
<li><p><code>-iname</code>: ignore cases</p>
</li>
<li><p><code>find /usr -name &quot;te*sh&quot;</code>: find all files types under <code>/usr</code>, starting with <strong>te</strong>, ending with <strong>sh</strong>.</p>
</li>
<li><p><code> -path</code> &amp; <code>-wholename</code>: find paths</p>
</li>
<li><p><code>find /usr -wholename /usr/bin</code>: find <strong>bin</strong> under <code>/usr</code> directory. Note that the 2 directories, path prefix <strong>must be the same, and must be whole paths</strong>.</p>
</li>
<li><p><code>-regex</code> &amp; <code>-iregex</code></p>
</li>
</ul>
<br>

<h3 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h3><p><strong>Symbolic Links (Soft Links):</strong></p>
<ul>
<li><p>  <code>-lname</code> &amp; <code>-ilname</code>: <strong>Test</strong>. Check if a file is a symbolic link. </p>
</li>
<li><p><code>find /usr/bin -lname &quot;*python3*&quot; </code>: find soft links that contain <strong>python3</strong> in the filenames.</p>
</li>
</ul>
<br>

<p><strong>Hard Links:</strong></p>
<ul>
<li><p><code>find /usr -samefile file1</code>: Use <code>-samefile</code> to find all hard links of file1. </p>
</li>
<li><p><code>find /usr -inum &lt;inode&gt;</code>: Each inode has a unique number, but hard links have the <strong>same inode</strong>.</p>
</li>
<li><p><code> find /usr -links 3</code>: find files that have 3 hard links.</p>
</li>
</ul>
<br>

<h3 id="Time"><a href="#Time" class="headerlink" title="Time"></a>Time</h3><p>Each file has three timestamps: </p>
<ul>
<li><strong>Access (<code>-atime n</code>, <code>-amin n</code>)</strong></li>
<li><strong>Change (<code>-ctime n</code>, <code>-cmin n</code>)</strong> : Change file status</li>
<li><strong>Modify (<code>-mtime n</code>, <code>-mmin n</code>)</strong> : Edit file content</li>
</ul>
 <br>

<p>e.g. Modify time between <strong>5 mins</strong> and <strong>24 hours</strong> before.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">find</span> <span class="string">/usr</span> <span class="string">-mtime</span> <span class="number">0</span> <span class="string">-mmin</span> <span class="string">+5</span></span><br></pre></td></tr></table></figure>



<br>

<h3 id="Size"><a href="#Size" class="headerlink" title="Size"></a>Size</h3><p><code>-size n[bckwMG]</code>: <strong>n</strong> is the number (+, -)</p>
<ul>
<li><p><code>b</code>: Block</p>
</li>
<li><p><code>c</code>: Char</p>
</li>
<li><p><code>k</code>: KB</p>
</li>
<li><p><code>w</code>: Number of 2-byte chars</p>
</li>
<li><p><code>M</code>: MB</p>
</li>
<li><p><code>G</code>: GB</p>
</li>
</ul>
<br>

<h3 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h3><p><code>-type [dfl]</code>:</p>
<ul>
<li><p><code>d</code>: Dir.</p>
</li>
<li><p><code>f</code>: File</p>
</li>
<li><p><code>l</code>: Links</p>
</li>
</ul>
 <br>

<p>e.g. Normal file, size &gt; 30k.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo find /etc -<span class="built_in">type</span> f size +30k</span><br></pre></td></tr></table></figure>



<br>

<h3 id="Owner"><a href="#Owner" class="headerlink" title="Owner"></a>Owner</h3><ul>
<li><code>-user &lt;NAME&gt;</code></li>
<li><code>-group &lt;GROUP&gt;</code></li>
<li><code>-uid n</code> &amp; <code>-gid n</code></li>
</ul>
 <br>

<p>e.g. <code>find /usr -uid 0</code>: (Root’s UID is 0)</p>
<br>

<h3 id="File-Mode-Bits"><a href="#File-Mode-Bits" class="headerlink" title="File Mode Bits"></a>File Mode Bits</h3><ul>
<li><code>-readable</code> &amp; <code>-writeable</code> &amp; <code>-executable</code></li>
</ul>
 <br>

<p>e.g. Check the files under <code>/etc</code> that can be executed by current user, ending with <strong>a</strong>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /etc -executable -name <span class="string">&quot;*a&quot;</span></span><br></pre></td></tr></table></figure>





<br>

<h3 id="Exec"><a href="#Exec" class="headerlink" title="-Exec"></a>-Exec</h3><p><strong>Must have <code>&#123;&#125;</code> and <code>\;</code>.</strong></p>
<br>

<p>List detailed info of the files</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /usr -<span class="built_in">type</span> f -<span class="built_in">exec</span> ls -l &#123;&#125; \;</span><br></pre></td></tr></table></figure>

<br>

<p>Delete all files that are modified <strong>more than 14 days ago</strong>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /usr -<span class="built_in">type</span> f -mtime +14 -<span class="built_in">exec</span> rm &#123;&#125; \;</span><br></pre></td></tr></table></figure>



<br>

<p>Delete <code>.log</code> files, and press <code>y</code> to confirm, before each deletion.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /usr -name <span class="string">&quot;*.log&quot;</span> -ok rm &#123;&#125; \;</span><br></pre></td></tr></table></figure>

<br>

<p>Find files <strong>start with passwd</strong>, and contains the word <strong>root</strong>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /etc -name <span class="string">&quot;passwd*&quot;</span> -<span class="built_in">exec</span> grep <span class="string">&quot;root&quot;</span> &#123;&#125; \;</span><br></pre></td></tr></table></figure>



<br>

<h3 id="More-Examples"><a href="#More-Examples" class="headerlink" title="More Examples"></a>More Examples</h3><p>Find all files (size &gt; 12k) under <code>/etc</code>, copy to <code>/home/backup</code>, <strong>with original directories</strong> (<code>-rp --parents</code>):</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo find /etc -<span class="built_in">type</span> f -size +12k -<span class="built_in">exec</span> cp -rp --parents &#123;&#125; /home/backup \;</span><br></pre></td></tr></table></figure>

<br>

<hr>
<h2 id="Searching-Files-locate"><a href="#Searching-Files-locate" class="headerlink" title="Searching Files: locate"></a>Searching Files: <code>locate</code></h2><p><code>locate</code> is to find results in a database that contains all files and directories in the system. The database isn’t updated in real time. To update, use:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">updatedb</span></span><br></pre></td></tr></table></figure>



 <br>

<p><strong>Usage:</strong> </p>
<ul>
<li><p><code>locate /usr/bin/python</code></p>
</li>
<li><p><code>locate --basename hello</code>: filename (not dir. name) contains <strong>hello</strong></p>
</li>
</ul>
<br>

<hr>
<h2 id="Packing-Files-gzip-and-tar"><a href="#Packing-Files-gzip-and-tar" class="headerlink" title="Packing Files: gzip and tar"></a>Packing Files: <code>gzip</code> and <code>tar</code></h2><p>Usually we need to first <strong>pack</strong> the files using <code>tar</code>, then <strong>zip</strong> the .tar files. Because many compressors in Linux can only compress <strong>one</strong> file each time, so it’s better to compress a packed file.</p>
<h3 id="gzip-gz"><a href="#gzip-gz" class="headerlink" title="gzip:  .gz"></a><code>gzip</code>:  .gz</h3><p>To zip a file: <code>gzip &lt;FILE&gt;</code></p>
<p>To unzip a file: <code>gunzip &lt;FILE&gt;</code></p>
<br>

<h3 id="tar-tar"><a href="#tar-tar" class="headerlink" title="tar:  .tar"></a><code>tar</code>:  .tar</h3><p><strong>Usage: <code>tar &lt;OPTION&gt; &lt;FILE&gt;</code></strong></p>
<ul>
<li><p><code>-z</code> &amp; <code>--gzip</code>: Use gzip to compress</p>
</li>
<li><p><code>-c</code>: Create</p>
</li>
<li><p><code>-v</code>: detailed process</p>
</li>
<li><p><code>-f</code>: filename</p>
</li>
<li><p><code>-x</code>: unpack</p>
</li>
<li><p><code>-r</code>: Append to end of file</p>
</li>
</ul>
<br>

<ul>
<li><p>e.g. <strong>Pack &amp; zip:</strong> </p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">tar</span> <span class="string">-zcvf</span> <span class="string">/etc/hello.tar.gz</span> <span class="string">/home/hello1</span> <span class="string">/home/hello2</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>e.g. <strong>Unpack &amp; unzip:</strong> </p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">/etc/hello.tar.gz</span> <span class="string">/home</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>


]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Shell Commands - 02 Env Vars &amp; Users</title>
    <url>/2017/Linux-Shell-2/</url>
    <content><![CDATA[<p>This post is <strong>Part Two</strong> of the summary of some common Linux Shell Commands.</p>
<span id="more"></span> 

 <br>
 
<hr>
<h2 id="Environment-Variables"><a href="#Environment-Variables" class="headerlink" title="Environment Variables"></a>Environment Variables</h2><blockquote>
<p>   The <strong>Path var</strong> determines where shell finds those commands, or processes. </p>
</blockquote>
<p>The vars point to directories, and processes find related files based on the assigned directories.</p>
<br>


<h3 id="System-Vars"><a href="#System-Vars" class="headerlink" title="System Vars"></a>System Vars</h3><p>Two paths:</p>
<ul>
<li><p><code>/etc/profile</code>: First to execute when log into shell</p>
</li>
<li><p> <code>/etc/environment</code>: System environment var. assignment</p>
</li>
</ul>
<p>e.g.   两种写法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo sh -c <span class="string">&#x27;echo &quot;export &lt;VAR&gt;=&lt;path&gt;&quot; &gt;&gt; /etc/profile&#x27;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> &lt;VAR&gt;=<span class="string">&#x27;&lt;path 1&gt;:&lt;path 2&gt;...&#x27;</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="User-Vars"><a href="#User-Vars" class="headerlink" title="User Vars"></a>User Vars</h3><p>Two paths:</p>
<ul>
<li><p><code>~/.profile</code>: Execute once each time the user logs in</p>
</li>
<li><p><code>~/.bashrc</code>: Every time when a new shell window is opened</p>
</li>
</ul>
<p>e.g. 两种写法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo sh -c <span class="string">&#x27;echo &quot;export &lt;VAR&gt;=&lt;path&gt;&quot; &gt;&gt; .bashrc&#x27;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> &lt;VAR&gt;=<span class="string">&#x27;&lt;path 1&gt;:&lt;path 2&gt;...&#x27;</span></span><br></pre></td></tr></table></figure>

<br>

<h3 id="Permanent-amp-Temporary-Vars"><a href="#Permanent-amp-Temporary-Vars" class="headerlink" title="Permanent &amp; Temporary Vars"></a>Permanent &amp; Temporary Vars</h3><ul>
<li><p><strong>Permanent:</strong> Add vars in system files</p>
</li>
<li><p><strong>Temp:</strong> Use <code>export</code> in bash</p>
</li>
</ul>
<p>e.g.  </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Set new var</span></span><br><span class="line"><span class="built_in">export</span> NAME=<span class="string">&#x27;hello&#x27;</span>		</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change existing var</span></span><br><span class="line">NAME=<span class="string">&#x27;world&#x27;</span>			</span><br></pre></td></tr></table></figure>


<br>

<h3 id="Related-Commands"><a href="#Related-Commands" class="headerlink" title="Related Commands"></a>Related Commands</h3><ul>
<li><p><code>env</code>: Check all environmental vars</p>
</li>
<li><p><code>set</code>: Check all vars in the current shell</p>
</li>
<li><p><code>unset &lt;VAR&gt;</code>: delete vars</p>
</li>
<li><p><code>vimdiff</code>: Compare differences</p>
</li>
<li><p>e.g. <code>./bashrc</code>: Make changes effective immediately</p>
</li>
</ul>
<br>

<h3 id="Common-Vars"><a href="#Common-Vars" class="headerlink" title="Common Vars"></a>Common Vars</h3><ul>
<li><p><code>PATH</code></p>
</li>
<li><p><code>HOME</code>: User’s main directory</p>
</li>
<li><p><code>HISTSIZE</code>: Number of stored commands </p>
</li>
<li><p><code>LOGNAME</code>: Current username</p>
</li>
<li><p><code>HOSTNAME</code></p>
</li>
<li><p><code>SHELL</code></p>
</li>
<li><p><code>PS1</code>: Prompt String 1. <code>#</code> for root, <code>$</code> for normal users</p>
</li>
</ul>
 <br>

<hr>
<h2 id="Users-amp-Usergroups"><a href="#Users-amp-Usergroups" class="headerlink" title="Users &amp; Usergroups"></a>Users &amp; Usergroups</h2><br>


<h3 id="Userinfo-amp-UID"><a href="#Userinfo-amp-UID" class="headerlink" title="Userinfo &amp; UID"></a>Userinfo &amp; UID</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">cat</span> <span class="string">/etc/passwd</span></span><br></pre></td></tr></table></figure>



<p>e.g. <strong>root</strong> : <strong>x</strong> : <strong>0</strong> : <strong>0</strong> : <strong>root</strong> : <strong>/root</strong> : <strong>/bin/bash</strong></p>
<p><strong>7</strong> parts in total. </p>
<p>Username : Password : User ID (UID) : Group ID (GID) : Comments : Main dir. : Shell </p>
<br>

<h3 id="Password-Info"><a href="#Password-Info" class="headerlink" title="Password Info"></a>Password Info</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">cat</span> <span class="string">/etc/shadow</span></span><br></pre></td></tr></table></figure>



<p><strong>root</strong> : <strong>*</strong> : <strong>17590</strong> : <strong>0</strong> : <strong>99999</strong> : <strong>7</strong> : : :</p>
<p><strong>9</strong> parts in total. </p>
<p>Username : Password : Last change : Min : Max : Warn : Inactive time : Expire time : (Reserved)</p>
<ul>
<li><p><strong>Last change</strong>: Last password change</p>
</li>
<li><p><strong>Min / Max</strong>: Minimum / Maximum days for the password to be effective</p>
</li>
<li><p><strong>Warn</strong>: Warnings before password expires</p>
</li>
</ul>
<br>

<h3 id="Usergroup-Info"><a href="#Usergroup-Info" class="headerlink" title="Usergroup Info:"></a>Usergroup Info:</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">cat</span> <span class="string">/etc/group</span></span><br></pre></td></tr></table></figure>



<p><strong>root</strong> : <strong>x</strong> : <strong>0</strong> : </p>
<p><strong>4</strong> parts in total.</p>
<p>Group name : Password: GID : List of users (1, 2, …)</p>
<br>

<h3 id="Manage-Users-amp-Usergroups"><a href="#Manage-Users-amp-Usergroups" class="headerlink" title="Manage Users &amp; Usergroups:"></a>Manage Users &amp; Usergroups:</h3><p><strong>Create Users:</strong> </p>
<ul>
<li><p><strong>Methods:</strong> <code> adduser &lt;NAME&gt;</code> or <code>sudo useradd</code></p>
</li>
<li><p>Set home directory: <code>useradd -d /home/&lt;USER&gt; &lt;NAME&gt;</code></p>
</li>
<li><p>Set usergroup: <code>useradd -g &lt;GROUP&gt; &lt;NAME&gt;</code></p>
</li>
<li><p>Set login shell: <code>useradd -s /bin/bash &lt;NAME&gt;</code></p>
</li>
<li><p><strong>Modify existing user info:</strong> <code>usermod</code> (same options with <code>useradd</code>)</p>
</li>
</ul>
<br>

<p><code>sudo passwd</code>:</p>
<ul>
<li><p>Modify password: <code>passwd &lt;NAME&gt;</code></p>
</li>
<li><p>Delete password: <code>passwd -d &lt;NAME&gt;</code></p>
</li>
<li><p>Block user from logging in: <code>passwd -l &lt;NAME&gt;</code></p>
</li>
<li><p>Unlock: <code>passwd -u &lt;NAME&gt;</code></p>
</li>
<li><p>Password status: <code>passwd -S &lt;NAME&gt;</code></p>
</li>
</ul>
<br>

<p><strong>Check Status:</strong></p>
<ul>
<li><p><code>sudo tail -5 /etc/passwd</code>: System file</p>
</li>
<li><p><code>id &lt;NAME&gt;</code>: User info</p>
</li>
<li><p><code>w</code>: Current user</p>
</li>
<li><p><code>lastlog</code>: login info</p>
</li>
<li><p>Switch user: <code>su &lt;NAME&gt;</code></p>
</li>
<li><p>Check user’s all groups: <code>groups &lt;NAME&gt;</code></p>
</li>
</ul>
<br>

<p><strong>Usergroup:</strong></p>
<ul>
<li><p>Add user to multiple groups: <code>usermod -aG &lt;Group1, Group2, ...&gt; &lt;NAME&gt;</code> (a: append)</p>
</li>
<li><p>Add new GID: e.g. <code>groupadd -g 1024 &lt;GROUP&gt;</code></p>
</li>
<li><p>Modify group name: <code>groupdmod -n &lt;NEW&gt; &lt;OLD&gt;</code></p>
</li>
</ul>
<p>​     </p>
<br>


]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Shell Commands - 01 Basic</title>
    <url>/2017/Linux-Shell-1/</url>
    <content><![CDATA[<p>This post is <strong>Part One</strong> of the summary of some common Linux Shell Commands. So let’s begin.</p>
<span id="more"></span> 



 <br>

<h2 id="Seeking-Help"><a href="#Seeking-Help" class="headerlink" title="Seeking Help"></a>Seeking Help</h2><p>It’s important to know where to seek help when we’re not familiar with certain commands, or just have doubts. </p>
<ul>
<li><p><code>whatis</code>: Quick explanation</p>
</li>
<li><p><code>man</code>: <strong><a href="https://man.cx/">Manuals</a>, in 8 sections</strong></p>
</li>
<li><p><code>info</code>: Provides more description than manual does</p>
</li>
<li><p><code>whereis</code> &amp; <code>which</code>: find paths</p>
</li>
</ul>
 <br>

<h2 id="Check-Status"><a href="#Check-Status" class="headerlink" title="Check Status"></a>Check Status</h2><p>Commands to check CPU info, processes status:</p>
<ul>
<li><p><code>top</code>: <strong>Task manager</strong></p>
</li>
<li><p><code>lscpu</code>: Check CPU info</p>
</li>
<li><p><code>ps</code>: Process status</p>
</li>
<li><p><code>ps aux</code>:  List all processes and their status and resource usage</p>
</li>
<li><p><code>tail -f</code>: Monitoring log files, etc. in <strong>real time</strong></p>
</li>
<li><p><code>stat</code>: Check file status</p>
</li>
<li><p><code>df -h</code>: Check disk space</p>
</li>
</ul>
<br>

<h2 id="Shortcuts"><a href="#Shortcuts" class="headerlink" title="Shortcuts"></a>Shortcuts</h2><p>Important shortcuts to make things easier.</p>
<ul>
<li><p><code>tab</code>: Auto-complete the commands (especially with <code>ls</code>)</p>
</li>
<li><p><code>*</code> &amp; <code>?</code>: fuzzy search</p>
</li>
<li><p><code>Ctrl + a</code> and <code>Ctrl + e</code></p>
</li>
<li><p><code>alias</code>: Create command shortcuts. <code>alias -p</code> shows all.</p>
<ul>
<li>e.g. <code>alias ll=&quot;ls -alh&quot; </code></li>
<li>Remove: <code>unalias ll</code></li>
</ul>
</li>
</ul>
<br>

<h2 id="Listings-amp-Paths"><a href="#Listings-amp-Paths" class="headerlink" title="Listings &amp; Paths"></a>Listings &amp; Paths</h2><p>Including commands regarding file paths, info, permissions, and more.</p>
<ul>
<li><p><code>ls -dlh</code>: Current directory’s info, human-readable</p>
</li>
<li><p><code>ls -alh</code>: All files in detail, human-readable</p>
</li>
<li><p><code>ls -asSh | sort</code>: File size, sorted</p>
</li>
<li><p><code>pwd</code>: print absolute paths.</p>
</li>
<li><p><code>mkdir -p</code>: Create multiple directories. </p>
</li>
<li><p>e.g. Note the use of <code>&#123; &#125;</code></p>
  <figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">-p</span> <span class="string">test/&#123;lib/,bin/,doc/&#123;info,product&#125;&#125;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<br>

<h2 id="Permissions"><a href="#Permissions" class="headerlink" title="Permissions"></a>Permissions</h2><ul>
<li><p><code>sudo usermod -G sudo &lt;USER&gt;</code>: Get sudo privileges.</p>
</li>
<li><p><code>sudo chown &lt;changed USER:changed GROUP&gt; &lt;FILE&gt;</code>: Change owner &amp; group</p>
</li>
<li><p><code>chgrp</code>: change group</p>
</li>
<li><p><code>umask</code></p>
</li>
<li><p><strong>read (4), write (2), execute (1)</strong></p>
<ul>
<li><img data-src="/images/posts/170110-1.png" style="zoom: 50%;" />

  

<table>
<thead>
<tr>
<th>Octal</th>
<th>Permission</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>—</td>
</tr>
<tr>
<td>1</td>
<td>–x</td>
</tr>
<tr>
<td>2</td>
<td>-w-</td>
</tr>
<tr>
<td>3</td>
<td>-wx</td>
</tr>
<tr>
<td>4</td>
<td>r–</td>
</tr>
<tr>
<td>5</td>
<td>r-x</td>
</tr>
<tr>
<td>6</td>
<td>rw-</td>
</tr>
<tr>
<td>7</td>
<td>rwx</td>
</tr>
</tbody></table>
</li>
<li><p><code>chmod 600</code> &amp; <code>chmod go-rw</code>: Only owner can read &amp; write</p>
</li>
<li><p><code>chmod 755</code> &amp; <code>chmod +x</code>: Permission to execute</p>
</li>
<li><p><code>chmod 777</code>: All Privileges</p>
</li>
</ul>
</li>
</ul>
<br>


]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>QuickSort with Python - 4 Ways of Implementation</title>
    <url>/2016/Python-Quicksort/</url>
    <content><![CDATA[<p>QuickSort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot. There are many versions of QuickSort that pick pivot(s) in different ways. Here I’m going to show <strong>4 ways</strong> of implementing QuickSort in Python.</p>
<span id="more"></span>

<br>

<h2 id="Version-1"><a href="#Version-1" class="headerlink" title="Version 1"></a>Version 1</h2><p>Version 1 is the most common way to implement QuickSort. Here we pick the <strong>first element</strong> as the pivot.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">qs1</span>(<span class="params">t, lo, hi</span>):</span></span><br><span class="line">    <span class="keyword">if</span> lo &gt;= hi:</span><br><span class="line">        <span class="keyword">return</span> t</span><br><span class="line">    p = t[lo]		<span class="comment"># Pivot is the 1st element</span></span><br><span class="line"></span><br><span class="line">    i = lo</span><br><span class="line">    j = hi</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> i != j:</span><br><span class="line">        <span class="comment"># 此间顺序不可颠倒</span></span><br><span class="line">        <span class="keyword">while</span> t[j] &gt;= p <span class="keyword">and</span> i &lt; j:  </span><br><span class="line">            j = j - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> t[i] &lt;= p <span class="keyword">and</span> i &lt; j:  </span><br><span class="line">            i = i + <span class="number">1</span></span><br><span class="line">        t[i], t[j] = t[j], t[i]</span><br><span class="line">    t[lo], t[i] = t[i], t[lo]</span><br><span class="line"> </span><br><span class="line">    qs1(t, lo, i-<span class="number">1</span>)</span><br><span class="line">    qs1(t, i+<span class="number">1</span>, hi)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Version-2"><a href="#Version-2" class="headerlink" title="Version 2"></a>Version 2</h2><p>Version 2 is from MIT’s <strong>Introduction to Algorithms</strong> (CLRS).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">qs2</span>(<span class="params">array, l, r</span>):</span></span><br><span class="line">    <span class="keyword">if</span> l &lt; r:</span><br><span class="line">        q = partition(array, l, r)</span><br><span class="line">        qs2(array, l, q - <span class="number">1</span>)</span><br><span class="line">        qs2(array, q + <span class="number">1</span>, r)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">array, l, r</span>):</span></span><br><span class="line">    x = array[r]</span><br><span class="line">    i = l - <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(l, r):</span><br><span class="line">        <span class="keyword">if</span> array[j] &lt;= x:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            array[i], array[j] = array[j], array[i]</span><br><span class="line">    array[i + <span class="number">1</span>], array[r] = array[r], array[i+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> i + <span class="number">1</span></span><br></pre></td></tr></table></figure>

<br>

<h2 id="Version-3"><a href="#Version-3" class="headerlink" title="Version 3"></a>Version 3</h2><p>Version 3 is a simplified way of implementing QuickSort. The pivot is the <strong>last element</strong> of the list.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">qs3</span>(<span class="params">t</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(t) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> t</span><br><span class="line">    l = []</span><br><span class="line">    r = []</span><br><span class="line">    p = t.pop()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> t:</span><br><span class="line">        <span class="keyword">if</span> c &lt; p:</span><br><span class="line">            l.append(c)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r.append(c)</span><br><span class="line">    <span class="keyword">return</span> qs3(l) + [p] + qs3(r)</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Version-4"><a href="#Version-4" class="headerlink" title="Version 4"></a>Version 4</h2><p>Version 4 is the improved quicksort (from Prof. Siegel’s textbook). Note that less comparisons are made.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">qs4</span>(<span class="params">t, lo, hi</span>):</span></span><br><span class="line">    <span class="keyword">if</span> lo &gt;= hi:</span><br><span class="line">        <span class="keyword">return</span> t</span><br><span class="line">    <span class="keyword">if</span> t[lo] &lt; t[hi]:</span><br><span class="line">        t[lo], t[hi] = t[hi], t[lo]</span><br><span class="line">    p = t[hi]</span><br><span class="line">    i = lo</span><br><span class="line">    j = hi</span><br><span class="line">    <span class="keyword">while</span> i &lt; j:</span><br><span class="line">        t[i], t[j] = t[j], t[i]</span><br><span class="line">        i = i + <span class="number">1</span>       </span><br><span class="line">        <span class="keyword">while</span> t[i] &lt; p:</span><br><span class="line">            i = i + <span class="number">1</span></span><br><span class="line">        j = j - <span class="number">1</span>     </span><br><span class="line">        <span class="keyword">while</span> t[j] &gt; p:</span><br><span class="line">            j = j - <span class="number">1</span></span><br><span class="line">    t[lo], t[j] = t[j], t[lo]</span><br><span class="line">    qs4(t, lo, j-<span class="number">1</span>)</span><br><span class="line">    qs4(t, j+<span class="number">1</span>, hi)</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h2><p>Among all the three, Version 3 is the fastest when the data isn’t very large (less than 1 million). It also comes with a cost of space, since multiple lists are created. However, <strong>when the data is larger than 1 million, Version 4 becomes the fastest.</strong> To time the performance, we could use Python’s built-in module <code>time</code>. For instance, to time Version 3’s performance:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeit</span>():</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    qs3(t)	</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Version 3: &#x27;</span>, end - start)</span><br></pre></td></tr></table></figure>

<p>To generate random numbers for testing, we use Python’s <code>random</code> module. For example,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 Million Numbers</span></span><br><span class="line">t = [random.randint(<span class="number">1</span>, <span class="number">2000000000</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>)]</span><br></pre></td></tr></table></figure>

<br>
]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>用Python预测小猫钓鱼的纸牌游戏</title>
    <url>/2016/Card-Game/</url>
    <content><![CDATA[<p><strong>规则</strong>： 将一副扑克牌平均分成两份，每人拿一份。小K先拿出手上的第一张扑克牌放在桌子上，然后小Q也拿出手上的第一张扑克牌，放在小K刚打出的牌上面，就这样两人交替出牌。出牌时，如果某人打出的牌与桌上的牌的牌面相同，即可将两张相同的牌及其中间所加的牌全部取走，并依次放到自己手中牌的末尾，当任意一人手中的牌全部出完时，游戏结束，对手获胜。</p>
<span id="more"></span> 

<br>

<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>我们用<strong>stack</strong>记录桌上的牌，用两个<strong>queue</strong>记录小K和小Q手中的牌（小K为<code>t1</code>，小Q为<code>t2</code>）。实现如下，详细见注释。</p>
<br>

<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">game</span>(<span class="params">t1, t2</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># stack, 桌上的牌</span></span><br><span class="line">    s = []	</span><br><span class="line">    <span class="comment"># 记录桌上的牌，一共13种花色</span></span><br><span class="line">    book = [<span class="number">0</span>] * (<span class="number">13</span>+<span class="number">1</span>)		</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 两种情况：赢牌，没赢牌</span></span><br><span class="line">    <span class="comment"># 小K：t1， 小Q：t2.  t1先出牌</span></span><br><span class="line">    <span class="keyword">while</span> t1 <span class="keyword">and</span> t2:</span><br><span class="line">        <span class="comment"># 加判断：防止游戏无法结束</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(t1) &lt;= <span class="number">52</span> <span class="keyword">and</span> <span class="built_in">len</span>(t2) &lt;= <span class="number">52</span>:</span><br><span class="line">            a = t1[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> book[a] == <span class="number">0</span>:</span><br><span class="line">                s.append(a)</span><br><span class="line">                book[a] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">del</span> t1[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                t1.append(a)</span><br><span class="line">                <span class="keyword">while</span> s[-<span class="number">1</span>] != a:</span><br><span class="line">                    book[s[-<span class="number">1</span>]] = <span class="number">0</span></span><br><span class="line">                    t1.append(s[-<span class="number">1</span>])</span><br><span class="line">                    <span class="keyword">del</span> s[-<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">del</span> t1[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            b = t2[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> book[b] == <span class="number">0</span>:</span><br><span class="line">                s.append(b)</span><br><span class="line">                book[b] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">del</span> t2[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                t2.append(b)</span><br><span class="line">                <span class="keyword">while</span> s[-<span class="number">1</span>] != b:</span><br><span class="line">                    book[s[-<span class="number">1</span>]] = <span class="number">0</span> </span><br><span class="line">                    t2.append(s[-<span class="number">1</span>])</span><br><span class="line">                    <span class="keyword">del</span> s[-<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">del</span> t2[<span class="number">0</span>]</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 一副牌最多52张，超过52，跳出循环 </span></span><br><span class="line">        <span class="keyword">else</span>: <span class="keyword">break</span>   </span><br><span class="line">                </span><br><span class="line">    <span class="keyword">if</span> t2 == []:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;t1, 小K赢&#x27;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;当前牌为： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(t1).strip(<span class="string">&#x27;[]&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> t1 == []:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;t2, 小Q赢&#x27;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;当前牌为： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(t2).strip(<span class="string">&#x27;[]&#x27;</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;平局&#x27;</span></span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;桌上牌为： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(s).strip(<span class="string">&#x27;[]&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">game([<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure>

<br>

]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>中文</tag>
      </tags>
  </entry>
  <entry>
    <title>Crontab in Linux</title>
    <url>/2016/Crontab/</url>
    <content><![CDATA[<p>Many tasks in Linux are running day and night, regardless when people are asleep or not. So in order to run some processes automatically and periodically, we need to resort to Linux’s <strong>Crontab</strong>.</p>
<span id="more"></span> 

<br>

<p>The crontab (cron derives from chronos, Greek for time; tab stands for table) command is used to schedule commands to be executed periodically. To see what crontabs are currently running on the system, we can open a terminal and run:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">crontab</span> <span class="string">-l</span></span><br></pre></td></tr></table></figure>

<p>To edit the list of jobs, we can run:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">crontab</span> <span class="string">-e</span></span><br></pre></td></tr></table></figure>

<p>If you want to add time to it, then use the command in this format:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">/command</span></span><br></pre></td></tr></table></figure>

<p>A brief explanation of the <code>*</code> here (from left to right):</p>
<table>
<thead>
<tr>
<th></th>
<th>Explanation</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1st *</td>
<td>Minutes</td>
<td>0 - 59</td>
</tr>
<tr>
<td>2nd *</td>
<td>Hours</td>
<td>1 - 23</td>
</tr>
<tr>
<td>3rd *</td>
<td>Date</td>
<td>1 - 31</td>
</tr>
<tr>
<td>4th *</td>
<td>Month</td>
<td>1 - 12</td>
</tr>
<tr>
<td>5th *</td>
<td>Days</td>
<td>0 - 6 (Sunday is 0)</td>
</tr>
</tbody></table>
<br>

<h2 id="More-Commands"><a href="#More-Commands" class="headerlink" title="More Commands"></a>More Commands</h2><p>To <strong>start the service manually</strong> (normally it’ll be on automatically):</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">cron</span> <span class="string">-f</span> <span class="string">&amp;</span></span><br></pre></td></tr></table></figure>

<p>Here, <code>&amp;</code> means to run processes in the background.</p>
<p>To <strong>start the log</strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">service</span> <span class="string">rsyslog</span> <span class="string">start</span></span><br></pre></td></tr></table></figure>

<p>To <strong>add new tasks</strong> (Below is an example):</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">*/1</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">*</span> <span class="string">touch</span> <span class="string">/home/folder/$(date</span> <span class="string">+\%Y-\%m-\%d)</span></span><br></pre></td></tr></table></figure>

<p><code>*/1</code> means to execute the task <strong>every 1 minute</strong>,<br>The commands after the <code>$</code> sign indicates the filename’s format. The line means to create a new file under that specific path every 1 minute.</p>
<p>Note that in Crontab, the escape character <code>\</code> must be added before <code>%</code>, otherwise the default will be to switch to the next line.</p>
<p>To <strong>check Crontab’s status in the background</strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">ps</span> <span class="string">aux</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">cron</span></span><br></pre></td></tr></table></figure>

<p>To <strong>check feedbacks</strong>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/var/log/syslog</span></span><br></pre></td></tr></table></figure>

<p>Here, <code>tail -f</code> means to get <strong>real-time feedbacks</strong>. This is particularly useful.</p>
<br>

]]></content>
      <categories>
        <category>Linux Notes</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
